{'_id': ObjectId('66b26b74b80f3f3035517f60'), 'file_id': ObjectId('641a8b1aa053a968d797f8a6'), 'file_name': '1679376655-6389d2cbb352ac0640395521__1679461142-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/1679376655-6389d2cbb352ac0640395521__1679461142-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '01:00:55', 'transcription_path': 'video-results/out_66b26b74b80f3f3035517f60.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 8, 583000), 'file_process_date': datetime.datetime(2024, 9, 25, 17, 33, 8, 672000), 'execution_time': 521.725659, 'status': 'COMPLETED', 'green_line': [{'topic': 'Session Introduction', 'start_time': '00:00:29', 'end_time': '00:00:42', 'transcript': 'first of all, a very good afternoon, everyone. So today we have a session by Renko. Mom. So she is the square lead here.', 'keywords': ['Session', 'Introduction', 'Speaker'], 'summary': 'The session begins with a warm greeting to the audience, introducing Renko Mom as the speaker and square lead for the session. The introduction sets a positive tone for the upcoming discussion.'}, {'topic': 'Network Issues & Session Overview', 'start_time': '00:00:43', 'end_time': '00:00:59', 'transcript': 'and my audible. Yes, us. Um Okay, so I think I am facing some network issues in my area. So I was just informing the Singh. Okay, So we will be having the topic for today as told procedures and triggers, which is a part of s cumin.', 'keywords': ['Network Issues', 'Procedures', 'Triggers'], 'summary': 'The speaker addresses some network issues they are experiencing while informing the audience about the topic for the day, which is focused on procedures and triggers, a component of S-CIM. They acknowledge the connectivity problems and mention their intent to proceed with the session.'}, {'topic': 'Topics Overview', 'start_time': '00:00:59', 'end_time': '00:01:16', 'transcript': "And the list of topics that ma'am shall be covering would be stored procedure and functions and eh, skewed. Then SQL triggers in different type, soft Rikers difference between store procedure and triggers some hands on with stored procedures and triggers. So Emmerich Mamady is though that", 'keywords': ['Stored Procedures', 'SQL Triggers', 'Functions'], 'summary': 'The transcript outlines the topics that will be covered in the session, including stored procedures, functions, SQL triggers, and the differences between stored procedures and triggers. It also mentions hands-on practice with these concepts, indicating a practical approach to learning.'}, {'topic': 'SQL Training Demand', 'start_time': '00:01:16', 'end_time': '00:01:46', 'transcript': 'was actually registered on the screen also can see my screen. Good afternoon, everyone. just about to start the session and wanted to share, you know, had been lost of request on SQL training from various Q people Anglo helpers. So, of course, as skilled as a big topic in its at Serra Silicon cover everything in here', 'keywords': ['SQL', 'Training', 'Demand'], 'summary': 'The session begins with the speaker addressing the audience, indicating that they are ready to start discussing SQL training. They mention receiving numerous requests for SQL training from various individuals and emphasize the importance of SQL as a significant topic that will be covered in the session.'}, {'topic': 'Previous SQL Training', 'start_time': '00:01:47', 'end_time': '00:02:16', 'transcript': "earlier, I have taken some basic and advanced skill training with joins and some indexers. And if you want to see similar, please share the recording if you happen to see that in chat window, so that people can refer if they won't have. questions on group by how we aggregate in sq Wales. Very basic, a scale or advance and Dex is and performance that I have already given last year.", 'keywords': ['SQL', 'Joins', 'Indexers'], 'summary': 'The speaker reflects on their previous training in SQL, mentioning both basic and advanced skills related to joins and indexers. They suggest sharing a recording of this training for reference, especially for those with questions about the GROUP BY clause and data aggregation in SQL. The speaker also notes that they have previously covered topics related to performance and indexing last year.'}, {'topic': 'Stored Procedures Basics', 'start_time': '00:02:17', 'end_time': '00:02:45', 'transcript': 'So if if anyone is interested in knowing that they can seem a video. So this particular topic I had taken as a 01 part of Israel which is stored for season and triggers why I have taken that this a more a kind of programming we need in this area. So normally, an SQL is just a statement wise. You run individually some statements when you', 'keywords': ['Stored Procedures', 'Triggers', 'SQL'], 'summary': 'The transcript introduces the topic of stored procedures and triggers in SQL programming. The speaker suggests that those interested can view additional videos for more information. They emphasize the importance of understanding stored procedures as a more structured programming approach compared to running SQL statements individually.'}, {'topic': 'SQL Use Cases', 'start_time': '00:02:45', 'end_time': '00:03:06', 'transcript': 'use SQL, but there are ways in ask you a which allow view to do according as well and for Luke if flow of these kind of things have there. So this is very much useful for our day to day operation where we are doing some repeated works and we want to', 'keywords': ['SQL', 'Use Cases', 'Operations'], 'summary': 'The transcript discusses the practical applications of SQL, highlighting its usefulness in day-to-day operations where repetitive tasks are performed. It suggests that there are different methods to utilize SQL effectively for various purposes.'}, {'topic': 'SQL Knowledge Requirement', 'start_time': '00:03:06', 'end_time': '00:03:21', 'transcript': 'keep that cold ready and avoid Manuel work. So for this, a basic s Q and knowledge, I think person should have it and but it will be useful for Cuba people as well as the developers', 'keywords': ['SQL', 'Manual Work', 'Developers'], 'summary': 'The speaker emphasizes the importance of having a basic knowledge of SQL to streamline processes and reduce manual work. This knowledge is deemed beneficial not only for individuals working in Cuba but also for developers in general.'}, {'topic': 'Function Syntax & Differences', 'start_time': '00:03:22', 'end_time': '00:03:49', 'transcript': "trying to keep it as simple. We will have to see that cheque? The time also. But I would share some codes which can be useful for people. And also this have taken databases as opposed this as Curiel right now. But what? I'm trying this If you if you know what is the store procedure and how to write it. Slights and tax might become different in my SQL or snow. Ask us.", 'keywords': ['Function Syntax', 'Stored Procedures', 'SQL'], 'summary': 'The transcript discusses the function syntax and differences in programming, aiming to simplify the topic for the audience. The speaker mentions sharing useful code snippets and refers to databases, indicating a comparison between stored procedures in different SQL variants like MySQL and Snowflake. The speaker also highlights that syntax may vary depending on the database system used.'}, {'topic': 'Function Logic', 'start_time': '00:03:49', 'end_time': '00:04:06', 'transcript': "But I think if understanding of logic, if you understand the logic that will remain same know your concept should be clear than to use function when to use for Caesar's and triggers rest. Adding Centex likes you can always find on Google", 'keywords': ['Logic', 'Functions', 'Triggers'], 'summary': "The speaker emphasizes the importance of understanding logic in the context of function usage. They mention that a clear grasp of concepts is essential for effectively utilizing functions, particularly in relation to Caesar's functions and triggers. The speaker also notes that resources for further learning, such as Centex, can be easily found on Google."}, {'topic': 'Database Functions', 'start_time': '00:04:06', 'end_time': '00:04:35', 'transcript': "are that particular documentation for that particular databases? So while day mowing, I might use progress SQL. But feel free to apply that concepts and you're on date of is whether you're working in Oracle or Snow, Snow Flake or whatever snowflake training re might do next month specific to snowflake. But this particular is passports, Chris asked", 'keywords': ['Database Functions', 'Progress SQL', 'Snowflake'], 'summary': 'The transcript discusses the usage of specific database functions and documentation related to various database systems such as Progress SQL, Oracle, and Snowflake. The speaker encourages the audience to apply these concepts across different platforms, indicating a forthcoming training session focused on Snowflake.'}, {'topic': 'Common SQL Functions', 'start_time': '00:04:36', 'end_time': '00:04:57', 'transcript': 'So first in all the most commonly used, you know, think in the snow are SQL Programming is user defined functions. Now, this user defying function are itself mistakenly taken as showed procedure. So, um,', 'keywords': ['SQL', 'User-Defined Functions', 'Stored Procedures'], 'summary': 'The discussion focuses on the most commonly used SQL programming functions, particularly user-defined functions. The speaker highlights a common misconception, stating that user-defined functions are often mistakenly regarded as stored procedures.'}, {'topic': 'User Defined Functions', 'start_time': '00:04:58', 'end_time': '00:05:26', 'transcript': "you know, when we are actually talking about sold procedure, most of the users are actually writing a functions on leaf. So because this not much difference between the two, but yes, there is difference which we will understand. So this user defying functions the Charlie Common Court, a complex calculation, whichever you want to do on something and you're organised that one together. So that is going to", 'keywords': ['User-Defined Functions', 'Stored Procedures', 'Complex Calculations'], 'summary': 'The transcript discusses user-defined functions in the context of stored procedures, highlighting that many users tend to write functions on the leaf level. The speaker notes that while there is a similarity between user-defined functions and stored procedures, there are also distinct differences that will be explored. User-defined functions are described as tools for organizing complex calculations and operations.'}, {'topic': 'Built-in Functions', 'start_time': '00:05:26', 'end_time': '00:05:40', 'transcript': 'perform a particular function. Now every database has its on and functions Also, I think whenever you have done maybe infighter anywhere, most of the people might have used this function lower.', 'keywords': ['Built-in Functions', 'Databases', 'Lower Function'], 'summary': "The transcript discusses built-in functions in databases, highlighting their importance and prevalence among users, particularly mentioning the 'lower' function as an example that many might have encountered in various contexts."}, {'topic': 'Case Functions', 'start_time': '00:05:41', 'end_time': '00:05:50', 'transcript': 'l case or lowers some database Has l case as there and some has a lower which which will just what will do', 'keywords': ['Case Functions', 'lcase', 'lower'], 'summary': "The transcript briefly discusses case functions in databases, mentioning the use of 'lcase' and 'lower' functions. It indicates that these functions serve specific purposes related to handling case sensitivity in data processing."}, {'topic': 'Lower Case Function', 'start_time': '00:05:50', 'end_time': '00:06:10', 'transcript': "it will change the from whatever case it is to lower case. So this if you see this select lower ABC, this is this Lower is not a user defined function. It is a function. It's a database function. It's a built in function", 'keywords': ['Lower Case Function', 'Database Function', 'Built-in Function'], 'summary': "The transcript discusses the lower case function, explaining its purpose of converting any string to lower case. The speaker clarifies that 'lower' is not a user-defined function but rather a built-in database function."}, {'topic': 'Interest Calculation Function', 'start_time': '00:06:10', 'end_time': '00:06:37', 'transcript': 'so built in function and ask your are there but you can write your on functions. Also, Suppose I want to have a a mom, you all must have done in Mass. Also, how do I do interest calculation if I have a principal amount with me and I have the time with me and interest rates so on these functions are everything can be part of a function ability, infection, but we can.', 'keywords': ['Interest Calculation', 'Functions', 'Principal Amount'], 'summary': 'The transcript discusses the concept of an interest calculation function, highlighting the possibility of using built-in functions as well as writing custom functions. The speaker refers to mathematical principles and explains how to calculate interest based on a principal amount, time, and interest rates. The emphasis is on the flexibility and utility of functions in performing such calculations.'}, {'topic': 'Function Creation Example', 'start_time': '00:06:37', 'end_time': '00:07:02', 'transcript': "create a function for the particular matter Ology like I I am going to show you. You know how we create a function Suppose I want I want a functionality When two numbers are given, we just multiply that and give the not saying this is not possible in database, but I'm just writing a simple function", 'keywords': ['Function Creation', 'Multiplication', 'Database'], 'summary': "The speaker discusses the creation of a function, specifically in the context of a particular subject matter, referred to as 'Ology'. They illustrate how to create a function that takes two numbers as input and returns their product. While acknowledging that such functionality could be implemented in a database, the speaker emphasizes the simplicity of writing a straightforward function for this purpose."}, {'topic': 'Function Parameters', 'start_time': '00:07:03', 'end_time': '00:07:19', 'transcript': 'how to ride that function. I am going to slip that is one. so Suppose I want to test this far. What is the Centex for function? So once I just about to show you', 'keywords': ['Function Parameters', 'Testing', 'Context'], 'summary': "The speaker introduces the topic of function parameters, discussing the approach to testing a specific function. They mention the importance of understanding the context or 'Centex' for function usage and prepare to demonstrate this concept."}, {'topic': 'Function Declaration', 'start_time': '00:07:27', 'end_time': '00:07:56', 'transcript': "So this is very simple. Centex and Post press with great or replaced function name and then you have a parameter declarations. Whichever pair a mentor you want and then returns in teacher, whatever kind of it it returns, it can return. If you don't want the function to return anything, you can simply write returns world also function can do something and it may not. Return also won value to you", 'keywords': ['Function Declaration', 'Parameter', 'Return Value'], 'summary': "The transcript provides a concise explanation of function declaration in programming. It outlines the simplicity of defining a function by specifying its name followed by parameter declarations. The speaker notes that functions can return various types of values, including nothing at all, which can be indicated by using 'return' without a value. Additionally, the speaker mentions that a function can perform actions without necessarily returning a value."}, {'topic': 'Function Usage', 'start_time': '00:07:56', 'end_time': '00:08:20', 'transcript': 'and there is a declare section where you declare variables and then the block main block is there where you will do some calculation and you return that. show you a happy to this writing one simple function. which takes one in teacher of 42 and teachers and simply multiplying it and returning this world', 'keywords': ['Function', 'Variable Declaration', 'Main Block'], 'summary': 'The transcript discusses the structure of a program, highlighting the declare section for variable declaration and the main block for calculations. It illustrates the concept by describing a simple function that takes an integer input of 42, multiplies it, and returns the result.'}, {'topic': 'Dynamic SQL', 'start_time': '00:08:20', 'end_time': '00:08:32', 'transcript': "very basic math. And if you say now, I just used this function, how do I use it? I can't use it simply in a select statement.", 'keywords': ['Dynamic SQL', 'Select Statement', 'Function Usage'], 'summary': 'The transcript discusses the concept of dynamic SQL, highlighting a basic mathematical function and its usage limitations. The speaker notes that this function cannot be directly used in a select statement, suggesting a need for deeper understanding of dynamic SQL applications.'}, {'topic': 'Function Output', 'start_time': '00:08:34', 'end_time': '00:08:44', 'transcript': 'so far, and I need to pass the parameters. This was the declaration and 98 to pass this. So how will I do? Suppose I want a', 'keywords': ['Function Declaration', 'Parameters', 'Function Output'], 'summary': 'The speaker discusses the process of passing parameters in a function declaration, indicating a transition in the topic towards the practical application of function outputs. They express a need for clarification on how to achieve this, suggesting a focus on understanding the mechanics of function outputs.'}, {'topic': 'Function with Multiple Returns', 'start_time': '00:08:44', 'end_time': '00:09:02', 'transcript': "tradition and just see the answer. It's just so when you are going to use a function, whatever you write, the the insight thing is executed and it becomes like a normal.", 'keywords': ['Function', 'Multiple Returns', 'Programming'], 'summary': 'The transcript discusses the concept of functions that can return multiple values in programming. It highlights the importance of understanding how functions operate and execute, indicating that the written code within a function will be executed and treated as standard operations during its use.'}, {'topic': 'SQL Function Parameters', 'start_time': '00:09:03', 'end_time': '00:09:24', 'transcript': 'table function or something, it can return a table as well. It can return a query as well, then Dire Select statement. It can return it, Can you have? And it may not return also so that there are different kinds of parameters it can have so it can have input output parameters where even the parameters where you can also change', 'keywords': ['SQL', 'Function Parameters', 'Input/Output'], 'summary': 'The transcript discusses SQL function parameters, highlighting their capability to return various types of outputs, including tables and queries. It also mentions the different kinds of parameters that can be utilized, such as input and output parameters, and the flexibility in changing these parameters during operations.'}, {'topic': 'Function in SQL Queries', 'start_time': '00:09:24', 'end_time': '00:09:41', 'transcript': 'if you want, So this is a very simple function. I am will show. You know how we can use it for in a lot of Q ever, which had been your own done in our project also.', 'keywords': ['SQL', 'Function', 'Queries'], 'summary': 'The speaker introduces a simple function in SQL queries, indicating its utility in various queries and mentioning its application in their own project. This sets the stage for demonstrating how the function can be effectively utilized.'}, {'topic': 'Stored Procedures vs Functions', 'start_time': '00:09:42', 'end_time': '00:09:55', 'transcript': 'so. let me just first take you to the store, procedure out how we do it and start Caesar than people compare. And I assure you what kind of things we have done in our project.', 'keywords': ['Stored Procedures', 'Functions', 'Project'], 'summary': 'The speaker begins by discussing stored procedures, outlining the process and comparing them with functions. They reference their experiences from a project to illustrate the differences and applications of stored procedures.'}, {'topic': 'Stored Procedure Basics', 'start_time': '00:10:02', 'end_time': '00:10:31', 'transcript': "so no, I'm mentioned in projects, restore procedure and triggers. But I people are sometimes confused in function and short procedure. So that's why his small slide I included for function. So this is the format, and now we let's jump to the store proces stored for Caesar's a Gain, a set of structured query languages. they are some set of festival statements you want to execute", 'keywords': ['Stored Procedure', 'SQL', 'Function'], 'summary': 'The transcript discusses the basics of stored procedures, addressing common confusion between functions and stored procedures. The speaker refers to a slide that outlines the format of functions before transitioning to the topic of stored procedures in the context of structured query language (SQL). The emphasis is on understanding the execution of a set of SQL statements.'}, {'topic': 'Stored Procedure Usage', 'start_time': '00:10:31', 'end_time': '00:10:40', 'transcript': 'with one compiled unit, of course. Zero. And suppose e When you say inserted, I want to insert into 23 tables, so', 'keywords': ['Stored Procedures', 'Database Management', 'Data Insertion'], 'summary': 'The transcript briefly discusses the usage of stored procedures, highlighting their capability to handle operations involving multiple tables within a single compiled unit. The speaker refers to the action of inserting data into 23 tables, indicating the efficiency and utility of stored procedures in database management.'}, {'topic': 'Stored Procedure Execution', 'start_time': '00:10:42', 'end_time': '00:10:51', 'transcript': 'So rather than having these three Chase mints have separately what you can have its you can combine them all in one, and then', 'keywords': ['Stored Procedure', 'Execution', 'Efficiency'], 'summary': 'The speaker discusses the concept of combining multiple Chase mints into a single stored procedure, rather than executing them separately. This approach emphasizes efficiency and consolidation in stored procedure execution.'}, {'topic': 'Return Values in Stored Procedures', 'start_time': '00:10:52', 'end_time': '00:11:15', 'transcript': 'we just run. Whenever we run this insert day tights, it will in certain. to through three rows or whatever we can have a can. A multiple kind of Esther statement altogether. But important thing about stored procedure is it does not return anything. It is going to execute the statement, but it is not going to.', 'keywords': ['Stored Procedures', 'SQL', 'Insert Operation'], 'summary': 'The transcript discusses the behavior of stored procedures when executing SQL statements, specifically focusing on the insert operation. It is noted that while the stored procedure can process multiple rows, it does not return any values upon execution, highlighting a key characteristic of stored procedures in database operations.'}, {'topic': 'Types of Stored Procedures', 'start_time': '00:11:16', 'end_time': '00:11:36', 'transcript': "I have a return statement in it with some value. It can simply return by ward to close that sort for Caesar. But it's not going to your return exactly venue. But there is a way to return a value in stock per Caesar and", 'keywords': ['Stored Procedures', 'Return Statement', 'Value Return'], 'summary': 'The transcript discusses the concept of return statements within stored procedures, explaining how they can return values. It mentions that while a return statement can be utilized to close a stored procedure, there are specific methods to return values in stored procedures effectively.'}, {'topic': 'SQL Count Example', 'start_time': '00:11:37', 'end_time': '00:11:56', 'transcript': 'we We will see that to a handsome and so there are 23 types of the euro store procedures. So one is a simple I will write one simple start procedure which.', 'keywords': ['SQL', 'Stored Procedures', 'Count'], 'summary': 'The transcript discusses the topic of SQL with a focus on stored procedures. It mentions that there are 23 types of stored procedures and introduces the intention to write a simple stored procedure as an example.'}, {'topic': 'Insert Operation Example', 'start_time': '00:11:59', 'end_time': '00:12:27', 'transcript': 'people count. I think this is very much required in Q. Ever. You need to cheque cross cheque, Kong of tables everywhere in Los of table. You want to see what Khamenei rose are there in this table or how many? count of Nelle values. What is the maximum value? Water is the minimum value. So I created a simple A.', 'keywords': ['Insert Operation', 'Database', 'Value Counting'], 'summary': 'The speaker discusses the importance of performing insert operations in a database context, highlighting the need for cross-checking values across multiple tables. They emphasize the necessity of counting the number of entries, identifying null values, and determining the maximum and minimum values within a table. The speaker mentions creating a simple example to illustrate these operations.'}, {'topic': 'Retrieve Row Count', 'start_time': '00:12:27', 'end_time': '00:12:41', 'transcript': 'This is the first one. They will go to the tougher one procedure so this particular store procedure will insert into a test law. Created a table test law which will insert', 'keywords': ['Stored Procedure', 'Data Insertion', 'Database'], 'summary': "The transcript discusses the initial steps of a procedure involving a stored procedure designed to insert data into a table named 'test law'. It also mentions the progression towards more complex procedures as part of the discussion."}, {'topic': 'Function Usage in SQL', 'start_time': '00:12:43', 'end_time': '00:13:01', 'transcript': "how many rows are in the stable? That's it. And this is a just the table lame it is putting. This is strength hard quarter string right now, which is restoring the count of that. So So if Q way want to run this job, they just", 'keywords': ['SQL', 'Functions', 'Row Count'], 'summary': 'The transcript discusses the use of functions in SQL, particularly focusing on counting the number of rows in a table. The speaker mentions a specific query and emphasizes the importance of understanding how to utilize SQL functions to execute this task effectively.'}, {'topic': 'Function Call in SQL', 'start_time': '00:13:02', 'end_time': '00:13:20', 'transcript': 'can just simply create this procedure with this insert statements, they might have the table name or not I had because I want to show you further. You know how we will improve it now If you cyst select star from s law, how do I call dysfunction?', 'keywords': ['SQL', 'Function Call', 'Insert Statements'], 'summary': 'The transcript discusses the creation of a procedure in SQL, specifically focusing on the use of insert statements and the potential inclusion of a table name. The speaker raises a question regarding how to call a function, particularly in the context of executing a select statement from a specific table, indicating a desire to explore improvements in this process.'}, {'topic': 'Function Return Values', 'start_time': '00:13:20', 'end_time': '00:13:31', 'transcript': 'how will and call it now function. We said Select an hour. But this party puller will be called that he will this call dysfunction call.', 'keywords': ['Function', 'Return Values', 'Parameters'], 'summary': "The discussion focuses on function return values, mentioning how to call a function and the significance of selecting parameters. The speaker highlights that a specific function, referred to as 'this party puller', will be invoked during the session."}, {'topic': 'Stored Procedure Execution', 'start_time': '00:13:33', 'end_time': '00:14:02', 'transcript': "public Apia. So if you and at this one Sorry one said, Why? So this function has executed something. It hasn't returned you anything. Neither just shows. If you has updated any rose, it is not returning you anything. But as we know, we had created a lock using this. So I just show you what is there listed.", 'keywords': ['Stored Procedure', 'Execution', 'Lock'], 'summary': 'The speaker discusses the execution of a stored procedure, noting that it has performed an action without returning any results. They point out that although the procedure does not provide output, it has created a lock during its execution. The speaker emphasizes the importance of understanding what has been executed and the implications of the lack of returned values.'}, {'topic': 'Dynamic Stored Procedures', 'start_time': '00:14:03', 'end_time': '00:14:17', 'transcript': 'So just ignore the first two rows. This was for my test. Rangnick had been doing so Eyes entered one table name fix Hard quarter Deka standing and whatever count it is is printed in it, so', 'keywords': ['Dynamic Stored Procedures', 'Database', 'SQL'], 'summary': 'The transcript briefly mentions a test scenario involving dynamic stored procedures, specifically referencing a table name and the process of counting entries within it. The speaker indicates that the initial part of the transcript can be disregarded, focusing instead on the practical application of dynamic stored procedures.'}, {'topic': 'Dynamic SQL Execution', 'start_time': '00:14:18', 'end_time': '00:14:29', 'transcript': "So now thing is we will expand this through Caesar further. How we expand this one's a hard quarter statement earlier.", 'keywords': ['Dynamic SQL', 'Execution', 'Quarter Statement'], 'summary': 'The discussion focuses on expanding a previous topic related to Dynamic SQL Execution, specifically referencing a complex quarter statement mentioned earlier. The speaker indicates a progression in understanding and application of the concept.'}, {'topic': 'System Tables', 'start_time': '00:14:32', 'end_time': '00:14:43', 'transcript': "Mansiz. We want to make it dynamic. So I want to say King, whatever table I passed to, it should give me the count office, so then haven't do and", 'keywords': ['Dynamic Functionality', 'System Tables', 'Data Management'], 'summary': 'The speaker discusses the need for dynamic functionality in system tables, specifically expressing a desire to input a table name and receive the count of entries within that table. This implies a focus on creating a flexible and efficient system for data management.'}, {'topic': 'System Information Schema', 'start_time': '00:14:44', 'end_time': '00:15:08', 'transcript': "so as same thing. I made it dynamic. How to make it dynamic. I think this is very much helpful for all the fun queuing or I think for coding. Also, this is tricky. How do you make it dynamic? Because you can't put a you know, in aware, Klaus, you can give a variable of parameters. But if you have to make a table lame dynamic which is used in", 'keywords': ['Dynamic Schema', 'Coding', 'Parameters'], 'summary': 'The speaker discusses the concept of making a system information schema dynamic, highlighting its usefulness in coding and fun queuing scenarios. They mention the challenges involved in creating a dynamic table, particularly the limitations of using static parameters. The complexity of the topic suggests a focus on dynamic programming techniques.'}, {'topic': 'Creating SQL Procedures', 'start_time': '00:15:08', 'end_time': '00:15:24', 'transcript': 'so how do we do it? So in this particular store procedure, I used a function execute. So this execute function will execute a string which have a strain you give it so we can build up that strength.', 'keywords': ['SQL Procedures', 'Execute Function', 'Stored Procedure'], 'summary': 'The discussion focuses on the creation of SQL procedures, specifically highlighting the use of the execute function. The speaker explains that this execute function allows the execution of a string that is provided, facilitating the process of building up that string for use within the stored procedure.'}, {'topic': 'Dynamic SQL Procedures', 'start_time': '00:15:25', 'end_time': '00:15:38', 'transcript': "So I'm not using of their class because acceptable name directly. And I want to see the common name office. So this execute is with format function and the same parameter the table name.", 'keywords': ['Dynamic SQL', 'Procedures', 'Format Function'], 'summary': 'The speaker discusses the use of dynamic SQL procedures, specifically mentioning the execution of a format function with parameters related to a table name. The focus is on retrieving common names from an office database and highlights the approach of not using a specific class for naming.'}, {'topic': 'Stored Procedures Creation', 'start_time': '00:15:40', 'end_time': '00:15:59', 'transcript': 'is being used to build up this insert statement. Now, what this insert statement is doing, this is percentage as means a stream stream parameters expected heirs of what is going to put its the stable name here. Because if you remember, in our previous this was', 'keywords': ['Stored Procedures', 'Insert Statement', 'Stream Parameters'], 'summary': 'The transcript discusses the process of creating stored procedures, specifically focusing on building an insert statement. It highlights the use of stream parameters and the expected behavior of the statement in relation to the table name, referencing previous discussions for context.'}, {'topic': 'Dynamic Action in Stored Procedures', 'start_time': '00:16:00', 'end_time': '00:16:22', 'transcript': 'hired border. But now this is becoming dynamic. So this table name particularly replace there. So this far, Mac, this is This is a parameter for farm at Kumar. This is making it dynamic. So whatever is purpose in that table name, it is going to pass that as parameter', 'keywords': ['Dynamic Action', 'Stored Procedures', 'Parameters'], 'summary': 'The transcript discusses the concept of dynamic action within stored procedures, highlighting how table names are being replaced with parameters to enhance flexibility. It emphasizes the ability to pass specific table names as parameters, showcasing the dynamic nature of the process in question.'}, {'topic': 'Stored Procedures for All Tables', 'start_time': '00:16:23', 'end_time': '00:16:33', 'transcript': "and also is going to put that name in the stable. This table test log was created with just two condoms, table name and Rocca. Let's use any table from", 'keywords': ['Stored Procedures', 'Database', 'Test Log'], 'summary': "The transcript discusses the creation of a test log table designed to record specific information, including the table name and another parameter referred to as 'Rocca'. The speaker indicates the process of utilizing any table from the database for this purpose."}, {'topic': 'Stored Procedure Efficiency', 'start_time': '00:16:34', 'end_time': '00:17:04', 'transcript': "and receive whether it will give you that counter. so Laz Z. so now because the store procedure is already created rival. Even if I run it again, it's going to just replace Crate or replace statement is there so?", 'keywords': ['Stored Procedure', 'Efficiency', 'Execution'], 'summary': 'The transcript discusses the efficiency of stored procedures, focusing on their functionality and behavior when executed multiple times. It highlights that once a stored procedure is created, subsequent executions will replace existing statements, raising questions about its performance and output.'}, {'topic': 'Stored Procedure Execution', 'start_time': '00:17:06', 'end_time': '00:17:13', 'transcript': "it will just a place, and but it's already there. I am just going to change the statement here. Seat SWAC.", 'keywords': ['Stored Procedure', 'Execution', 'SQL'], 'summary': 'The transcript discusses the execution of a stored procedure, mentioning that it is already in place and that a statement will be modified. The context is brief and lacks detailed technical content.'}, {'topic': 'Stored Procedures with Count', 'start_time': '00:17:29', 'end_time': '00:17:39', 'transcript': "so again, it hasn't returned you anything because it's of sort for Caesar. It has done a task. Lot of task in this. So we just show you", 'keywords': ['Stored Procedures', 'Count', 'Database'], 'summary': 'The transcript discusses the functioning of stored procedures, specifically focusing on their behavior when executing tasks without returning any results. The speaker indicates that the procedure has completed its task, emphasizing its operational aspects.'}, {'topic': 'Audit Logging', 'start_time': '00:17:39', 'end_time': '00:18:17', 'transcript': "now the test? Well, it should have an entry for F B and all. So this is how many rows were this is you can use it for any table now. We expanded this functionality further. So in one of our requirement, climbed wanted count for all the tables, whatever we have in our system. So we want account of all that paper's not only that the client also want Ear's. What is the maximum value in that for each column?", 'keywords': ['Audit Logging', 'Data Count', 'Maximum Value'], 'summary': 'The transcript discusses audit logging, focusing on the necessity of having entries for various tables within a system. It highlights an expanded functionality request from a client who requires a count of all tables and the maximum value for each column in the dataset. The speaker emphasizes the importance of these metrics in meeting client needs.'}, {'topic': 'Dynamic SQL for All Tables', 'start_time': '00:18:17', 'end_time': '00:18:32', 'transcript': 'Which columns are and home, Um, in how many null values in in gyro for each and every column so so far that then we will not even dependent on the stable name reused system tables.', 'keywords': ['Dynamic SQL', 'Null Values', 'System Tables'], 'summary': "The transcript discusses the examination of columns and the number of null values present in a specific table, referred to as 'gyro'. It emphasizes the importance of not relying solely on table names and suggests the use of system tables for a more dynamic approach to SQL queries."}, {'topic': 'Statistics and Data Integrity', 'start_time': '00:18:32', 'end_time': '00:18:50', 'transcript': "So that is the system information scheme. Our Table, which has columns and tables column It will be different for a again for different databases. Snowflake CASS. It's on information. Ski Mark My A school might have a slight different name, but Salama the other", 'keywords': ['Database', 'System Information', 'Data Integrity'], 'summary': 'The speaker discusses the system information scheme related to databases, particularly mentioning that the structure of tables and columns may vary across different database systems such as Snowflake and CASS. They note that different institutions might have slightly different naming conventions for these elements.'}, {'topic': 'Data Analysis Automation', 'start_time': '00:18:50', 'end_time': '00:19:09', 'transcript': 'they they had That is the same logic. The system lists the names of all the people. So in one go, you will have. If you have the statement within a far Luke Foreign for each row in the information scheme are not tables, then you can', 'keywords': ['Data Analysis', 'Automation', 'Database'], 'summary': 'The speaker discusses the concept of data analysis automation, highlighting a systematic approach where the system can list names and process information efficiently. They emphasize the logic behind automating the analysis, suggesting that using a statement within a loop for each row in a database can enhance productivity in handling data.'}, {'topic': 'Data Insights', 'start_time': '00:19:10', 'end_time': '00:19:18', 'transcript': 'go one by one and create that lock for all the tables. And if you want to see that court, I can show you that also.', 'keywords': ['Data Locking', 'Tables', 'Code Demonstration'], 'summary': 'The speaker discusses the process of creating locks for various tables, indicating a methodical approach by addressing each table individually. They also offer to demonstrate the code related to this process if requested.'}, {'topic': 'SQL Validation Process', 'start_time': '00:19:20', 'end_time': '00:19:53', 'transcript': 'so sorry. so this particular I just want to show you. this state, this one. And I think this If if you would have worked this for this particular functionality manually, it would have taken even a week would have been less er so. There were so many columns in one table and each and every column we had to see What was the count of null What is our How many account of', 'keywords': ['SQL', 'Validation', 'Null Values'], 'summary': 'The speaker discusses the SQL validation process, highlighting the efficiency of automated methods compared to manual efforts. They mention that manually checking the count of null values across many columns in a table would have taken an extended period, possibly a week, emphasizing the advantages of using automated processes for such tasks.'}, {'topic': 'Error Handling in SQL', 'start_time': '00:19:54', 'end_time': '00:20:05', 'transcript': "table rolls then we had two can play a part for the distinct value. And Max, we're losin and I can show you this table also. You know how what kind of summary it crater, but", 'keywords': ['SQL', 'Error Handling', 'Distinct Values'], 'summary': 'The transcript discusses error handling in SQL, mentioning the use of tables and the importance of distinct values. The speaker is likely demonstrating how to handle errors related to table operations and summarizing the relevant concepts.'}, {'topic': 'Validation Logic', 'start_time': '00:20:07', 'end_time': '00:20:23', 'transcript': 'internally again. This was this Execute foreigners statement was only used, but it use and again informations cable dot columns. This was for a particular table and columns, so for one, they will we can.', 'keywords': ['Validation Logic', 'SQL', 'Data Integrity'], 'summary': 'The transcript discusses the validation logic related to the execution of a specific SQL statement, highlighting its application to certain tables and columns. The speaker notes that this process is used internally and emphasizes the importance of the information being validated for the respective columns.'}, {'topic': 'SQL Trigger Introduction', 'start_time': '00:20:24', 'end_time': '00:20:54', 'transcript': "all the columns first. Then we go to another table. This was the vein designed. So if you want the details or you want the court, you can come to me and discuss with me. But this was ever saying, you know, this can really make the life of Cuba dwell. Persall so easy. So the programming is not just required for dwell first, even if you wait, Does this kind of they can do this? Morning Tunnels, cheques? I know there are lot of Cuba people's hair and they might be able to cordial it. In many cases, they are", 'keywords': ['SQL Trigger', 'Database', 'Programming'], 'summary': "The transcript revolves around the introduction of SQL triggers, highlighting their utility in simplifying programming tasks within databases. The speaker mentions the importance of understanding the details and encourages discussion for further clarification. There is a focus on how SQL triggers can significantly enhance efficiency for users, especially those familiar with coding, while also addressing the broader audience's capabilities in managing complex tasks."}, {'topic': 'Trigger Overview', 'start_time': '00:20:54', 'end_time': '00:21:02', 'transcript': 'doing this more not on his cheques many times and with one accord, it just You need to run this query then', 'keywords': ['Query', 'Execution', 'Collective Action'], 'summary': 'The transcript discusses the necessity of running a specific query, suggesting that this process has been done multiple times and requires collective agreement or action. The speaker emphasizes the importance of executing the query correctly.'}, {'topic': 'Triggers in SQL', 'start_time': '00:21:03', 'end_time': '00:21:12', 'transcript': 'then a It will just give you that data in this particular table. I was building up the stable in served in do this', 'keywords': ['SQL', 'Triggers', 'Database'], 'summary': 'The transcript briefly discusses the functionality of SQL triggers, indicating that they will provide specific data from a designated table. The speaker mentions the process of building up the table and how triggers serve to execute actions when certain conditions are met.'}, {'topic': 'Trigger Types', 'start_time': '00:21:13', 'end_time': '00:21:22', 'transcript': 'So only the trick is how the build of does this damn inquiry and you this system. any cautions till long.', 'keywords': ['Trigger Types', 'System', 'Inquiries'], 'summary': 'The transcript briefly discusses the concept of trigger types, mentioning the challenges involved in building a system that effectively manages inquiries. The speaker hints at potential cautions or considerations that should be taken into account, although the details are not fully elaborated.'}, {'topic': 'Trigger Functions', 'start_time': '00:21:27', 'end_time': '00:21:49', 'transcript': "any hand cushions. And to further about this cone, Belka, I'd advise and go into the next truck. So this is the table will be created log and sorry, Wannsee.", 'keywords': ['Trigger Functions', 'Table Creation', 'Structured Approach'], 'summary': 'The transcript discusses the subject of trigger functions, mentioning the creation of a table related to this topic. The speaker suggests moving on to the next part of the discussion, indicating a structured approach to the content.'}, {'topic': 'Trigger Events', 'start_time': '00:21:58', 'end_time': '00:22:14', 'transcript': "this table has changed. Okay? Sorry. And running this in another environment. so are any where it's not wanted. So it was a mainly along kind of table I can just show you from her.", 'keywords': ['Table', 'Environment', 'Modification'], 'summary': "The speaker discusses changes made to a specific table, indicating that it has been modified and is being run in a different environment. They express concern about its application in environments where it may not be desired, and they mention the table's structure, hinting at a more detailed explanation that they can provide."}, {'topic': 'Trigger Usage', 'start_time': '00:22:31', 'end_time': '00:22:44', 'transcript': 'to Cedars. So which column name it was switched Able arm. This automatically did. And how many got is a Kong governor distinct values? How many districts for the the if there were any values which were zero?', 'keywords': ['Triggers', 'Database', 'Distinct Values'], 'summary': "The speaker discusses the usage of triggers in relation to a database, specifically mentioning a column name that was switched to 'Able arm.' They elaborate on the automatic processes that occurred and inquire about the distinct values in a certain context, including the count of districts and any zero values present."}, {'topic': 'Trigger Logic', 'start_time': '00:22:45', 'end_time': '00:22:52', 'transcript': 'maximum minimum value. The film factor for stance. We always, you know, for data science. We really need to find out', 'keywords': ['Trigger Logic', 'Data Science', 'Maximum Minimum Values'], 'summary': 'The transcript discusses the concept of trigger logic in the context of data science, focusing on determining maximum and minimum values and the importance of these factors in analysis. The speaker emphasizes the need to identify these values to enhance understanding in data-driven decision-making.'}, {'topic': 'Trigger for Data Validation', 'start_time': '00:22:53', 'end_time': '00:23:16', 'transcript': "how much per portion of this column is filled up. If it's not filled up, should be used into an hour regression model or not. I think this kind of analyses also is done automatically and some statistical functions. But I know this was in data base level. We wanted to particularly do analyses and testing for these columns will be dated automatically.", 'keywords': ['Data Validation', 'Regression Model', 'Statistical Functions'], 'summary': 'The transcript discusses the evaluation of data quality in a specific column, focusing on how much of it is filled. It raises the question of whether to include this column in a regression model if it contains missing values. The speaker notes that such analyses and testing can be performed automatically, indicating a reliance on statistical functions at the database level to facilitate the assessment of these columns.'}, {'topic': 'Trigger Implementation', 'start_time': '00:23:17', 'end_time': '00:23:31', 'transcript': "so person had couldn't only see this excel then and you can you know it is a table you can always query on this table with where class, which has less Phil factor of which has more nahl known on sending.", 'keywords': ['Trigger', 'Excel', 'Query'], 'summary': "The speaker discusses the implementation of a trigger in relation to a table in Excel. They explain that users can query the table using specific conditions, such as filtering based on a 'Phil factor' and other criteria. The focus is on how to effectively use queries to retrieve relevant data."}, {'topic': 'DML Triggers', 'start_time': '00:23:32', 'end_time': '00:23:47', 'transcript': 'so similarly you can use it for. you can use it for your validation, Sze also So if you run a validation and if it is not meeting a condition, you can just one Singh.', 'keywords': ['DML', 'Triggers', 'Validation'], 'summary': 'The discussion focuses on the application of DML triggers, mentioning their utility for validation purposes. It highlights that if a validation check does not meet a specified condition, a particular action can be executed, indicating the conditional nature of triggers in database management.'}, {'topic': 'Row vs Statement Triggers', 'start_time': '00:23:51', 'end_time': '00:24:09', 'transcript': "so if you are not doing some variations and it is not following, you can put this kind of code here. Also, side like you can have a statement and only thing is even need to maintain a table, some some law table or somewhere where you're inserting these values.", 'keywords': ['Row Triggers', 'Statement Triggers', 'Database Management'], 'summary': 'The transcript discusses the implementation of row versus statement triggers, highlighting the importance of maintaining a table to insert values when variations are not being followed. It suggests that one can utilize specific coding practices to manage this process.'}, {'topic': 'Before and After Triggers', 'start_time': '00:24:11', 'end_time': '00:24:43', 'transcript': 'so, Yeah, that that was for a function and so on. Stored for Caesar, there is one more thing. a installed to Caesar. I said We can make it dynamic. Earlier was a static. The stock for Caesar one was a function but installed to Caesar. Also, I said You can return of value. You can never return statement with the value. But if you want to return something, there is one other veils. This also want to show', 'keywords': ['Triggers', 'Dynamic', 'Function'], 'summary': "The transcript discusses the concept of 'Before and After Triggers' in relation to a function for Caesar. It highlights the transition from a static to a dynamic approach, mentioning that earlier, the stock for Caesar was a function, but now it can return a value. The speaker indicates a desire to demonstrate another aspect related to returning values in this context."}, {'topic': 'Trigger Scenarios', 'start_time': '00:24:44', 'end_time': '00:25:06', 'transcript': "there is a n out kind of parameter or out kind of parameter which lets you get a value from a store procedure. So stop A zither is not just sending a value, it can also receive a wearing this one example. I don't want it to have that law table add on to create it. I just want that variable bank.", 'keywords': ['Trigger Scenarios', 'Stored Procedure', 'Parameter'], 'summary': 'The transcript discusses trigger scenarios, particularly focusing on a parameter that allows retrieving a value from a stored procedure. It highlights that a stored procedure can not only send a value but also receive information. The speaker expresses a desire to avoid adding complexity by not incorporating a specific table, indicating a preference for a simpler variable structure.'}, {'topic': 'Trigger Limitations', 'start_time': '00:25:07', 'end_time': '00:25:32', 'transcript': "with me. So then I hire I don't have any lock table. I only have a count star Any to table count. This was a parameter which was declared as this. And now if I call it, it is going to give me that Kong for that. So here again it was a hard quarter or testing you can again make it dynamic. So lets us run this.", 'keywords': ['Trigger Limitations', 'Count Star', 'Dynamic Parameters'], 'summary': 'The speaker discusses the concept of trigger limitations, specifically mentioning the absence of a lock table and the use of a count star to manage table counts. They describe a parameter declaration and how it relates to retrieving counts dynamically, emphasizing the testing aspect and suggesting that it can be made more flexible. The session concludes with a prompt to run the discussed code.'}, {'topic': 'Trigger Access', 'start_time': '00:25:34', 'end_time': '00:25:41', 'transcript': 'as it is the procedure we need. We need to use a call if it would abandon a function we would have done.', 'keywords': ['Trigger Access', 'Procedure', 'Function'], 'summary': 'The transcript outlines the procedure for trigger access, highlighting the necessity of using a call in order to prevent the abandonment of a function that would have otherwise been executed.'}, {'topic': 'Creating Triggers', 'start_time': '00:25:42', 'end_time': '00:26:06', 'transcript': 'our test, you will need to ride the function name. but see now it has returned. Show knew that value. We are not going anywhere table and anything checking it. So because we return through', 'keywords': ['Triggers', 'Function Name', 'Return Value'], 'summary': 'The transcript discusses the process of creating triggers, highlighting the importance of referencing the function name and returning values. It suggests that there is a need to check values within a table, indicating a focus on ensuring that the return process is properly executed.'}, {'topic': 'Trigger Comparison', 'start_time': '00:26:06', 'end_time': '00:26:22', 'transcript': 'output Vira metre input output means it will allow you put So this is the beauty of out fair. Um, And this now why we will when we should create a function and when we should create a stored procedure.', 'keywords': ['Trigger', 'Function', 'Stored Procedure'], 'summary': 'The transcript discusses the concept of trigger comparison in the context of database management. It highlights the advantages of using output and input in triggers, particularly emphasizing the effectiveness of output in facilitating operations. Furthermore, the speaker mentions the importance of knowing when to create a function versus when to create a stored procedure, suggesting a strategic approach to database design.'}, {'topic': 'Trigger Logic and Performance', 'start_time': '00:26:23', 'end_time': '00:27:02', 'transcript': "So I'm just going to the presentation again. So you function as he said, is the normal as to a statement. But why? What is a clause of a function? Is it car? It cannot allow you to begin or commit transaction. You cannot have because when you are saying select and function name with a parameter and if you have a from they will hear it is going to call that function that many times from the", 'keywords': ['Trigger Logic', 'Function', 'Performance'], 'summary': "The presentation focuses on trigger logic and performance, explaining the normal functioning of statements in relation to functions. The speaker raises questions about the nature of clauses within functions, emphasizing that certain operations, like beginning or committing transactions, are not permissible. They clarify that when using a function with a parameter in a select statement, the function will be invoked multiple times as specified in the 'from' clause."}, {'topic': 'Trigger Implementation Example', 'start_time': '00:27:03', 'end_time': '00:27:25', 'transcript': "a table. So then you can't have a you notice of a million of rose. So you can't have a million of time committing and begin transaction here. But a store possessor is a bat statement. It is running on an entire transitions, Not functioned can be row bases. Also, it might be also running a", 'keywords': ['Triggers', 'Database', 'Transactions'], 'summary': "The transcript discusses the implementation of triggers in a database context, highlighting limitations such as the inability to handle a large number of rows and the transactional nature of certain statements. It mentions that a 'store possessor' operates on complete transitions rather than on individual rows, emphasizing the functional differences in handling transactions."}, {'topic': 'Trigger Functionality', 'start_time': '00:27:26', 'end_time': '00:27:37', 'transcript': "you're in one that statement also, I'm not saying it's always like that, but if you call through from table statement, then is going to run again. Anarchy and", 'keywords': ['Trigger Functionality', 'Table Statement', 'Execution'], 'summary': 'The transcript discusses trigger functionality, highlighting that when a call is made from a table statement, the function is executed again. The speaker hints at variability in this behavior, suggesting that it may not always be the case.'}, {'topic': 'Trigger Code Sharing', 'start_time': '00:27:39', 'end_time': '00:27:48', 'transcript': 'it can have multiple transactions, your stock procedures and they cannot return of their Liu. So it has to be called like this. It is a separate.', 'keywords': ['Trigger Code', 'Transactions', 'Stock Procedures'], 'summary': 'The transcript discusses the concept of trigger code sharing in programming, highlighting that it can involve multiple transactions and stock procedures. It emphasizes the need for specific calling conventions, indicating that the procedures cannot return in a traditional manner, and notes that the trigger code operates as a separate entity.'}, {'topic': 'Triggers in Application Logic', 'start_time': '00:27:48', 'end_time': '00:28:09', 'transcript': "ask you a statement in in itself. But when you are calling a function, you can call it with other rescue a statement within the same civic statement. So that is the major difference. So that's why the key thing is, do you want to call it as a user defying function at a role levels are you want to", 'keywords': ['Triggers', 'Application Logic', 'User-defined Functions'], 'summary': 'The discussion revolves around the concept of triggers in application logic, highlighting the distinction between calling a function as a user-defined function versus invoking it within a specific statement. The speaker stresses the importance of understanding this difference in the context of application design and logic management.'}, {'topic': 'User-based Triggers', 'start_time': '00:28:09', 'end_time': '00:28:19', 'transcript': 'run a bad statement? So there are lots of advantages of slow procedures while, you know, some of like I have shown you.', 'keywords': ['User-based Triggers', 'Slow Procedures', 'Advantages'], 'summary': 'The transcript discusses the advantages of using slow procedures in the context of user-based triggers, suggesting that while there may be some drawbacks, there are also significant benefits that have been demonstrated in previous examples.'}, {'topic': 'Triggers vs Stored Procedures', 'start_time': '00:28:20', 'end_time': '00:28:45', 'transcript': "how we do it. And I think we did this static, dynamic and returning valleys to the store for Caesar's So and so, particularly this tortoise sees. I said, How you are doing, you ever work and you're crediting different logs for it and you are. Actually what you're doing is you are also making your concern data and process consistent through store position.", 'keywords': ['Triggers', 'Stored Procedures', 'Data Consistency'], 'summary': 'The transcript discusses the differences between triggers and stored procedures in database management. It highlights the importance of maintaining data consistency and processing efficiency through the use of stored procedures. The speaker mentions specific examples and the role of logging in this context.'}, {'topic': 'Triggers and User Permissions', 'start_time': '00:28:45', 'end_time': '00:28:59', 'transcript': 'If your climbed applications are directly using your procedures for suppose integrity cheques when you want to see if I am inserting this in table, the foreign key should be there', 'keywords': ['User Permissions', 'Triggers', 'Data Integrity'], 'summary': 'The transcript discusses the importance of user permissions and triggers in database applications, particularly focusing on integrity checks during data insertion. It highlights the necessity of ensuring that foreign keys are present when performing operations that rely on procedures, indicating the role of triggers in maintaining data integrity.'}, {'topic': 'Trigger Use Cases', 'start_time': '00:28:59', 'end_time': '00:29:18', 'transcript': "and some of the data basis, like snowflakes and all, they don't even have referential integrity cheques. And so in that case, is best to have it installed procedure. And there are some cheques which are not just rest, foreign key and primary cheques. There are many other cheques and some processes some business", 'keywords': ['Referential Integrity', 'Stored Procedures', 'Data Checks'], 'summary': 'The transcript discusses the limitations of certain databases, such as Snowflake, which lack referential integrity checks. It suggests that in such scenarios, utilizing installed procedures can be beneficial. The speaker also notes that there are various checks beyond just REST, foreign key, and primary checks, indicating a broader discussion about data integrity and business processes.'}, {'topic': 'Trigger Advantages', 'start_time': '00:29:18', 'end_time': '00:29:43', 'transcript': 'logic calculation. Like I know how to calculate simple interest and compound interest. That formula is fixed so that from life we keep it in store per Caesar. If it changes the rules for compound interest changes or something changes, I will be changing only one small path. One store per Caesar. I will not be doing changes across,', 'keywords': ['Triggers', 'Logic Calculation', 'Interest Calculation'], 'summary': 'The transcript discusses the advantages of using triggers in logic calculation, specifically relating to the calculation of simple and compound interest. The speaker highlights the fixed nature of these formulas and mentions that if there are changes in the rules for calculating compound interest, only a small part of the process needs to be adjusted, rather than making extensive changes across the board.'}, {'topic': 'Trigger Disadvantages', 'start_time': '00:29:43', 'end_time': '00:30:10', 'transcript': "you know, suppose this this kind of functionality was used Five or 10 places or hundreds of places. They're not changing at 100 of places. We are just changing one stored for Caesar through the maintenance. The change management is very much requirement for stored procedures. So another we are and supposed a table in changes.", 'keywords': ['Triggers', 'Change Management', 'Stored Procedures'], 'summary': 'The transcript discusses the disadvantages of using triggers in database management, particularly focusing on the challenges associated with change management. It highlights the scenario where a functionality is implemented in multiple locations, making it cumbersome to update all instances when a change is needed. Instead, it suggests that managing changes through stored procedures might be more efficient, emphasizing the need for careful maintenance and management of these stored procedures.'}, {'topic': 'Trigger Performance', 'start_time': '00:30:10', 'end_time': '00:30:38', 'transcript': "Sorry. Within a table, you have extra Khanum to be shown in report, or we have a new column column being renamed or anything so those all these things will be part of our stored. Proceed. You're not calling that as Curiel. Suppose at fight and places separately, but that astral safe is encapsulated within your stored procedure. Your business logic layer is", 'keywords': ['Trigger Performance', 'Stored Procedure', 'Business Logic'], 'summary': 'The transcript discusses aspects related to trigger performance within a database context. It mentions the inclusion of additional columns in reports and the renaming of existing ones, emphasizing that these modifications will be incorporated into the stored procedures. The speaker highlights the encapsulation of business logic within the stored procedures, indicating a structured approach to managing database operations.'}, {'topic': 'Trigger Context', 'start_time': '00:30:39', 'end_time': '00:30:59', 'transcript': "no. I'm a hidden in that and all the complex operations also explained warns. And so it's easy performance wise. Also, the stored procedures are lot better because they are come pyre cold of units and the performance of store procedure is better than.", 'keywords': ['Trigger Context', 'Stored Procedures', 'Performance'], 'summary': 'The speaker discusses the concept of trigger context, highlighting the complexity of operations involved and their implications for performance. They emphasize that stored procedures are more efficient compared to other methods due to their compiled nature, resulting in improved performance.'}, {'topic': 'Trigger Logging', 'start_time': '00:31:00', 'end_time': '00:31:21', 'transcript': "user defined function. User defined function can slow down as explain news. It does a row level function and a few times, so the performance of stored procedure is much faster. Compile code is not again checking and vesting is not again hitting server again and again. Suppose if you're running for select statement", 'keywords': ['User-Defined Function', 'Stored Procedure', 'Trigger Logging'], 'summary': 'The transcript discusses the performance implications of user-defined functions compared to stored procedures in the context of trigger logging. It highlights that user-defined functions can slow down processes due to their row-level execution, while stored procedures benefit from compiled code and reduced server hits, leading to faster performance especially during operations like select statements.'}, {'topic': 'Trigger Functionality in Applications', 'start_time': '00:31:22', 'end_time': '00:31:36', 'transcript': 'separately in a D V engine four times it is going across networks going from server to client runs. A query gets you result than run the next statement in a normal scenario,', 'keywords': ['Trigger Functionality', 'D V Engine', 'Query Execution'], 'summary': 'The transcript discusses the trigger functionality in applications, particularly focusing on its operation within a D V engine. It outlines the process where a query is executed across networks, transitioning from server to client, and highlights the sequential execution of statements in a typical scenario.'}, {'topic': 'Final Questions', 'start_time': '00:31:36', 'end_time': '00:31:59', 'transcript': 'but not but in a store procedure, If you have 14 Cilic statement and one stork procedure, it will be sent to the server vans and all the returns or the result is return. so we can utilise again. Transactions. Also, 40 time ticket e began a multiple transactions. We can begin comment', 'keywords': ['Stored Procedures', 'Transactions', 'SQL Statements'], 'summary': 'The transcript discusses the concept of stored procedures in programming, specifically in the context of handling multiple SQL statements and transactions. It highlights how a stored procedure can encapsulate various SQL commands, allowing for efficient interaction with the server and returning results. The speaker also mentions the importance of transactions, indicating that they can manage multiple operations effectively.'}, {'topic': 'Trigger vs Function Comparison', 'start_time': '00:31:59', 'end_time': '00:32:12', 'transcript': 'ways on that it will execute the state. So this is all about the stored per Caesar. And before I move to the triggers, I will like to take any questions of commence. Um', 'keywords': ['Triggers', 'Functions', 'Stored Procedures'], 'summary': 'The transcript discusses the execution of states in relation to stored procedures, with a particular focus on the comparison between triggers and functions. The speaker invites questions before proceeding with the topic of triggers.'}, {'topic': 'Session Conclusion', 'start_time': '00:32:16', 'end_time': '00:32:41', 'transcript': 'and even. men can we do all things we are doing in procedure in also function? Yes, you can. only transaction is not so. In fact, most of the cases because of the limitation of return clause in Proceso, people are tend to use functions on the complex functions.', 'keywords': ['Procedures', 'Functions', 'Return Clause'], 'summary': 'The session concludes with a discussion on the capabilities of procedures and functions in programming. The speaker addresses the common misconception about transactions, explaining that while procedures can perform various tasks, there are limitations associated with the return clause. This often leads people to prefer using functions, especially in complex scenarios.'}, {'topic': 'Feedback and Closing', 'start_time': '00:32:42', 'end_time': '00:32:55', 'transcript': 'and calling to become different Now, how you college? It has to be part of a select statement. So you also want to see that outer application, which is calling it how that will be designed.', 'keywords': ['Feedback', 'Select Statement', 'Outer Application'], 'summary': 'The transcript discusses the importance of feedback in the context of a select statement and its outer application. It emphasizes the need for design considerations when calling different elements in a programming context, suggesting that feedback mechanisms should be integrated into the overall structure.'}, {'topic': 'Session Ending', 'start_time': '00:33:00', 'end_time': '00:33:28', 'transcript': "In fact, if you see that I was showing you this one. this function which was complex, which we created for the way people while everything was summarised for them, it was actually issues it, we would have noticed this was also retired a function, not it's sort procedure. It could have been done, but it was being called from another outside. Also, there was one stored, one function which", 'keywords': ['Function', 'Summarization', 'Software Structure'], 'summary': 'The transcript discusses the conclusion of a session, where the speaker reflects on a complex function created for summarizing information for users. They mention that this function was actually retired and that it was being called from an external source. Additionally, the speaker notes the existence of another stored function, suggesting a focus on function usage and software structure.'}, {'topic': 'Future Sessions', 'start_time': '00:33:29', 'end_time': '00:33:43', 'transcript': "for which it had to return a value. And that's why this was also returned as a function. So this this entire, in fact, I would have I can this copy paste this thing and placed it in a crate for season candidate.", 'keywords': ['Function', 'Return Value', 'Programming'], 'summary': 'The transcript discusses the necessity of returning a value from a function, indicating that the content could be copied and utilized in a crate for season candidates. The speaker seems to be explaining a programming concept related to functions and their return values.'}, {'topic': 'Thank You', 'start_time': '00:33:44', 'end_time': '00:34:05', 'transcript': 'fun walking. yes. anything else. This is a message on the chat. kicks. Yeah, you can. Can you also share those', 'keywords': ['Chat', 'Interaction', 'Sharing'], 'summary': 'The transcript captures a brief interaction that includes expressions of enjoyment and requests for sharing information through chat. The dialogue suggests a casual atmosphere, with participants engaging in light conversation and confirming the ability to share certain materials.'}, {'topic': 'Session Recordings', 'start_time': '00:34:05', 'end_time': '00:34:12', 'transcript': "in the chance those video links for my training if you're able to find out or the other? I sent the email to the group.", 'keywords': ['Video Links', 'Training', 'Email Communication'], 'summary': 'The speaker discusses the availability of video links related to their training sessions, indicating that they have sent an email to the group regarding this matter and encourages the audience to find the links if possible.'}, {'topic': 'Session Transition to Triggers', 'start_time': '00:34:13', 'end_time': '00:34:24', 'transcript': "Nobody's Mark. Those videos are already accessible on it to collapse, so all of them they have their links to visit to that site and got food was recording", 'keywords': ['Videos', 'Accessibility', 'Session Transition'], 'summary': 'The transcript discusses the accessibility of videos related to the topic, mentioning that all videos have links available for viewers. It indicates that the session is transitioning and emphasizes the importance of accessing the recorded content.'}, {'topic': 'Event-based Triggers', 'start_time': '00:34:24', 'end_time': '00:34:48', 'transcript': "sessions. So then any other question I'm moving to triggers. So now triggers. Know, I think everyone has must have heard off. And if you have not heard off, the trigger means anything you know it's a", 'keywords': ['Event-based Triggers', 'Triggers', 'Actions'], 'summary': 'The speaker transitions to the topic of event-based triggers, indicating that the audience is likely familiar with the concept. They briefly define triggers as events that prompt certain actions or responses, suggesting that the audience should have some prior knowledge of the topic.'}, {'topic': 'Trigger Event Types', 'start_time': '00:34:49', 'end_time': '00:35:18', 'transcript': 'special type of event has occurred. One trigger has occurred. So Anne Askew Award a trigger is a a special type of store to Caesar only that automatically runs when an event occur in a date of resources. So as soon as you answered a record, you want the record to be inserted in a lock. Pick something like if you are changing or deleting a record you want', 'keywords': ['Trigger', 'Database', 'Event Management'], 'summary': 'The transcript discusses trigger event types, specifically focusing on the occurrence of a special type of event known as a trigger. The speaker explains that a trigger automatically executes when a specific event occurs, such as inserting a record into a log when a record is added, changed, or deleted. This highlights the functionality and importance of triggers in managing database events.'}, {'topic': 'Trigger Functionality', 'start_time': '00:35:18', 'end_time': '00:35:34', 'transcript': 'and order clock to women dating or you want to do the assembly a chair you want to do. A validation for that data is that date is courage only then it should go, so this kind should automatically happen if somebody is calling', 'keywords': ['Trigger Functionality', 'Data Validation', 'Automation'], 'summary': 'The transcript discusses trigger functionality related to data validation in processes, such as ordering or assembling items. It highlights that validation should ensure data integrity, specifically that dates are accurate, and that this validation process should occur automatically when certain conditions or calls are made.'}, {'topic': 'Trigger Uses', 'start_time': '00:35:34', 'end_time': '00:35:52', 'transcript': 'a special validation. you know manually, you may or may not call it, but trigger is want, which is automatically Ron when an event occur and a very useful in database on maintaining these all of allegations and integrity cheques.', 'keywords': ['Triggers', 'Database', 'Data Integrity'], 'summary': 'The transcript discusses the concept of triggers in databases, highlighting their role as automatic procedures that run in response to specific events. It emphasizes the utility of triggers in maintaining data integrity and performing validation checks, which can be done manually or automatically.'}, {'topic': 'DDL Triggers', 'start_time': '00:35:54', 'end_time': '00:36:15', 'transcript': 'so there are in database work. There are many kinds of triggers, but we will focus on only two. There are DDS triggers also which occurs when a date. The realise data definition language. When a table or viewed changes that kind of triggers are triggers and a user long in', 'keywords': ['DDL Triggers', 'Database', 'Triggers'], 'summary': 'The discussion focuses on database triggers, specifically highlighting two types of triggers. The speaker mentions DDL (Data Definition Language) triggers, which are activated when there are changes to a table or view. The explanation emphasizes the relevance of these triggers in the context of user logins and database operations.'}, {'topic': 'Trigger Configuration', 'start_time': '00:36:16', 'end_time': '00:36:34', 'transcript': 'the trigger are occurred. There are some different, but we will focus only on these two kind of trainer. One is the day, um, El Trigger and other is a instead of trick. So what are the M military? Damen means anyone here which can Who can tell me what is a demon?', 'keywords': ['Trigger Configuration', 'Day Trigger', 'Instead of Trigger'], 'summary': "The discussion centers on trigger configuration, specifically focusing on two types of triggers: the 'day' trigger and the 'instead of' trigger. The speaker engages the audience by asking for clarification on the term 'demon', suggesting a discussion about its meaning and relevance in the context of triggers."}, {'topic': 'Trigger Logic', 'start_time': '00:36:39', 'end_time': '00:37:00', 'transcript': "in for a date of death, Mum. Yeah, it's actually a data. Many pollution language. The full former fighters? Yes. And which can manipulate the data? Yes, There are three things which can manipulate a data. One is an insert, update and delete so we can have", 'keywords': ['Trigger Logic', 'Data Manipulation', 'Insert Update Delete'], 'summary': "The transcript discusses trigger logic in the context of data manipulation, specifically focusing on operations related to a 'date of death' scenario. The speaker outlines three primary actions that can manipulate data: insert, update, and delete. These operations are fundamental to understanding how triggers function within data management systems."}, {'topic': 'Insert Triggers', 'start_time': '00:37:01', 'end_time': '00:37:35', 'transcript': "triggers on all these three actions for the and then there is a instead of triggers which are, you know, instead of means They were triggered foreign operation which can fail if it can do this than though this something like that. Everyone knows motor views here if they don't know as views is a comm pine as cure Compile. Ask your statement on top of tables if tower If a table has", 'keywords': ['Insert Triggers', 'Instead of Triggers', 'Database Management'], 'summary': 'The transcript discusses the concept of insert triggers, focusing on their application across three specific actions. It mentions the functionality of instead of triggers, which are designed to handle operations that may fail, highlighting the importance of understanding these mechanisms. The speaker references motor views and provides a brief explanation of views as a compilation aspect in databases. Additionally, there is mention of applying statements on top of tables, suggesting a deeper dive into database management concepts.'}, {'topic': 'View Usage with Triggers', 'start_time': '00:37:36', 'end_time': '00:37:48', 'transcript': "100 columns and I don't want to show all that to user, I just want a four columns out of that. I came straight of you over our if there are two day was department and employees and I want to.", 'keywords': ['Database Management', 'Views', 'Columns'], 'summary': 'The speaker discusses the use of views in database management, specifically focusing on the need to limit the number of columns displayed to users. They express a desire to present only four columns out of a total of one hundred, indicating a scenario involving departments and employees.'}, {'topic': 'Trigger Application', 'start_time': '00:37:48', 'end_time': '00:38:15', 'transcript': "we know. Show to the user only employ and the department name, not the department ID. So I can make a joint and I can create a view. And specially this trigger instead of triggers are applicable for views where we can update a record it because it is being referred from two tables so supposed other showing that so let's go to first day military.", 'keywords': ['Trigger', 'View', 'Database'], 'summary': 'The discussion focuses on the implementation of a trigger application, highlighting the need to display only the employee and department name, while omitting the department ID. The speaker explains the process of creating a view and discusses the applicability of triggers in scenarios where records can be updated, especially when they reference multiple tables. The conversation hints at a more complex scenario, suggesting a transition to a practical example or case study.'}, {'topic': 'Row Level Triggers', 'start_time': '00:38:16', 'end_time': '00:38:35', 'transcript': 'Sawada, d M L triggers as we explained their insert update, but in threat all these itself. All these triggers insert, update and delete trigger can also have descendants of one is for each row,', 'keywords': ['Row Level Triggers', 'Insert', 'Update'], 'summary': 'The transcript discusses row level triggers, specifically their functions related to insert, update, and delete operations. It highlights that these triggers can have descendants that correspond to each row affected by the operations.'}, {'topic': 'Statement Level Triggers', 'start_time': '00:38:36', 'end_time': '00:38:52', 'transcript': 'for one is for each statement. So for each row means whenever Suppose you are doing a big concert or bat in served, but for each row will be running for each and every road.', 'keywords': ['Statement Level Triggers', 'Execution', 'Row'], 'summary': 'The discussion focuses on statement level triggers, explaining their application for each statement and the execution for every row in a given context. The speaker provides an example related to a large concert or event, indicating how triggers operate on a row-by-row basis.'}, {'topic': 'Trigger Execution', 'start_time': '00:38:53', 'end_time': '00:39:28', 'transcript': "So for every road will cheque separately and will do whatever you provide the information. And so I need to be careful also. Then you are doing insert of millions of records or a big volume of the consul's. Then again, we have a for each statement which says it will run once. For you know, if you have a batch of insert a big 1000 millions or whatever record, it will run only once for that statement,", 'keywords': ['Trigger Execution', 'Database Management', 'Batch Processing'], 'summary': "The transcript discusses the process of trigger execution in database management, highlighting the need for careful handling when inserting a large volume of records. It mentions that a 'for each' statement is utilized, which will run only once for a specified batch of records, regardless of whether it's a thousand or millions. This suggests a focus on optimizing performance during massive data insertions."}, {'topic': 'Trigger Logic Implementation', 'start_time': '00:39:28', 'end_time': '00:39:55', 'transcript': "and within that also, we have before and after. So 11 of the trigger you can run before your, um, statement runs so you don't want it the record to be inserted at all, and you want to do a cheque only then let it run out. Otherwise, you can just cancel that operation. Also, he will say it is invalid and you are not. And during the report", 'keywords': ['Trigger Logic', 'Database Operations', 'Condition Checking'], 'summary': 'The transcript discusses the implementation of trigger logic, specifically focusing on the functionality of triggers that can execute before or after a database statement runs. It highlights the importance of checking conditions before allowing a record to be inserted, and the option to cancel the operation if certain criteria are not met. The speaker also notes that an invalid operation will be reported.'}, {'topic': 'Trigger Logic and Performance', 'start_time': '00:39:56', 'end_time': '00:40:21', 'transcript': 'and one is asked for it, this is required when you have inserted a record, you want foreign table also to be updated or some other table also to be a better like inventory. If you have done a sale or purchase of a record a sale of others than you want, the inventory of that record should be reduced. So in that case, what we will do it will use and after', 'keywords': ['Trigger Logic', 'Database Management', 'Inventory'], 'summary': 'The transcript discusses the necessity of trigger logic in database management, particularly when a record is inserted. It highlights the importance of updating related tables, such as inventory, when a sale or purchase occurs. The speaker explains that triggers can automate these updates to ensure consistency across the database.'}, {'topic': 'Trigger Implementation Example', 'start_time': '00:40:22', 'end_time': '00:40:49', 'transcript': 'after update so this. These are different scenarios and if you see so for a single ask you a statement can fire up to four types of trigger at the same time. We can have all those triggers at the centre. We can have before RO before statement after row. And so, while important thing about right rigorous, it is also a slot per Caesar only', 'keywords': ['Triggers', 'Database', 'Implementation'], 'summary': "The transcript discusses the implementation of triggers in a database context, highlighting that a single statement can activate up to four types of triggers simultaneously. It mentions the different types of triggers that can be utilized, including 'before row', 'before statement', and 'after row'. The speaker emphasizes the importance of rigorous management of these triggers."}, {'topic': 'Trigger Functionality', 'start_time': '00:40:49', 'end_time': '00:41:16', 'transcript': "it will run itself and it cannot take parameters. But it cannot take parameters like stored poor Caesars and function may or may not take parameters, but triggered cannot take them. But how dues access information is through it has internal tables with so, uh, let's see the so aver just sharing.", 'keywords': ['Trigger', 'Parameters', 'Internal Tables'], 'summary': 'The transcript discusses the functionality of triggers in a database context, highlighting that triggers operate automatically without the ability to accept parameters like stored procedures or functions. The speaker mentions that triggers access information through internal tables, indicating the internal workings of triggers.'}, {'topic': 'Trigger Function Usage', 'start_time': '00:41:17', 'end_time': '00:41:37', 'transcript': 'the Centex of the trees. So what? Hard to be created. So which is create, er, Tigger a name. And we right, which on which table it is, it is before update on after update. And then for each row, suppose they want or not.', 'keywords': ['Trigger Function', 'Database', 'Row Update'], 'summary': 'The transcript discusses the usage of trigger functions within a database context, focusing on the creation of triggers and their association with specific tables. It mentions the timing of triggers, whether before or after an update occurs, and addresses the application of these triggers for each row in a table.'}, {'topic': 'Trigger Limitations', 'start_time': '00:41:38', 'end_time': '00:41:56', 'transcript': "this particular you need to see. There are two important things in this trigger which are used for for triggers and why they are different from sort for Caesar. They have access to to information which normal store procedure don't have.", 'keywords': ['Triggers', 'Stored Procedures', 'Database'], 'summary': 'The transcript discusses the limitations of triggers, highlighting two important aspects that differentiate them from stored procedures. It emphasizes that triggers have access to certain information that regular stored procedures do not possess, underlining the unique functionalities and constraints associated with triggers.'}, {'topic': 'Trigger Use Case Example', 'start_time': '00:41:57', 'end_time': '00:42:09', 'transcript': 'That is the old tables and the new tip. So the old table, what is has is the time, the table, the values which were just before the update', 'keywords': ['Data Table', 'Update', 'Values'], 'summary': 'The transcript discusses a comparison between old and new tables, specifically focusing on the attributes of the old table, which include time and values prior to an update. This sets the stage for understanding how data changes over time with updates.'}, {'topic': 'Trigger Logic and Access', 'start_time': '00:42:09', 'end_time': '00:42:34', 'transcript': "and newest, which will be updated so you can compare also. So, like, if previous value was this, I don't want to update this. And if previous followed, wonders if your calculations are based on all table also previous value and new value, this kind of information is very useful. So now because this was an update review guard,", 'keywords': ['Trigger Logic', 'Data Management', 'Value Comparison'], 'summary': 'The speaker discusses the importance of trigger logic and access in data management, particularly focusing on how previous and new values affect updates. They highlight the utility of comparing calculations based on previous values and the need for careful consideration during updates. The emphasis is on ensuring that updates do not inadvertently alter essential information.'}, {'topic': 'Trigger Functionality', 'start_time': '00:42:34', 'end_time': '00:42:45', 'transcript': 'if you update a recording of modifying the records. So it has all when you also suppose my inventory has become from 2 22 10.', 'keywords': ['Trigger', 'Record Modification', 'Inventory'], 'summary': 'The transcript discusses the functionality of triggers in relation to updating records. It mentions modifying records and implies that there is a system in place that tracks inventory changes, specifically referencing a transition from one state to another with numerical values.'}, {'topic': 'Trigger Functionality in Projects', 'start_time': '00:42:46', 'end_time': '00:43:05', 'transcript': 'So the all in 13 year tables value of suppose we have some stores dot in entry quantity so the quantity of that column will be 10. Also in a sorry 20 in old and 10 in new', 'keywords': ['Trigger Functionality', 'Data Entries', 'Quantity'], 'summary': 'The speaker discusses the trigger functionality in projects, specifically focusing on the values in a table related to store entries. They explain that for a specific column, the quantity is represented as 10 in the new data and 20 in the old data, illustrating how changes in data entries are tracked over time.'}, {'topic': 'Trigger Implementation', 'start_time': '00:43:05', 'end_time': '00:43:29', 'transcript': "So and then you execute that function. So this this particular is there. That's why we have excess to trigger. So let's do and simply hands on. Alleges show you on the project how we are creating different triggers for different kinds of usage and deletes are like Want to clarify van? It's a daily trigger.", 'keywords': ['Trigger Implementation', 'Function Execution', 'Hands-on Demonstration'], 'summary': 'The speaker discusses the execution of a function related to trigger implementation, highlighting the necessity of triggers for various use cases. They emphasize a hands-on approach by demonstrating the creation of different triggers within a project, specifically mentioning daily triggers and the purpose of using them for deletion tasks.'}, {'topic': 'Trigger Configuration', 'start_time': '00:43:30', 'end_time': '00:43:49', 'transcript': "it only has access to old kind of this before you're deleting Arroyo are not creating a new row of a delete, so you have the access of all those old values before and after update after delete both. This access is very important. So that's why you can", 'keywords': ['Trigger Configuration', 'Database', 'Data Integrity'], 'summary': 'The transcript discusses the concept of trigger configuration, highlighting the access to old values before and after events like updates and deletions in a database. This access is deemed crucial for understanding the implications of these operations, particularly in the context of data integrity and management.'}, {'topic': 'Project Trigger Example', 'start_time': '00:43:49', 'end_time': '00:44:01', 'transcript': 'you have the literature record, but you want to create a another table. With the snapshot of that, the record this record was related. This can be achieved only by trigger NARC bias toward proceeds.', 'keywords': ['Trigger', 'Literature Record', 'Data Management'], 'summary': 'The discussion focuses on the process of creating a new table that captures a snapshot of a literature record, highlighting its relationship to another record. The speaker mentions that this can be accomplished specifically through the use of a trigger, which is part of a system that manages data operations and biases toward the necessary procedures.'}, {'topic': 'Trigger Functionality in Practice', 'start_time': '00:44:02', 'end_time': '00:44:28', 'transcript': 'and this has your you can have within that what functionality you want to do, You can have it. as the store procedure of function only they internally execute a function on all these tricks. So this this function can be written 100 days. But vesting the trigger is it can has access of all and a lot of different things which I can chew.', 'keywords': ['Trigger', 'Functionality', 'Database'], 'summary': 'The discussion focuses on the functionality of triggers in database systems, highlighting that triggers can execute functions automatically in response to specific events. The speaker explains that while a function may be defined and reusable, triggers have the capability to access a wide range of data and operations, enhancing their utility in various scenarios.'}, {'topic': 'Dynamic Trigger Implementation', 'start_time': '00:44:31', 'end_time': '00:45:06', 'transcript': 'this answer. So is showing you example of one. I will not be creating it right now because of some wrong access issues on triggers and all are destroyed. I tell you. You know what are some limitations of triggers also? So this particular trigger is created another one of our', 'keywords': ['Dynamic Triggers', 'Implementation', 'Limitations'], 'summary': 'The discussion focuses on the implementation of dynamic triggers, with the speaker indicating that they will provide an example. However, they refrain from creating it in real-time due to access issues and the concerns about triggers being destroyed. The speaker also mentions the limitations associated with triggers.'}, {'topic': 'Trigger Functionality', 'start_time': '00:45:06', 'end_time': '00:45:28', 'transcript': 'project. And it has whenever we update a particular column a soppy I mean, it is on one of the table. This was internal function which was created. It has some some keys. Also some sect words, TG. So this particular was function was return so that', 'keywords': ['Trigger', 'Functionality', 'Database'], 'summary': 'The transcript discusses the functionality of a trigger within a project, specifically focusing on how it activates whenever a particular column is updated in a specific table. It mentions that this internal function was created with certain keys and keywords, indicating its purpose and operational context.'}, {'topic': 'Trigger Usage in Projects', 'start_time': '00:45:29', 'end_time': '00:45:50', 'transcript': 'we can use it in update mode also. And we can you till insert mode also. So both the triggers in certain update can cause the same function. But how we distinguish it, whether it has been a update. Moderate insert. We have a T g upset. So based on that,', 'keywords': ['Triggers', 'Update Mode', 'Insert Mode'], 'summary': "The discussion focuses on the usage of triggers in projects, explaining their functionality in both update and insert modes. It highlights how both types of triggers can invoke the same function, and introduces a method for distinguishing between them using a specific parameter, referred to as 'T g upset'."}, {'topic': 'Trigger Logic in Practice', 'start_time': '00:45:50', 'end_time': '00:46:00', 'transcript': 'we were changing some values. If it was insert, we were doing something. And if it was date, if Khun catting it with previous values and that', 'keywords': ['Trigger Logic', 'Insert Operation', 'Value Comparison'], 'summary': 'The transcript discusses the practical application of trigger logic, specifically focusing on the manipulation of values during an insert operation. It touches upon the process of comparing the current values with previous ones, although the details are somewhat fragmented.'}, {'topic': 'Trigger Use Case', 'start_time': '00:46:02', 'end_time': '00:46:15', 'transcript': "and we were using If you see in update we were using new and we were also using the old tax. But in an insert operation we have a new robe but we don't have a old room now. There was.", 'keywords': ['Trigger', 'Database Operations', 'Insert'], 'summary': 'The discussion focuses on the trigger use case, highlighting the distinction between using new and old records during different database operations. Specifically, it addresses the situation where both new and old records are utilized in update operations, while in insert operations, only new records are available, leading to different handling in these scenarios.'}, {'topic': 'Trigger Functionality and Limitations', 'start_time': '00:46:16', 'end_time': '00:46:25', 'transcript': 'You are This is for a particular road so hot There was no previous value. It is new, so only we have this new dot tax notice.', 'keywords': ['Trigger Functionality', 'Limitations', 'Tax Notice'], 'summary': 'The transcript discusses a specific road and mentions the absence of previous values, indicating that the subject matter is related to a new situation or element, specifically referencing a new dot tax notice. The context suggests a focus on the functionality and limitations of a trigger associated with this new data.'}, {'topic': 'Trigger Usage', 'start_time': '00:46:26', 'end_time': '00:47:03', 'transcript': "they don't have. If you will see the value of all non tax, it will be not. and this kind of thing disposal trigger that we was Khun Cat knitting it in the column. If some some column has changed, just we were updating all the another column. Based on that, we will concur ordinating tag names with tanks. So this was for some calculations, and another function we rode for was the audit long", 'keywords': ['Triggers', 'Data Management', 'Auditing'], 'summary': 'The discussion focuses on the usage of triggers, particularly in the context of non-tax values and their implications for data management. The speaker explains that when a specific column changes, it necessitates updating other related columns accordingly. Additionally, there is a mention of coordinating tag names with tanks for calculation purposes, as well as referencing the creation of a function for auditing logs.'}, {'topic': 'User Logging', 'start_time': '00:47:03', 'end_time': '00:47:14', 'transcript': 'whenever a table was changed. we wanted. a log to be maintain if you want to see that long has show you', 'keywords': ['User Logging', 'Table Modification', 'Change Tracking'], 'summary': 'The transcript discusses the necessity of maintaining a log whenever a table is modified. The speaker emphasizes the importance of having this log for tracking changes and indicates a desire to demonstrate how the log functions.'}, {'topic': 'Change Tracking', 'start_time': '00:47:19', 'end_time': '00:47:44', 'transcript': "the we were facing with the problem. One of the table name was some column names or changing through some value, and we were not able to know. You know why the application is failing? Who changes value though somebody we're changing manually or not. So we created one lakh table father's. So whenever one tabled a", 'keywords': ['Change Tracking', 'Database', 'Application Failure'], 'summary': 'The discussion revolves around a problem with change tracking in a database, specifically highlighting issues with column names and values that were being altered without clear visibility. The speaker points out the difficulty in identifying the cause of application failures, questioning whether changes were made manually. To address this issue, a solution involving the creation of a new table is mentioned, which aims to track changes more effectively.'}, {'topic': 'Data Change Tracking', 'start_time': '00:47:44', 'end_time': '00:48:16', 'transcript': 'column changes, whichever column changes its new value and all value were printed. So you can see this particular column was made from trying to falls on this. And it was also because it was a row level was also storing the primary key for this. This was the primary key, and this value was become from through to false of all studio. For this and is very important for this is a few way kind of environmental when I am showing you all this. But', 'keywords': ['Data Change Tracking', 'Primary Key', 'Column Changes'], 'summary': 'The transcript discusses the concept of data change tracking, focusing on how changes in specific columns are recorded, including their new values. It highlights the importance of tracking changes at the row level, particularly in relation to primary keys. The speaker notes the significance of this process in various environmental contexts, although the explanation is somewhat fragmented.'}, {'topic': 'User Tracking', 'start_time': '00:48:17', 'end_time': '00:48:37', 'transcript': 'this was to, you know, find out the root cause and allies is also for some problems. Why it has occurred then was it made to an vase? It made falls all the date and time and law was menting and also this trigger function as access to the user name. Also who who was the user who ran it.', 'keywords': ['User Tracking', 'Root Cause Analysis', 'Data Collection'], 'summary': 'The transcript discusses the purpose of user tracking, which is aimed at identifying the root causes of certain issues. It mentions the collection of data, including timestamps and user actions, to analyze problems effectively. Additionally, it highlights a trigger function that accesses the username of the individual who executed the tracking.'}, {'topic': 'Trigger Use Case', 'start_time': '00:48:38', 'end_time': '00:48:57', 'transcript': 'and what was the value and this really help us and tracking the issues. who how they were generated. and even a few where user, if they are incorrectly updated, they could have been also corrected Also from this.', 'keywords': ['Trigger', 'Issue Tracking', 'Data Correction'], 'summary': 'The transcript discusses the value of tracking issues related to triggers, focusing on understanding how these issues were generated. It also touches on the ability to correct instances where users might have incorrectly updated data, highlighting the importance of maintaining accurate records.'}, {'topic': 'Dynamic Trigger Logic', 'start_time': '00:48:58', 'end_time': '00:49:13', 'transcript': 'So again we use that kind of. If you see this function was created a Prague under law and internally. This is very this was actually I had', 'keywords': ['Dynamic Trigger Logic', 'Function Creation', 'Legal Framework'], 'summary': 'The transcript briefly discusses the creation of a function related to dynamic trigger logic, mentioning its development in Prague under specific legal frameworks. The speaker highlights the internal aspects of this function, although the details are limited.'}, {'topic': 'Trigger Flexibility', 'start_time': '00:49:14', 'end_time': '00:49:44', 'transcript': "created more flexible and dynamic. In that sense, you can't limited to one table. I had made the option, even whichever tabled updated. If the table in is not just fixed one table MD and you the chair bird table Ling is updated. We can change that table name also so but trigger we made active only on this day and you So it's recording on Lydia.", 'keywords': ['Trigger Flexibility', 'Database Management', 'Dynamic Triggers'], 'summary': "The transcript discusses the concept of trigger flexibility in database management, highlighting the ability to create more dynamic and adaptable triggers that are not limited to a single table. The speaker explains that the trigger functionality allows for updates to multiple tables, enabling the system to reflect changes in real-time. The mention of 'active only on this day' suggests a specific condition for trigger activation, emphasizing its dynamic nature."}, {'topic': 'Trigger Code Sharing', 'start_time': '00:49:45', 'end_time': '00:50:10', 'transcript': "So this trigger has access to this function. Also. Tichy Table name, sir. TV means triggers stable. which table has triggered this stable. So this trigger itself, it's not difficult to court same like store procedure, but has some extra variables also. So that then tg relation. I'd so you have this kind of", 'keywords': ['Trigger', 'Stored Procedure', 'Tichy Table'], 'summary': "The transcript discusses the concept of trigger code sharing, detailing how a trigger has access to specific functions and references a Tichy Table, which indicates the table related to the trigger. The speaker explains that while writing this trigger is not significantly challenging compared to stored procedures, it includes additional variables, such as 'tg relation'."}, {'topic': 'Trigger Functionality', 'start_time': '00:50:11', 'end_time': '00:50:24', 'transcript': 'columns also. So if anyone wants this code, I can share it. I think good piece of court to be used in order locks and most of the applications have any further.', 'keywords': ['Trigger', 'Order Locks', 'Applications'], 'summary': 'The speaker discusses the functionality of a trigger in coding, highlighting its utility in order locks and various applications. They also offer to share the code with anyone interested, suggesting its effectiveness as a good piece of code.'}, {'topic': 'Trigger Functionality in Practice', 'start_time': '00:50:24', 'end_time': '00:50:33', 'transcript': 'so which table value changes towards everything can be recorded and the primary key, particularly whichever is the primary key we can find out that also.', 'keywords': ['Trigger', 'Primary Key', 'Database'], 'summary': 'The transcript discusses the functionality of triggers in database systems, focusing on how changes in table values can be recorded. It highlights the importance of the primary key in identifying which specific record has changed.'}, {'topic': 'Session Questions', 'start_time': '00:50:34', 'end_time': '00:51:01', 'transcript': 'So this is our and is any questions. any questions. I reckon, and I know was slightly heavy topic for few.', 'keywords': ['Questions', 'Engagement', 'Audience'], 'summary': 'The session opens with an invitation for questions from the audience, acknowledging that the previous topic may have been somewhat challenging for some attendees. The speaker encourages engagement and addresses any uncertainties.'}, {'topic': 'Trigger Application Questions', 'start_time': '00:51:02', 'end_time': '00:51:21', 'transcript': 'But idea is to get the concept of triggers. They will be automatically licking. We want be kicking if he initialised this trigger on a table on account. Suppose updates whenever is updated, it will because ensure your in own data cheques or whatever you do and', 'keywords': ['Triggers', 'Database', 'Data Integrity'], 'summary': 'The transcript discusses the concept of triggers in a database context. It highlights that triggers will be automatically activated, particularly when they are initialized on a specific table. The speaker emphasizes that the triggers are designed to respond to updates, ensuring that any changes made are properly reflected in the data checks or processes involved.'}, {'topic': 'Trigger Function Questions', 'start_time': '00:51:25', 'end_time': '00:51:40', 'transcript': 'questions. now I request everyone. If you have questions, you can please a new door celebrant. Ask otherwise, I cannot see anything on child box right now.', 'keywords': ['Trigger Function', 'Audience Engagement', 'Questions'], 'summary': 'The speaker invites the audience to ask questions regarding the trigger function, encouraging participation and emphasizing the importance of interaction. They note that currently, they cannot see any questions in the chat box, indicating a need for audience engagement.'}, {'topic': 'Session Closing', 'start_time': '00:51:47', 'end_time': '00:52:15', 'transcript': "so I'm just taking the last topic them out of it, the triggers which are instead of triggers. So just wanted to explain this is a situation in this kind of situation. Like we are using lot of views and mata lies views in our projects. So sometimes we just give access to of you to a user. But something like this was an employee cable, and this was a department table,", 'keywords': ['Triggers', 'Views', 'Materialized Views'], 'summary': 'The session closing remarks focus on the topic of triggers and their alternatives in project implementations. The speaker elaborates on the use of various views and materialized views, particularly in scenarios where access is granted to users. They mention a specific case involving employee and department tables, highlighting the complexities and considerations in managing access rights.'}, {'topic': 'Trigger Usage in Views', 'start_time': '00:52:15', 'end_time': '00:52:28', 'transcript': 'and we combined these tour one common view. We removed the department idea, um, to user. It was this only now, if user his typing suppose seventh record in it.', 'keywords': ['Triggers', 'Views', 'Data Management'], 'summary': 'The transcript discusses the integration of triggers within a unified view, mentioning the removal of the department identifier for user clarity. It highlights a scenario where a user is interacting with the system, specifically referencing the input of a record, illustrating the practical application of triggers in managing data inputs.'}, {'topic': 'Trigger Use Cases', 'start_time': '00:52:29', 'end_time': '00:52:42', 'transcript': 'then six. Like Ben Mail H R it want let you in of you view should give a feeling to the user s separatist table but they are not able to Ankara recalls normally.', 'keywords': ['Triggers', 'User Experience', 'Use Cases'], 'summary': 'The transcript discusses a specific use case related to triggers, suggesting that the user experience should be enhanced through a separate table. However, it notes that there are limitations, as users are unable to access this information normally.'}, {'topic': 'Trigger Application', 'start_time': '00:52:42', 'end_time': '00:53:05', 'transcript': "But if you have to allow them to anchor a record we should be using instead of triggers I want go into the details of Instead of triggers on Lee Thing is same Sing dykes. like if he don't have instead of tigers. If I would have run this insert into this this value this, I would have got this.", 'keywords': ['Triggers', 'Database', 'Insert Statements'], 'summary': 'The speaker discusses the use of triggers in database applications, suggesting that there are preferable methods for anchoring records. They emphasize that instead of relying on triggers, alternative approaches should be considered, particularly mentioning the implications of using insert statements. The speaker appears to be explaining the limitations of triggers and advocating for a different strategy in managing database records.'}, {'topic': 'Trigger Logic', 'start_time': '00:53:05', 'end_time': '00:53:30', 'transcript': 'I would have gone this views not updated table because the modification of affect multiple bay states so normally in a situation we will ignore it. We will say to the client, This is not up table view. No, but we can an instead of trigger we can define, we can define support. This row has come a charred we know a charge department i ds three.', 'keywords': ['Trigger Logic', 'Database Management', 'Support Definition'], 'summary': 'The speaker discusses the concept of trigger logic, highlighting the importance of not using outdated tables due to their potential impact on multiple states. They suggest that in such scenarios, it is advisable to inform the client about the limitations of the table view. Furthermore, the speaker introduces the idea of defining support instead of relying solely on triggers, mentioning a specific row associated with a charge department.'}, {'topic': 'Trigger Logic', 'start_time': '00:53:30', 'end_time': '00:53:39', 'transcript': 'It was inserting for the it. So the it department at is one internally should cheque it and save that reform in', 'keywords': ['IT Department', 'Reform', 'Internal Processes'], 'summary': 'The transcript discusses a process involving the IT department, emphasizing the importance of checking and saving reform internally. The speaker highlights the need for careful handling of certain tasks within the department.'}, {'topic': 'Trigger Logic', 'start_time': '00:53:39', 'end_time': '00:54:03', 'transcript': "So we can modify that logic so internally to the client and level Kashmir will never be aware what is happening in the trigger. They can't see the triggers. This is snow automatic and it's hard to identify the errors also intrigue assed so they want to know about. But so for you only if you have to allow", 'keywords': ['Trigger Logic', 'Error Identification', 'Client System'], 'summary': 'The discussion focuses on modifying trigger logic within a client system, emphasizing that the internal workings of triggers remain invisible to the client. This obscurity makes error identification challenging. The speaker highlights the importance of understanding this logic for those who require access to it.'}, {'topic': 'Trigger Logic', 'start_time': '00:54:04', 'end_time': '00:54:14', 'transcript': 'a concert of a update of A If you which is found to separate Davis, they will say Crate bigger this in Tex.', 'keywords': ['Trigger Logic', 'Update', 'Condition'], 'summary': 'The transcript appears to discuss a specific aspect of trigger logic, possibly in the context of updates or conditions. It mentions the separation of elements, likely related to programming or system design, but lacks clarity and coherence in the phrasing.'}, {'topic': 'Trigger Logic', 'start_time': '00:54:15', 'end_time': '00:54:28', 'transcript': "And here, instead of table name, we can write the view name. that's and it won't be a before update, it will be instead ofthe update on instead of insert.", 'keywords': ['Trigger Logic', 'Database Management', 'Views'], 'summary': "The discussion focuses on the implementation of trigger logic in database management, specifically highlighting the use of view names instead of table names. It also clarifies the distinction between 'before update' triggers and 'instead of' triggers for updates and inserts."}, {'topic': 'Trigger Logic', 'start_time': '00:54:30', 'end_time': '00:54:57', 'transcript': 'and last, not the laced. What are the advantages of trigger as we just got to know it? Help us to maintain the integrity of data Where I know this. If this data is updated or changes should be changed in the foreign table also, and that will be useful for catching some errors like I saw we created or Dick Log and be maintained. Then was it changed? And by whom?', 'keywords': ['Trigger Logic', 'Data Integrity', 'Foreign Table'], 'summary': 'The transcript discusses the advantages of trigger logic, highlighting its role in maintaining data integrity. It explains that when data is updated, corresponding changes should also occur in the foreign table, which is essential for identifying errors. Additionally, it mentions the importance of logging changes, including details on what was modified and by whom.'}, {'topic': 'Trigger Logic', 'start_time': '00:54:57', 'end_time': '00:55:15', 'transcript': "And this is alternative way to run a schedule towns, because it's automatic way of kicking whenever insert happens. Help was an auditing. It helps and prevention of Khun valid transactions. They can do validation and we can just throw an era and don't let.", 'keywords': ['Trigger Logic', 'Automated Scheduling', 'Transaction Validation'], 'summary': 'The transcript discusses an alternative method for running scheduled tasks, highlighting its automated nature that triggers actions upon the occurrence of an insert. This approach aids in auditing processes and helps prevent invalid transactions by allowing for validation checks, which can lead to error generation if validation fails.'}, {'topic': 'Trigger Logic', 'start_time': '00:55:16', 'end_time': '00:55:25', 'transcript': 'the insertion of record and we can log of events. As I said, the DD L triggers are there, and there are some', 'keywords': ['Trigger Logic', 'DDL', 'Event Logging'], 'summary': 'The transcript discusses the concept of trigger logic, specifically focusing on the insertion of records and the logging of events. It mentions DDL (Data Definition Language) triggers and hints at the existence of additional related topics.'}, {'topic': 'Trigger Logic', 'start_time': '00:55:27', 'end_time': '00:55:45', 'transcript': "user log in events also, which can be also long triggers. But there are some disadvantages of trigger and be careful and using it. They cannot replace all relegations. Some validation will have to be done and the application level or separately. Also, the can't handle each and every,", 'keywords': ['Trigger Logic', 'User Login Events', 'Validation'], 'summary': 'The transcript discusses the concept of trigger logic, particularly in the context of user login events. It highlights that while triggers can be useful, they have disadvantages and cannot replace all regulations. The speaker notes the necessity for some validation to be performed at the application level or separately, indicating that triggers cannot handle every scenario.'}, {'topic': 'Trigger Logic', 'start_time': '00:55:46', 'end_time': '00:56:01', 'transcript': "and they are invisible from client applications. Client application will never know met, so his chances. If there are triggered being kicked automatically, they will not know why it's being duplicated. If they were not aware of it and", 'keywords': ['Trigger Logic', 'Client Applications', 'Automatic Triggers'], 'summary': 'The transcript discusses the concept of trigger logic, highlighting how certain triggers operate invisibly from client applications. It points out that client applications remain unaware of the automatic triggers being activated, which can lead to unrecognized duplications.'}, {'topic': 'Trigger Logic', 'start_time': '00:56:02', 'end_time': '00:56:28', 'transcript': "they but imposed load on a server, they can make your database server slow, and it is not recommended for high velocity of data. That data is changing very rapidly. The streaming get on where there are millions of rose. It's better to have a storey for Caesar and have extra functionality in your client application, which cause those stored procedure.", 'keywords': ['Server Load', 'Database Performance', 'Stored Procedures'], 'summary': 'The transcript discusses the implications of imposed load on a server, specifically highlighting how it can slow down a database server, especially under high data velocity conditions where data changes rapidly. It suggests that in scenarios involving millions of rows, it is more effective to utilize stored procedures and enhance functionality in the client application rather than overloading the server.'}, {'topic': 'Trigger Logic', 'start_time': '00:56:29', 'end_time': '00:56:40', 'transcript': "Otherwise, they can make a lock also in your so be careful and using them. This is all about triggers, and it's for procedures. They're good ways to", 'keywords': ['Trigger Logic', 'Procedures', 'Locks'], 'summary': 'The discussion focuses on trigger logic, specifically in the context of procedures. The speaker warns about the careful use of triggers, indicating that they can also lead to locks if not handled correctly. Overall, the dialogue emphasizes the importance of understanding trigger mechanisms.'}, {'topic': 'Trigger Logic', 'start_time': '00:56:41', 'end_time': '00:56:51', 'transcript': "dough programming and ask you and maintaining data integrity and cheques. So that's all on my side. Any questions you have Welcome otherwise.", 'keywords': ['Trigger Logic', 'Data Integrity', 'Programming'], 'summary': 'The transcript discusses trigger logic in the context of programming, emphasizing the importance of maintaining data integrity and checks. The speaker invites questions from the audience, indicating a willingness to clarify any uncertainties regarding the topic.'}, {'topic': 'Trigger Logic', 'start_time': '00:56:52', 'end_time': '00:57:07', 'transcript': 'can. and the session, I mean. Mm. I have a question. his place. How is is desist it, Baloo in pollution', 'keywords': ['Trigger Logic', 'Pollution'], 'summary': 'The transcript features a brief and somewhat disjointed conversation about trigger logic, though the specific details are unclear. The speaker poses a question related to the topic, indicating a discussion on its implications, possibly in a broader context like pollution, but the content lacks clarity and depth.'}, {'topic': 'Trigger Logic', 'start_time': '00:57:07', 'end_time': '00:57:36', 'transcript': 'high. Tell me. greetings. Go to that instead of trigger flied? Yeah, sure. a difficult for mind information. Like, I would like to know if if I want to inferred something in this in this lower one lower view. which does not come from I T department, which is from some new department can and do that', 'keywords': ['Trigger Logic', 'Information Inference', 'Department Integration'], 'summary': 'The transcript presents a dialogue about trigger logic, where the speaker expresses a desire to understand how to infer information from a department outside of the IT sector. The conversation suggests a challenge in integrating or interpreting data from a new department, highlighting the complexities involved in trigger logic applications.'}, {'topic': 'Trigger Logic', 'start_time': '00:57:37', 'end_time': '00:57:46', 'transcript': "very good question. So, you know, again, that's a choice with a new within a trigger to raise an error out, throw an era.", 'keywords': ['Trigger Logic', 'Error Handling', 'Database'], 'summary': 'The speaker addresses a question regarding trigger logic, explaining that the choice to raise an error or throw an error is an important decision within the context of triggers. This highlights the flexibility and considerations involved in implementing trigger logic effectively.'}, {'topic': 'Trigger Logic', 'start_time': '00:57:46', 'end_time': '00:58:14', 'transcript': "this idea department does not exist. Or then you get, you know, in the programming where nothing is impossible. If you see the, uh, department name is not there. So you suppose this is an automatic and agreement kind kind of sequence? I'd you just insert that department and do it this again. If blocks are there, it blocks are possible.", 'keywords': ['Trigger Logic', 'Programming', 'Department'], 'summary': 'The transcript discusses the concept of trigger logic in programming, particularly focusing on the existence of departments within a system. It highlights the situation where a department may not exist and suggests that programming allows for the possibility of inserting a department and executing a sequence again. The speaker also mentions the importance of blocks in this context.'}, {'topic': 'Trigger Logic', 'start_time': '00:58:14', 'end_time': '00:58:27', 'transcript': 'in that gift, will it be inferred ID in the base views also. Yeah, if you are inserting it. always remember when we are inserting a recording of you, it goes into the based it.', 'keywords': ['Trigger Logic', 'ID Inference', 'Data Insertion'], 'summary': 'The transcript discusses the concept of trigger logic, specifically addressing the inference of an ID in base views when inserting records. The speaker emphasizes the importance of remembering how the insertion process operates, particularly in relation to the base data.'}, {'topic': 'Trigger Logic', 'start_time': '00:58:27', 'end_time': '00:58:42', 'transcript': 'okay? like five iffy delayed from the base views. Similarly, that updated should also go into the lower one.', 'keywords': ['Trigger Logic', 'Delayed Updates', 'Synchronization'], 'summary': 'The transcript discusses the concept of trigger logic, specifically referring to the implementation of delayed updates in a system. It mentions that updates should be reflected in both the base views and the lower views, indicating a need for synchronization in the logic applied.'}, {'topic': 'Trigger Logic', 'start_time': '00:58:42', 'end_time': '00:59:00', 'transcript': 'Yeah. Depends on the permission on the views. More kind of commissions you have. And again, you might need a instead of trigger, which will handle all that quickly. So because the data integrity should should be maintained if you are deleting that so it might.', 'keywords': ['Trigger Logic', 'Data Integrity', 'Database Management'], 'summary': 'The discussion revolves around trigger logic in database management, specifically focusing on the importance of permissions and views. The speaker highlights the necessity of using triggers to manage data integrity, especially when performing deletion operations.'}, {'topic': 'Trigger Logic', 'start_time': '00:59:01', 'end_time': '00:59:13', 'transcript': "Yeah. So the business logic You really want to give that right to them to delete it? Science. If you don't want to, then you just control it. You can't delete it, but you can delay that employees.", 'keywords': ['Trigger Logic', 'Business Logic', 'User Permissions'], 'summary': "The conversation revolves around the topic of trigger logic in business applications. The speaker discusses the importance of providing users the ability to delete certain elements within the system, implying that there's a need to manage permissions carefully. If deletion is not desired, alternative controls can be implemented to delay action rather than allowing immediate deletion."}, {'topic': 'Trigger Logic', 'start_time': '00:59:14', 'end_time': '00:59:33', 'transcript': "So it's a decision of programmer and the product managers real if they really want only the employed a vigil later. They can tell you if they don't want to let it the delete use than razor error. No, it can't be deleted. Permission denied of whatever.", 'keywords': ['Trigger Logic', 'Permissions', 'Error Handling'], 'summary': 'The transcript discusses trigger logic in programming, focusing on the decision-making process of programmers and product managers regarding permissions for deleting certain elements. It highlights the importance of defining whether an item can be deleted or not, emphasizing that if deletion is not allowed, an error message will be presented to indicate permission denial.'}, {'topic': 'Trigger Logic', 'start_time': '00:59:34', 'end_time': '00:59:49', 'transcript': "Slater in that referential integrating. so it's all depends on. the bank. Um um that's it. and even else.", 'keywords': ['Trigger Logic', 'Integrating', 'Bank'], 'summary': 'The transcript provides a brief and somewhat fragmented discussion on trigger logic, mentioning its reliance on certain factors related to banks. The content appears to be incomplete and lacks a comprehensive explanation of the topic.'}, {'topic': 'Session End', 'start_time': '00:59:55', 'end_time': '01:00:04', 'transcript': 'so I think we have always almost finished the time on sore Swimmer. No one has cautioned we can end the session. That Okay, Um', 'keywords': ['Session', 'Conclusion', 'Time Management'], 'summary': 'The transcript concludes with a brief remark indicating that the session is nearing its end. The speaker notes that the time allocated for the discussion is almost up and suggests that it is appropriate to conclude the session.'}, {'topic': 'Session Feedback', 'start_time': '01:00:04', 'end_time': '01:00:33', 'transcript': 'um, okay, sure. Thank you. Thank you so much, Mom, for this wonderful session and to all a few of the recording of this session and the feedback phone that shall be attached on the A couple of Oh, it says. And since you have the access and Karhan has already guided you with the steps, you can access it and fill the feedback home as well. If not, he also will be sharing the session or details again tomorrow.', 'keywords': ['Feedback', 'Session', 'Recording'], 'summary': 'The speaker expresses gratitude for the session and mentions the availability of a recording along with a feedback form that will be attached. They inform the audience that they can access and fill out the feedback form, highlighting that guidance has been provided by a person named Karhan. Additionally, they indicate that session details will be shared again the following day.'}, {'topic': 'Feedback Reminder', 'start_time': '01:00:33', 'end_time': '01:00:43', 'transcript': 'And you can go through the steps. And according the march of feedback and also go through the other Jha solution recordings, which are there on the and a collab.', 'keywords': ['Feedback', 'Jha Solutions', 'Collaboration'], 'summary': 'The speaker encourages the audience to review the steps related to feedback and suggests accessing other relevant Jha solution recordings available on the platform, as well as on a collaborative environment.'}, {'topic': 'Session Wrap-up', 'start_time': '01:00:49', 'end_time': '01:00:55', 'transcript': 'is it fine? Thank you.', 'keywords': ['Session Wrap-up', 'Acknowledgment', 'Audience Interaction'], 'summary': 'The session concludes with a brief acknowledgment, where the speaker checks in with the audience, expressing gratitude. The interaction is concise, indicating a positive wrap-up of the session.'}], 'yellow_line': [{'Topic': 'Session Introduction', 'transcript': 'first of all, a very good afternoon, everyone. So today we have a session by Renko. Mom. So she is the square lead here.', 'start_time': '00:00:29', 'end_time': '00:00:42'}, {'Topic': 'Network Issues & Session Overview', 'transcript': 'and my audible. Yes, us. Um Okay, so I think I am facing some network issues in my area. So I was just informing the Singh. Okay, So we will be having the topic for today as told procedures and triggers, which is a part of s cumin.', 'start_time': '00:00:43', 'end_time': '00:00:59'}, {'Topic': 'Topics Overview', 'transcript': "And the list of topics that ma'am shall be covering would be stored procedure and functions and eh, skewed. Then SQL triggers in different type, soft Rikers difference between store procedure and triggers some hands on with stored procedures and triggers. So Emmerich Mamady is though that", 'start_time': '00:00:59', 'end_time': '00:01:16'}, {'Topic': 'SQL Training Demand', 'transcript': 'was actually registered on the screen also can see my screen. Good afternoon, everyone. just about to start the session and wanted to share, you know, had been lost of request on SQL training from various Q people Anglo helpers. So, of course, as skilled as a big topic in its at Serra Silicon cover everything in here', 'start_time': '00:01:16', 'end_time': '00:01:46'}, {'Topic': 'Previous SQL Training', 'transcript': "earlier, I have taken some basic and advanced skill training with joins and some indexers. And if you want to see similar, please share the recording if you happen to see that in chat window, so that people can refer if they won't have. questions on group by how we aggregate in sq Wales. Very basic, a scale or advance and Dex is and performance that I have already given last year.", 'start_time': '00:01:47', 'end_time': '00:02:16'}, {'Topic': 'Stored Procedures Basics', 'transcript': 'So if if anyone is interested in knowing that they can seem a video. So this particular topic I had taken as a 01 part of Israel which is stored for season and triggers why I have taken that this a more a kind of programming we need in this area. So normally, an SQL is just a statement wise. You run individually some statements when you', 'start_time': '00:02:17', 'end_time': '00:02:45'}, {'Topic': 'SQL Use Cases', 'transcript': 'use SQL, but there are ways in ask you a which allow view to do according as well and for Luke if flow of these kind of things have there. So this is very much useful for our day to day operation where we are doing some repeated works and we want to', 'start_time': '00:02:45', 'end_time': '00:03:06'}, {'Topic': 'SQL Knowledge Requirement', 'transcript': 'keep that cold ready and avoid Manuel work. So for this, a basic s Q and knowledge, I think person should have it and but it will be useful for Cuba people as well as the developers', 'start_time': '00:03:06', 'end_time': '00:03:21'}, {'Topic': 'Function Syntax & Differences', 'transcript': "trying to keep it as simple. We will have to see that cheque? The time also. But I would share some codes which can be useful for people. And also this have taken databases as opposed this as Curiel right now. But what? I'm trying this If you if you know what is the store procedure and how to write it. Slights and tax might become different in my SQL or snow. Ask us.", 'start_time': '00:03:22', 'end_time': '00:03:49'}, {'Topic': 'Function Logic', 'transcript': "But I think if understanding of logic, if you understand the logic that will remain same know your concept should be clear than to use function when to use for Caesar's and triggers rest. Adding Centex likes you can always find on Google", 'start_time': '00:03:49', 'end_time': '00:04:06'}, {'Topic': 'Database Functions', 'transcript': "are that particular documentation for that particular databases? So while day mowing, I might use progress SQL. But feel free to apply that concepts and you're on date of is whether you're working in Oracle or Snow, Snow Flake or whatever snowflake training re might do next month specific to snowflake. But this particular is passports, Chris asked", 'start_time': '00:04:06', 'end_time': '00:04:35'}, {'Topic': 'Common SQL Functions', 'transcript': 'So first in all the most commonly used, you know, think in the snow are SQL Programming is user defined functions. Now, this user defying function are itself mistakenly taken as showed procedure. So, um,', 'start_time': '00:04:36', 'end_time': '00:04:57'}, {'Topic': 'User Defined Functions', 'transcript': "you know, when we are actually talking about sold procedure, most of the users are actually writing a functions on leaf. So because this not much difference between the two, but yes, there is difference which we will understand. So this user defying functions the Charlie Common Court, a complex calculation, whichever you want to do on something and you're organised that one together. So that is going to", 'start_time': '00:04:58', 'end_time': '00:05:26'}, {'Topic': 'Built-in Functions', 'transcript': 'perform a particular function. Now every database has its on and functions Also, I think whenever you have done maybe infighter anywhere, most of the people might have used this function lower.', 'start_time': '00:05:26', 'end_time': '00:05:40'}, {'Topic': 'Case Functions', 'transcript': 'l case or lowers some database Has l case as there and some has a lower which which will just what will do', 'start_time': '00:05:41', 'end_time': '00:05:50'}, {'Topic': 'Lower Case Function', 'transcript': "it will change the from whatever case it is to lower case. So this if you see this select lower ABC, this is this Lower is not a user defined function. It is a function. It's a database function. It's a built in function", 'start_time': '00:05:50', 'end_time': '00:06:10'}, {'Topic': 'Interest Calculation Function', 'transcript': 'so built in function and ask your are there but you can write your on functions. Also, Suppose I want to have a a mom, you all must have done in Mass. Also, how do I do interest calculation if I have a principal amount with me and I have the time with me and interest rates so on these functions are everything can be part of a function ability, infection, but we can.', 'start_time': '00:06:10', 'end_time': '00:06:37'}, {'Topic': 'Function Creation Example', 'transcript': "create a function for the particular matter Ology like I I am going to show you. You know how we create a function Suppose I want I want a functionality When two numbers are given, we just multiply that and give the not saying this is not possible in database, but I'm just writing a simple function", 'start_time': '00:06:37', 'end_time': '00:07:02'}, {'Topic': 'Function Parameters', 'transcript': 'how to ride that function. I am going to slip that is one. so Suppose I want to test this far. What is the Centex for function? So once I just about to show you', 'start_time': '00:07:03', 'end_time': '00:07:19'}, {'Topic': 'Function Declaration', 'transcript': "So this is very simple. Centex and Post press with great or replaced function name and then you have a parameter declarations. Whichever pair a mentor you want and then returns in teacher, whatever kind of it it returns, it can return. If you don't want the function to return anything, you can simply write returns world also function can do something and it may not. Return also won value to you", 'start_time': '00:07:27', 'end_time': '00:07:56'}, {'Topic': 'Function Usage', 'transcript': 'and there is a declare section where you declare variables and then the block main block is there where you will do some calculation and you return that. show you a happy to this writing one simple function. which takes one in teacher of 42 and teachers and simply multiplying it and returning this world', 'start_time': '00:07:56', 'end_time': '00:08:20'}, {'Topic': 'Dynamic SQL', 'transcript': "very basic math. And if you say now, I just used this function, how do I use it? I can't use it simply in a select statement.", 'start_time': '00:08:20', 'end_time': '00:08:32'}, {'Topic': 'Function Output', 'transcript': 'so far, and I need to pass the parameters. This was the declaration and 98 to pass this. So how will I do? Suppose I want a', 'start_time': '00:08:34', 'end_time': '00:08:44'}, {'Topic': 'Function with Multiple Returns', 'transcript': "tradition and just see the answer. It's just so when you are going to use a function, whatever you write, the the insight thing is executed and it becomes like a normal.", 'start_time': '00:08:44', 'end_time': '00:09:02'}, {'Topic': 'SQL Function Parameters', 'transcript': 'table function or something, it can return a table as well. It can return a query as well, then Dire Select statement. It can return it, Can you have? And it may not return also so that there are different kinds of parameters it can have so it can have input output parameters where even the parameters where you can also change', 'start_time': '00:09:03', 'end_time': '00:09:24'}, {'Topic': 'Function in SQL Queries', 'transcript': 'if you want, So this is a very simple function. I am will show. You know how we can use it for in a lot of Q ever, which had been your own done in our project also.', 'start_time': '00:09:24', 'end_time': '00:09:41'}, {'Topic': 'Stored Procedures vs Functions', 'transcript': 'so. let me just first take you to the store, procedure out how we do it and start Caesar than people compare. And I assure you what kind of things we have done in our project.', 'start_time': '00:09:42', 'end_time': '00:09:55'}, {'Topic': 'Stored Procedure Basics', 'transcript': "so no, I'm mentioned in projects, restore procedure and triggers. But I people are sometimes confused in function and short procedure. So that's why his small slide I included for function. So this is the format, and now we let's jump to the store proces stored for Caesar's a Gain, a set of structured query languages. they are some set of festival statements you want to execute", 'start_time': '00:10:02', 'end_time': '00:10:31'}, {'Topic': 'Stored Procedure Usage', 'transcript': 'with one compiled unit, of course. Zero. And suppose e When you say inserted, I want to insert into 23 tables, so', 'start_time': '00:10:31', 'end_time': '00:10:40'}, {'Topic': 'Stored Procedure Execution', 'transcript': 'So rather than having these three Chase mints have separately what you can have its you can combine them all in one, and then', 'start_time': '00:10:42', 'end_time': '00:10:51'}, {'Topic': 'Return Values in Stored Procedures', 'transcript': 'we just run. Whenever we run this insert day tights, it will in certain. to through three rows or whatever we can have a can. A multiple kind of Esther statement altogether. But important thing about stored procedure is it does not return anything. It is going to execute the statement, but it is not going to.', 'start_time': '00:10:52', 'end_time': '00:11:15'}, {'Topic': 'Types of Stored Procedures', 'transcript': "I have a return statement in it with some value. It can simply return by ward to close that sort for Caesar. But it's not going to your return exactly venue. But there is a way to return a value in stock per Caesar and", 'start_time': '00:11:16', 'end_time': '00:11:36'}, {'Topic': 'SQL Count Example', 'transcript': 'we We will see that to a handsome and so there are 23 types of the euro store procedures. So one is a simple I will write one simple start procedure which.', 'start_time': '00:11:37', 'end_time': '00:11:56'}, {'Topic': 'Insert Operation Example', 'transcript': 'people count. I think this is very much required in Q. Ever. You need to cheque cross cheque, Kong of tables everywhere in Los of table. You want to see what Khamenei rose are there in this table or how many? count of Nelle values. What is the maximum value? Water is the minimum value. So I created a simple A.', 'start_time': '00:11:59', 'end_time': '00:12:27'}, {'Topic': 'Retrieve Row Count', 'transcript': 'This is the first one. They will go to the tougher one procedure so this particular store procedure will insert into a test law. Created a table test law which will insert', 'start_time': '00:12:27', 'end_time': '00:12:41'}, {'Topic': 'Function Usage in SQL', 'transcript': "how many rows are in the stable? That's it. And this is a just the table lame it is putting. This is strength hard quarter string right now, which is restoring the count of that. So So if Q way want to run this job, they just", 'start_time': '00:12:43', 'end_time': '00:13:01'}, {'Topic': 'Function Call in SQL', 'transcript': 'can just simply create this procedure with this insert statements, they might have the table name or not I had because I want to show you further. You know how we will improve it now If you cyst select star from s law, how do I call dysfunction?', 'start_time': '00:13:02', 'end_time': '00:13:20'}, {'Topic': 'Function Return Values', 'transcript': 'how will and call it now function. We said Select an hour. But this party puller will be called that he will this call dysfunction call.', 'start_time': '00:13:20', 'end_time': '00:13:31'}, {'Topic': 'Stored Procedure Execution', 'transcript': "public Apia. So if you and at this one Sorry one said, Why? So this function has executed something. It hasn't returned you anything. Neither just shows. If you has updated any rose, it is not returning you anything. But as we know, we had created a lock using this. So I just show you what is there listed.", 'start_time': '00:13:33', 'end_time': '00:14:02'}, {'Topic': 'Dynamic Stored Procedures', 'transcript': 'So just ignore the first two rows. This was for my test. Rangnick had been doing so Eyes entered one table name fix Hard quarter Deka standing and whatever count it is is printed in it, so', 'start_time': '00:14:03', 'end_time': '00:14:17'}, {'Topic': 'Dynamic SQL Execution', 'transcript': "So now thing is we will expand this through Caesar further. How we expand this one's a hard quarter statement earlier.", 'start_time': '00:14:18', 'end_time': '00:14:29'}, {'Topic': 'System Tables', 'transcript': "Mansiz. We want to make it dynamic. So I want to say King, whatever table I passed to, it should give me the count office, so then haven't do and", 'start_time': '00:14:32', 'end_time': '00:14:43'}, {'Topic': 'System Information Schema', 'transcript': "so as same thing. I made it dynamic. How to make it dynamic. I think this is very much helpful for all the fun queuing or I think for coding. Also, this is tricky. How do you make it dynamic? Because you can't put a you know, in aware, Klaus, you can give a variable of parameters. But if you have to make a table lame dynamic which is used in", 'start_time': '00:14:44', 'end_time': '00:15:08'}, {'Topic': 'Creating SQL Procedures', 'transcript': 'so how do we do it? So in this particular store procedure, I used a function execute. So this execute function will execute a string which have a strain you give it so we can build up that strength.', 'start_time': '00:15:08', 'end_time': '00:15:24'}, {'Topic': 'Dynamic SQL Procedures', 'transcript': "So I'm not using of their class because acceptable name directly. And I want to see the common name office. So this execute is with format function and the same parameter the table name.", 'start_time': '00:15:25', 'end_time': '00:15:38'}, {'Topic': 'Stored Procedures Creation', 'transcript': 'is being used to build up this insert statement. Now, what this insert statement is doing, this is percentage as means a stream stream parameters expected heirs of what is going to put its the stable name here. Because if you remember, in our previous this was', 'start_time': '00:15:40', 'end_time': '00:15:59'}, {'Topic': 'Dynamic Action in Stored Procedures', 'transcript': 'hired border. But now this is becoming dynamic. So this table name particularly replace there. So this far, Mac, this is This is a parameter for farm at Kumar. This is making it dynamic. So whatever is purpose in that table name, it is going to pass that as parameter', 'start_time': '00:16:00', 'end_time': '00:16:22'}, {'Topic': 'Stored Procedures for All Tables', 'transcript': "and also is going to put that name in the stable. This table test log was created with just two condoms, table name and Rocca. Let's use any table from", 'start_time': '00:16:23', 'end_time': '00:16:33'}, {'Topic': 'Stored Procedure Efficiency', 'transcript': "and receive whether it will give you that counter. so Laz Z. so now because the store procedure is already created rival. Even if I run it again, it's going to just replace Crate or replace statement is there so?", 'start_time': '00:16:34', 'end_time': '00:17:04'}, {'Topic': 'Stored Procedure Execution', 'transcript': "it will just a place, and but it's already there. I am just going to change the statement here. Seat SWAC.", 'start_time': '00:17:06', 'end_time': '00:17:13'}, {'Topic': 'Stored Procedures with Count', 'transcript': "so again, it hasn't returned you anything because it's of sort for Caesar. It has done a task. Lot of task in this. So we just show you", 'start_time': '00:17:29', 'end_time': '00:17:39'}, {'Topic': 'Audit Logging', 'transcript': "now the test? Well, it should have an entry for F B and all. So this is how many rows were this is you can use it for any table now. We expanded this functionality further. So in one of our requirement, climbed wanted count for all the tables, whatever we have in our system. So we want account of all that paper's not only that the client also want Ear's. What is the maximum value in that for each column?", 'start_time': '00:17:39', 'end_time': '00:18:17'}, {'Topic': 'Dynamic SQL for All Tables', 'transcript': 'Which columns are and home, Um, in how many null values in in gyro for each and every column so so far that then we will not even dependent on the stable name reused system tables.', 'start_time': '00:18:17', 'end_time': '00:18:32'}, {'Topic': 'Statistics and Data Integrity', 'transcript': "So that is the system information scheme. Our Table, which has columns and tables column It will be different for a again for different databases. Snowflake CASS. It's on information. Ski Mark My A school might have a slight different name, but Salama the other", 'start_time': '00:18:32', 'end_time': '00:18:50'}, {'Topic': 'Data Analysis Automation', 'transcript': 'they they had That is the same logic. The system lists the names of all the people. So in one go, you will have. If you have the statement within a far Luke Foreign for each row in the information scheme are not tables, then you can', 'start_time': '00:18:50', 'end_time': '00:19:09'}, {'Topic': 'Data Insights', 'transcript': 'go one by one and create that lock for all the tables. And if you want to see that court, I can show you that also.', 'start_time': '00:19:10', 'end_time': '00:19:18'}, {'Topic': 'SQL Validation Process', 'transcript': 'so sorry. so this particular I just want to show you. this state, this one. And I think this If if you would have worked this for this particular functionality manually, it would have taken even a week would have been less er so. There were so many columns in one table and each and every column we had to see What was the count of null What is our How many account of', 'start_time': '00:19:20', 'end_time': '00:19:53'}, {'Topic': 'Error Handling in SQL', 'transcript': "table rolls then we had two can play a part for the distinct value. And Max, we're losin and I can show you this table also. You know how what kind of summary it crater, but", 'start_time': '00:19:54', 'end_time': '00:20:05'}, {'Topic': 'Validation Logic', 'transcript': 'internally again. This was this Execute foreigners statement was only used, but it use and again informations cable dot columns. This was for a particular table and columns, so for one, they will we can.', 'start_time': '00:20:07', 'end_time': '00:20:23'}, {'Topic': 'SQL Trigger Introduction', 'transcript': "all the columns first. Then we go to another table. This was the vein designed. So if you want the details or you want the court, you can come to me and discuss with me. But this was ever saying, you know, this can really make the life of Cuba dwell. Persall so easy. So the programming is not just required for dwell first, even if you wait, Does this kind of they can do this? Morning Tunnels, cheques? I know there are lot of Cuba people's hair and they might be able to cordial it. In many cases, they are", 'start_time': '00:20:24', 'end_time': '00:20:54'}, {'Topic': 'Trigger Overview', 'transcript': 'doing this more not on his cheques many times and with one accord, it just You need to run this query then', 'start_time': '00:20:54', 'end_time': '00:21:02'}, {'Topic': 'Triggers in SQL', 'transcript': 'then a It will just give you that data in this particular table. I was building up the stable in served in do this', 'start_time': '00:21:03', 'end_time': '00:21:12'}, {'Topic': 'Trigger Types', 'transcript': 'So only the trick is how the build of does this damn inquiry and you this system. any cautions till long.', 'start_time': '00:21:13', 'end_time': '00:21:22'}, {'Topic': 'Trigger Functions', 'transcript': "any hand cushions. And to further about this cone, Belka, I'd advise and go into the next truck. So this is the table will be created log and sorry, Wannsee.", 'start_time': '00:21:27', 'end_time': '00:21:49'}, {'Topic': 'Trigger Events', 'transcript': "this table has changed. Okay? Sorry. And running this in another environment. so are any where it's not wanted. So it was a mainly along kind of table I can just show you from her.", 'start_time': '00:21:58', 'end_time': '00:22:14'}, {'Topic': 'Trigger Usage', 'transcript': 'to Cedars. So which column name it was switched Able arm. This automatically did. And how many got is a Kong governor distinct values? How many districts for the the if there were any values which were zero?', 'start_time': '00:22:31', 'end_time': '00:22:44'}, {'Topic': 'Trigger Logic', 'transcript': 'maximum minimum value. The film factor for stance. We always, you know, for data science. We really need to find out', 'start_time': '00:22:45', 'end_time': '00:22:52'}, {'Topic': 'Trigger for Data Validation', 'transcript': "how much per portion of this column is filled up. If it's not filled up, should be used into an hour regression model or not. I think this kind of analyses also is done automatically and some statistical functions. But I know this was in data base level. We wanted to particularly do analyses and testing for these columns will be dated automatically.", 'start_time': '00:22:53', 'end_time': '00:23:16'}, {'Topic': 'Trigger Implementation', 'transcript': "so person had couldn't only see this excel then and you can you know it is a table you can always query on this table with where class, which has less Phil factor of which has more nahl known on sending.", 'start_time': '00:23:17', 'end_time': '00:23:31'}, {'Topic': 'DML Triggers', 'transcript': 'so similarly you can use it for. you can use it for your validation, Sze also So if you run a validation and if it is not meeting a condition, you can just one Singh.', 'start_time': '00:23:32', 'end_time': '00:23:47'}, {'Topic': 'Row vs Statement Triggers', 'transcript': "so if you are not doing some variations and it is not following, you can put this kind of code here. Also, side like you can have a statement and only thing is even need to maintain a table, some some law table or somewhere where you're inserting these values.", 'start_time': '00:23:51', 'end_time': '00:24:09'}, {'Topic': 'Before and After Triggers', 'transcript': 'so, Yeah, that that was for a function and so on. Stored for Caesar, there is one more thing. a installed to Caesar. I said We can make it dynamic. Earlier was a static. The stock for Caesar one was a function but installed to Caesar. Also, I said You can return of value. You can never return statement with the value. But if you want to return something, there is one other veils. This also want to show', 'start_time': '00:24:11', 'end_time': '00:24:43'}, {'Topic': 'Trigger Scenarios', 'transcript': "there is a n out kind of parameter or out kind of parameter which lets you get a value from a store procedure. So stop A zither is not just sending a value, it can also receive a wearing this one example. I don't want it to have that law table add on to create it. I just want that variable bank.", 'start_time': '00:24:44', 'end_time': '00:25:06'}, {'Topic': 'Trigger Limitations', 'transcript': "with me. So then I hire I don't have any lock table. I only have a count star Any to table count. This was a parameter which was declared as this. And now if I call it, it is going to give me that Kong for that. So here again it was a hard quarter or testing you can again make it dynamic. So lets us run this.", 'start_time': '00:25:07', 'end_time': '00:25:32'}, {'Topic': 'Trigger Access', 'transcript': 'as it is the procedure we need. We need to use a call if it would abandon a function we would have done.', 'start_time': '00:25:34', 'end_time': '00:25:41'}, {'Topic': 'Creating Triggers', 'transcript': 'our test, you will need to ride the function name. but see now it has returned. Show knew that value. We are not going anywhere table and anything checking it. So because we return through', 'start_time': '00:25:42', 'end_time': '00:26:06'}, {'Topic': 'Trigger Comparison', 'transcript': 'output Vira metre input output means it will allow you put So this is the beauty of out fair. Um, And this now why we will when we should create a function and when we should create a stored procedure.', 'start_time': '00:26:06', 'end_time': '00:26:22'}, {'Topic': 'Trigger Logic and Performance', 'transcript': "So I'm just going to the presentation again. So you function as he said, is the normal as to a statement. But why? What is a clause of a function? Is it car? It cannot allow you to begin or commit transaction. You cannot have because when you are saying select and function name with a parameter and if you have a from they will hear it is going to call that function that many times from the", 'start_time': '00:26:23', 'end_time': '00:27:02'}, {'Topic': 'Trigger Implementation Example', 'transcript': "a table. So then you can't have a you notice of a million of rose. So you can't have a million of time committing and begin transaction here. But a store possessor is a bat statement. It is running on an entire transitions, Not functioned can be row bases. Also, it might be also running a", 'start_time': '00:27:03', 'end_time': '00:27:25'}, {'Topic': 'Trigger Functionality', 'transcript': "you're in one that statement also, I'm not saying it's always like that, but if you call through from table statement, then is going to run again. Anarchy and", 'start_time': '00:27:26', 'end_time': '00:27:37'}, {'Topic': 'Trigger Code Sharing', 'transcript': 'it can have multiple transactions, your stock procedures and they cannot return of their Liu. So it has to be called like this. It is a separate.', 'start_time': '00:27:39', 'end_time': '00:27:48'}, {'Topic': 'Triggers in Application Logic', 'transcript': "ask you a statement in in itself. But when you are calling a function, you can call it with other rescue a statement within the same civic statement. So that is the major difference. So that's why the key thing is, do you want to call it as a user defying function at a role levels are you want to", 'start_time': '00:27:48', 'end_time': '00:28:09'}, {'Topic': 'User-based Triggers', 'transcript': 'run a bad statement? So there are lots of advantages of slow procedures while, you know, some of like I have shown you.', 'start_time': '00:28:09', 'end_time': '00:28:19'}, {'Topic': 'Triggers vs Stored Procedures', 'transcript': "how we do it. And I think we did this static, dynamic and returning valleys to the store for Caesar's So and so, particularly this tortoise sees. I said, How you are doing, you ever work and you're crediting different logs for it and you are. Actually what you're doing is you are also making your concern data and process consistent through store position.", 'start_time': '00:28:20', 'end_time': '00:28:45'}, {'Topic': 'Triggers and User Permissions', 'transcript': 'If your climbed applications are directly using your procedures for suppose integrity cheques when you want to see if I am inserting this in table, the foreign key should be there', 'start_time': '00:28:45', 'end_time': '00:28:59'}, {'Topic': 'Trigger Use Cases', 'transcript': "and some of the data basis, like snowflakes and all, they don't even have referential integrity cheques. And so in that case, is best to have it installed procedure. And there are some cheques which are not just rest, foreign key and primary cheques. There are many other cheques and some processes some business", 'start_time': '00:28:59', 'end_time': '00:29:18'}, {'Topic': 'Trigger Advantages', 'transcript': 'logic calculation. Like I know how to calculate simple interest and compound interest. That formula is fixed so that from life we keep it in store per Caesar. If it changes the rules for compound interest changes or something changes, I will be changing only one small path. One store per Caesar. I will not be doing changes across,', 'start_time': '00:29:18', 'end_time': '00:29:43'}, {'Topic': 'Trigger Disadvantages', 'transcript': "you know, suppose this this kind of functionality was used Five or 10 places or hundreds of places. They're not changing at 100 of places. We are just changing one stored for Caesar through the maintenance. The change management is very much requirement for stored procedures. So another we are and supposed a table in changes.", 'start_time': '00:29:43', 'end_time': '00:30:10'}, {'Topic': 'Trigger Performance', 'transcript': "Sorry. Within a table, you have extra Khanum to be shown in report, or we have a new column column being renamed or anything so those all these things will be part of our stored. Proceed. You're not calling that as Curiel. Suppose at fight and places separately, but that astral safe is encapsulated within your stored procedure. Your business logic layer is", 'start_time': '00:30:10', 'end_time': '00:30:38'}, {'Topic': 'Trigger Context', 'transcript': "no. I'm a hidden in that and all the complex operations also explained warns. And so it's easy performance wise. Also, the stored procedures are lot better because they are come pyre cold of units and the performance of store procedure is better than.", 'start_time': '00:30:39', 'end_time': '00:30:59'}, {'Topic': 'Trigger Logging', 'transcript': "user defined function. User defined function can slow down as explain news. It does a row level function and a few times, so the performance of stored procedure is much faster. Compile code is not again checking and vesting is not again hitting server again and again. Suppose if you're running for select statement", 'start_time': '00:31:00', 'end_time': '00:31:21'}, {'Topic': 'Trigger Functionality in Applications', 'transcript': 'separately in a D V engine four times it is going across networks going from server to client runs. A query gets you result than run the next statement in a normal scenario,', 'start_time': '00:31:22', 'end_time': '00:31:36'}, {'Topic': 'Final Questions', 'transcript': 'but not but in a store procedure, If you have 14 Cilic statement and one stork procedure, it will be sent to the server vans and all the returns or the result is return. so we can utilise again. Transactions. Also, 40 time ticket e began a multiple transactions. We can begin comment', 'start_time': '00:31:36', 'end_time': '00:31:59'}, {'Topic': 'Trigger vs Function Comparison', 'transcript': 'ways on that it will execute the state. So this is all about the stored per Caesar. And before I move to the triggers, I will like to take any questions of commence. Um', 'start_time': '00:31:59', 'end_time': '00:32:12'}, {'Topic': 'Session Conclusion', 'transcript': 'and even. men can we do all things we are doing in procedure in also function? Yes, you can. only transaction is not so. In fact, most of the cases because of the limitation of return clause in Proceso, people are tend to use functions on the complex functions.', 'start_time': '00:32:16', 'end_time': '00:32:41'}, {'Topic': 'Feedback and Closing', 'transcript': 'and calling to become different Now, how you college? It has to be part of a select statement. So you also want to see that outer application, which is calling it how that will be designed.', 'start_time': '00:32:42', 'end_time': '00:32:55'}, {'Topic': 'Session Ending', 'transcript': "In fact, if you see that I was showing you this one. this function which was complex, which we created for the way people while everything was summarised for them, it was actually issues it, we would have noticed this was also retired a function, not it's sort procedure. It could have been done, but it was being called from another outside. Also, there was one stored, one function which", 'start_time': '00:33:00', 'end_time': '00:33:28'}, {'Topic': 'Future Sessions', 'transcript': "for which it had to return a value. And that's why this was also returned as a function. So this this entire, in fact, I would have I can this copy paste this thing and placed it in a crate for season candidate.", 'start_time': '00:33:29', 'end_time': '00:33:43'}, {'Topic': 'Thank You', 'transcript': 'fun walking. yes. anything else. This is a message on the chat. kicks. Yeah, you can. Can you also share those', 'start_time': '00:33:44', 'end_time': '00:34:05'}, {'Topic': 'Session Recordings', 'transcript': "in the chance those video links for my training if you're able to find out or the other? I sent the email to the group.", 'start_time': '00:34:05', 'end_time': '00:34:12'}, {'Topic': 'Session Transition to Triggers', 'transcript': "Nobody's Mark. Those videos are already accessible on it to collapse, so all of them they have their links to visit to that site and got food was recording", 'start_time': '00:34:13', 'end_time': '00:34:24'}, {'Topic': 'Event-based Triggers', 'transcript': "sessions. So then any other question I'm moving to triggers. So now triggers. Know, I think everyone has must have heard off. And if you have not heard off, the trigger means anything you know it's a", 'start_time': '00:34:24', 'end_time': '00:34:48'}, {'Topic': 'Trigger Event Types', 'transcript': 'special type of event has occurred. One trigger has occurred. So Anne Askew Award a trigger is a a special type of store to Caesar only that automatically runs when an event occur in a date of resources. So as soon as you answered a record, you want the record to be inserted in a lock. Pick something like if you are changing or deleting a record you want', 'start_time': '00:34:49', 'end_time': '00:35:18'}, {'Topic': 'Trigger Functionality', 'transcript': 'and order clock to women dating or you want to do the assembly a chair you want to do. A validation for that data is that date is courage only then it should go, so this kind should automatically happen if somebody is calling', 'start_time': '00:35:18', 'end_time': '00:35:34'}, {'Topic': 'Trigger Uses', 'transcript': 'a special validation. you know manually, you may or may not call it, but trigger is want, which is automatically Ron when an event occur and a very useful in database on maintaining these all of allegations and integrity cheques.', 'start_time': '00:35:34', 'end_time': '00:35:52'}, {'Topic': 'DDL Triggers', 'transcript': 'so there are in database work. There are many kinds of triggers, but we will focus on only two. There are DDS triggers also which occurs when a date. The realise data definition language. When a table or viewed changes that kind of triggers are triggers and a user long in', 'start_time': '00:35:54', 'end_time': '00:36:15'}, {'Topic': 'Trigger Configuration', 'transcript': 'the trigger are occurred. There are some different, but we will focus only on these two kind of trainer. One is the day, um, El Trigger and other is a instead of trick. So what are the M military? Damen means anyone here which can Who can tell me what is a demon?', 'start_time': '00:36:16', 'end_time': '00:36:34'}, {'Topic': 'Trigger Logic', 'transcript': "in for a date of death, Mum. Yeah, it's actually a data. Many pollution language. The full former fighters? Yes. And which can manipulate the data? Yes, There are three things which can manipulate a data. One is an insert, update and delete so we can have", 'start_time': '00:36:39', 'end_time': '00:37:00'}, {'Topic': 'Insert Triggers', 'transcript': "triggers on all these three actions for the and then there is a instead of triggers which are, you know, instead of means They were triggered foreign operation which can fail if it can do this than though this something like that. Everyone knows motor views here if they don't know as views is a comm pine as cure Compile. Ask your statement on top of tables if tower If a table has", 'start_time': '00:37:01', 'end_time': '00:37:35'}, {'Topic': 'View Usage with Triggers', 'transcript': "100 columns and I don't want to show all that to user, I just want a four columns out of that. I came straight of you over our if there are two day was department and employees and I want to.", 'start_time': '00:37:36', 'end_time': '00:37:48'}, {'Topic': 'Trigger Application', 'transcript': "we know. Show to the user only employ and the department name, not the department ID. So I can make a joint and I can create a view. And specially this trigger instead of triggers are applicable for views where we can update a record it because it is being referred from two tables so supposed other showing that so let's go to first day military.", 'start_time': '00:37:48', 'end_time': '00:38:15'}, {'Topic': 'Row Level Triggers', 'transcript': 'Sawada, d M L triggers as we explained their insert update, but in threat all these itself. All these triggers insert, update and delete trigger can also have descendants of one is for each row,', 'start_time': '00:38:16', 'end_time': '00:38:35'}, {'Topic': 'Statement Level Triggers', 'transcript': 'for one is for each statement. So for each row means whenever Suppose you are doing a big concert or bat in served, but for each row will be running for each and every road.', 'start_time': '00:38:36', 'end_time': '00:38:52'}, {'Topic': 'Trigger Execution', 'transcript': "So for every road will cheque separately and will do whatever you provide the information. And so I need to be careful also. Then you are doing insert of millions of records or a big volume of the consul's. Then again, we have a for each statement which says it will run once. For you know, if you have a batch of insert a big 1000 millions or whatever record, it will run only once for that statement,", 'start_time': '00:38:53', 'end_time': '00:39:28'}, {'Topic': 'Trigger Logic Implementation', 'transcript': "and within that also, we have before and after. So 11 of the trigger you can run before your, um, statement runs so you don't want it the record to be inserted at all, and you want to do a cheque only then let it run out. Otherwise, you can just cancel that operation. Also, he will say it is invalid and you are not. And during the report", 'start_time': '00:39:28', 'end_time': '00:39:55'}, {'Topic': 'Trigger Logic and Performance', 'transcript': 'and one is asked for it, this is required when you have inserted a record, you want foreign table also to be updated or some other table also to be a better like inventory. If you have done a sale or purchase of a record a sale of others than you want, the inventory of that record should be reduced. So in that case, what we will do it will use and after', 'start_time': '00:39:56', 'end_time': '00:40:21'}, {'Topic': 'Trigger Implementation Example', 'transcript': 'after update so this. These are different scenarios and if you see so for a single ask you a statement can fire up to four types of trigger at the same time. We can have all those triggers at the centre. We can have before RO before statement after row. And so, while important thing about right rigorous, it is also a slot per Caesar only', 'start_time': '00:40:22', 'end_time': '00:40:49'}, {'Topic': 'Trigger Functionality', 'transcript': "it will run itself and it cannot take parameters. But it cannot take parameters like stored poor Caesars and function may or may not take parameters, but triggered cannot take them. But how dues access information is through it has internal tables with so, uh, let's see the so aver just sharing.", 'start_time': '00:40:49', 'end_time': '00:41:16'}, {'Topic': 'Trigger Function Usage', 'transcript': 'the Centex of the trees. So what? Hard to be created. So which is create, er, Tigger a name. And we right, which on which table it is, it is before update on after update. And then for each row, suppose they want or not.', 'start_time': '00:41:17', 'end_time': '00:41:37'}, {'Topic': 'Trigger Limitations', 'transcript': "this particular you need to see. There are two important things in this trigger which are used for for triggers and why they are different from sort for Caesar. They have access to to information which normal store procedure don't have.", 'start_time': '00:41:38', 'end_time': '00:41:56'}, {'Topic': 'Trigger Use Case Example', 'transcript': 'That is the old tables and the new tip. So the old table, what is has is the time, the table, the values which were just before the update', 'start_time': '00:41:57', 'end_time': '00:42:09'}, {'Topic': 'Trigger Logic and Access', 'transcript': "and newest, which will be updated so you can compare also. So, like, if previous value was this, I don't want to update this. And if previous followed, wonders if your calculations are based on all table also previous value and new value, this kind of information is very useful. So now because this was an update review guard,", 'start_time': '00:42:09', 'end_time': '00:42:34'}, {'Topic': 'Trigger Functionality', 'transcript': 'if you update a recording of modifying the records. So it has all when you also suppose my inventory has become from 2 22 10.', 'start_time': '00:42:34', 'end_time': '00:42:45'}, {'Topic': 'Trigger Functionality in Projects', 'transcript': 'So the all in 13 year tables value of suppose we have some stores dot in entry quantity so the quantity of that column will be 10. Also in a sorry 20 in old and 10 in new', 'start_time': '00:42:46', 'end_time': '00:43:05'}, {'Topic': 'Trigger Implementation', 'transcript': "So and then you execute that function. So this this particular is there. That's why we have excess to trigger. So let's do and simply hands on. Alleges show you on the project how we are creating different triggers for different kinds of usage and deletes are like Want to clarify van? It's a daily trigger.", 'start_time': '00:43:05', 'end_time': '00:43:29'}, {'Topic': 'Trigger Configuration', 'transcript': "it only has access to old kind of this before you're deleting Arroyo are not creating a new row of a delete, so you have the access of all those old values before and after update after delete both. This access is very important. So that's why you can", 'start_time': '00:43:30', 'end_time': '00:43:49'}, {'Topic': 'Project Trigger Example', 'transcript': 'you have the literature record, but you want to create a another table. With the snapshot of that, the record this record was related. This can be achieved only by trigger NARC bias toward proceeds.', 'start_time': '00:43:49', 'end_time': '00:44:01'}, {'Topic': 'Trigger Functionality in Practice', 'transcript': 'and this has your you can have within that what functionality you want to do, You can have it. as the store procedure of function only they internally execute a function on all these tricks. So this this function can be written 100 days. But vesting the trigger is it can has access of all and a lot of different things which I can chew.', 'start_time': '00:44:02', 'end_time': '00:44:28'}, {'Topic': 'Dynamic Trigger Implementation', 'transcript': 'this answer. So is showing you example of one. I will not be creating it right now because of some wrong access issues on triggers and all are destroyed. I tell you. You know what are some limitations of triggers also? So this particular trigger is created another one of our', 'start_time': '00:44:31', 'end_time': '00:45:06'}, {'Topic': 'Trigger Functionality', 'transcript': 'project. And it has whenever we update a particular column a soppy I mean, it is on one of the table. This was internal function which was created. It has some some keys. Also some sect words, TG. So this particular was function was return so that', 'start_time': '00:45:06', 'end_time': '00:45:28'}, {'Topic': 'Trigger Usage in Projects', 'transcript': 'we can use it in update mode also. And we can you till insert mode also. So both the triggers in certain update can cause the same function. But how we distinguish it, whether it has been a update. Moderate insert. We have a T g upset. So based on that,', 'start_time': '00:45:29', 'end_time': '00:45:50'}, {'Topic': 'Trigger Logic in Practice', 'transcript': 'we were changing some values. If it was insert, we were doing something. And if it was date, if Khun catting it with previous values and that', 'start_time': '00:45:50', 'end_time': '00:46:00'}, {'Topic': 'Trigger Use Case', 'transcript': "and we were using If you see in update we were using new and we were also using the old tax. But in an insert operation we have a new robe but we don't have a old room now. There was.", 'start_time': '00:46:02', 'end_time': '00:46:15'}, {'Topic': 'Trigger Functionality and Limitations', 'transcript': 'You are This is for a particular road so hot There was no previous value. It is new, so only we have this new dot tax notice.', 'start_time': '00:46:16', 'end_time': '00:46:25'}, {'Topic': 'Trigger Usage', 'transcript': "they don't have. If you will see the value of all non tax, it will be not. and this kind of thing disposal trigger that we was Khun Cat knitting it in the column. If some some column has changed, just we were updating all the another column. Based on that, we will concur ordinating tag names with tanks. So this was for some calculations, and another function we rode for was the audit long", 'start_time': '00:46:26', 'end_time': '00:47:03'}, {'Topic': 'User Logging', 'transcript': 'whenever a table was changed. we wanted. a log to be maintain if you want to see that long has show you', 'start_time': '00:47:03', 'end_time': '00:47:14'}, {'Topic': 'Change Tracking', 'transcript': "the we were facing with the problem. One of the table name was some column names or changing through some value, and we were not able to know. You know why the application is failing? Who changes value though somebody we're changing manually or not. So we created one lakh table father's. So whenever one tabled a", 'start_time': '00:47:19', 'end_time': '00:47:44'}, {'Topic': 'Data Change Tracking', 'transcript': 'column changes, whichever column changes its new value and all value were printed. So you can see this particular column was made from trying to falls on this. And it was also because it was a row level was also storing the primary key for this. This was the primary key, and this value was become from through to false of all studio. For this and is very important for this is a few way kind of environmental when I am showing you all this. But', 'start_time': '00:47:44', 'end_time': '00:48:16'}, {'Topic': 'User Tracking', 'transcript': 'this was to, you know, find out the root cause and allies is also for some problems. Why it has occurred then was it made to an vase? It made falls all the date and time and law was menting and also this trigger function as access to the user name. Also who who was the user who ran it.', 'start_time': '00:48:17', 'end_time': '00:48:37'}, {'Topic': 'Trigger Use Case', 'transcript': 'and what was the value and this really help us and tracking the issues. who how they were generated. and even a few where user, if they are incorrectly updated, they could have been also corrected Also from this.', 'start_time': '00:48:38', 'end_time': '00:48:57'}, {'Topic': 'Dynamic Trigger Logic', 'transcript': 'So again we use that kind of. If you see this function was created a Prague under law and internally. This is very this was actually I had', 'start_time': '00:48:58', 'end_time': '00:49:13'}, {'Topic': 'Trigger Flexibility', 'transcript': "created more flexible and dynamic. In that sense, you can't limited to one table. I had made the option, even whichever tabled updated. If the table in is not just fixed one table MD and you the chair bird table Ling is updated. We can change that table name also so but trigger we made active only on this day and you So it's recording on Lydia.", 'start_time': '00:49:14', 'end_time': '00:49:44'}, {'Topic': 'Trigger Code Sharing', 'transcript': "So this trigger has access to this function. Also. Tichy Table name, sir. TV means triggers stable. which table has triggered this stable. So this trigger itself, it's not difficult to court same like store procedure, but has some extra variables also. So that then tg relation. I'd so you have this kind of", 'start_time': '00:49:45', 'end_time': '00:50:10'}, {'Topic': 'Trigger Functionality', 'transcript': 'columns also. So if anyone wants this code, I can share it. I think good piece of court to be used in order locks and most of the applications have any further.', 'start_time': '00:50:11', 'end_time': '00:50:24'}, {'Topic': 'Trigger Functionality in Practice', 'transcript': 'so which table value changes towards everything can be recorded and the primary key, particularly whichever is the primary key we can find out that also.', 'start_time': '00:50:24', 'end_time': '00:50:33'}, {'Topic': 'Session Questions', 'transcript': 'So this is our and is any questions. any questions. I reckon, and I know was slightly heavy topic for few.', 'start_time': '00:50:34', 'end_time': '00:51:01'}, {'Topic': 'Trigger Application Questions', 'transcript': 'But idea is to get the concept of triggers. They will be automatically licking. We want be kicking if he initialised this trigger on a table on account. Suppose updates whenever is updated, it will because ensure your in own data cheques or whatever you do and', 'start_time': '00:51:02', 'end_time': '00:51:21'}, {'Topic': 'Trigger Function Questions', 'transcript': 'questions. now I request everyone. If you have questions, you can please a new door celebrant. Ask otherwise, I cannot see anything on child box right now.', 'start_time': '00:51:25', 'end_time': '00:51:40'}, {'Topic': 'Session Closing', 'transcript': "so I'm just taking the last topic them out of it, the triggers which are instead of triggers. So just wanted to explain this is a situation in this kind of situation. Like we are using lot of views and mata lies views in our projects. So sometimes we just give access to of you to a user. But something like this was an employee cable, and this was a department table,", 'start_time': '00:51:47', 'end_time': '00:52:15'}, {'Topic': 'Trigger Usage in Views', 'transcript': 'and we combined these tour one common view. We removed the department idea, um, to user. It was this only now, if user his typing suppose seventh record in it.', 'start_time': '00:52:15', 'end_time': '00:52:28'}, {'Topic': 'Trigger Use Cases', 'transcript': 'then six. Like Ben Mail H R it want let you in of you view should give a feeling to the user s separatist table but they are not able to Ankara recalls normally.', 'start_time': '00:52:29', 'end_time': '00:52:42'}, {'Topic': 'Trigger Application', 'transcript': "But if you have to allow them to anchor a record we should be using instead of triggers I want go into the details of Instead of triggers on Lee Thing is same Sing dykes. like if he don't have instead of tigers. If I would have run this insert into this this value this, I would have got this.", 'start_time': '00:52:42', 'end_time': '00:53:05'}, {'Topic': 'Trigger Logic', 'transcript': 'I would have gone this views not updated table because the modification of affect multiple bay states so normally in a situation we will ignore it. We will say to the client, This is not up table view. No, but we can an instead of trigger we can define, we can define support. This row has come a charred we know a charge department i ds three.', 'start_time': '00:53:05', 'end_time': '00:53:30'}, {'Topic': 'Trigger Logic', 'transcript': 'It was inserting for the it. So the it department at is one internally should cheque it and save that reform in', 'start_time': '00:53:30', 'end_time': '00:53:39'}, {'Topic': 'Trigger Logic', 'transcript': "So we can modify that logic so internally to the client and level Kashmir will never be aware what is happening in the trigger. They can't see the triggers. This is snow automatic and it's hard to identify the errors also intrigue assed so they want to know about. But so for you only if you have to allow", 'start_time': '00:53:39', 'end_time': '00:54:03'}, {'Topic': 'Trigger Logic', 'transcript': 'a concert of a update of A If you which is found to separate Davis, they will say Crate bigger this in Tex.', 'start_time': '00:54:04', 'end_time': '00:54:14'}, {'Topic': 'Trigger Logic', 'transcript': "And here, instead of table name, we can write the view name. that's and it won't be a before update, it will be instead ofthe update on instead of insert.", 'start_time': '00:54:15', 'end_time': '00:54:28'}, {'Topic': 'Trigger Logic', 'transcript': 'and last, not the laced. What are the advantages of trigger as we just got to know it? Help us to maintain the integrity of data Where I know this. If this data is updated or changes should be changed in the foreign table also, and that will be useful for catching some errors like I saw we created or Dick Log and be maintained. Then was it changed? And by whom?', 'start_time': '00:54:30', 'end_time': '00:54:57'}, {'Topic': 'Trigger Logic', 'transcript': "And this is alternative way to run a schedule towns, because it's automatic way of kicking whenever insert happens. Help was an auditing. It helps and prevention of Khun valid transactions. They can do validation and we can just throw an era and don't let.", 'start_time': '00:54:57', 'end_time': '00:55:15'}, {'Topic': 'Trigger Logic', 'transcript': 'the insertion of record and we can log of events. As I said, the DD L triggers are there, and there are some', 'start_time': '00:55:16', 'end_time': '00:55:25'}, {'Topic': 'Trigger Logic', 'transcript': "user log in events also, which can be also long triggers. But there are some disadvantages of trigger and be careful and using it. They cannot replace all relegations. Some validation will have to be done and the application level or separately. Also, the can't handle each and every,", 'start_time': '00:55:27', 'end_time': '00:55:45'}, {'Topic': 'Trigger Logic', 'transcript': "and they are invisible from client applications. Client application will never know met, so his chances. If there are triggered being kicked automatically, they will not know why it's being duplicated. If they were not aware of it and", 'start_time': '00:55:46', 'end_time': '00:56:01'}, {'Topic': 'Trigger Logic', 'transcript': "they but imposed load on a server, they can make your database server slow, and it is not recommended for high velocity of data. That data is changing very rapidly. The streaming get on where there are millions of rose. It's better to have a storey for Caesar and have extra functionality in your client application, which cause those stored procedure.", 'start_time': '00:56:02', 'end_time': '00:56:28'}, {'Topic': 'Trigger Logic', 'transcript': "Otherwise, they can make a lock also in your so be careful and using them. This is all about triggers, and it's for procedures. They're good ways to", 'start_time': '00:56:29', 'end_time': '00:56:40'}, {'Topic': 'Trigger Logic', 'transcript': "dough programming and ask you and maintaining data integrity and cheques. So that's all on my side. Any questions you have Welcome otherwise.", 'start_time': '00:56:41', 'end_time': '00:56:51'}, {'Topic': 'Trigger Logic', 'transcript': 'can. and the session, I mean. Mm. I have a question. his place. How is is desist it, Baloo in pollution', 'start_time': '00:56:52', 'end_time': '00:57:07'}, {'Topic': 'Trigger Logic', 'transcript': 'high. Tell me. greetings. Go to that instead of trigger flied? Yeah, sure. a difficult for mind information. Like, I would like to know if if I want to inferred something in this in this lower one lower view. which does not come from I T department, which is from some new department can and do that', 'start_time': '00:57:07', 'end_time': '00:57:36'}, {'Topic': 'Trigger Logic', 'transcript': "very good question. So, you know, again, that's a choice with a new within a trigger to raise an error out, throw an era.", 'start_time': '00:57:37', 'end_time': '00:57:46'}, {'Topic': 'Trigger Logic', 'transcript': "this idea department does not exist. Or then you get, you know, in the programming where nothing is impossible. If you see the, uh, department name is not there. So you suppose this is an automatic and agreement kind kind of sequence? I'd you just insert that department and do it this again. If blocks are there, it blocks are possible.", 'start_time': '00:57:46', 'end_time': '00:58:14'}, {'Topic': 'Trigger Logic', 'transcript': 'in that gift, will it be inferred ID in the base views also. Yeah, if you are inserting it. always remember when we are inserting a recording of you, it goes into the based it.', 'start_time': '00:58:14', 'end_time': '00:58:27'}, {'Topic': 'Trigger Logic', 'transcript': 'okay? like five iffy delayed from the base views. Similarly, that updated should also go into the lower one.', 'start_time': '00:58:27', 'end_time': '00:58:42'}, {'Topic': 'Trigger Logic', 'transcript': 'Yeah. Depends on the permission on the views. More kind of commissions you have. And again, you might need a instead of trigger, which will handle all that quickly. So because the data integrity should should be maintained if you are deleting that so it might.', 'start_time': '00:58:42', 'end_time': '00:59:00'}, {'Topic': 'Trigger Logic', 'transcript': "Yeah. So the business logic You really want to give that right to them to delete it? Science. If you don't want to, then you just control it. You can't delete it, but you can delay that employees.", 'start_time': '00:59:01', 'end_time': '00:59:13'}, {'Topic': 'Trigger Logic', 'transcript': "So it's a decision of programmer and the product managers real if they really want only the employed a vigil later. They can tell you if they don't want to let it the delete use than razor error. No, it can't be deleted. Permission denied of whatever.", 'start_time': '00:59:14', 'end_time': '00:59:33'}, {'Topic': 'Trigger Logic', 'transcript': "Slater in that referential integrating. so it's all depends on. the bank. Um um that's it. and even else.", 'start_time': '00:59:34', 'end_time': '00:59:49'}, {'Topic': 'Session End', 'transcript': 'so I think we have always almost finished the time on sore Swimmer. No one has cautioned we can end the session. That Okay, Um', 'start_time': '00:59:55', 'end_time': '01:00:04'}, {'Topic': 'Session Feedback', 'transcript': 'um, okay, sure. Thank you. Thank you so much, Mom, for this wonderful session and to all a few of the recording of this session and the feedback phone that shall be attached on the A couple of Oh, it says. And since you have the access and Karhan has already guided you with the steps, you can access it and fill the feedback home as well. If not, he also will be sharing the session or details again tomorrow.', 'start_time': '01:00:04', 'end_time': '01:00:33'}, {'Topic': 'Feedback Reminder', 'transcript': 'And you can go through the steps. And according the march of feedback and also go through the other Jha solution recordings, which are there on the and a collab.', 'start_time': '01:00:33', 'end_time': '01:00:43'}, {'Topic': 'Session Wrap-up', 'transcript': 'is it fine? Thank you.', 'start_time': '01:00:49', 'end_time': '01:00:55'}], 'session_id': [ObjectId('641a8b46a053a968d797f8a9')], 'assessment': ObjectId('66f45076c248cb8c52153ff9'), 'job_name': 'my-transcription-jobb56831b9-0f9b-4b44-bfce-3b419c02f3d2', 'keywords': ['Data Collection', 'Application Failure', 'Trigger Functionality', 'Databases', 'Sharing', 'Trigger Limitations', 'Change Tracking', 'Database Management', 'Statement Triggers', 'Query', 'User Login Events', 'Table', 'Function', 'Lock', 'Bank', 'Software Structure', 'Operations', 'Applications', 'Validation Logic', 'Quarter Statement', 'Actions', 'Instead of Triggers', 'Regression Model', 'Variable Declaration', 'Quantity', 'Primary Key', 'Dynamic Trigger Logic', 'Support Definition', 'Trigger Context', 'Execute Function', 'Format Function', 'Data Consistency', 'Use Cases', 'Return Clause', 'Stored Procedure', 'Null Values', 'Distinct Values', 'Data Table', 'Permissions', 'Delayed Updates', 'Insert Statement', 'Multiple Returns', 'SQL Procedures', 'Time Management', 'Change Management', 'Error Identification', 'Transaction Validation', 'System Information', 'Database Performance', 'Row Update', 'Function Output', 'Input/Output', 'Integrating', 'Row Triggers', 'User-defined Functions', 'Data Insertion', 'Session Transition', 'Lower Case Function', 'Principal Amount', 'Record Modification', 'Materialized Views', 'Views', 'Jha Solutions', 'Email Communication', 'Logic', 'Dynamic', 'Procedure', 'SQL Statements', 'Values', 'Internal Tables', 'Reform', 'Foreign Table', 'Session Wrap-up', 'Trigger Functions', 'Function Declaration', 'Chat', 'Indexers', 'Efficiency', 'Training', 'System Tables', 'Function Syntax', 'Return Value', 'Multiplication', 'Trigger Configuration', 'Dynamic Stored Procedures', 'Dynamic Triggers', 'DML', 'Testing', 'D V Engine', 'Dynamic Functionality', 'Value Counting', 'Value Return', 'Data Validation', 'Performance', 'Trigger Implementation', 'Functionality', 'Code Demonstration', 'Network Issues', 'Data Science', 'Inventory', 'Interest Calculation', 'Information Inference', 'Audit Logging', 'Data Locking', 'IT Department', 'Outer Application', 'Business Logic', 'Trigger Access', 'Function Creation', 'Update', 'Main Block', 'Insert', 'Update Mode', 'Stream Parameters', 'Data Checks', 'Day Trigger', 'Trigger Function', 'User Tracking', 'Developers', 'Event-based Triggers', 'Context', 'Maximum Value', 'Column Changes', 'Insert Operation', 'Statistical Functions', 'Collaboration', 'Joins', 'Feedback', 'Data Change Tracking', 'Accessibility', 'Advantages', 'Snowflake', 'Data Integrity', 'Order Locks', 'Event Logging', 'Pollution', 'Summarization', 'Collective Action', 'Hands-on Demonstration', 'Excel', 'Demand', 'Transactions', 'Internal Processes', 'Client System', 'Locks', 'Columns', 'Server Load', 'Row Count', 'Table Statement', 'Query Execution', 'Trigger', 'Interaction', 'Client Applications', 'Session', 'Statement Level Triggers', 'Dynamic Parameters', 'Lower Function', 'Dynamic Schema', 'Department Integration', 'Test Log', 'Maximum Minimum Values', 'lower', 'Video Links', 'Function Execution', 'Audience Engagement', 'Condition', 'Parameter', 'Validation', 'Queries', 'Coding', 'Built-in Functions', 'Data Correction', 'Structured Approach', 'Data Management', 'Database Operations', 'Stock Procedures', 'Trigger Logging', 'Instead of Trigger', 'Value Comparison', 'Project', 'Tax Notice', 'Conclusion', 'Insert Triggers', 'Database Function', 'Execution', 'Functions', 'Data Count', 'Procedures', 'Slow Procedures', 'Legal Framework', 'User-Defined Functions', 'Data Analysis', 'Application Logic', 'Condition Checking', 'Return Statement', 'Insert Mode', 'Built-in Function', 'Row Level Triggers', 'Table Modification', 'Case Functions', 'Count Star', 'Function Usage', 'Parameters', 'Function Call', 'Batch Processing', 'Insert Update Delete', 'Database Functions', 'SQL', 'Dynamic Action', 'Implementation', 'Literature Record', 'User Logging', 'DDL', 'Automatic Triggers', 'Stored Procedures', 'Triggers', 'User Permissions', 'Database', 'Complex Calculations', 'Questions', 'SQL Trigger', 'Tables', 'lcase', 'Event Management', 'Dynamic SQL', 'SQL Triggers', 'Count', 'Acknowledgment', 'Audience Interaction', 'DDL Triggers', 'Table Creation', 'Function Name', 'ID Inference', 'Trigger Types', 'Recording', 'Environment', 'Return Values', 'Logic Calculation', 'Synchronization', 'Automation', 'Issue Tracking', 'Progress SQL', 'User Experience', 'Manual Work', 'Trigger Logic', 'Programming', 'User-Defined Function', 'Trigger Performance', 'Row', 'Limitations', 'Trigger Code', 'User-based Triggers', 'Tichy Table', 'Trigger Execution', 'Automated Scheduling', 'Select Statement', 'Data Manipulation', 'Insert Statements', 'Auditing', 'Referential Integrity', 'Videos', 'Trigger Flexibility', 'System', 'Error Handling', 'Trigger Scenarios', 'View', 'Engagement', 'Speaker', 'Function Parameters', 'Root Cause Analysis', 'Department', 'Inquiries', 'Data Entries', 'Introduction', 'Modification', 'Audience'], 'topic': 'Database Management and Trigger Functions', 'interaction': [{'status': 'answered', 'answer': 'Yes, you can. only transaction is not so. In fact, most of the cases because of the limitation of return clause in Proceso, people are tend to use functions on the complex functions.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'men can we do all things we are doing in procedure in also function?', 'timestamp': '[0:32:20]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': "Incomplete, the question about 'how is is desist it, Baloo in pollution?' is not addressed.", 'relevancy': '0', 'question': 'how is is desist it, Baloo in pollution?', 'timestamp': '[0:57:05]'}, {'status': 'answered', 'answer': "very good question. So, you know, again, that's a choice with a new within a trigger to raise an error out, throw an era. this idea department does not exist. Or then you get, you know, in the programming where nothing is impossible. If you see the, uh, department name is not there. So you suppose this is an automatic and agreement kind kind of sequence? I'd you just insert that department and do it this again. If blocks are there, it blocks are possible.", 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'if I want to inferred something in this lower one lower view. which does not come from I T department, which is from some new department can and do that?', 'timestamp': '[0:57:11]'}, {'status': 'answered', 'answer': 'Yeah, if you are inserting it. always remember when we are inserting a recording of you, it goes into the based it.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'will it be inferred ID in the base views also?', 'timestamp': '[0:58:14]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question about deleting business logic is not addressed.', 'relevancy': '0', 'question': 'if I want to delete that so it might. Yeah. So the business logic You really want to give that right to them to delete it?', 'timestamp': '[0:59:36]'}], 'summary': "The session focuses on SQL programming, specifically discussing procedures, triggers, and their practical applications within database management. Key topics include the distinctions between stored procedures and triggers, hands-on practice with SQL concepts, and the importance of understanding stored procedures for more structured programming. The session emphasizes SQL's significance in automating repetitive tasks and improving efficiency in data processing.\n\nVarious SQL functions are covered, including user-defined functions and built-in functions, along with their differences and use cases. The concept of dynamic SQL is introduced, highlighting its flexibility in managing data. The transcript discusses the role of triggers in maintaining data integrity, performing validation checks, and automating responses to specific events, such as insertions and updates.\n\nThe discussion also addresses the limitations of triggers compared to stored procedures, focusing on performance implications and the necessity of rigorous management. The session highlights the importance of understanding trigger logic, including its impact on data updates and the execution of various operations across different contexts. Additionally, the importance of logging changes and maintaining accurate records is emphasized for effective data management.\n\nOverall, the session provides an in-depth exploration of SQL programming, with a focus on stored procedures, triggers, and their implications for efficient database operations, emphasizing the need for careful handling of SQL functions and trigger logic in practice."}
{'_id': ObjectId('66b26b74b80f3f3035517f5e'), 'file_id': ObjectId('6419a94ca053a968d797f89e'), 'file_name': '1677585013-6389d2cbb352ac0640395521__1677747124-60365dfa25bdf1241f86fa30__1679403333-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/1677585013-6389d2cbb352ac0640395521__1677747124-60365dfa25bdf1241f86fa30__1679403333-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '00:50:31', 'transcription_path': 'video-results/out_66b26b74b80f3f3035517f5e.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 8, 351000), 'file_process_date': datetime.datetime(2024, 9, 25, 17, 5, 18, 368000), 'execution_time': 501.61165, 'status': 'COMPLETED', 'green_line': [{'topic': 'Capacity Planning Overview', 'start_time': '00:00:03', 'end_time': '00:00:21', 'transcript': 'Okay, So hello, everyone on this Iman Alyssa. So today will be conducting session on two topics. One is capacity planning, and the second is the road map in Jiro. So try to cover capacity planning within the first half an hour span and then will continue with the road map injera,', 'keywords': ['Capacity Planning', 'Roadmap', 'JIRA'], 'summary': 'The session begins with a warm greeting from the speaker, Alyssa, who outlines the agenda for the discussion. The main focus will be on capacity planning, which will be covered in the first half-hour. Following this, the conversation will shift to the roadmap in JIRA. The speaker aims to provide a comprehensive overview of both topics.'}, {'topic': 'Capacity Planning Definition', 'start_time': '00:00:22', 'end_time': '00:00:52', 'transcript': "so the festival bodies capacity planning. So, according to the definition that is given here, is capacity planning is the process of identifying how many hours a project or task will require too demanding whether or not your team has the available bans it to complete it and then coordinating that work for maximum efficiency. So what it exactly means is instead offer. You know, I'm just guessing that how much offer can be done.", 'keywords': ['Capacity Planning', 'Efficiency', 'Project Management'], 'summary': 'The transcript discusses the concept of capacity planning, defining it as the process of determining the number of hours required for a project or task. It emphasizes the importance of assessing whether the team has the necessary bandwidth to complete the work and highlights the need for coordinating tasks to maximize efficiency. The speaker critiques the approach of merely guessing the workload without a structured planning process.'}, {'topic': 'Capacity Planning Process', 'start_time': '00:00:52', 'end_time': '00:01:19', 'transcript': 'Capacity planning is a complete process in which we are actually identifying the number of work hours that a person on already member in the scrum team can put in and the maximum work that can be achieved with within the spring time frame. For example, if it is a two week spent, then what is the maximum number of effective work hours that each of the resource can give? So that determines the capacity', 'keywords': ['Capacity Planning', 'Scrum Team', 'Work Hours'], 'summary': 'The transcript discusses the capacity planning process, which involves determining the number of work hours that a member of a scrum team can contribute within a specific sprint time frame. It highlights the importance of identifying the maximum effective work hours available for each resource, using a two-week sprint as an example to illustrate how to calculate overall capacity.'}, {'topic': 'Factors Affecting Capacity Planning', 'start_time': '00:01:19', 'end_time': '00:01:49', 'transcript': "and er It also includes things like, you know, complexity of the storey, and also it's like if it is a very complex storey, then definitely the storey point is more and so that's the reason the efficiency or the, you know work hours will be more and if it is a a medium or lesser complex than definitely the number of our covers required will be lives. So everything of this we take into consideration along with", 'keywords': ['Capacity Planning', 'Store Complexity', 'Efficiency'], 'summary': 'The discussion focuses on the factors affecting capacity planning, highlighting the impact of store complexity on efficiency and work hours. It explains that a more complex store requires more resources and time, while a medium or less complex store will need fewer resources. The speaker emphasizes that all these factors are taken into consideration during the planning process.'}, {'topic': 'Team Member Availability', 'start_time': '00:01:50', 'end_time': '00:02:15', 'transcript': "a, for example, a team member out of 15 days. Or to explain that the stand a strength, he will be only for the next two days or last two days. Whatever. Okay, so his effective days will be around eight days, right? So they'll also consider that that okay, he is actually available for eight days, and according to its, his work hours will be calculated.", 'keywords': ['Team Member', 'Availability', 'Work Hours'], 'summary': "The discussion revolves around the availability of a team member, illustrating the calculation of effective workdays. The speaker explains that out of a total of 15 days, the team member will only be available for eight days due to specific constraints. This availability will be factored into the calculation of the individual's work hours."}, {'topic': 'Benefits of Capacity Planning', 'start_time': '00:02:15', 'end_time': '00:02:34', 'transcript': "So what is the benefit of this? So the benefit of this is that you know, we are not keeping anything for, you know, like Cobb, depending on the chance of completion. It's like a sure shot. What they are projecting, what they are planning, what we are focusing, we are able to achieve it. So that is the main benefit of compact", 'keywords': ['Capacity Planning', 'Projecting', 'Resource Management'], 'summary': 'The transcript discusses the benefits of capacity planning, highlighting that it allows for a more certain and reliable approach to achieving projected goals. Instead of relying on chances for completion, capacity planning ensures that efforts are focused and directed towards achieving planned objectives.'}, {'topic': 'Capacity Planning Importance', 'start_time': '00:02:34', 'end_time': '00:02:57', 'transcript': "D planning. When we do capacity planning in a proper weight and there is very less chance that the gold will be missed or, you know, the maximum among the work we are able to achieve, rather than if we are not doing any capacity planning and randomly taking into work the new know Most of the time it's like we miss on the target and there are storeys which will spill over and you know there will be a chaos with industry.", 'keywords': ['Capacity Planning', 'Operational Efficiency', 'Work Output'], 'summary': 'The transcript discusses the importance of capacity planning in achieving operational efficiency. It highlights that proper capacity planning minimizes the likelihood of missing goals and maximizes work output. In contrast, a lack of capacity planning can lead to chaos, missed targets, and work spilling over into other areas, resulting in disorganization within the industry.'}, {'topic': 'Capacity Planning in Practice', 'start_time': '00:02:58', 'end_time': '00:03:14', 'transcript': "So this is the basic things are going forward with some more points on capacity planning. It's like on tapestry. Planning helps the team understand the amount of productive engineering time available in a sprint. For example, To perform capacity planning for energy team, you must gather each team", 'keywords': ['Capacity Planning', 'Engineering Resources', 'Sprint'], 'summary': 'The discussion on capacity planning highlights its importance in managing engineering resources effectively within a sprint. It is compared to a tapestry, where careful planning aids teams in understanding their available productive engineering time. The speaker uses the energy team as an example to illustrate the process of gathering information necessary for effective capacity planning.'}, {'topic': 'Team Availability Considerations', 'start_time': '00:03:14', 'end_time': '00:03:30', 'transcript': 'members availability and time of, as I said regarding their holidays or leaves, you know, I said about the leaves. If there is holidays during those springtime, then definitely we also considered that. And that time of will be for everybody. That is part of the strength.', 'keywords': ['Team Availability', 'Holidays', 'Leaves'], 'summary': "The discussion addresses the considerations of team availability, particularly focusing on members' holidays and leaves. The speaker emphasizes the importance of accounting for these factors during the springtime, highlighting that such considerations apply to all team members and contribute to the team's overall strength."}, {'topic': 'Calculating Team Capacity', 'start_time': '00:03:31', 'end_time': '00:03:58', 'transcript': "So So this is telling that and then add up the individual capacity to calculate the team's overall capacity. So the complete work covers for each of the team members in adding of all each team members complete work hours. We can make the full capacity of the T right that aghast on your team's overall capacity, which is maximum amount of work that you can pile on their plate before you have over extended them, which we don't want.", 'keywords': ['Team Capacity', 'Individual Capacity', 'Work Hours'], 'summary': 'The transcript discusses the process of calculating team capacity by summing the individual capacities of team members to determine the overall capacity of the team. It emphasizes the importance of understanding the total work hours contributed by each member to avoid overextending the team, ensuring that they are not burdened with excessive tasks beyond their maximum capacity.'}, {'topic': 'Planning Stage in Capacity Planning', 'start_time': '00:03:58', 'end_time': '00:04:27', 'transcript': "So once you have that information, you move into the planning stage. That's very will prioritise task and scheduled those hours so that work is completed by the intended deadline. So capacity means you will root the project plan expectations in reality. So we are not keeping anything for, you know, guess work rather than you're optimistic guesses about what team can churn. Oh, this is the basic thing about capacity. The next comes the ways to estimate so.", 'keywords': ['Capacity Planning', 'Task Prioritization', 'Estimation Methods'], 'summary': 'The speaker discusses the planning stage in capacity planning, highlighting its importance in prioritizing tasks and scheduling hours to ensure that work is completed by the intended deadline. They emphasize that capacity should be grounded in realistic project expectations rather than optimistic guesses about team productivity. The speaker then introduces the next topic, which is methods for estimating capacity.'}, {'topic': 'Estimation Techniques', 'start_time': '00:04:27', 'end_time': '00:04:47', 'transcript': 'if a some of you guys are working currently on sprint based projects or even if you are not, I think you must be familiar with things like estimation of the storeys. So how do we do the estimates? So the most common thing that we currently laid to is Storey pointing right?', 'keywords': ['Estimation Techniques', 'Story Points', 'Sprint-Based Projects'], 'summary': 'The speaker introduces the topic of estimation techniques, particularly in the context of sprint-based projects. They emphasize the importance of estimating story points, which is a common practice in project management. The discussion hints at methods used for making these estimations effectively.'}, {'topic': 'Story Pointing Methods', 'start_time': '00:04:47', 'end_time': '00:05:12', 'transcript': "So this is just a just in which I am trying to explain to Otis Storey pointing. So there are a couple of methods that we tried to estimate there's old school, May 3rd storey point, May 3rd storey count and hybrid matters. The most common method is the storey appointments or which we normally deal in storey pointing. Also, there are two ways of Storey pointing that this T shirt sizing and the Fibonacci series one", 'keywords': ['Story Pointing', 'T-shirt Sizing', 'Fibonacci Series'], 'summary': 'The transcript discusses various methods of story pointing, which is a technique used in estimating work in agile project management. The speaker introduces different approaches, including the traditional story pointing and hybrid methods. They specifically mention T-shirt sizing and the Fibonacci series as two common techniques within story pointing.'}, {'topic': 'Story Pointing Techniques', 'start_time': '00:05:12', 'end_time': '00:05:24', 'transcript': 'so again a T shirt sizing, which is like small, medium large Axl, this is not that much used and the Fib Unity series, which is the most commonly used currently on storey pointing.', 'keywords': ['Story Pointing', 'Fibonacci Series', 'T-shirt Sizing'], 'summary': 'The transcript discusses various story pointing techniques in project management, specifically mentioning T-shirt sizing, which categorizes tasks into sizes such as small, medium, large, and extra-large. It notes that this method is not widely used. The speaker highlights the Fibonacci series as the most commonly utilized technique for story pointing at present.'}, {'topic': 'Story Pointing Process', 'start_time': '00:05:24', 'end_time': '00:05:48', 'transcript': "So how is this done? For example? It's a very simple storey and we do not have anything to explore or lots of understanding. Then it will be a storey 0.1 or two, so here. The series is given of it wrong. And sorry I didn't cheque that out. It will be one told 357 notches. Cities. Okay, so if it is a simple one will give a one or two pointers.", 'keywords': ['Story Pointing', 'Estimation', 'Agile'], 'summary': 'The transcript discusses the story pointing process, explaining how to assign story points based on the complexity of a task. It mentions that for simple stories, a score of 0.1 or 2 points may be assigned, while more complex stories would receive higher scores, such as one to three or five points. The speaker reflects on the importance of accurately assessing the complexity to ensure proper estimation.'}, {'topic': 'Team Involvement in Story Pointing', 'start_time': '00:05:48', 'end_time': '00:06:17', 'transcript': 'that a storey pointing is done along with the whole team. As you know, there are grooming sessions during which the whole team sits together, understands the storey and then, as per everybody is voting that is decided whether that storeys and easy one then will give an auto. If it is a medium complex storey will give it a three if it is more complex than it is a five and if it is extremely complicated and very, very difficult will give it eight.', 'keywords': ['Story Pointing', 'Team Collaboration', 'Grooming Sessions'], 'summary': 'The transcript discusses the process of story pointing as a collaborative effort involving the entire team. It highlights the importance of grooming sessions where team members collectively engage in understanding the story. During these sessions, team members vote on the complexity of the story, assigning values based on difficulty: an easy story receives a value of one, a medium complex story receives three, a more complex story is assigned a five, and an extremely complicated story gets an eight.'}, {'topic': 'Breaking Down Story Points', 'start_time': '00:06:17', 'end_time': '00:06:37', 'transcript': 'So most of the times we tried to break down eight point of storeys into lesser points. Like, you know, two models of three and five. Okay, one storey of three points, another of five points. So body A. This is the way of just, you know, deciding which storey is of how much difficulty level', 'keywords': ['Story Points', 'Difficulty Level', 'Agile Methodology'], 'summary': 'The discussion focuses on the process of breaking down story points into smaller, manageable units for better assessment of difficulty levels. The speaker explains a method of dividing eight story points into two models, one comprising three points and the other five points, to facilitate decision-making regarding the difficulty of each story.'}, {'topic': 'Capacity Planning Templates', 'start_time': '00:06:40', 'end_time': '00:07:00', 'transcript': 'So this is just a rough or in a very simple what can is it? A table which is showing how we are doing the capacity planning, though in other real instance are in show you how it issues showing. So the normally we have two ways of doing this capacity planning.', 'keywords': ['Capacity Planning', 'Templates', 'Process'], 'summary': 'The transcript discusses a basic overview of capacity planning templates, illustrating a simple table that reflects the current capacity planning process. The speaker mentions that there are typically two approaches to executing capacity planning and indicates that further examples will be provided in real instances.'}, {'topic': 'Excel Template for Capacity Planning', 'start_time': '00:07:00', 'end_time': '00:07:16', 'transcript': 'Either we do we have a template of Axl shit temperate in which we put in the work hours or else we can donate directly through. So how we are putting a tear in the simple largest explained to him So these are the name of the resources that are part of those Graham.', 'keywords': ['Excel Template', 'Capacity Planning', 'Work Hours'], 'summary': 'The transcript discusses the use of an Excel template for capacity planning, mentioning the need to input work hours and the option to donate directly. It highlights the importance of organizing resources as part of the planning process.'}, {'topic': 'Work Hour Calculation', 'start_time': '00:07:16', 'end_time': '00:07:34', 'transcript': "So although people are names are written one other work days for which, for example, this is showing that it is a to experience that why that's why it is 10 days. Okay, In the two weeks we have 10 days, then we have categorised each type of work. Okay, so here you can see the available", 'keywords': ['Work Hours', 'Categorization', 'Workdays'], 'summary': 'The transcript discusses the calculation of work hours, indicating that there are 10 workdays within a two-week period. It highlights the categorization of each type of work and presents information on the available workdays.'}, {'topic': 'Individual Work Hour Availability', 'start_time': '00:07:34', 'end_time': '00:07:52', 'transcript': "number of days. Okay, So for example, this person don't have any vacation or anything else. So that's why he is completely available for all the 10 days and his complete work hours is 7010 into seven sewing plans. Seven hours. I am sorry", 'keywords': ['Work Hours', 'Availability', 'Vacation'], 'summary': 'The transcript discusses the individual work hour availability of a specific person, noting that they are completely available for 10 days due to the absence of any vacations or other commitments. The speaker mentions that the total work hours for this individual amount to 7010 hours, clarifying that the average daily work hour is seven.'}, {'topic': 'Vacation Impact on Capacity', 'start_time': '00:07:53', 'end_time': '00:08:17', 'transcript': "something is here in miss Okay, He So we are considering here seven work hours per day. That's the reason we're have given a den into 7. 3070 of us. Okay, then the second person, as you can see here, he has a vacation of one day. Right? So that's the reason his effective days is only nine.", 'keywords': ['Vacation', 'Work Capacity', 'Effective Days'], 'summary': "The transcript discusses the impact of vacation on work capacity, specifically analyzing how taking a day off affects an individual's effective workdays. The speaker explains that, given a standard of seven work hours per day, one person's vacation results in only nine effective days of work."}, {'topic': 'Total Work Hour Calculation', 'start_time': '00:08:17', 'end_time': '00:08:36', 'transcript': "And hence the calculation that is coming. It's nine into seven. That is an an hours per day of her, which comes to 63. So in this way, all the team's effort or work hours is calculated, and the total comes to around 3 15 hours.", 'keywords': ['Work Hours', 'Calculation', 'Team Effort'], 'summary': 'The transcript discusses the calculation of total work hours for a team. It explains that the calculation involves multiplying nine by seven to determine daily hours, resulting in a total of 63 hours. Ultimately, the total work hours for the team is summarized to be approximately 315 hours.'}, {'topic': 'Advanced Capacity Planning', 'start_time': '00:08:37', 'end_time': '00:08:49', 'transcript': "So this is a basic capacity plan, so I'll just give you a glimpse of the actual ones, which we normally use, so it's a bit more complicated than what you have seen, so", 'keywords': ['Capacity Planning', 'Resource Management', 'Operational Efficiency'], 'summary': 'The speaker introduces a basic capacity plan and indicates that they will provide a glimpse of more complex, actual capacity plans typically used in practice. They suggest that these real plans are more complicated than the basic example presented.'}, {'topic': 'Technical Issues during Presentation', 'start_time': '00:08:57', 'end_time': '00:09:37', 'transcript': "not able to. I was able to see this. it's the said this light show. right. the thinking, okay? so went above this one. Is it so now unable to? You guys were able to say this.", 'keywords': ['Technical Issues', 'Presentation', 'Communication'], 'summary': "The speaker discusses technical issues encountered during a presentation, highlighting their inability to view certain content while expressing uncertainty about the audience's ability to see it. The dialogue reflects frustration with the technical setup and communication challenges during the presentation."}, {'topic': 'Technical Issues during Presentation', 'start_time': '00:09:38', 'end_time': '00:09:50', 'transcript': "it's better than before. Yeah, literally. Can you zoom? And I don't think it's a numbing with resume.", 'keywords': ['Presentation', 'Technical Issues', 'Zoom'], 'summary': 'The transcript captures a brief exchange during a presentation, where participants discuss improvements in the presentation quality. One speaker asks if they can zoom in on the content, while another expresses uncertainty regarding a tool or feature, indicating some technical issues are still present.'}, {'topic': 'Technical Issues during Presentation', 'start_time': '00:09:50', 'end_time': '00:09:59', 'transcript': "Maybe you have to come out on the slide show and land new China. There's an option to. consume you never screams as well.", 'keywords': ['Technical Issues', 'Presentation', 'Screen Sharing'], 'summary': 'The speaker discusses potential technical issues that may arise during a presentation, specifically mentioning the need to exit the slideshow and the option to manage settings related to screen sharing. They highlight the importance of being aware of these options to ensure a smooth presentation.'}, {'topic': 'Technical Issues during Presentation', 'start_time': '00:10:00', 'end_time': '00:10:16', 'transcript': 'There is a plus sign the next two years. Aargh! Point on ya, hon. Just under Insert Manu Under in 30 days a zoo Michael.', 'keywords': ['Technical Issues', 'Presentation', 'Instructions'], 'summary': 'The transcript contains a brief and unclear description of technical issues encountered during a presentation. The speaker expresses frustration, mentioning a plus sign and referencing some instructions or elements related to the presentation, but the context remains vague.'}, {'topic': 'Real-Life Capacity Planning Example', 'start_time': '00:10:17', 'end_time': '00:10:42', 'transcript': "just take on the drop down arrow and them. Zuman. Okay. Okay. Lydia. Thank you, Yah! so Yeah. So this is actually some sort of a real life capacity planning sheet that we are actually using. So it's a bit more complex than what I show new as a unit sister format, you can see", 'keywords': ['Capacity Planning', 'Real-Life Example', 'Complexity'], 'summary': 'The speaker introduces a real-life capacity planning example, indicating that they are using a detailed capacity planning sheet that is more complex than previously shown simpler formats. They mention the use of a dropdown arrow, suggesting an interactive or dynamic element in the planning sheet.'}, {'topic': 'Team Member Listing', 'start_time': '00:10:42', 'end_time': '00:11:08', 'transcript': "So here you can say everything is mentioned. Who are the team members? What are the total number of this string shot is not full. So because I couldn't take it in a single stream. So there are some more few more members the chairman sing here. So this is train shot with, I mean part of the scrum team, not the full. As you can see from here, all the members are being seen", 'keywords': ['Team Members', 'Scrum Team', 'Chairman'], 'summary': 'The transcript discusses the listing of team members within a scrum team, indicating that not all members are included in the current screenshot. The speaker points out that the image does not capture the complete team but highlights the presence of certain members, including the chairman. The focus is on providing an overview of the team structure as shown in the screenshot.'}, {'topic': 'Holiday Considerations in Capacity Planning', 'start_time': '00:11:09', 'end_time': '00:11:28', 'transcript': 'so here that the members are there. So total spring daisy A mentioning water, the holidays. If there is any any leads for any of the resources, what on the actual days. So what are the actual days means what at the days that they are actually working per day hours. So here we have taken six tape', 'keywords': ['Capacity Planning', 'Resource Management', 'Working Days'], 'summary': 'The discussion focuses on the importance of considering holidays in capacity planning. It highlights the need to identify the actual working days and hours of resources during holiday periods. The speaker mentions a specific example involving a total of six tapes, indicating a structured approach to managing resources effectively during holidays.'}, {'topic': 'Buffer Time for Meetings', 'start_time': '00:11:29', 'end_time': '00:11:51', 'transcript': "six hours per day and we keep two hours for buffer. Usually that is assigned because, you know, we do have several meetings when we are part of the sprint or a scam. We have several meetings. So that's why be assigned belief to ask per day for this kind of activities, meeting activities and other, you know.", 'keywords': ['Buffer Time', 'Meetings', 'Sprint'], 'summary': 'The transcript discusses the allocation of time for meetings, specifically mentioning a structure of six hours per day with two hours dedicated as buffer time. This buffer is necessary due to the multiple meetings that occur during a sprint or scam, indicating the importance of managing time effectively for meeting-related activities.'}, {'topic': 'Total Effective Hours Calculation', 'start_time': '00:11:51', 'end_time': '00:12:05', 'transcript': 'Connexion, connecting with the your team members and also effective work hours. This six. So accordingly of what is the number of hours per person gets is 36 hours for the full sprint, which is two week Sprint Reich.', 'keywords': ['Effective Hours', 'Team Members', 'Sprint'], 'summary': 'The transcript discusses the calculation of total effective work hours in a team setting, specifically for a two-week sprint. It mentions that each team member has a total of 36 effective work hours allocated for the full sprint.'}, {'topic': 'Effort and Capacity Calculation', 'start_time': '00:12:05', 'end_time': '00:12:32', 'transcript': "So hearing you can see for 68 here we have another small thing where we are calculating the total death effort, complete depth effort of work hours and the queue way work hours. Okay, so 20 for is the Dever covers and 140 for Solly. It's percent estimate. Whatever 135 you ever covered", 'keywords': ['Effort Calculation', 'Capacity', 'Work Hours'], 'summary': 'The transcript discusses the calculation of total effort and capacity in relation to work hours, specifically mentioning the complete depth effort and queue work hours. It provides numerical values, indicating that 20 hours are allocated for a specific task and 140 hours for another, with a mention of a 135 percent estimate for coverage.'}, {'topic': 'Capacity Utilization Monitoring', 'start_time': '00:12:32', 'end_time': '00:13:27', 'transcript': 'along with, we have another. okay? becoming Dombeck 50 person, 100%. Okay, so yeah, along that we have a few more things, like, you know, what is the available capacity? What is the time estimate and capacity utilisation. Capacity remaining. So, for example, a person has 36 capacity. But as per the storey points, we are able to assign only 30 work hours, so he will have a remaining capacity of 5% or five', 'keywords': ['Capacity Utilization', 'Available Capacity', 'Time Estimates'], 'summary': 'The transcript discusses capacity utilization monitoring, focusing on determining available capacity, time estimates, and remaining capacity. It provides an example where an individual has a total capacity of 36 but can only be assigned 30 work hours, resulting in a remaining capacity of 5%.'}, {'topic': 'Monitoring Team Capacity', 'start_time': '00:13:27', 'end_time': '00:13:50', 'transcript': 'in which he can accommodate any ad host stance or anything that comes in between. So those kind of things are also there. So here we can monitor which team member has got the, you know, his capacities move than his actual available capacity or it is lesser. And if if he has any banned with left, where we can take on', 'keywords': ['Team Capacity', 'Workload Management', 'Bandwidth'], 'summary': "The transcript discusses the monitoring of team capacity, focusing on how to assess individual team members' available capacities compared to their actual workloads. It highlights the importance of tracking whether team members are over or under capacity and mentions the need to manage any remaining bandwidth effectively."}, {'topic': 'Calculating Total Development Hours', 'start_time': '00:13:51', 'end_time': '00:14:16', 'transcript': 'one Moting here is like here is the like, for example, here having all the team members and then So we are calculating here. The total devours the total Q hours. So he are out of these members. The people that are mentioned in yellow are testing team people, so the addition of all these people', 'keywords': ['Development Hours', 'Testing Team', 'Team Members'], 'summary': 'The conversation focuses on calculating the total development hours for a project, highlighting the involvement of team members. The speaker notes that the individuals highlighted in yellow are part of the testing team, indicating that their hours are included in the overall calculation of total development hours.'}, {'topic': 'Total Development Work Calculation', 'start_time': '00:14:17', 'end_time': '00:14:44', 'transcript': "we will be able to calculate the the way of us. And similarly, the addition of all these people that are in grade are the other deaf people. So the damper cars were able to calculate separately, and then we have the total bar covers. But yeah, this thing, whatever is the total, is it? It's coming here and we're getting the total were covers for Q and the for deaf and also for the team, So this is the way so.", 'keywords': ['Total Development Work', 'Calculation', 'Bar Covers'], 'summary': "The discussion focuses on the calculation of total development work, highlighting the addition of contributions from various team members including those in different grades and roles. The speaker explains the methodology for calculating totals separately for different categories, specifically mentioning the calculation of total bar covers for both 'Q' and 'deaf' teams. The overall approach to aggregating these totals is emphasized."}, {'topic': 'Velocity Calculation', 'start_time': '00:14:45', 'end_time': '00:15:07', 'transcript': "some of them things like. so long. Also, you know, though, didn't use this one much, but sometimes also from this. whatever data we are giving, we can also culprit velocity here. Or we can project the velocity that we will be able to achieve, okay?", 'keywords': ['Velocity', 'Data Projection', 'Calculation'], 'summary': "The transcript discusses the concept of velocity calculation, mentioning that it can be derived from various types of data provided. The speaker notes that although they haven't frequently used a particular method, it is possible to project the velocity that can be achieved based on the given data."}, {'topic': 'Manual vs Automated Capacity Planning', 'start_time': '00:15:09', 'end_time': '00:15:38', 'transcript': "sahib. department in this manually, or is it through the era? So I am telling youth of this Excel sheet is actually mental manually. But we do have a G option of it doesn't happen like this. I will show you the gene option as after we have discussed. So I told him in to his red wine, raise the Excel sheet, which is a manual thing, which we do right. This is the one and also may have a Gina option which have issued.", 'keywords': ['Capacity Planning', 'Excel', 'Automation'], 'summary': "The transcript discusses the differences between manual and automated capacity planning. The speaker mentions the use of an Excel sheet for manual planning and hints at an automated option, referred to as the 'G option.' They plan to demonstrate this automated process after discussing the manual method, emphasizing the importance of understanding both approaches."}, {'topic': 'Screen Sharing Issues', 'start_time': '00:15:38', 'end_time': '00:15:52', 'transcript': 'Sorry, Mon Amis. However question So withdrawing the screen on the right hand side where you have listed down the storey numbers and the name of the other way of doing the capacity Planning, however,', 'keywords': ['Screen Sharing', 'Capacity Planning', 'Story Numbers'], 'summary': 'The speaker expresses apologies to the audience while addressing screen sharing issues. They mention a specific aspect of the screen, referring to the right-hand side where story numbers and an alternative method for capacity planning are listed. The discussion hints at challenges faced during the presentation.'}, {'topic': 'Listing Stories for Sprint Planning', 'start_time': '00:15:52', 'end_time': '00:16:05', 'transcript': 'know like this is the same capacity. So here now we are register jotting down the storeys that will be covering in the spread ride for every sprint before starting the spring. We are', 'keywords': ['Sprint Planning', 'Story Listing', 'Agile'], 'summary': 'The discussion focuses on the process of listing stories for sprint planning, highlighting the importance of documenting the stories to be covered in each sprint before its commencement. The speaker emphasizes maintaining the same capacity for effective planning.'}, {'topic': 'Work Hour Allocation for Stories', 'start_time': '00:16:05', 'end_time': '00:16:31', 'transcript': 'doing a capacity planning, right? So the upcoming streamed We are listing down all the storeys that we will do in this train. And who will work on this print. Right? So for example, if this storey is being done by the developer Dipak So the package will have here his workouts. How many work of us even allocated? For example, out of his total capacity of 36 he will just give three hours for this. And then again there will be', 'keywords': ['Capacity Planning', 'Work Hour Allocation', 'Story Management'], 'summary': "The transcript discusses the process of capacity planning for upcoming stories in a project. It details how team members, like a developer named Dipak, will allocate their available work hours to specific tasks. For instance, it mentions that out of Dipak's total capacity of 36 hours, he will allocate only three hours to a particular story, highlighting the importance of managing work hour distribution effectively."}, {'topic': 'Story Breakdown for Developers and Testers', 'start_time': '00:16:31', 'end_time': '00:16:58', 'transcript': "some Barca was for the tested as well they will give. Maybe they will give two hours. Okay, so that is the reason the invention ing it. Storey buys how much a storey points or how much Barca will not store ippon. Sorry hours breakdown actually right at the breakdown and the the task, right? Completely a ride. So every storeys we are breaking down. We're taking the hours considering the hours that will be", 'keywords': ['Story Points', 'Task Breakdown', 'Estimation'], 'summary': 'The transcript discusses the breakdown of story points and hours for developers and testers. It highlights the importance of accurately estimating the time required for tasks, mentioning that every story is analyzed in terms of the hours needed for completion. The speaker aims to clarify the process of how story points relate to the overall task breakdown.'}, {'topic': 'Advantages of Capacity Planning', 'start_time': '00:16:58', 'end_time': '00:17:25', 'transcript': 'of more like the developer. How much hours they spend? The tester, How much I was Davis pen And how much is the total hours? So accordingly you know, open the Pakis parking on this storey as well as this storey as well as this Storey said the complete fire cover should come to near about 36 so we can keep a track. Okay Addition of all these storeys will come to around 36 right? So you can get the totally here.', 'keywords': ['Capacity Planning', 'Resource Management', 'Time Tracking'], 'summary': "The speaker discusses the importance of capacity planning, particularly in understanding the hours spent by developers and testers. They emphasize tracking the total hours, which is necessary for managing multiple projects or 'storeys'. The conversation suggests that by aggregating these hours, a clearer picture of overall capacity can be achieved, with a target of around 36 hours mentioned."}, {'topic': 'Avoiding Team Burnout', 'start_time': '00:17:26', 'end_time': '00:18:03', 'transcript': 'So next comes is the advantages of capacity planning. So I want to just zoom out. You can get a you. so so for the advantages. So first of all, it is avoid burnout. So what is about team won out is like, you know, the Arges piling work on somebody. And we exactly do not have any idea that whether that person will be able to do or not, or whether he is stretching more just to, you know, fulfil the work and to a', 'keywords': ['Capacity Planning', 'Team Burnout', 'Workload Management'], 'summary': 'The transcript discusses the advantages of capacity planning, specifically highlighting its role in avoiding team burnout. It addresses the issue of workload management and the potential for team members to feel overwhelmed when tasks are assigned without a clear understanding of their ability to handle the workload.'}, {'topic': 'Realistic Deadline Setting', 'start_time': '00:18:03', 'end_time': '00:18:19', 'transcript': "we do not want want to stumped him to function like that. We want the work to be done. But also it's not like a person is, you know, working late nights and weekends just to compete. We do not one that can be a planning properly,", 'keywords': ['Deadline Setting', 'Work-Life Balance', 'Proper Planning'], 'summary': 'The discussion focuses on the importance of realistic deadline setting to ensure that work is completed without putting excessive pressure on individuals, such as working late nights and weekends. The speaker emphasizes the need for proper planning in order to achieve this balance.'}, {'topic': 'Identifying Skill Shortages', 'start_time': '00:18:19', 'end_time': '00:18:49', 'transcript': "and we are able to estimate that. Okay, we have a delivery in the state. And so if they are planning in this way, our definitely will meet our posts will meet her deliberated. So this will help to do the work effectively without any stress on the team bus. It is the main thing, like so taking steps to get for understanding of your teams at Children positive in she won't overwhelm them with too many tasks and responsibilities and also support them in managing their time by prioritising the most impactful.", 'keywords': ['Skill Shortages', 'Team Management', 'Time Management'], 'summary': 'The transcript discusses the estimation of skill shortages in a particular state, highlighting the importance of effective planning to meet staffing needs. It emphasizes the necessity of understanding team dynamics and ensuring that team members are not overwhelmed with tasks. The speaker advocates for supporting team members in time management by prioritizing impactful responsibilities, which is crucial for maintaining a productive work environment.'}, {'topic': 'Proactive Problem Identification', 'start_time': '00:18:49', 'end_time': '00:19:14', 'transcript': "then sent more realistic deadlines again the same thing. So it's like something which they can achieve. It's not like a career piling them on, and then at the end of the strength of, even if they are trying their level best, they are not able to achieve so Yah, we do not want that. So get details about availability straight from your team. You will get a much needed reality. Cheques on the Dugan manage deadline expectations according to what your team can actually produce,", 'keywords': ['Proactive Problem Identification', 'Deadline Management', 'Team Availability'], 'summary': "The discussion focuses on the importance of proactive problem identification in managing project deadlines. The speaker emphasizes the need for realistic deadlines that align with the team's capabilities, rather than overwhelming them with unattainable goals. They advocate for gathering detailed information about team availability to establish achievable expectations and effectively manage deadline pressure."}, {'topic': 'Challenges in Capacity Planning', 'start_time': '00:19:14', 'end_time': '00:19:38', 'transcript': "then the third point is identify skin sock shortages. So by evaluating your team's capacity and planning work in advance, it's easier to spot if projects require skills that your team doesn't have. Accounting for that early allows you to take proactive action, such as training someone on your team. Outsourcing attacks are changing the scope of the project, so I think this is very self explanatory. So when we are planning ahead, so we in.", 'keywords': ['Capacity Planning', 'Skill Shortages', 'Outsourcing'], 'summary': "The discussion focuses on the challenges of capacity planning, particularly the importance of identifying skill shortages within a team. By assessing the team's capacity and planning work in advance, project managers can recognize when specific skills are lacking. This proactive approach enables them to take necessary actions, such as providing training or considering outsourcing, to address these gaps before they impact project execution."}, {'topic': 'Understanding Bandwidth', 'start_time': '00:20:03', 'end_time': '00:20:24', 'transcript': 'so the challenges of capacity planning said stuff to understand band with. So, yeah, it is tough to understand band with because, you know, view we are projecting that. Okay, this person can do this much hours. It may be that Okay, that person, even if for he is mentioning that I will need three hours of world,', 'keywords': ['Bandwidth', 'Capacity Planning', 'Workload Estimation'], 'summary': 'The discussion addresses the challenges of capacity planning in relation to understanding bandwidth. It highlights the difficulties in projecting the required bandwidth based on individual workload estimations, indicating that the expected hours of work may not align with actual needs.'}, {'topic': 'Estimating Work Hours', 'start_time': '00:20:24', 'end_time': '00:20:45', 'transcript': "Sometimes something happens and he is getting stuck and he needs another more two hours. It's actually not three hours. It's actually five hours. So in that way, when we are calculating everything we are considering, Okay, this work will only take three hours, but actually it is taking more. So this type of difficulty comes.", 'keywords': ['Work Hours', 'Estimation', 'Task Management'], 'summary': 'The speaker discusses the challenges in estimating work hours, particularly when unexpected complications arise that prolong tasks beyond initial estimates. They highlight a scenario where a task anticipated to take three hours actually requires five, emphasizing the need to account for such difficulties in time calculations.'}, {'topic': 'Team Changes Impacting Capacity', 'start_time': '00:20:45', 'end_time': '00:21:13', 'transcript': "And so that's why it is written. It's tough to understand band with, and though we have a solution to this, which is like the always came buffer hours, as I told you so, that that will take care of this and the gritty or whatever. So your team's bandits is always evolving as projects change and team members leave or join the ranks. So this is another challenge, right? Because, you know, team members are leaving and joining in the middle of this print and also that definitely impacts it.", 'keywords': ['Team Changes', 'Bandwidth', 'Project Capacity'], 'summary': "The transcript discusses the challenges associated with team changes impacting capacity, particularly how team bandwidth evolves as projects progress and team members transition in and out. The speaker mentions a solution involving 'always came buffer hours' to manage these changes. The dynamic nature of team composition is highlighted as a significant factor influencing project capacity."}, {'topic': 'Team Honesty in Work Estimates', 'start_time': '00:21:14', 'end_time': '00:21:36', 'transcript': "So plus, you need to rely on people's honesty about the current again. The same thing as I told a work may take more a work may take less. So that is also restriction all of that making a challenging to get a firm grasp on just how much capacity your team has available to tackle new work and request, particularly if you have a team full of high achievers always believed that they can take", 'keywords': ['Team Honesty', 'Work Estimates', 'Capacity Assessment'], 'summary': "The discussion focuses on the importance of team honesty in work estimates, highlighting the challenges that arise when team members overestimate or underestimate their capacities. It emphasizes the difficulty in accurately assessing the team's available capacity for new work, particularly when dealing with high achievers who often believe they can take on more than they realistically can."}, {'topic': 'Improving Capacity Understanding', 'start_time': '00:21:36', 'end_time': '00:21:59', 'transcript': 'more. Okay, the more often you have, you talked your team about their most three teams to it weekly, the easier it will get for you to be realist. So as an venue work with a certain team. You know, maybe in the first print your capacity may not be a perfect, but as and when you work on a multiple sprints, you know, like er', 'keywords': ['Capacity Planning', 'Team Communication', 'Sprint Management'], 'summary': 'The speaker discusses the importance of regular communication with team members regarding their capacity, suggesting that having weekly discussions about the top three tasks can lead to better realism in capacity planning. They emphasize that while initial estimates may not be perfect, experience gained from working through multiple sprints will improve the understanding of team capacity.'}, {'topic': 'Dealing with Project Changes', 'start_time': '00:21:59', 'end_time': '00:22:22', 'transcript': "after first a Ken than third and consecutive sprint. Then you get the more better grasp on how much each person's capacities is. And if you were, you know, if you are committing more than that, also can district or if you are committing less than also that also you can increase it, so we will get a more realistic idea. Changes will throw you off track. They're gonna risk associated with them.", 'keywords': ['Project Management', 'Sprints', 'Team Capacity'], 'summary': "The speaker discusses the importance of understanding team capacities after completing a few sprints in a project. They emphasize that overcommitting or undercommitting can affect the team's performance, leading to a more realistic assessment of capabilities. Additionally, the speaker warns that project changes can disrupt progress and introduce associated risks."}, {'topic': 'Planning for Unforeseen Challenges', 'start_time': '00:22:22', 'end_time': '00:22:44', 'transcript': "The project and enforcement circumstances, from sense in seasonality to industry changes, will throw wrenches senior plans when you need to try to account for all these potentials. At best, capacity planning isn't always so straight forward. Planning in a cushion, even if it's just an extra day or two, will help you roll with the punches without things running of Paris. So again, this is something it it is like", 'keywords': ['Capacity Planning', 'Seasonality', 'Industry Changes'], 'summary': 'The discussion focuses on the challenges of project planning in response to unforeseen circumstances such as seasonality and industry changes. It highlights the complexities involved in capacity planning and suggests that incorporating a buffer, even a small one, can help teams adapt more effectively to unexpected disruptions, ensuring that operations do not falter.'}, {'topic': 'Importance of Capacity Planning', 'start_time': '00:22:44', 'end_time': '00:22:55', 'transcript': "even if you are planning, there may be some hindrances, but you know it's much better to go with capacity than without capacity. Then it is like completely chaos, and", 'keywords': ['Capacity Planning', 'Chaos', 'Strategic Management'], 'summary': 'The discussion highlights the significance of capacity planning, indicating that although obstacles may arise during the planning process, having a capacity strategy is essential. The speaker contrasts this with a scenario lacking capacity, which leads to complete chaos.'}, {'topic': 'Identifying Overcommitment', 'start_time': '00:22:55', 'end_time': '00:23:23', 'transcript': "there is no planning and all if you're doing any, you know, starting or sprint without the capacity, so you will have to engage in some hard conversations again. This is a part of capacity and a tapestry. Planning is only useful if you though something with the information you identify that can involve turning down projects due to lack of bandwidth, adjusting a reducing expectations, pushing out deadlines. It's always better to say no than too serious and not to deliver. So this is the most in", 'keywords': ['Capacity Management', 'Project Commitment', 'Planning'], 'summary': 'The transcript discusses the importance of planning in the context of capacity management and recognizing overcommitment. It highlights the need for engaging in difficult conversations regarding project commitments when resources are limited. The speaker emphasizes making informed decisions, which may include declining projects, adjusting expectations, or extending deadlines, to avoid overpromising and underdelivering.'}, {'topic': 'Best Practices in Capacity Planning', 'start_time': '00:23:50', 'end_time': '00:24:10', 'transcript': 'purpose of the president planning the next is capital planning. Best Praxis is so some of the tapestry planning West practises are sorry. So learn from past projects. Okay, so this is the main our thing, you know, and a capacity in the first sprint that Udo will never be perfect. It will be a kind of Okay,', 'keywords': ['Capacity Planning', 'Best Practices', 'Project Management'], 'summary': 'The transcript discusses the importance of best practices in capacity planning, highlighting the role of learning from past projects to improve future planning efforts. The speaker notes that while capacity planning may not be perfect, it will serve as a foundational element in the planning process.'}, {'topic': 'Learning from Past Projects', 'start_time': '00:24:10', 'end_time': '00:24:36', 'transcript': 'we are just trying to see. But as and when the A growth, the capacity planning for the future strengths on the next prince will definitely be better and will have a better idea about the amount of work which we should take and will be able to complete. Have honest conversations with Team OK song in here. The you know, transparency is very important, though Scram, Master and the', 'keywords': ['Capacity Planning', 'Transparency', 'Scrum Master'], 'summary': 'The discussion focuses on learning from past projects, emphasizing the importance of capacity planning as the organization grows. The speaker highlights the need for honest conversations within the team and underscores the significance of transparency, particularly in the role of the Scrum Master.'}, {'topic': 'Team Transparency in Capacity Planning', 'start_time': '00:24:37', 'end_time': '00:24:56', 'transcript': "A team member should be completely true with each other so that the another's come. Master understands the limitations of the developer of the tester and also the developer, and the tester truly identifies water. The actual bar covers that he or she is putting, which will again, you know, help us in doing a good capacity.", 'keywords': ['Team Transparency', 'Capacity Planning', 'Developer Limitations'], 'summary': 'The transcript discusses the importance of team transparency in capacity planning, highlighting the need for team members to be honest with one another. It emphasizes that a master should understand the limitations of both developers and testers, while also ensuring that developers and testers accurately identify their capacities. This transparency is presented as a crucial factor that can enhance overall capacity planning.'}, {'topic': 'Project Request Understanding', 'start_time': '00:24:56', 'end_time': '00:25:11', 'transcript': "so get the necessary details up front. So when a project request some across comes across your desk as thoughtful questions to make sure you grass the INS and out awards being requested, you can also create a brief. So it is again. It's like you are predicting", 'keywords': ['Project Request', 'Details', 'Brief'], 'summary': 'The speaker emphasizes the importance of gathering necessary details upfront when handling project requests. They suggest asking thoughtful questions to fully understand the ins and outs of the awards being requested. Additionally, the speaker mentions the creation of a brief, likening the process to making predictions based on the information gathered.'}, {'topic': 'Creating a Flow Chart for Planning', 'start_time': '00:25:34', 'end_time': '00:25:42', 'transcript': 'so. This is kind of a flow A charge Stating of what? We are putting it all together so they can go through. It is just', 'keywords': ['Flow Chart', 'Planning', 'Organization'], 'summary': 'The transcript discusses the creation of a flow chart for planning purposes, indicating that it serves as a summary or overview of the information being organized. The speaker emphasizes the importance of compiling all elements into a cohesive format to facilitate understanding and navigation of the content.'}, {'topic': 'Technical Issues with Roadmap', 'start_time': '00:25:42', 'end_time': '00:25:59', 'transcript': "okay. So yeah. Now I just want you to show how in Gina we're doing it right. So sorry for this. As you can see in the left side, there was some glitch in the Gina when I was taking the screenshots. Because of that,", 'keywords': ['Technical Issues', 'Gina', 'Screenshot'], 'summary': 'The speaker addresses technical issues encountered with the Gina platform, specifically highlighting a glitch that occurred during the screenshot process. They express a desire to demonstrate the correct usage of Gina despite these technical challenges.'}, {'topic': 'Defining Roles in Roadmap', 'start_time': '00:25:59', 'end_time': '00:26:18', 'transcript': "I couldn't get the actual is to ensure here, as you can see, did not a PLO badia, for what you have to do is first to go to the ups and here you have to define okay define the rules like deaf rosewater. The rules that will give you a teen froze for example You will have developers development, role testing room", 'keywords': ['Roles', 'Roadmap', 'Collaboration'], 'summary': 'The transcript discusses the importance of defining roles within a project roadmap. The speaker emphasizes the need to establish clear roles, such as development and testing roles, to ensure effective collaboration and project execution. This process involves outlining specific responsibilities to enhance workflow and accountability among team members.'}, {'topic': 'Creating Team Structure', 'start_time': '00:26:18', 'end_time': '00:26:37', 'transcript': "support role. Then there will be sued. Hell, so on. And so so far. You can give Rolls. You will identify. So all these things will Did define first right Role step team step. What other teams that you're using see will identify this first? Once that is done, you will come to the sprint capacity. Okay,", 'keywords': ['Team Structure', 'Roles', 'Sprint Capacity'], 'summary': 'The transcript discusses the process of creating a team structure by identifying roles and responsibilities within the team. It emphasizes defining the first roles and steps needed to establish the team effectively, as well as the importance of understanding the sprint capacity after identifying these roles.'}, {'topic': 'Work Hour Management', 'start_time': '00:27:10', 'end_time': '00:27:33', 'transcript': "and whether their development, the members just inky member supporting members, front 20 members. You can mention these things. Then you have the work hours here. It's very simple, like the same capacity per day is six for everyone most of the time. But, you know, if there are certain people who are taking on had on work or they are, you know, some people are there who've", 'keywords': ['Work Hour Management', 'Team Capacity', 'Work Distribution'], 'summary': 'The transcript discusses work hour management, focusing on the distribution of work hours among team members. It notes that typically, each member has a capacity of six work hours per day. However, it acknowledges that some individuals may take on additional work or have varying capacities.'}, {'topic': 'Sprint Capacity Management', 'start_time': '00:28:05', 'end_time': '00:28:27', 'transcript': 'his contributed. with one question How did you come to this cream? The app that arrived in the app There is a sprint capacity which for our project, like I was in good united. So they had taken this sprint capacity.', 'keywords': ['Sprint Capacity', 'Project Management', 'Application'], 'summary': 'The transcript addresses a discussion on sprint capacity management, highlighting a question about the origin of a particular application and its relevance to project management. The speaker mentions that the app arrived in the context of sprint capacity, indicating its importance to the project they were involved in.'}, {'topic': 'Full Picture of Sprint Capacity', 'start_time': '00:28:27', 'end_time': '00:28:44', 'transcript': "So, uh, we were able to, you know, put this forward. So I think we need some access is for getting there. It's not like free. There is There is some judge, a bill amount. So if that project is taking that you will be able to use this service.", 'keywords': ['Sprint Capacity', 'Access', 'Billing'], 'summary': 'The transcript discusses the importance of accessing certain services related to sprint capacity, indicating that there are costs involved and a billing amount to consider. The speaker suggests that for a project to utilize these services, specific access needs to be arranged.'}, {'topic': 'Planning Tab Overview', 'start_time': '00:29:06', 'end_time': '00:29:32', 'transcript': 'This is the sec tender. So first we were seeing this team Sprint capacity conflict. Now the sec tender cab. What we can see here is the planning tab in which you know you can see all the storeys that you have taken in that sprint. Okay? All the storeys it will show along with the assigning for those storeys. And also if the estimates have been done and the storey points have been mentioned, that will also be show.', 'keywords': ['Planning Tab', 'Sprint Capacity', 'Story Points'], 'summary': 'The transcript provides an overview of the planning tab, highlighting its functionality in managing team sprint capacity and conflicts. It explains that the planning tab displays all the stories taken in a sprint, along with their assignments and estimates, including the story points associated with each story.'}, {'topic': 'Work Completion Tracking', 'start_time': '00:29:32', 'end_time': '00:29:48', 'transcript': 'What will it also show is the percentage of work that the person has already? For example, out of 30 hours, that shit Ege is assigned, He has already 24 hours over.', 'keywords': ['Work Completion', 'Tracking', 'Percentage'], 'summary': 'The transcript discusses a feature related to work completion tracking, specifically focusing on how it displays the percentage of work completed by an individual. An example is provided where a person, assigned 30 hours of work, has already completed 24 hours.'}, {'topic': 'Work Allocation Analysis', 'start_time': '00:30:04', 'end_time': '00:30:29', 'transcript': "And for the picker, like it is showing too much of work. So definitely, we need to move out some of the things. So similarly for individual people, you can see the allocations, right? So for NeJame, we have to assign the full capacity she has, and then we haven't assigned anything to it means right. So in this way, by this craft, you can understand and identify and accordingly assigned.", 'keywords': ['Work Allocation', 'Task Distribution', 'Resource Management'], 'summary': 'The transcript discusses the analysis of work allocation among individuals, highlighting an imbalance in task distribution. The speaker points out that one individual, NeJame, has not been assigned any tasks despite having full capacity available, indicating the need to redistribute workloads effectively. The discussion emphasizes the importance of identifying and adjusting allocations to optimize work distribution.'}, {'topic': 'Project Progress Visualization', 'start_time': '00:30:32', 'end_time': '00:31:00', 'transcript': 'This is another part that some, you know, for this sprint capacity, there multiple reports that you can see. So though we did not use this much party on, you can see that the actual versus expected so, for example, planned versus potential capacity. So this much of percentage of work is done, and we have so much of eight hours out of expected 38 hours. So this is like', 'keywords': ['Project Progress', 'Visualization', 'Capacity Tracking'], 'summary': 'The transcript discusses project progress visualization, highlighting the use of reports in tracking capacity during a sprint. It contrasts actual work completed against expected performance, providing an example of planned versus potential capacity, where a certain percentage of work is completed against a set number of hours.'}, {'topic': 'Roadmap Overview', 'start_time': '00:32:45', 'end_time': '00:33:19', 'transcript': "so I think we are five minutes more. So can we moved to the road map. okay? So now moving ahead with the road maps of what is roadmap? Okay, so road mapping, Jill A software. Our team level roadmaps useful for planning large basis of work several months in advance. A terrific level within a single project. Simple planning and dependency management features help your team's visualise and manage work better. So what is exactly a roadmap is nothing but a planning feature in bet. You know, you can", 'keywords': ['Roadmap', 'Planning', 'Dependency Management'], 'summary': 'The discussion transitions to an overview of roadmaps, focusing on their importance in planning for software development projects. The speaker explains that team-level roadmaps are useful for organizing large-scale work over several months and highlight the simplicity of planning and dependency management features that enhance team visualization and management of tasks. The roadmap is described as a crucial planning tool within projects.'}, {'topic': 'Roadmap Planning Process', 'start_time': '00:33:19', 'end_time': '00:33:39', 'transcript': 'put in all the epics and under native storeys, and you can see the complete picture of like, for example, in which sprint you will be able to complete what feature Sova. Normally, you know the identify features okay, will do this by this April end will do this feature by maybe June will do this feature so f', 'keywords': ['Roadmap Planning', 'Epics', 'Sprints'], 'summary': 'The transcript discusses the roadmap planning process, focusing on the organization of epics and user stories. It highlights the importance of visualizing the complete picture of feature completion across different sprints, specifying target deadlines for features, such as completing certain tasks by the end of April and others by June.'}, {'topic': 'Roadmap Visualization', 'start_time': '00:33:39', 'end_time': '00:33:59', 'transcript': 'nothing will be clearly visible. If we are using a Roadmaster of Witch spring, we will be able to complete feature one will sprint will be able to complete feature too. So this was kind of a projection. So how does it look into looks like this? Okay, so here you can see, I just', 'keywords': ['Roadmap Visualization', 'Feature Development', 'Sprint Planning'], 'summary': "The speaker discusses the concept of roadmap visualization, highlighting the importance of clarity in presenting features during the development process. They mention using a specific tool, referred to as 'Roadmaster', for planning and completing features in various sprints. The speaker also hints at a visual representation of the roadmap, but the details remain unclear."}, {'topic': 'Epic and Story Relationships', 'start_time': '00:34:49', 'end_time': '00:35:10', 'transcript': "so far, the key concepts of ethics. Okay, so for I'm in for creating a road map, things that you need to know at the Buddhism and epic is a large body of us that can be broken down into individual tasks required to ship of feature. The world probe becomes a child issue of the epic. Sometimes owner spending epics are displayed as collard bus on", 'keywords': ['Epic', 'Story', 'Task'], 'summary': 'The transcript discusses key concepts related to epics and their relationship with stories in project management. It explains that an epic is a large body of work that can be divided into smaller tasks necessary for delivering a feature. Additionally, it mentions that the work items under an epic are often referred to as child issues, and sometimes the ownership of these epics is represented visually, possibly through colored indicators.'}, {'topic': 'Breaking Down Features into Epics', 'start_time': '00:35:10', 'end_time': '00:35:31', 'transcript': "the road map. As I showed you, it was so of epics Are you know again? As I said, like a feature, you there is a feature. Okay, So if that feature is a small feature, if it is a big feature than again, features will be broken down. But if it is a small features that you can't convert into an epic,", 'keywords': ['Features', 'Epics', 'Roadmap'], 'summary': 'The discussion focuses on the concept of breaking down features into epics within a roadmap context. The speaker elaborates on how features, depending on their size, can either remain as small features or be further developed into larger epics. If a feature is too small, it cannot be transformed into an epic, highlighting the importance of feature size in this process.'}, {'topic': 'Child Issues in Roadmap', 'start_time': '00:36:02', 'end_time': '00:36:37', 'transcript': "and these are, though, things depicted in coloured bars. what is a child issue again? As I said, under need the epic the create storeys. So the storeys are nothing but child issues. Child issues can be created directly from the road map and administered within the epic the belonged So the storeys that will create under the epic an honest child issues the most common childish you a storeys, tasks and bugs. Okay, but you can create new issue types to represent different type of work for your team's quickly move issues to other tipping and reorder issues or epics by dragging and dropping them", 'keywords': ['Child Issues', 'Epic', 'Roadmap'], 'summary': "The transcript discusses the concept of child issues within a roadmap, explaining that child issues are essentially stories created under an epic. It highlights that these child issues can be directly generated from the roadmap and managed within their respective epic. The speaker identifies the common types of child issues, which include stories, tasks, and bugs, while also noting the flexibility to create new issue types tailored to the team's needs. Additionally, it mentions the ability to efficiently manage these issues by moving and reordering them through a simple drag-and-drop interface."}, {'topic': 'Importance of Start and Due Dates', 'start_time': '00:37:01', 'end_time': '00:37:27', 'transcript': 'next to start and dude is the length of the bar on the road map for alleged at the start and due date set for Europe. Pick setting dates for your epic helps to communicate plans with the team and provide visual visibility to external stakeholders. Informed dependence in mapping and helped the resource management. So yeah, so start and doodles are very important. In order to project when you will be able to complete the feature or the epic,', 'keywords': ['Project Management', 'Start Dates', 'Due Dates'], 'summary': 'The transcript discusses the significance of start and due dates in project management, particularly in relation to visualizing timelines on a roadmap. It emphasizes that establishing these dates aids in communicating plans with the team and offers transparency to external stakeholders. Additionally, it highlights how informed dependencies and resource management are enhanced through the use of start and due dates, which are crucial for projecting the completion timeline of features or epics.'}, {'topic': 'Tracking Progress of Features', 'start_time': '00:37:27', 'end_time': '00:37:41', 'transcript': "you're starting a due date of each of the storeys or child into issues matter, you know, so that you are able to understand. OK, completely a get this epic we will be able to complete in the stand this epic. This temps of this feature will be done by this time Fring.", 'keywords': ['Progress Tracking', 'Due Dates', 'Project Management'], 'summary': 'The transcript discusses the importance of tracking the due dates of features and their corresponding tasks within a project. It emphasizes the need to understand the timelines associated with each epic and feature, ensuring that progress can be monitored effectively and that the completion of tasks aligns with set deadlines.'}, {'topic': 'Epic Completion Tracking', 'start_time': '00:37:42', 'end_time': '00:38:30', 'transcript': "So this is depicting being depicted here. As you can see, the the the the thing that the Yeah. So So far epic when you are putting her start date and the due date So that is kind of you know, high level but in a storey is you know, when you are taking up storeys we normally understand that this storey will be completing in this print trade even if it's a storey you were expecting", 'keywords': ['Epic Completion Tracking', 'Project Management', 'Task Timelines'], 'summary': 'The transcript discusses the concept of Epic Completion Tracking, highlighting how it is represented visually. It mentions the importance of setting a start date and due date for tasks, suggesting that understanding timelines is crucial for project management. The speaker implies that even if certain tasks are expected to be completed in a specific sprint, it is essential to keep track of overall progress.'}, {'topic': 'Planning for Team Input', 'start_time': '00:39:21', 'end_time': '00:39:43', 'transcript': 'it while doing the activity from THING is also the part of They are completely a part of this because of they are the ones who will you know, who will be actually doing the work. Right? So they at the ones who will say Okay, Veil late leaders will need four days to definitely they their input matters a lot.', 'keywords': ['Team Input', 'Planning', 'Collaboration'], 'summary': 'The transcript discusses the importance of team input in planning activities, highlighting that team members are integral to the process as they will be the ones executing the tasks. It emphasizes that their feedback is crucial, particularly in estimating the time required to complete the work, underscoring the value of their contributions.'}, {'topic': 'Filtering and Managing Roadmap', 'start_time': '00:39:45', 'end_time': '00:40:03', 'transcript': 'Okay, so then there is philtres and view settings with again. These are some of the features of roadmap Yadira software roadmap has built in philtres that make waving and managing work simple. Find and refine your road member searching for key words and filled of a Sinus status labelled issue at just view settings or your road map to cheque.', 'keywords': ['Filtering', 'View Settings', 'Roadmap Management'], 'summary': "The transcript discusses the filtering and view settings features of the Roadmap Yadira software. It highlights how the built-in filters facilitate the management and organization of work. The speaker explains the process of searching for keywords and filtering by status to enhance the user's ability to navigate and manage their roadmap effectively."}, {'topic': 'Managing Dependencies', 'start_time': '00:40:26', 'end_time': '00:40:50', 'transcript': "There are some times this situation's right In other storey the you will be able to start when you have completed the storey again there will be like a storey See you can be able to start menu of computers the storey So these kind of dependence is of these things These are dependencies and the dependencies were also one kind of You can sit blockers right, Unless and until you complete Storey eh? You cannot start storey p", 'keywords': ['Dependencies', 'Task Management', 'Blockers'], 'summary': "The transcript discusses the concept of managing dependencies, explaining that certain situations require completing one task (referred to as 'storey') before starting another. The speaker highlights that these dependencies can act as blockers, indicating that until a particular task is finished, one cannot proceed to the next. The focus is on understanding how to navigate these dependencies in a structured manner."}, {'topic': 'Importance of Dependency Management', 'start_time': '00:40:51', 'end_time': '00:41:11', 'transcript': 'right. So this can be, you know, Mom, this can be shown in the road map dependency Management is critical for teams. When dependence is our visualised and well mapped, a team can adapt and plan for alternative parts. Indira Software You can easily show the relationship between epics by mapping dependence is directly from the road.', 'keywords': ['Dependency Management', 'Visualization', 'Epic Relationships'], 'summary': 'The transcript discusses the critical role of dependency management for teams, highlighting that when dependencies are visualized and well-mapped, teams can better adapt and plan for alternative paths. It also mentions that software tools can effectively illustrate the relationships between epics by mapping dependencies directly from the roadmap.'}, {'topic': 'Dependency Visualization', 'start_time': '00:41:11', 'end_time': '00:41:34', 'transcript': "So this is the way. As I told you, these things show that dependencies. Okay, So for example, once this is done, you can be able to do this. Okay? Say it's mentioned, Bill. Cheque out Experience blocks this. So you have to do this epic bill cheque out experience first, and then only you can be able to do the improve U M U S lite score.", 'keywords': ['Dependency Visualization', 'Interdependent Tasks', 'Process Management'], 'summary': "The speaker discusses the concept of dependency visualization, explaining how certain tasks are interdependent. They provide an example involving a 'Bill Cheque Out Experience' that must be completed before improving a specific score. This highlights the importance of understanding dependencies to effectively manage processes."}, {'topic': 'Addressing Roadmap Questions', 'start_time': '00:41:35', 'end_time': '00:42:00', 'transcript': 'this on owners at the dependency. Right? This one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back? This is a plan. And the kind of things can I say that this is a plan the way of', 'keywords': ['Project Roadmap', 'Dependencies', 'Project Management'], 'summary': "The speaker addresses questions related to a project roadmap, specifically focusing on the integration of various tasks and dependencies. They inquire about the ability to view their ongoing work in relation to the planned roadmap, seeking clarity on whether the project's direction aligns with the original plan or if it has diverged. The discussion highlights the importance of maintaining visibility on project progress and alignment with strategic objectives."}, {'topic': 'Actual vs Planned Projection', 'start_time': '00:42:57', 'end_time': '00:43:08', 'transcript': 'at Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what we', 'keywords': ['Projected Completion', 'Estimation', 'Timeline'], 'summary': 'The discussion revolves around the projected completion date for a project at Silly Gandhi, which was initially estimated to be finished by April. However, it has now been extended until the end of April. The speaker inquires about the possibility of reviewing the initial estimates compared to the current projections.'}, {'topic': 'Exporting the Roadmap', 'start_time': '00:44:32', 'end_time': '00:44:59', 'transcript': 'so again and other feature is sure and exports of whatever road matter of created, you will be able to share and export the road map. So sandy, a roadmap directly from Gina to from here a software by typing in news animal innocently copy to grab the roadmap, your export year old map and just the timeline views Star date and in dates before expecting it as an image. So this is like some of the features of road map.', 'keywords': ['Roadmap', 'Exporting', 'Timeline'], 'summary': 'The transcript discusses the features related to exporting a roadmap created in a software called Gina. It highlights the ability to share and export the roadmap by copying it directly from the application. Additionally, it mentions options for exporting the roadmap as an image and the inclusion of timeline views, including start and end dates.'}, {'topic': 'Creating a Roadmap in Software', 'start_time': '00:44:59', 'end_time': '00:45:18', 'transcript': "create a roadmap injera software. So one of the steps to create a roadmap, Najera software creator, knew Gina Software Project or go to an existing project and then navigate to the side bag and click roadmap. Okay, not if they're not showing saying your roadmap have enabled the road map in the board setting. So again there's a Y.", 'keywords': ['Roadmap', 'Najera Software', 'Board Settings'], 'summary': 'The transcript discusses the process of creating a roadmap in a software called Najera. It outlines the steps involved, including how to access the roadmap feature by navigating to the side bag and clicking on the roadmap option. The speaker also mentions the importance of ensuring that the roadmap feature is enabled in the board settings.'}, {'topic': 'Enabling Roadmap Features', 'start_time': '00:45:18', 'end_time': '00:45:37', 'transcript': "And here, if you are not able to see the roadmap tap than definitely in the board sitting, you need to go and enable it. So people who are comfortable Najera will be understanding what I'm talking about. But if people who are not having hand from Nigeria, they may find it difficult in reading this and understanding that.", 'keywords': ['Roadmap Features', 'Enable', 'Nigeria'], 'summary': 'The speaker discusses the process of enabling roadmap features, specifically addressing those who may have difficulty accessing this information. They suggest that individuals in Nigeria might be more familiar with the context, while others may struggle to comprehend the details without prior knowledge or experience.'}, {'topic': 'Adding Epics to Roadmap', 'start_time': '00:45:38', 'end_time': '00:45:58', 'transcript': 'Then click plus create a pick on the road map to create a picks directly on your road map. If he roadmap is empty, simply start typing to create right name, year epic and hit Enter. You can double click into epics at any time from your road map to add information such a start and ended assigning attachment and more at child issues to European from the road map by clicking', 'keywords': ['Epics', 'Roadmap', 'Child Issues'], 'summary': 'The transcript discusses the process of adding epics to a roadmap. It explains how to create a new epic by clicking the plus icon on the roadmap, typing the name and year of the epic, and hitting Enter if the roadmap is empty. Additionally, it mentions that users can double-click on existing epics to add further details such as start and end dates, assignments, attachments, and link child issues from the roadmap.'}, {'topic': 'Visualizing Dependencies', 'start_time': '00:45:58', 'end_time': '00:46:18', 'transcript': 'next to the epic name. Okay, select the type of childish uses in the drop down on the named Asia and of the covered it right in a single single points. Few tips for or Mac creation visualise dependence is between epics by creating or removing dependence ceilings directly on Iroda. So this thing for this thing, you actually need to work with the team, right?', 'keywords': ['Visualizing Dependencies', 'Epics', 'Iroda'], 'summary': 'The transcript discusses the process of visualizing dependencies in project management, particularly in relation to epics. It advises users to select the appropriate options from a dropdown menu to manage these dependencies effectively. The speaker emphasizes the importance of collaboration with the team when creating or modifying dependency ceilings on the platform, Iroda.'}, {'topic': 'Team Collaboration in Roadmap Creation', 'start_time': '00:46:18', 'end_time': '00:46:40', 'transcript': "The team will be able to help you, guy do and understand and of took Lego, the product owner as well as the team. Both will be able to guide do help you in understanding what other dependencies and how to create the road map and how to mention the dependencies. Right? So that's why", 'keywords': ['Team Collaboration', 'Roadmap Creation', 'Dependencies'], 'summary': 'The discussion focuses on the collaborative process involved in roadmap creation, highlighting the roles of both the product owner and the team in guiding members to understand dependencies. The speaker emphasizes the importance of teamwork in effectively creating a roadmap and identifying these dependencies.'}, {'topic': 'Updating Epic Dates', 'start_time': '00:46:41', 'end_time': '00:46:58', 'transcript': 'the product owner as well as the team members both are very important for creating year proper road map in with all the details. Keep your old man up today by adjusting the length of the epic or slide the epic to change the start and due dates. Okay,', 'keywords': ['Product Owner', 'Epic Dates', 'Roadmap'], 'summary': 'The transcript discusses the importance of collaboration between the product owner and team members in creating a proper roadmap for project management. It emphasizes the necessity of keeping the epic dates updated by adjusting the length of the epic or sliding the epic to modify the start and due dates.'}, {'topic': 'Team Visibility on Work Progress', 'start_time': '00:46:58', 'end_time': '00:47:22', 'transcript': 'So again, as I said on that, you can change the started do days. You know, if you something happened and you are not able to complete on the mention time or whatever time the timeframe has registered or shifted. So then you can definitely change the start in. And when work is assigned to team members in Gina, they can easily see how they', 'keywords': ['Project Management', 'Task Assignment', 'Team Collaboration'], 'summary': 'The speaker discusses the flexibility in managing project timelines, particularly in adjusting the start dates if team members encounter obstacles that prevent them from completing tasks on time. They highlight the ease with which team members can view their assigned work in the project management tool Gina.'}, {'topic': 'Tracking Progress Towards Goals', 'start_time': '00:47:45', 'end_time': '00:48:10', 'transcript': "roadmaps. Help Help your team track progress towards big picture bulls in a single do. So this is the main importantly, the lamp later, the feature releases it happening on proper time. The the epics How many pixie horrible to complete, which picks terrible to complete. All districts make your roadmap shine by changing the colour of your epics. There are clear on the road map. Simply rightly, they're picking pick yokel, This is a", 'keywords': ['Roadmap', 'Progress Tracking', 'Epics'], 'summary': 'The transcript discusses the importance of using roadmaps to help teams track their progress towards achieving significant goals. It emphasizes the need for clarity in the roadmap, including the timely release of features and the management of various epics. Additionally, it highlights the visual aspect of the roadmap, suggesting that changing the colors of epics can enhance clarity and effectiveness.'}, {'topic': 'Conclusion and Questions', 'start_time': '00:49:32', 'end_time': '00:49:52', 'transcript': 'a roadmap ting So far handed, we share with the people who have joined here. not are not can go ahead and share this but Ariel so that people can go through it and the in future, if they have anything, they can get back to me. Hand indefinitely, discuss', 'keywords': ['Roadmap', 'Discussion', 'Future Reference'], 'summary': 'The transcript covers the conclusion of a session, highlighting the sharing of a roadmap with attendees and encouraging them to reach out in the future with any questions or discussions. The speaker emphasizes the importance of making the information accessible for future reference.'}, {'topic': 'Closing Remarks', 'start_time': '00:49:55', 'end_time': '00:50:21', 'transcript': 'so intense, guys. Any other questions? Thank you. Thanks times a lot. of frustration. And I including the feedback An assessment form with the recording on, please. Thank you.', 'keywords': ['Feedback', 'Assessment', 'Recording'], 'summary': 'In the closing remarks, the speaker expresses gratitude to the participants and acknowledges the intensity of the session. They invite any final questions and mention the importance of feedback, indicating that an assessment form will be provided along with the recording of the session.'}, {'topic': 'Final Thank You', 'start_time': '00:50:22', 'end_time': '00:50:23', 'transcript': 'Thank you.', 'keywords': ['Gratitude', 'Closing Remarks', 'Acknowledgment'], 'summary': "The transcript consists of a brief expression of gratitude, with the speaker simply stating 'Thank you.' This indicates a closing remark or acknowledgment at the end of a session."}], 'yellow_line': [{'Topic': 'Capacity Planning Overview', 'transcript': 'Okay, So hello, everyone on this Iman Alyssa. So today will be conducting session on two topics. One is capacity planning, and the second is the road map in Jiro. So try to cover capacity planning within the first half an hour span and then will continue with the road map injera,', 'start_time': '00:00:03', 'end_time': '00:00:21'}, {'Topic': 'Capacity Planning Definition', 'transcript': "so the festival bodies capacity planning. So, according to the definition that is given here, is capacity planning is the process of identifying how many hours a project or task will require too demanding whether or not your team has the available bans it to complete it and then coordinating that work for maximum efficiency. So what it exactly means is instead offer. You know, I'm just guessing that how much offer can be done.", 'start_time': '00:00:22', 'end_time': '00:00:52'}, {'Topic': 'Capacity Planning Process', 'transcript': 'Capacity planning is a complete process in which we are actually identifying the number of work hours that a person on already member in the scrum team can put in and the maximum work that can be achieved with within the spring time frame. For example, if it is a two week spent, then what is the maximum number of effective work hours that each of the resource can give? So that determines the capacity', 'start_time': '00:00:52', 'end_time': '00:01:19'}, {'Topic': 'Factors Affecting Capacity Planning', 'transcript': "and er It also includes things like, you know, complexity of the storey, and also it's like if it is a very complex storey, then definitely the storey point is more and so that's the reason the efficiency or the, you know work hours will be more and if it is a a medium or lesser complex than definitely the number of our covers required will be lives. So everything of this we take into consideration along with", 'start_time': '00:01:19', 'end_time': '00:01:49'}, {'Topic': 'Team Member Availability', 'transcript': "a, for example, a team member out of 15 days. Or to explain that the stand a strength, he will be only for the next two days or last two days. Whatever. Okay, so his effective days will be around eight days, right? So they'll also consider that that okay, he is actually available for eight days, and according to its, his work hours will be calculated.", 'start_time': '00:01:50', 'end_time': '00:02:15'}, {'Topic': 'Benefits of Capacity Planning', 'transcript': "So what is the benefit of this? So the benefit of this is that you know, we are not keeping anything for, you know, like Cobb, depending on the chance of completion. It's like a sure shot. What they are projecting, what they are planning, what we are focusing, we are able to achieve it. So that is the main benefit of compact", 'start_time': '00:02:15', 'end_time': '00:02:34'}, {'Topic': 'Capacity Planning Importance', 'transcript': "D planning. When we do capacity planning in a proper weight and there is very less chance that the gold will be missed or, you know, the maximum among the work we are able to achieve, rather than if we are not doing any capacity planning and randomly taking into work the new know Most of the time it's like we miss on the target and there are storeys which will spill over and you know there will be a chaos with industry.", 'start_time': '00:02:34', 'end_time': '00:02:57'}, {'Topic': 'Capacity Planning in Practice', 'transcript': "So this is the basic things are going forward with some more points on capacity planning. It's like on tapestry. Planning helps the team understand the amount of productive engineering time available in a sprint. For example, To perform capacity planning for energy team, you must gather each team", 'start_time': '00:02:58', 'end_time': '00:03:14'}, {'Topic': 'Team Availability Considerations', 'transcript': 'members availability and time of, as I said regarding their holidays or leaves, you know, I said about the leaves. If there is holidays during those springtime, then definitely we also considered that. And that time of will be for everybody. That is part of the strength.', 'start_time': '00:03:14', 'end_time': '00:03:30'}, {'Topic': 'Calculating Team Capacity', 'transcript': "So So this is telling that and then add up the individual capacity to calculate the team's overall capacity. So the complete work covers for each of the team members in adding of all each team members complete work hours. We can make the full capacity of the T right that aghast on your team's overall capacity, which is maximum amount of work that you can pile on their plate before you have over extended them, which we don't want.", 'start_time': '00:03:31', 'end_time': '00:03:58'}, {'Topic': 'Planning Stage in Capacity Planning', 'transcript': "So once you have that information, you move into the planning stage. That's very will prioritise task and scheduled those hours so that work is completed by the intended deadline. So capacity means you will root the project plan expectations in reality. So we are not keeping anything for, you know, guess work rather than you're optimistic guesses about what team can churn. Oh, this is the basic thing about capacity. The next comes the ways to estimate so.", 'start_time': '00:03:58', 'end_time': '00:04:27'}, {'Topic': 'Estimation Techniques', 'transcript': 'if a some of you guys are working currently on sprint based projects or even if you are not, I think you must be familiar with things like estimation of the storeys. So how do we do the estimates? So the most common thing that we currently laid to is Storey pointing right?', 'start_time': '00:04:27', 'end_time': '00:04:47'}, {'Topic': 'Story Pointing Methods', 'transcript': "So this is just a just in which I am trying to explain to Otis Storey pointing. So there are a couple of methods that we tried to estimate there's old school, May 3rd storey point, May 3rd storey count and hybrid matters. The most common method is the storey appointments or which we normally deal in storey pointing. Also, there are two ways of Storey pointing that this T shirt sizing and the Fibonacci series one", 'start_time': '00:04:47', 'end_time': '00:05:12'}, {'Topic': 'Story Pointing Techniques', 'transcript': 'so again a T shirt sizing, which is like small, medium large Axl, this is not that much used and the Fib Unity series, which is the most commonly used currently on storey pointing.', 'start_time': '00:05:12', 'end_time': '00:05:24'}, {'Topic': 'Story Pointing Process', 'transcript': "So how is this done? For example? It's a very simple storey and we do not have anything to explore or lots of understanding. Then it will be a storey 0.1 or two, so here. The series is given of it wrong. And sorry I didn't cheque that out. It will be one told 357 notches. Cities. Okay, so if it is a simple one will give a one or two pointers.", 'start_time': '00:05:24', 'end_time': '00:05:48'}, {'Topic': 'Team Involvement in Story Pointing', 'transcript': 'that a storey pointing is done along with the whole team. As you know, there are grooming sessions during which the whole team sits together, understands the storey and then, as per everybody is voting that is decided whether that storeys and easy one then will give an auto. If it is a medium complex storey will give it a three if it is more complex than it is a five and if it is extremely complicated and very, very difficult will give it eight.', 'start_time': '00:05:48', 'end_time': '00:06:17'}, {'Topic': 'Breaking Down Story Points', 'transcript': 'So most of the times we tried to break down eight point of storeys into lesser points. Like, you know, two models of three and five. Okay, one storey of three points, another of five points. So body A. This is the way of just, you know, deciding which storey is of how much difficulty level', 'start_time': '00:06:17', 'end_time': '00:06:37'}, {'Topic': 'Capacity Planning Templates', 'transcript': 'So this is just a rough or in a very simple what can is it? A table which is showing how we are doing the capacity planning, though in other real instance are in show you how it issues showing. So the normally we have two ways of doing this capacity planning.', 'start_time': '00:06:40', 'end_time': '00:07:00'}, {'Topic': 'Excel Template for Capacity Planning', 'transcript': 'Either we do we have a template of Axl shit temperate in which we put in the work hours or else we can donate directly through. So how we are putting a tear in the simple largest explained to him So these are the name of the resources that are part of those Graham.', 'start_time': '00:07:00', 'end_time': '00:07:16'}, {'Topic': 'Work Hour Calculation', 'transcript': "So although people are names are written one other work days for which, for example, this is showing that it is a to experience that why that's why it is 10 days. Okay, In the two weeks we have 10 days, then we have categorised each type of work. Okay, so here you can see the available", 'start_time': '00:07:16', 'end_time': '00:07:34'}, {'Topic': 'Individual Work Hour Availability', 'transcript': "number of days. Okay, So for example, this person don't have any vacation or anything else. So that's why he is completely available for all the 10 days and his complete work hours is 7010 into seven sewing plans. Seven hours. I am sorry", 'start_time': '00:07:34', 'end_time': '00:07:52'}, {'Topic': 'Vacation Impact on Capacity', 'transcript': "something is here in miss Okay, He So we are considering here seven work hours per day. That's the reason we're have given a den into 7. 3070 of us. Okay, then the second person, as you can see here, he has a vacation of one day. Right? So that's the reason his effective days is only nine.", 'start_time': '00:07:53', 'end_time': '00:08:17'}, {'Topic': 'Total Work Hour Calculation', 'transcript': "And hence the calculation that is coming. It's nine into seven. That is an an hours per day of her, which comes to 63. So in this way, all the team's effort or work hours is calculated, and the total comes to around 3 15 hours.", 'start_time': '00:08:17', 'end_time': '00:08:36'}, {'Topic': 'Advanced Capacity Planning', 'transcript': "So this is a basic capacity plan, so I'll just give you a glimpse of the actual ones, which we normally use, so it's a bit more complicated than what you have seen, so", 'start_time': '00:08:37', 'end_time': '00:08:49'}, {'Topic': 'Technical Issues during Presentation', 'transcript': "not able to. I was able to see this. it's the said this light show. right. the thinking, okay? so went above this one. Is it so now unable to? You guys were able to say this.", 'start_time': '00:08:57', 'end_time': '00:09:37'}, {'Topic': 'Technical Issues during Presentation', 'transcript': "it's better than before. Yeah, literally. Can you zoom? And I don't think it's a numbing with resume.", 'start_time': '00:09:38', 'end_time': '00:09:50'}, {'Topic': 'Technical Issues during Presentation', 'transcript': "Maybe you have to come out on the slide show and land new China. There's an option to. consume you never screams as well.", 'start_time': '00:09:50', 'end_time': '00:09:59'}, {'Topic': 'Technical Issues during Presentation', 'transcript': 'There is a plus sign the next two years. Aargh! Point on ya, hon. Just under Insert Manu Under in 30 days a zoo Michael.', 'start_time': '00:10:00', 'end_time': '00:10:16'}, {'Topic': 'Real-Life Capacity Planning Example', 'transcript': "just take on the drop down arrow and them. Zuman. Okay. Okay. Lydia. Thank you, Yah! so Yeah. So this is actually some sort of a real life capacity planning sheet that we are actually using. So it's a bit more complex than what I show new as a unit sister format, you can see", 'start_time': '00:10:17', 'end_time': '00:10:42'}, {'Topic': 'Team Member Listing', 'transcript': "So here you can say everything is mentioned. Who are the team members? What are the total number of this string shot is not full. So because I couldn't take it in a single stream. So there are some more few more members the chairman sing here. So this is train shot with, I mean part of the scrum team, not the full. As you can see from here, all the members are being seen", 'start_time': '00:10:42', 'end_time': '00:11:08'}, {'Topic': 'Holiday Considerations in Capacity Planning', 'transcript': 'so here that the members are there. So total spring daisy A mentioning water, the holidays. If there is any any leads for any of the resources, what on the actual days. So what are the actual days means what at the days that they are actually working per day hours. So here we have taken six tape', 'start_time': '00:11:09', 'end_time': '00:11:28'}, {'Topic': 'Buffer Time for Meetings', 'transcript': "six hours per day and we keep two hours for buffer. Usually that is assigned because, you know, we do have several meetings when we are part of the sprint or a scam. We have several meetings. So that's why be assigned belief to ask per day for this kind of activities, meeting activities and other, you know.", 'start_time': '00:11:29', 'end_time': '00:11:51'}, {'Topic': 'Total Effective Hours Calculation', 'transcript': 'Connexion, connecting with the your team members and also effective work hours. This six. So accordingly of what is the number of hours per person gets is 36 hours for the full sprint, which is two week Sprint Reich.', 'start_time': '00:11:51', 'end_time': '00:12:05'}, {'Topic': 'Effort and Capacity Calculation', 'transcript': "So hearing you can see for 68 here we have another small thing where we are calculating the total death effort, complete depth effort of work hours and the queue way work hours. Okay, so 20 for is the Dever covers and 140 for Solly. It's percent estimate. Whatever 135 you ever covered", 'start_time': '00:12:05', 'end_time': '00:12:32'}, {'Topic': 'Capacity Utilization Monitoring', 'transcript': 'along with, we have another. okay? becoming Dombeck 50 person, 100%. Okay, so yeah, along that we have a few more things, like, you know, what is the available capacity? What is the time estimate and capacity utilisation. Capacity remaining. So, for example, a person has 36 capacity. But as per the storey points, we are able to assign only 30 work hours, so he will have a remaining capacity of 5% or five', 'start_time': '00:12:32', 'end_time': '00:13:27'}, {'Topic': 'Monitoring Team Capacity', 'transcript': 'in which he can accommodate any ad host stance or anything that comes in between. So those kind of things are also there. So here we can monitor which team member has got the, you know, his capacities move than his actual available capacity or it is lesser. And if if he has any banned with left, where we can take on', 'start_time': '00:13:27', 'end_time': '00:13:50'}, {'Topic': 'Calculating Total Development Hours', 'transcript': 'one Moting here is like here is the like, for example, here having all the team members and then So we are calculating here. The total devours the total Q hours. So he are out of these members. The people that are mentioned in yellow are testing team people, so the addition of all these people', 'start_time': '00:13:51', 'end_time': '00:14:16'}, {'Topic': 'Total Development Work Calculation', 'transcript': "we will be able to calculate the the way of us. And similarly, the addition of all these people that are in grade are the other deaf people. So the damper cars were able to calculate separately, and then we have the total bar covers. But yeah, this thing, whatever is the total, is it? It's coming here and we're getting the total were covers for Q and the for deaf and also for the team, So this is the way so.", 'start_time': '00:14:17', 'end_time': '00:14:44'}, {'Topic': 'Velocity Calculation', 'transcript': "some of them things like. so long. Also, you know, though, didn't use this one much, but sometimes also from this. whatever data we are giving, we can also culprit velocity here. Or we can project the velocity that we will be able to achieve, okay?", 'start_time': '00:14:45', 'end_time': '00:15:07'}, {'Topic': 'Manual vs Automated Capacity Planning', 'transcript': "sahib. department in this manually, or is it through the era? So I am telling youth of this Excel sheet is actually mental manually. But we do have a G option of it doesn't happen like this. I will show you the gene option as after we have discussed. So I told him in to his red wine, raise the Excel sheet, which is a manual thing, which we do right. This is the one and also may have a Gina option which have issued.", 'start_time': '00:15:09', 'end_time': '00:15:38'}, {'Topic': 'Screen Sharing Issues', 'transcript': 'Sorry, Mon Amis. However question So withdrawing the screen on the right hand side where you have listed down the storey numbers and the name of the other way of doing the capacity Planning, however,', 'start_time': '00:15:38', 'end_time': '00:15:52'}, {'Topic': 'Listing Stories for Sprint Planning', 'transcript': 'know like this is the same capacity. So here now we are register jotting down the storeys that will be covering in the spread ride for every sprint before starting the spring. We are', 'start_time': '00:15:52', 'end_time': '00:16:05'}, {'Topic': 'Work Hour Allocation for Stories', 'transcript': 'doing a capacity planning, right? So the upcoming streamed We are listing down all the storeys that we will do in this train. And who will work on this print. Right? So for example, if this storey is being done by the developer Dipak So the package will have here his workouts. How many work of us even allocated? For example, out of his total capacity of 36 he will just give three hours for this. And then again there will be', 'start_time': '00:16:05', 'end_time': '00:16:31'}, {'Topic': 'Story Breakdown for Developers and Testers', 'transcript': "some Barca was for the tested as well they will give. Maybe they will give two hours. Okay, so that is the reason the invention ing it. Storey buys how much a storey points or how much Barca will not store ippon. Sorry hours breakdown actually right at the breakdown and the the task, right? Completely a ride. So every storeys we are breaking down. We're taking the hours considering the hours that will be", 'start_time': '00:16:31', 'end_time': '00:16:58'}, {'Topic': 'Advantages of Capacity Planning', 'transcript': 'of more like the developer. How much hours they spend? The tester, How much I was Davis pen And how much is the total hours? So accordingly you know, open the Pakis parking on this storey as well as this storey as well as this Storey said the complete fire cover should come to near about 36 so we can keep a track. Okay Addition of all these storeys will come to around 36 right? So you can get the totally here.', 'start_time': '00:16:58', 'end_time': '00:17:25'}, {'Topic': 'Avoiding Team Burnout', 'transcript': 'So next comes is the advantages of capacity planning. So I want to just zoom out. You can get a you. so so for the advantages. So first of all, it is avoid burnout. So what is about team won out is like, you know, the Arges piling work on somebody. And we exactly do not have any idea that whether that person will be able to do or not, or whether he is stretching more just to, you know, fulfil the work and to a', 'start_time': '00:17:26', 'end_time': '00:18:03'}, {'Topic': 'Realistic Deadline Setting', 'transcript': "we do not want want to stumped him to function like that. We want the work to be done. But also it's not like a person is, you know, working late nights and weekends just to compete. We do not one that can be a planning properly,", 'start_time': '00:18:03', 'end_time': '00:18:19'}, {'Topic': 'Identifying Skill Shortages', 'transcript': "and we are able to estimate that. Okay, we have a delivery in the state. And so if they are planning in this way, our definitely will meet our posts will meet her deliberated. So this will help to do the work effectively without any stress on the team bus. It is the main thing, like so taking steps to get for understanding of your teams at Children positive in she won't overwhelm them with too many tasks and responsibilities and also support them in managing their time by prioritising the most impactful.", 'start_time': '00:18:19', 'end_time': '00:18:49'}, {'Topic': 'Proactive Problem Identification', 'transcript': "then sent more realistic deadlines again the same thing. So it's like something which they can achieve. It's not like a career piling them on, and then at the end of the strength of, even if they are trying their level best, they are not able to achieve so Yah, we do not want that. So get details about availability straight from your team. You will get a much needed reality. Cheques on the Dugan manage deadline expectations according to what your team can actually produce,", 'start_time': '00:18:49', 'end_time': '00:19:14'}, {'Topic': 'Challenges in Capacity Planning', 'transcript': "then the third point is identify skin sock shortages. So by evaluating your team's capacity and planning work in advance, it's easier to spot if projects require skills that your team doesn't have. Accounting for that early allows you to take proactive action, such as training someone on your team. Outsourcing attacks are changing the scope of the project, so I think this is very self explanatory. So when we are planning ahead, so we in.", 'start_time': '00:19:14', 'end_time': '00:19:38'}, {'Topic': 'Understanding Bandwidth', 'transcript': 'so the challenges of capacity planning said stuff to understand band with. So, yeah, it is tough to understand band with because, you know, view we are projecting that. Okay, this person can do this much hours. It may be that Okay, that person, even if for he is mentioning that I will need three hours of world,', 'start_time': '00:20:03', 'end_time': '00:20:24'}, {'Topic': 'Estimating Work Hours', 'transcript': "Sometimes something happens and he is getting stuck and he needs another more two hours. It's actually not three hours. It's actually five hours. So in that way, when we are calculating everything we are considering, Okay, this work will only take three hours, but actually it is taking more. So this type of difficulty comes.", 'start_time': '00:20:24', 'end_time': '00:20:45'}, {'Topic': 'Team Changes Impacting Capacity', 'transcript': "And so that's why it is written. It's tough to understand band with, and though we have a solution to this, which is like the always came buffer hours, as I told you so, that that will take care of this and the gritty or whatever. So your team's bandits is always evolving as projects change and team members leave or join the ranks. So this is another challenge, right? Because, you know, team members are leaving and joining in the middle of this print and also that definitely impacts it.", 'start_time': '00:20:45', 'end_time': '00:21:13'}, {'Topic': 'Team Honesty in Work Estimates', 'transcript': "So plus, you need to rely on people's honesty about the current again. The same thing as I told a work may take more a work may take less. So that is also restriction all of that making a challenging to get a firm grasp on just how much capacity your team has available to tackle new work and request, particularly if you have a team full of high achievers always believed that they can take", 'start_time': '00:21:14', 'end_time': '00:21:36'}, {'Topic': 'Improving Capacity Understanding', 'transcript': 'more. Okay, the more often you have, you talked your team about their most three teams to it weekly, the easier it will get for you to be realist. So as an venue work with a certain team. You know, maybe in the first print your capacity may not be a perfect, but as and when you work on a multiple sprints, you know, like er', 'start_time': '00:21:36', 'end_time': '00:21:59'}, {'Topic': 'Dealing with Project Changes', 'transcript': "after first a Ken than third and consecutive sprint. Then you get the more better grasp on how much each person's capacities is. And if you were, you know, if you are committing more than that, also can district or if you are committing less than also that also you can increase it, so we will get a more realistic idea. Changes will throw you off track. They're gonna risk associated with them.", 'start_time': '00:21:59', 'end_time': '00:22:22'}, {'Topic': 'Planning for Unforeseen Challenges', 'transcript': "The project and enforcement circumstances, from sense in seasonality to industry changes, will throw wrenches senior plans when you need to try to account for all these potentials. At best, capacity planning isn't always so straight forward. Planning in a cushion, even if it's just an extra day or two, will help you roll with the punches without things running of Paris. So again, this is something it it is like", 'start_time': '00:22:22', 'end_time': '00:22:44'}, {'Topic': 'Importance of Capacity Planning', 'transcript': "even if you are planning, there may be some hindrances, but you know it's much better to go with capacity than without capacity. Then it is like completely chaos, and", 'start_time': '00:22:44', 'end_time': '00:22:55'}, {'Topic': 'Identifying Overcommitment', 'transcript': "there is no planning and all if you're doing any, you know, starting or sprint without the capacity, so you will have to engage in some hard conversations again. This is a part of capacity and a tapestry. Planning is only useful if you though something with the information you identify that can involve turning down projects due to lack of bandwidth, adjusting a reducing expectations, pushing out deadlines. It's always better to say no than too serious and not to deliver. So this is the most in", 'start_time': '00:22:55', 'end_time': '00:23:23'}, {'Topic': 'Best Practices in Capacity Planning', 'transcript': 'purpose of the president planning the next is capital planning. Best Praxis is so some of the tapestry planning West practises are sorry. So learn from past projects. Okay, so this is the main our thing, you know, and a capacity in the first sprint that Udo will never be perfect. It will be a kind of Okay,', 'start_time': '00:23:50', 'end_time': '00:24:10'}, {'Topic': 'Learning from Past Projects', 'transcript': 'we are just trying to see. But as and when the A growth, the capacity planning for the future strengths on the next prince will definitely be better and will have a better idea about the amount of work which we should take and will be able to complete. Have honest conversations with Team OK song in here. The you know, transparency is very important, though Scram, Master and the', 'start_time': '00:24:10', 'end_time': '00:24:36'}, {'Topic': 'Team Transparency in Capacity Planning', 'transcript': "A team member should be completely true with each other so that the another's come. Master understands the limitations of the developer of the tester and also the developer, and the tester truly identifies water. The actual bar covers that he or she is putting, which will again, you know, help us in doing a good capacity.", 'start_time': '00:24:37', 'end_time': '00:24:56'}, {'Topic': 'Project Request Understanding', 'transcript': "so get the necessary details up front. So when a project request some across comes across your desk as thoughtful questions to make sure you grass the INS and out awards being requested, you can also create a brief. So it is again. It's like you are predicting", 'start_time': '00:24:56', 'end_time': '00:25:11'}, {'Topic': 'Creating a Flow Chart for Planning', 'transcript': 'so. This is kind of a flow A charge Stating of what? We are putting it all together so they can go through. It is just', 'start_time': '00:25:34', 'end_time': '00:25:42'}, {'Topic': 'Technical Issues with Roadmap', 'transcript': "okay. So yeah. Now I just want you to show how in Gina we're doing it right. So sorry for this. As you can see in the left side, there was some glitch in the Gina when I was taking the screenshots. Because of that,", 'start_time': '00:25:42', 'end_time': '00:25:59'}, {'Topic': 'Defining Roles in Roadmap', 'transcript': "I couldn't get the actual is to ensure here, as you can see, did not a PLO badia, for what you have to do is first to go to the ups and here you have to define okay define the rules like deaf rosewater. The rules that will give you a teen froze for example You will have developers development, role testing room", 'start_time': '00:25:59', 'end_time': '00:26:18'}, {'Topic': 'Creating Team Structure', 'transcript': "support role. Then there will be sued. Hell, so on. And so so far. You can give Rolls. You will identify. So all these things will Did define first right Role step team step. What other teams that you're using see will identify this first? Once that is done, you will come to the sprint capacity. Okay,", 'start_time': '00:26:18', 'end_time': '00:26:37'}, {'Topic': 'Work Hour Management', 'transcript': "and whether their development, the members just inky member supporting members, front 20 members. You can mention these things. Then you have the work hours here. It's very simple, like the same capacity per day is six for everyone most of the time. But, you know, if there are certain people who are taking on had on work or they are, you know, some people are there who've", 'start_time': '00:27:10', 'end_time': '00:27:33'}, {'Topic': 'Sprint Capacity Management', 'transcript': 'his contributed. with one question How did you come to this cream? The app that arrived in the app There is a sprint capacity which for our project, like I was in good united. So they had taken this sprint capacity.', 'start_time': '00:28:05', 'end_time': '00:28:27'}, {'Topic': 'Full Picture of Sprint Capacity', 'transcript': "So, uh, we were able to, you know, put this forward. So I think we need some access is for getting there. It's not like free. There is There is some judge, a bill amount. So if that project is taking that you will be able to use this service.", 'start_time': '00:28:27', 'end_time': '00:28:44'}, {'Topic': 'Planning Tab Overview', 'transcript': 'This is the sec tender. So first we were seeing this team Sprint capacity conflict. Now the sec tender cab. What we can see here is the planning tab in which you know you can see all the storeys that you have taken in that sprint. Okay? All the storeys it will show along with the assigning for those storeys. And also if the estimates have been done and the storey points have been mentioned, that will also be show.', 'start_time': '00:29:06', 'end_time': '00:29:32'}, {'Topic': 'Work Completion Tracking', 'transcript': 'What will it also show is the percentage of work that the person has already? For example, out of 30 hours, that shit Ege is assigned, He has already 24 hours over.', 'start_time': '00:29:32', 'end_time': '00:29:48'}, {'Topic': 'Work Allocation Analysis', 'transcript': "And for the picker, like it is showing too much of work. So definitely, we need to move out some of the things. So similarly for individual people, you can see the allocations, right? So for NeJame, we have to assign the full capacity she has, and then we haven't assigned anything to it means right. So in this way, by this craft, you can understand and identify and accordingly assigned.", 'start_time': '00:30:04', 'end_time': '00:30:29'}, {'Topic': 'Project Progress Visualization', 'transcript': 'This is another part that some, you know, for this sprint capacity, there multiple reports that you can see. So though we did not use this much party on, you can see that the actual versus expected so, for example, planned versus potential capacity. So this much of percentage of work is done, and we have so much of eight hours out of expected 38 hours. So this is like', 'start_time': '00:30:32', 'end_time': '00:31:00'}, {'Topic': 'Roadmap Overview', 'transcript': "so I think we are five minutes more. So can we moved to the road map. okay? So now moving ahead with the road maps of what is roadmap? Okay, so road mapping, Jill A software. Our team level roadmaps useful for planning large basis of work several months in advance. A terrific level within a single project. Simple planning and dependency management features help your team's visualise and manage work better. So what is exactly a roadmap is nothing but a planning feature in bet. You know, you can", 'start_time': '00:32:45', 'end_time': '00:33:19'}, {'Topic': 'Roadmap Planning Process', 'transcript': 'put in all the epics and under native storeys, and you can see the complete picture of like, for example, in which sprint you will be able to complete what feature Sova. Normally, you know the identify features okay, will do this by this April end will do this feature by maybe June will do this feature so f', 'start_time': '00:33:19', 'end_time': '00:33:39'}, {'Topic': 'Roadmap Visualization', 'transcript': 'nothing will be clearly visible. If we are using a Roadmaster of Witch spring, we will be able to complete feature one will sprint will be able to complete feature too. So this was kind of a projection. So how does it look into looks like this? Okay, so here you can see, I just', 'start_time': '00:33:39', 'end_time': '00:33:59'}, {'Topic': 'Epic and Story Relationships', 'transcript': "so far, the key concepts of ethics. Okay, so for I'm in for creating a road map, things that you need to know at the Buddhism and epic is a large body of us that can be broken down into individual tasks required to ship of feature. The world probe becomes a child issue of the epic. Sometimes owner spending epics are displayed as collard bus on", 'start_time': '00:34:49', 'end_time': '00:35:10'}, {'Topic': 'Breaking Down Features into Epics', 'transcript': "the road map. As I showed you, it was so of epics Are you know again? As I said, like a feature, you there is a feature. Okay, So if that feature is a small feature, if it is a big feature than again, features will be broken down. But if it is a small features that you can't convert into an epic,", 'start_time': '00:35:10', 'end_time': '00:35:31'}, {'Topic': 'Child Issues in Roadmap', 'transcript': "and these are, though, things depicted in coloured bars. what is a child issue again? As I said, under need the epic the create storeys. So the storeys are nothing but child issues. Child issues can be created directly from the road map and administered within the epic the belonged So the storeys that will create under the epic an honest child issues the most common childish you a storeys, tasks and bugs. Okay, but you can create new issue types to represent different type of work for your team's quickly move issues to other tipping and reorder issues or epics by dragging and dropping them", 'start_time': '00:36:02', 'end_time': '00:36:37'}, {'Topic': 'Importance of Start and Due Dates', 'transcript': 'next to start and dude is the length of the bar on the road map for alleged at the start and due date set for Europe. Pick setting dates for your epic helps to communicate plans with the team and provide visual visibility to external stakeholders. Informed dependence in mapping and helped the resource management. So yeah, so start and doodles are very important. In order to project when you will be able to complete the feature or the epic,', 'start_time': '00:37:01', 'end_time': '00:37:27'}, {'Topic': 'Tracking Progress of Features', 'transcript': "you're starting a due date of each of the storeys or child into issues matter, you know, so that you are able to understand. OK, completely a get this epic we will be able to complete in the stand this epic. This temps of this feature will be done by this time Fring.", 'start_time': '00:37:27', 'end_time': '00:37:41'}, {'Topic': 'Epic Completion Tracking', 'transcript': "So this is depicting being depicted here. As you can see, the the the the thing that the Yeah. So So far epic when you are putting her start date and the due date So that is kind of you know, high level but in a storey is you know, when you are taking up storeys we normally understand that this storey will be completing in this print trade even if it's a storey you were expecting", 'start_time': '00:37:42', 'end_time': '00:38:30'}, {'Topic': 'Planning for Team Input', 'transcript': 'it while doing the activity from THING is also the part of They are completely a part of this because of they are the ones who will you know, who will be actually doing the work. Right? So they at the ones who will say Okay, Veil late leaders will need four days to definitely they their input matters a lot.', 'start_time': '00:39:21', 'end_time': '00:39:43'}, {'Topic': 'Filtering and Managing Roadmap', 'transcript': 'Okay, so then there is philtres and view settings with again. These are some of the features of roadmap Yadira software roadmap has built in philtres that make waving and managing work simple. Find and refine your road member searching for key words and filled of a Sinus status labelled issue at just view settings or your road map to cheque.', 'start_time': '00:39:45', 'end_time': '00:40:03'}, {'Topic': 'Managing Dependencies', 'transcript': "There are some times this situation's right In other storey the you will be able to start when you have completed the storey again there will be like a storey See you can be able to start menu of computers the storey So these kind of dependence is of these things These are dependencies and the dependencies were also one kind of You can sit blockers right, Unless and until you complete Storey eh? You cannot start storey p", 'start_time': '00:40:26', 'end_time': '00:40:50'}, {'Topic': 'Importance of Dependency Management', 'transcript': 'right. So this can be, you know, Mom, this can be shown in the road map dependency Management is critical for teams. When dependence is our visualised and well mapped, a team can adapt and plan for alternative parts. Indira Software You can easily show the relationship between epics by mapping dependence is directly from the road.', 'start_time': '00:40:51', 'end_time': '00:41:11'}, {'Topic': 'Dependency Visualization', 'transcript': "So this is the way. As I told you, these things show that dependencies. Okay, So for example, once this is done, you can be able to do this. Okay? Say it's mentioned, Bill. Cheque out Experience blocks this. So you have to do this epic bill cheque out experience first, and then only you can be able to do the improve U M U S lite score.", 'start_time': '00:41:11', 'end_time': '00:41:34'}, {'Topic': 'Addressing Roadmap Questions', 'transcript': 'this on owners at the dependency. Right? This one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back? This is a plan. And the kind of things can I say that this is a plan the way of', 'start_time': '00:41:35', 'end_time': '00:42:00'}, {'Topic': 'Actual vs Planned Projection', 'transcript': 'at Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what we', 'start_time': '00:42:57', 'end_time': '00:43:08'}, {'Topic': 'Exporting the Roadmap', 'transcript': 'so again and other feature is sure and exports of whatever road matter of created, you will be able to share and export the road map. So sandy, a roadmap directly from Gina to from here a software by typing in news animal innocently copy to grab the roadmap, your export year old map and just the timeline views Star date and in dates before expecting it as an image. So this is like some of the features of road map.', 'start_time': '00:44:32', 'end_time': '00:44:59'}, {'Topic': 'Creating a Roadmap in Software', 'transcript': "create a roadmap injera software. So one of the steps to create a roadmap, Najera software creator, knew Gina Software Project or go to an existing project and then navigate to the side bag and click roadmap. Okay, not if they're not showing saying your roadmap have enabled the road map in the board setting. So again there's a Y.", 'start_time': '00:44:59', 'end_time': '00:45:18'}, {'Topic': 'Enabling Roadmap Features', 'transcript': "And here, if you are not able to see the roadmap tap than definitely in the board sitting, you need to go and enable it. So people who are comfortable Najera will be understanding what I'm talking about. But if people who are not having hand from Nigeria, they may find it difficult in reading this and understanding that.", 'start_time': '00:45:18', 'end_time': '00:45:37'}, {'Topic': 'Adding Epics to Roadmap', 'transcript': 'Then click plus create a pick on the road map to create a picks directly on your road map. If he roadmap is empty, simply start typing to create right name, year epic and hit Enter. You can double click into epics at any time from your road map to add information such a start and ended assigning attachment and more at child issues to European from the road map by clicking', 'start_time': '00:45:38', 'end_time': '00:45:58'}, {'Topic': 'Visualizing Dependencies', 'transcript': 'next to the epic name. Okay, select the type of childish uses in the drop down on the named Asia and of the covered it right in a single single points. Few tips for or Mac creation visualise dependence is between epics by creating or removing dependence ceilings directly on Iroda. So this thing for this thing, you actually need to work with the team, right?', 'start_time': '00:45:58', 'end_time': '00:46:18'}, {'Topic': 'Team Collaboration in Roadmap Creation', 'transcript': "The team will be able to help you, guy do and understand and of took Lego, the product owner as well as the team. Both will be able to guide do help you in understanding what other dependencies and how to create the road map and how to mention the dependencies. Right? So that's why", 'start_time': '00:46:18', 'end_time': '00:46:40'}, {'Topic': 'Updating Epic Dates', 'transcript': 'the product owner as well as the team members both are very important for creating year proper road map in with all the details. Keep your old man up today by adjusting the length of the epic or slide the epic to change the start and due dates. Okay,', 'start_time': '00:46:41', 'end_time': '00:46:58'}, {'Topic': 'Team Visibility on Work Progress', 'transcript': 'So again, as I said on that, you can change the started do days. You know, if you something happened and you are not able to complete on the mention time or whatever time the timeframe has registered or shifted. So then you can definitely change the start in. And when work is assigned to team members in Gina, they can easily see how they', 'start_time': '00:46:58', 'end_time': '00:47:22'}, {'Topic': 'Tracking Progress Towards Goals', 'transcript': "roadmaps. Help Help your team track progress towards big picture bulls in a single do. So this is the main importantly, the lamp later, the feature releases it happening on proper time. The the epics How many pixie horrible to complete, which picks terrible to complete. All districts make your roadmap shine by changing the colour of your epics. There are clear on the road map. Simply rightly, they're picking pick yokel, This is a", 'start_time': '00:47:45', 'end_time': '00:48:10'}, {'Topic': 'Conclusion and Questions', 'transcript': 'a roadmap ting So far handed, we share with the people who have joined here. not are not can go ahead and share this but Ariel so that people can go through it and the in future, if they have anything, they can get back to me. Hand indefinitely, discuss', 'start_time': '00:49:32', 'end_time': '00:49:52'}, {'Topic': 'Closing Remarks', 'transcript': 'so intense, guys. Any other questions? Thank you. Thanks times a lot. of frustration. And I including the feedback An assessment form with the recording on, please. Thank you.', 'start_time': '00:49:55', 'end_time': '00:50:21'}, {'Topic': 'Final Thank You', 'transcript': 'Thank you.', 'start_time': '00:50:22', 'end_time': '00:50:23'}], 'session_id': [ObjectId('641a849fa053a968d797f8a1')], 'assessment': ObjectId('66f44727c248cb8c52153b7a'), 'job_name': 'my-transcription-job30497c89-a29c-4e09-9146-63a0312663a4', 'keywords': ['Epic', 'Filtering', 'Flow Chart', 'Effective Days', 'Due Dates', 'Story Management', 'Start Dates', 'Team Honesty', 'Chairman', 'Project Roadmap', 'Scrum Master', 'Testing Team', 'Roadmap Creation', 'Epics', 'Tracking', 'Project Commitment', 'Availability', 'Time Management', 'Store Complexity', 'Feature Development', 'Total Development Work', 'Capacity Tracking', 'Roadmap Visualization', 'Epic Completion Tracking', 'Proactive Problem Identification', 'Proper Planning', 'Billing', 'Team Transparency', 'Story', 'Engineering Resources', 'Project Request', 'Time Estimates', 'Progress Tracking', 'Sprint Management', 'Epic Dates', 'Dependency Visualization', 'Efficiency', 'Task Prioritization', 'Velocity', 'Communication', 'Work Hour Allocation', 'Interdependent Tasks', 'Task Timelines', 'Workload Management', 'Work Hour Management', 'Task Distribution', 'Team Communication', 'Fibonacci Series', 'Board Settings', 'Team Burnout', 'Process', 'Data Projection', 'Team Capacity', 'Future Reference', 'Estimation Techniques', 'Collaboration', 'Story Listing', 'Feedback', 'Work Capacity', 'Calculation', 'Estimation Methods', 'Best Practices', 'Child Issues', 'Task Breakdown', 'Available Capacity', 'Development Hours', 'Organization', 'Roadmap', 'Excel', 'Dependency Management', 'Leaves', 'Team Structure', 'Chaos', 'Gina', 'Work Output', 'Closing Remarks', 'Strategic Management', 'Sprint-Based Projects', 'Iroda', 'Team Members', 'Buffer Time', 'Assessment', 'Effort Calculation', 'Agile Methodology', 'Visualization', 'Visualizing Dependencies', 'Complexity', 'View Settings', 'Work Hours', 'Team Effort', 'Outsourcing', 'Work Completion', 'Work Allocation', 'Planning', 'Difficulty Level', 'Roles', 'Capacity Management', 'Task', 'Najera Software', 'Workdays', 'Roadmap Management', 'Meetings', 'Deadline Management', 'Work Estimates', 'Seasonality', 'Resource Management', 'Bandwidth', 'Project Management', 'Work Distribution', 'Real-Life Example', 'Sprint Capacity', 'Features', 'Screen Sharing', 'Scrum', 'Work-Life Balance', 'Roadmap Planning', 'Enable', 'Task Assignment', 'Story Numbers', 'Dependencies', 'Individual Capacity', 'Application', 'Percentage', 'Sprints', 'Product Owner', 'Project Progress', 'Vacation', 'Deadline Setting', 'Project Capacity', 'Zoom', 'Team Availability', 'Blockers', 'Gratitude', 'Details', 'Bar Covers', 'Holidays', 'Presentation', 'Nigeria', 'Acknowledgment', 'Time Tracking', 'Working Days', 'Sprint Planning', 'Team Member', 'Estimation', 'Categorization', 'Industry Changes', 'Operational Efficiency', 'T-shirt Sizing', 'Grooming Sessions', 'Team Management', 'Capacity Assessment', 'Discussion', 'Recording', 'Sprint', 'Capacity Planning', 'Story Pointing', 'Templates', 'Team Changes', 'Developer Limitations', 'Automation', 'Capacity', 'Exporting', 'JIRA', 'Agile', 'Process Management', 'Task Management', 'Workload Estimation', 'Team Collaboration', 'Instructions', 'Epic Relationships', 'Projecting', 'Planning Tab', 'Technical Issues', 'Excel Template', 'Timeline', 'Story Points', 'Capacity Utilization', 'Screenshot', 'Skill Shortages', 'Access', 'Scrum Team', 'Roadmap Features', 'Team Input', 'Transparency', 'Projected Completion', 'Effective Hours', 'Brief'], 'topic': 'Agile Project Management', 'interaction': [{'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How did you come to this cream? The app that', 'timestamp': '[0:28:08]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Can you go back to the queen like the Yeah. So what does this mean, Ours? Out of expected 38 hours.', 'timestamp': '[0:31:46]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Is there a way of I can see side by side how my actual work is going on? Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back?', 'timestamp': '[0:41:40]'}, {'status': 'answered', 'answer': "You can see the actual due date by manually changing it in the roadmap. It won't automatically show the earlier projected date, but it will display whatever due date you have given currently.", 'completeness': 'Complete answer, all aspects of the question addressed.', 'relevancy': '2', 'question': "Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reports at Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is there a way of I can see what we estimated and what we", 'timestamp': '[0:42:49]'}], 'summary': 'The session focuses on capacity planning and roadmap management in project management, emphasizing the process of determining necessary work hours and assessing team bandwidth. Capacity planning is defined as the systematic approach to avoid overcommitting resources and ensuring efficient task coordination. Key aspects include calculating individual work hours based on availability, understanding the impact of project complexity on resource allocation, and ensuring realistic deadlines to enhance operational efficiency and minimize chaos. The discussion highlights various estimation techniques, particularly story pointing methods like T-shirt sizing and the Fibonacci series, which aid in assessing task complexity collaboratively. The importance of a structured planning process, including managing dependencies and utilizing tools for tracking progress and visualizing timelines, is emphasized. Furthermore, the session addresses best practices such as learning from past projects, fostering team transparency, and actively managing project timelines to adapt to unforeseen challenges. Overall, the focus is on effective capacity planning as a foundational element for achieving project goals while maintaining team well-being.'}
{'_id': ObjectId('66b26b61b80f3f3035517ee8'), 'file_id': ObjectId('620e13b5fb338ccd0017f91a'), 'file_name': '1645089715-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/1645089715-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '01:28:17', 'transcription_path': 'video-results/out_66b26b61b80f3f3035517ee8.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 58, 49, 358000), 'file_process_date': datetime.datetime(2024, 9, 25, 16, 1, 3, 335000), 'execution_time': 1028.893204, 'status': 'COMPLETED', 'green_line': [{'topic': 'Technical Setup', 'start_time': '00:00:23', 'end_time': '00:00:56', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'keywords': ['Screen Sharing', 'Technical Setup', 'Collaboration'], 'summary': 'The transcript involves a brief interaction where one participant is prompted to share their screen, indicating a technical setup process. The dialogue suggests a casual and collaborative atmosphere, with participants checking on the status of the screen sharing and confirming if everything is functioning properly.'}, {'topic': 'Introduction to Convolutional Neural Networks', 'start_time': '00:01:23', 'end_time': '00:02:40', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with me", 'keywords': ['Convolutional Neural Networks', 'Deep Learning', 'Image Processing'], 'summary': "The session begins with an introduction to convolutional neural networks (CNNs), where the speaker expresses excitement about the topic and mentions a colleague's presence as a special treat for the audience. This sets the stage for a collaborative exploration of CNNs."}, {'topic': 'Deep Learning Applications', 'start_time': '00:02:41', 'end_time': '00:04:10', 'transcript': "and, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.", 'keywords': ['Deep Learning', 'Image Analysis', 'Natural Language Processing'], 'summary': 'The transcript discusses various applications of deep learning, particularly in image analysis. It highlights a specific project where an app was developed to analyze the contents of a fridge by taking a photograph, identifying ingredients, and recommending recipes. Additionally, the speaker mentions other applications, including insect detection, disease detection in plants, and projects in natural language processing. The role of convolutional neural networks (CNNs) is emphasized, particularly in the context of image-related tasks.'}, {'topic': 'CNN Architecture and Functionality', 'start_time': '00:04:11', 'end_time': '00:10:03', 'transcript': "Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the image", 'keywords': ['CNN', 'Backpropagation', 'Spatial Invariance'], 'summary': 'The transcript discusses the versatility and applications of Convolutional Neural Networks (CNNs) beyond image processing, including their effectiveness in speech data and natural language processing (NLP). The speaker outlines the agenda for the session, which includes motivations for using CNNs, historical context, basic building blocks, backpropagation, and common architectures. An example involving the MNIST dataset is presented, explaining how a simple Multi-Layer Perceptron (MLP) classifies images of handwritten digits. The speaker highlights the importance of spatial information and the challenges of generalization in models, emphasizing the need for architectures that maintain spatial invariance to variations such as shifts and rotations in input images.'}, {'topic': 'Spatial Invariance in CNNs', 'start_time': '00:10:06', 'end_time': '00:12:27', 'transcript': "Okay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.", 'keywords': ['Spatial Invariance', 'Convolutional Neural Networks', 'Neurons'], 'summary': "The transcript discusses the concept of spatial invariance in convolutional neural networks (CNNs) using an example of a dog observed from various angles and sizes. It provides a historical perspective on CNNs, referencing a study conducted by Hubel and Wiesel in the 1950s, where they investigated the brain responses of a cat to visual stimuli. The experiment involved showing the cat edges of different orientations while recording the electrical impulses in its brain. The key findings indicated that specific neurons in the cat's brain were activated by certain visual stimuli, particularly edges and their movements. The discussion emphasizes the need to maintain spatial information without flattening the data and suggests that a hierarchical approach is necessary to achieve this in CNN models."}, {'topic': 'Historical Context of CNNs', 'start_time': '00:12:29', 'end_time': '00:13:36', 'transcript': "Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'keywords': ['CNN', 'LeNet-5', 'Digit Recognition'], 'summary': 'The transcript discusses the historical context of convolutional neural networks (CNNs), starting with the foundational experiments that influenced research over the next two decades. It mentions significant contributions made in 1986 by scientist Fukushima, who developed the neo-cognitive architecture for digit recognition, which was considered state-of-the-art at the time but limited by computational constraints. The 1990s saw advancements that led to the creation of the first successful CNN, known as LeNet-5, which demonstrated effective character recognition without significant errors. The speaker indicates that this architecture will be highlighted in the discussion.'}, {'topic': 'CNN Training and Optimization', 'start_time': '00:13:37', 'end_time': '00:16:22', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. So", 'keywords': ['Spatial Invariance', 'MLP', 'Digit Detection'], 'summary': "The transcript discusses strategies for modifying a trained neural network to improve its robustness to spatial invariance. The speaker encourages the audience to consider how to approach the problem of detecting a digit (specifically zero) in modified images that may have undergone transformations like shrinking or translation. They describe a method involving a simple multi-layer perceptron (MLP) that scans small sections of an image, flattens them, and evaluates the presence of the digit zero. The MLP outputs a probability distribution indicating the likelihood of zero's presence in the scanned area. This process of scanning the entire image allows for the detection of the digit regardless of its location, highlighting the importance of spatial robustness in neural network training."}, {'topic': 'Model Predictions and Generalization', 'start_time': '00:16:22', 'end_time': '00:18:08', 'transcript': "one question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.", 'keywords': ['Model Predictions', 'Generalization', 'Probability'], 'summary': 'The transcript discusses the process of making model predictions and the importance of generalization in machine learning. The speaker explains how to determine the output by taking the maximum probability from a set of probabilities associated with different outputs, such as recognizing digits. They address a common question among students about this method, clarifying that it involves identifying the highest probability and correlating it with a specific output. Additionally, the speaker suggests enhancing prediction accuracy by introducing additional features that focus on specific parts of the digits rather than evaluating the entire digit at once.'}, {'topic': 'Feature Extraction and Hierarchical Learning', 'start_time': '00:18:09', 'end_time': '00:20:39', 'transcript': "So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uhuh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the questionwho asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.", 'keywords': ['Feature Extraction', 'Hierarchical Learning', 'Weight Sharing'], 'summary': 'The transcript discusses the concept of feature extraction and hierarchical learning in the context of image processing. The speaker explains how a hierarchical structure is built by using a multi-layer perceptron (MLP) that processes small sets of pixels. They emphasize the importance of choosing an appropriate box size for scanning and the implications of shifting this box, which may lead to incomplete feature capture. The process involves stacking learned features from one layer onto another, gradually moving from partial features to more complete ones, which ultimately aids in classification. The speaker also highlights the significance of weight sharing in the MLP, explaining that the same weights are maintained across scans to reduce the total number of parameters, ensuring efficiency in the learning process.'}, {'topic': 'Hyperparameters in CNNs', 'start_time': '00:20:40', 'end_time': '00:26:04', 'transcript': "So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.Okay, so you just, uh, scan. So these are the hair are different. New MLPs here. So this this MLP has, uh, one set of age. This is a new MLP. Here we are, scanning through it, okay. And then we have the final classification will happen. And so now we have sequentially added layers in one direction. We could also add, uh, complexity in the depth of it.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.right. And so, finally, you just can't get it. All of the features and you have a final classification.So this is how the idea of hair are key is taken into account from that horrible and visual experiment that we just build upon small features of the offer input and use those to classify, uh, actual image.Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,", 'keywords': ['Hyperparameters', 'Multilayer Perceptron', 'Feature Hierarchy'], 'summary': 'The transcript discusses the concept of hyperparameters in convolutional neural networks (CNNs) and their role in building a hierarchy of features from input images. The speaker explains that each layer in a multilayer perceptron (MLP) takes a weighted sum of inputs and applies a non-linearity, similar to the process in CNNs where smaller parts of an image are analyzed. A hierarchy of features is built by extracting small features in initial layers, which are then combined to learn more complex features in subsequent layers. The speaker emphasizes the importance of hyperparameters such as the number of hidden nodes, hidden layers, filter sizes, and stride sizes, which define the architecture of the network and are distinct from the model parameters like weights. The discussion also touches on the use of multiple MLPs to detect different features within the same image, culminating in a final classification based on the learned features.'}, {'topic': 'Filter Operations and Image Processing', 'start_time': '00:26:05', 'end_time': '00:29:37', 'transcript': "uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimension", 'keywords': ['Filters', 'Image Processing', 'Multi-layer Perceptron'], 'summary': 'The transcript discusses filter operations in image processing, explaining how convolutional filters are used to extract features from input images. It describes the creation of compact representations of images, with filters detecting various features such as horizontal and vertical lines. The speaker emphasizes the transition from traditional handcrafted filters to automated processes, detailing how filters can be seen as M by N boxes that connect pixels. The discussion includes the use of a simple multi-layer perceptron (MLP) for output, highlighting the importance of shared weights in extracting features across different areas of the image. The speaker also notes the difference in filter dimensions when dealing with grayscale versus color images.'}, {'topic': 'Pooling and Downsampling Techniques', 'start_time': '00:29:37', 'end_time': '00:34:08', 'transcript': "is three. So it's a M by n by three or the image that is a colour image which has got the red, green and blue.channels. right. So one way of visualising this you've got an image of some size. You are reducing the size of the image by doing the scanningright. And with every feature that you're creating is like another channel. Right? So we went from RGB Channel to another description of the same data which has a smaller X and Y axis as such of the image. But it has a depth to it, which is the number of features that have been extracted. Right. And this is a very common feature that you will see when you book shows you the more complicated structures of a CNN.You'll find that you start off with a large image with three channels and you end up with very small images, but with lots of features, lots of channels with it.Right. So this is a very, very important thing to remember when you're doing CNN's, because later on, you will see some very interesting uses of the same philtre to reduce dimensionality.Okay, so do you understand all of these concepts? the shift size. you can see that the boxes are overlapping over each other, right? And so you can have a shiftof one pixel or two pixels or whatever. So that becomes a hyper parameter. Like you said, the philtre size definitely the size of the box, the number of philtres at each layer that you're definingright, and the number of such hidden layers that are transforming the input into a smaller, more compact representation.Right is another type of parameters. So very good. And what is the shift called? What is the technical term for shift?stride. Okay, great. Excellent. Okay. Good luck. Any questions on this before it goes on? Because things will only get more complex as we go on.Okay, Wonderful. Okay, So this is the example of, uh, typical Syrian architecture. This is called the Leonard five, which was developed by young liquid.Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresThen you will have six feature maps for each philtre because one feature because one philtre will scan the entire image.So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.", 'keywords': ['Pooling', 'Downsampling', 'Max Pooling'], 'summary': 'The transcript discusses pooling and downsampling techniques in the context of convolutional neural networks (CNNs). It explains how color images, represented by three channels (RGB), can be reduced in size while extracting features. The speaker highlights the importance of understanding parameters such as stride and filter size, which influence how the input image is transformed into smaller, compact representations with deeper feature maps. The example of a typical CNN architecture is introduced, specifically referencing the LeNet-5 model. The speaker elaborates on the process of sub-sampling, particularly focusing on the Max Pooling technique, where a two by two matrix is analyzed to retain the maximum value, effectively reducing dimensionality from 28x28 to 14x14. This explanation lays the groundwork for understanding more complex CNN structures.'}, {'topic': 'Understanding CNN Feature Maps', 'start_time': '00:34:09', 'end_time': '00:39:54', 'transcript': "Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.okay? Okay, So there was one thing I want to visualise here. Yeah, so? So this is a typical grayscale image. So this is the original image you can see here. And this is just a zoom in version, so you can see that every pixel has a value from 0 to 2. 56 to 55. Sorry.So you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,uh, let's take something near the so you can see here. Uh, the left, the left, and the first element in this, uh,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.So, uh, we've got an answer. Which is minus 157. Yes. Uh, be clipped to zero. It will be close to zero.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.", 'keywords': ['Feature Maps', 'Filters', 'Sobel'], 'summary': 'The transcript discusses the concept of CNN feature maps, starting with the explanation of sub-sampling and the architecture of convolutional neural networks (CNNs). It describes the fully connected layer, which classifies input images into multiple outputs. The speaker highlights the significance of feature maps and their dimensions, as well as the process of transforming grayscale images through filters. The use of different filters, such as sharpen and blur filters, is explained in detail, demonstrating how they affect the image and produce distinct feature maps. The speaker also introduces various Sobel filters for edge detection, emphasizing their role in creating feature maps.'}, {'topic': 'Advanced Filter Techniques', 'start_time': '00:39:56', 'end_time': '00:44:43', 'transcript': "Okay, so there is another example of this image. So this is the original image. Okay, Now, if I apply, sharpen, uh around it, you can see it's got a bit sharp.And if you you stop symbol on it, it detects, uh, like horizontal edges. If I apply right Sobel, it detects vertical edges so on and so forth.is this clear? Yes, sir. Okay. so these weights are okay, So, uh, which no one is asking a question here. Uh, how? Well, normalising the pixel values affect the neural network.Um, so we should make sure you don't send it privately because those questions come to me, Uh, is not able to see it, but I've explained this, right? So when you talk about normalising the pixel values, what are you referring to? What you're talking about theapplication of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.", 'keywords': ['Normalization', 'Feature Extraction', 'Sobel Filter'], 'summary': 'The transcript discusses advanced filter techniques in image processing, particularly focusing on the application of sharpening filters and edge detection methods like Sobel filters for horizontal and vertical edges. It emphasizes the importance of normalizing pixel values to improve the performance of neural networks, explaining how different scales of input values can affect the cost function and the learning process. The speaker highlights that normalization leads to a more uniform cost function, enabling faster convergence towards the minimum during training. Additionally, it is noted that the weights for filters can be handcrafted or learned by the neural network itself, allowing for the automatic extraction of features that may not be easily interpretable by humans. This capability enhances the flexibility and efficiency of neural networks in feature extraction.'}, {'topic': 'Convolution vs Cross-Correlation', 'start_time': '00:44:44', 'end_time': '00:49:36', 'transcript': "that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.Uh, so let's say for, uh, I'll take an example of this portion of this image. I'm just, uh, mathematically describing what we have just discussed. Okay,so here we are going from minus Kate. Okay, for let's say, let's say this philtre will have zero in the centre zeroth index.instead of beginning from any side, we begin from the centre. So this has, uh, zero comma zero. Uh, Index, this has, uh,minus one comma one. I could have minus one for my one. This is my new school, Uh this is minus one common minus one just to be clear.And this is, uh, one comma one. And this is one common minus one. So basically, we are saying that the loop power fromminus 1 to 1 in case of a three dimensional feature or philtre so for, Let's say. four g three or three. So Okay,the left corner will be minus 11. the corner with bottom, Yeah. mhm. uh, one here because we are going from, uh, which is, uh,so So, uh, this is the X one. And this is why? right. So, uh, but the other way around. Right. So why is pointing downwards?Yeah. So the coordinator, there will be a minus 11, left bottom. X is minus right the X coordinate ofminus one. uh this should be minus 11. okay, so Okay, So, uh, idea here is So let's say we have this original image, and we want to, uh, slide this fritter across this entire image. And I want to have an output G, which is my feature map. You could sayokay. So what I'm gonna do here is, um So starting with U N. Vehicle to minus one here in this submission,you equal to minus one and equal to minus one. So I will take the minus one minus 11 element of this, uh, this edge metrics, which is the A.Okay. And, uh, I plus Youth Index. So I am calculating for G three of three. So this is +0123 and again. 0123. So this is my G three comma three.Okay. So if I take, uh, take this philtre and, uh, make the cost cross correlation, I will have a single value, which will be substituted in the place of E here.", 'keywords': ['Convolution', 'Cross-Correlation', 'Feature Map'], 'summary': 'The transcript provides a detailed explanation of the mathematical concepts of convolution and cross-correlation, particularly in the context of image processing. The speaker discusses how features are identified within an image, specifically whether it contains certain digits. They describe the mechanics of applying a filter to an image, outlining the process of sliding the filter across the image and calculating the resulting feature map. The discussion includes specific examples of filter indices and how they relate to the original image, demonstrating the operation of convolution in a structured manner.'}, {'topic': 'Mathematical Representation of CNNs', 'start_time': '00:49:37', 'end_time': '00:54:34', 'transcript': "Right. So what I'm looking here is that, uh, eyes here three and us minus one. And Jay is also three.This is the icon DJ and J minus one. So I'm looking at second element here. So for her 01 to zero. we want. So to buy second by second element is this so I'm multiplying, uh, small a from the philtre with this matrix A herewith a element of these, uh, metrics. and similarly, I'm just looping over. So being small capital B plus small capital C includes. So this way, this time calculating the, uh, waited waited some hereand this will be a single output, which will be replaced here in my future map. Uh, so let's see if I have this. This is my G output. So in place of E here, I will have one single value, which will be the output of this entire operation.Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.", 'keywords': ['Cross-Correlation', 'Convolution', 'Feature Map'], 'summary': 'The transcript discusses the mathematical representation of convolutional neural networks (CNNs), focusing on the operations of cross-correlation and convolution. The speaker explains how to calculate the output of a feature map by multiplying elements from a filter with a given matrix, iterating over the elements to obtain a single output value. The session includes visual examples of various filters like sharpen, blur, and edge detection, illustrating their application to an original image. The speaker clarifies the distinction between cross-correlation and convolution, emphasizing that while the forward pass involves cross-correlation, convolution entails flipping the filter before the operation. The discussion aims to establish a mathematical foundation that will be used for backpropagation in CNNs.'}, {'topic': 'CNN Architecture Examples', 'start_time': '00:54:34', 'end_time': '01:00:18', 'transcript': "Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottomto the top. Okay. So because the future has rotated and just changing the sign here, uh, will assist in that happening, soOkay, Uh, you can just explore this on your own later on. If you just try to write these expressions down and you will be able to figure out that we're just recreating the philtreand doing the cross correlation, okay? Okay, so So till now we discuss these handcrafted philtres like the blur sharpen, agitation, etcetera. But these are the things which the model learns as just described. So what we're gonna do is we're gonna visualise these features for the religion. It Okay, Uh, so let me first explain that how these, uhhow these architectures look like. Okay, so, uh, the input here is, uh, before we go into the architecture, can we just, uh, do a little bit of discussion around how the philtre size impact, the output image size, But is that coming after this?Yes. I was just trying to bring Troy. I don't have, uh Okay. Okay. So let's say religion yet We use colour images, so let's say it will be a three dimensional image.And let's say it is 2. 56 by 2. 56 with three channels of input. Okay, so now we want to, uh, involved used 32 philtres here.Okay of dimensions, Uh, three by three. Okay, So this is how you generally defining your chaos or you're open source, uh, libraries, but under the hood. Uh, what is happening is that each philtre will have dimensionsthree by three. And this three, the depth is coming from the input. because the input image has three channels as death. So you're each philtre will also have a depth of three. Okay, so what we do here is that we take small, uh,crop of size three by three hair from this bigger image. three by three by three And we just, uh, do an element wise multiplication of all these elements in this cubewith this philtre. Okay, So if there are, let's say, uh, three numbers here and three numbers in the first, uh, slice. Then you just, uh, do the cross correlation, and there would be one output.Okay. And you do same for all the layers. So for second slice here also, okay, and output of this result would be single number.this is very important to note. Okay, so after conclusion where there will be one value here. So you do this for across entire this image. So you have access right of one.so let's let's leave it to them to come up with the answer. Okay, So with the stride of one pixel means that you're shifting by one pixel to the right all the way till you get to the end of the image, right? So recognise that you get to the end of the image when the right side of your philtre reaches the edge. Okay, so there's no paddingfor those of you know what padding is. There's no padding. For those of you who don't know about padding, just don't worry about it. Just tell us what is going to be the size of the image that comes out on the other side when we do the scanning. Now the stride works left to rightand talk to bottom. right. So as you scan across, you're going one pixel at a time and going to the next position where the philtre is applied. And then when you get to the end, you shift the philtre down by one,uh, pixel and apply it again. Correct? Yes, sir. Okay. So what is going to be the size of the image that is coming out on the other end? Or the the two dimensional array that's coming out at the end? Because remember what is sayingthat the three by three by three is producing only one number, so the multilayered Perceptron is taking27 inputs and is out putting one value. Okay, So what you're getting as a result of applying this philtre is a two dimensional", 'keywords': ['Convolution', 'Filters', 'Cross-Correlation'], 'summary': 'The transcript discusses the mathematical concepts behind CNN architectures, particularly focusing on the process of cross-correlation and convolution. It explains how filters are applied to images, detailing the movement direction and the dimensions of the filters in relation to the input images. The conversation transitions into how filter sizes affect the output image size, elaborating on the application of filters through element-wise multiplication in a three-dimensional context. The speaker emphasizes the significance of the stride in the scanning process and addresses how these operations yield a two-dimensional output array from the input image.'}, {'topic': 'Parameter Counting in CNNs', 'start_time': '01:00:20', 'end_time': '01:05:22', 'transcript': "matrix of numbers, and I want to know the dimensionality of that. 54. other ways, okay? there were two people speaking. So one person said to 54.And what was the other person saying? I think, uh, zero comma zero is concerned at the centre, and, uh, the other things are taken at that size in the same way you look at work,right? So, like I said, the we are resuming zero padding go padding right now. Right? So your philtre starts from the edge and takes the first three into account.right, and then it moves by one and moves by one. Right? So the size is going to be there. One answer that's been given us 254.Is that the number of rows or the number of columns, or what is to 54? I think both. Okay, Anybody else have a different answer?no sort of 54 and 54 in total Tito. in 2. 32. Okay, 32 because we've got 32 philtres. Good. Okay. I have been looking for one philtre with Excellent. Okay, so 254 by 2. 50 for 5. 32 will be the third dimension.Uh, just for this philtre Yes, output will be just a matrix. Uh, considering for just one philtre, this is just one,Uh, that's correct that we will have 32 such philtres. So for each of that philtre, we will have one,to the output. Yes. Yes. And then that will build up to 30 to do that. Yeah. Perfect. Perfect. Okay, So what happens now if we make the stride?Ooh! Okay, so now let's make the strive to what becomes the output size now? Does the output size change?instead. How much does it change? Uh, third dimension in the same 1. 27 1 27 127. So how did you come up with 1. 27?sir. And if you take in putting measures in and the philtres. I just Yes. And we We are taking a straight to that isminus Yes. And we are adding one to the and mine the eff s blossom. Okay. Do you want to write the formula they're given? You've got access toYes, Uh, like the formula, which, uh Okay, can you please repeat and I say important measure that is 256 in 2016 and a filtered site.and at that stage. the farm law of the output. The message will be and minus f s plus one. listen. so that would be a 56 minus.three dots. Bye. HM. That doesn't seems correct. It's two less 127. So now you've got 253 divided by two, right?So what happens? We've got a decimal number there. So I have that too. From the looks. you will take in digital partnership.If we have fraction, then we protect right? so Yeah. So that is the same formula. Uh, only were riding fighting out here. Right? Fighting is zero w minus scale over this. That's whywhich is fine. And then what you're saying is we are taking the interior part. So are we rounding up or are we rounding down?so if there is greater than five, then we are all being up. but now it's point. What do we do? I think running, don't you?", 'keywords': ['Dimensionality', 'Zero Padding', 'Stride'], 'summary': 'The transcript discusses the dimensionality of matrices in the context of convolutional neural networks (CNNs) and involves a dialogue between two individuals. They explore the implications of zero padding and the behavior of filters as they process input data. The conversation delves into calculating output sizes based on filter dimensions and stride, applying the formula for determining output dimensions. There is a focus on the importance of rounding in calculations when dealing with decimal outputs and the participants clarify the mathematical principles involved.'}, {'topic': 'Feature Map Analysis', 'start_time': '01:05:23', 'end_time': '01:11:33', 'transcript': "Okay, so let's just take a small example of, uh, seven by seven image, right? and what is happening here when we are not doing a padding, So the first one is three by three.the philtre application. And then we're taking a stride of two, which means now we're starting from pixel, too.23. And, uh, so we're starting the numbering from zero. Right, So 0 to 6 is the pixel numbering. Okay,Right. And now we're doing a three by three. right. So the three by three the first philtre, then we're taking a stride of two.so we start from now 23 and four. And now we take another stride of two, which gives us now. four, five and six.right. So in this case, if we look at the formula, what's happening is N is seven minus three. great.stride is too so seven minus 3/2. which is three, right? So that's 4/2. That's 13, so we can see we have created three. Now the problem comes when we have an eight by eight image, right? And now we have an issue in that if we had another pixels in rows and columns.we basically not be able to do any further, right? So if we had an eight by eight image, if you can just draw that additional problem and go.Now, when we go for the stride of two, we are going over the edge, so we can't do anymore, right? So we are always looking at the number below, as the output were basically ignoring the that last follow. And that last room. Right? So we will always take the lower number out here.right. okay? So now my question is, how many parameters does the neural network have just in this layer?So who's gonna tell me that now? How many parameters? Now we've got 32 philtres. We've got a three by three philtres,right? And an RGB image. How many parameters do we need to learn in this? one pair of lives. who's gonna tell us?930 two. Sorry. nine by 30 to 1930 to 19 to 19 to 32. Okay. Any other answers? 20 7 to 32. Okay. Any other answers?thanks. Nobody else wants to suggest the answer. 20 730 to 30 two. Correct. So the reason why it's 27 by 32 and not nine by 32 it would be nine by 32 if we had a.grayscale image, right? We didn't have the channel. So you must always remember that we have got a three dimensional Fridawhere the third dimensions depth is defined by the number of input channels to that live. Okay, good. Now, what would be the number of parameters that needs to be learned? If we were not using CNN,we were actually using a multilayered percent promise. that depends on the number of notes hidden next to them. Iwant the same number of notes as I have in the hidden layer in the CNN. So how many notes do I have in the hidden layer in the CNN?trick questions. mhm. 56. Close to 56. Crusty. That is my input layer. Right? So that's 2. 56 times 2, 56 times three.that's the input Lear sites. what it was before. Before 254 by 254. right. by 32 right, and how many parameters would we have to learn?", 'keywords': ['Feature Map', 'Stride', 'Filters'], 'summary': 'The transcript discusses feature map analysis using a convolutional neural network, focusing on how a 7x7 image is processed without padding and with a stride of two. The speaker explains the pixel numbering system and the application of 3x3 filters, illustrating the calculations involved in determining the output dimensions based on the input size and stride. The discussion shifts to an 8x8 image, highlighting the limitations that arise when the stride exceeds the available pixels, leading to an incomplete output. The speaker poses questions regarding the number of parameters in the neural network layer, emphasizing the importance of input channels and the dimensionality of filters. The conversation concludes with a comparison between parameters learned in CNNs versus multilayer perceptrons, highlighting how the number of hidden layer nodes influences the total parameters to be learned.'}, {'topic': 'Comparison of CNN and MLP', 'start_time': '01:11:37', 'end_time': '01:13:38', 'transcript': "uh, we have to do, like the four 130 two cross, uh, test is too extreme. right. So we're basically multiplying all of these, right? Because every note in the input layer must be connected to every note and the output.right, So it's 256 squared, multiplied by three. multiplied by 254 squared, multiplied by 32. right. which one is big?There's no argument, right? I mean, we are comparing a very large number of parameters here with just 27 multiplied by 32.right, and this is a huge advantage of CNN. It's the weird. sharing with sharing. That's happening. That is a hugely important aspect.Oh, CNN. Okay, so you appreciate that. And what have we talked about that as the number of parameters increases, what do we need to do? We need a lot more data to learn them.right. And so we are actually talking about unnecessarily learning a lot of weights. Whereas we know that really what we're looking for is a scan through theright. So hopefully this is clear to you that actually the CNN can be represented as a multi layer perceptron also. So the multi layer Perceptron can do the work of the CNN as we see it right now, but the number of parameters is going to be much larger.okay, and so it's much more difficult to learn the same representation comparative. Okay, so here's another question.", 'keywords': ['CNN', 'MLP', 'Parameters'], 'summary': 'The transcript discusses the comparison between Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons (MLPs) in terms of their parameter counts and learning efficiency. It highlights how CNNs, with their parameter sharing mechanism, significantly reduce the number of parameters compared to MLPs, making them more efficient for learning from data. The speaker emphasizes that while MLPs can technically perform the tasks of CNNs, they require a much larger number of parameters, leading to increased complexity in learning. The importance of having sufficient data to train models with many parameters is also mentioned, underscoring the efficiency advantage of CNNs over MLPs.'}, {'topic': 'CNN Feature Learning', 'start_time': '01:13:39', 'end_time': '01:16:41', 'transcript': "Now we have a 54 by 2. 54 by 32. right, and we are again using. Now we are using a five by five philtres.So what is going to be the dimensions of the next left? 54 by 254. by 32. right. So now we're using a five by five philtre.how many such features, let's say 64. such tried stride of, mm. 124 into 1, 24 and 60 for the lesson.Mm. for 254. find us. five, divided by two plus one. so that's 249 divided by two. 1 24 +11 25 1 25 by 125 by 64.how many parameters. and what will be the shape of the philtre? you tell me. Uh, sorry. Was that good book?Uh, that's part of the number 64. 55 or 60. Uh, And so we got an answer here for the number of parameters, I think.Okay, 25 by 64. So he said it could be what we do here. pretty good. so one person's answer is 25 by 64.Don't you find it that you don't look beautiful? 25 and 32. That's right. Okay. And so they will be. Bias is also right. Yes.good point. Thank you for keeping us right there. So in the last one, also, we forgot about the biases thatso remember the bias stone is important, right? What does the bias give us gives us? It gives us a fine transformation.", 'keywords': ['CNN', 'Feature Maps', 'Parameters'], 'summary': "The transcript discusses CNN feature learning, focusing on the dimensions and parameters involved in using filters in a convolutional neural network. It begins with specifying dimensions such as 54 by 32 and introduces the use of 5 by 5 filters. The conversation includes calculations related to the dimensions of the resulting layers and the number of feature maps, as well as the importance of biases in the network. The speaker and participants engage in a back-and-forth dialogue to clarify these concepts and ensure an understanding of how parameters and biases influence the model's performance."}, {'topic': 'Classifying Image Features', 'start_time': '01:16:42', 'end_time': '01:23:00', 'transcript': "Right? So we must have that constant added and also so, plus 64 there and we've got the total number of parameters yet.Okay, Good. Excellent. Okay. Uh, let's, uh, move on. I think hopefully everybody's got anybody. Got a question here? I know there are a few of you who have dealt with CNN's and done some deep learning. That does not mean that people who are not understanding this can't ask questions.Okay, So for those of you who are new to this, this is very, very important that you understand this. Okay, here's another. Okay, Let's go. There is another question I want to ask you, okay?which is the number of computations you're doing. so floating point operations, floating point operations do you need to do here? But I believe that as an exercise for you, let's carry on.okay? Okay, So next, uh, was trying to visualise these features. So? So what we have here is so he worked with it was that we took an RGB image.and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.", 'keywords': ['CNN', 'Feature Maps', 'Convolutional Layers'], 'summary': "The transcript discusses the classification of image features using convolutional neural networks (CNNs). The speaker emphasizes the importance of understanding the number of parameters and computations involved in CNNs. They explain the process of visualizing features by using 32 filters to create feature maps from RGB images. The architecture mentioned includes multiple convolutional blocks with varying numbers of filters, detailing how each filter highlights specific features in the images, such as edges and textures. As the layers progress, the feature maps become more abstract, showcasing the network's learning and representation of complex features. The speaker also demonstrates this by providing visual examples of the feature maps at different layers, illustrating the increasing abstraction and detail in the representations generated by the CNN."}, {'topic': 'Feature Map Interpretations', 'start_time': '01:23:01', 'end_time': '01:28:14', 'transcript': "and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'keywords': ['Feature Maps', 'Activation', 'Classification'], 'summary': 'The transcript discusses the interpretation of feature maps in convolutional neural networks (CNNs), specifically focusing on how these maps extract and highlight various features from images. The speaker explains that the output consists of multiple feature maps, with each map corresponding to different aspects of the input image, such as edges and shapes. As the network progresses through its layers, the features become increasingly abstract, ultimately aiding in classifying images, like distinguishing between a house and a human face. The speaker illustrates this process using examples of feature activations, detailing how different features respond to different classes of images. The lecture concludes with a summary of the importance of these activations in classification tasks.'}], 'yellow_line': [{'Topic': 'Technical Setup', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'start_time': '00:00:23', 'end_time': '00:00:56'}, {'Topic': 'Introduction to Convolutional Neural Networks', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with me", 'start_time': '00:01:23', 'end_time': '00:02:40'}, {'Topic': 'Deep Learning Applications', 'transcript': "and, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.", 'start_time': '00:02:41', 'end_time': '00:04:10'}, {'Topic': 'CNN Architecture and Functionality', 'transcript': "Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the image", 'start_time': '00:04:11', 'end_time': '00:10:03'}, {'Topic': 'Spatial Invariance in CNNs', 'transcript': "Okay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.", 'start_time': '00:10:06', 'end_time': '00:12:27'}, {'Topic': 'Historical Context of CNNs', 'transcript': "Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'start_time': '00:12:29', 'end_time': '00:13:36'}, {'Topic': 'CNN Training and Optimization', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. So", 'start_time': '00:13:37', 'end_time': '00:16:22'}, {'Topic': 'Model Predictions and Generalization', 'transcript': "one question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.", 'start_time': '00:16:22', 'end_time': '00:18:08'}, {'Topic': 'Feature Extraction and Hierarchical Learning', 'transcript': "So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uhuh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the questionwho asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.", 'start_time': '00:18:09', 'end_time': '00:20:39'}, {'Topic': 'Hyperparameters in CNNs', 'transcript': "So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.Okay, so you just, uh, scan. So these are the hair are different. New MLPs here. So this this MLP has, uh, one set of age. This is a new MLP. Here we are, scanning through it, okay. And then we have the final classification will happen. And so now we have sequentially added layers in one direction. We could also add, uh, complexity in the depth of it.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.right. And so, finally, you just can't get it. All of the features and you have a final classification.So this is how the idea of hair are key is taken into account from that horrible and visual experiment that we just build upon small features of the offer input and use those to classify, uh, actual image.Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,", 'start_time': '00:20:40', 'end_time': '00:26:04'}, {'Topic': 'Filter Operations and Image Processing', 'transcript': "uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimension", 'start_time': '00:26:05', 'end_time': '00:29:37'}, {'Topic': 'Pooling and Downsampling Techniques', 'transcript': "is three. So it's a M by n by three or the image that is a colour image which has got the red, green and blue.channels. right. So one way of visualising this you've got an image of some size. You are reducing the size of the image by doing the scanningright. And with every feature that you're creating is like another channel. Right? So we went from RGB Channel to another description of the same data which has a smaller X and Y axis as such of the image. But it has a depth to it, which is the number of features that have been extracted. Right. And this is a very common feature that you will see when you book shows you the more complicated structures of a CNN.You'll find that you start off with a large image with three channels and you end up with very small images, but with lots of features, lots of channels with it.Right. So this is a very, very important thing to remember when you're doing CNN's, because later on, you will see some very interesting uses of the same philtre to reduce dimensionality.Okay, so do you understand all of these concepts? the shift size. you can see that the boxes are overlapping over each other, right? And so you can have a shiftof one pixel or two pixels or whatever. So that becomes a hyper parameter. Like you said, the philtre size definitely the size of the box, the number of philtres at each layer that you're definingright, and the number of such hidden layers that are transforming the input into a smaller, more compact representation.Right is another type of parameters. So very good. And what is the shift called? What is the technical term for shift?stride. Okay, great. Excellent. Okay. Good luck. Any questions on this before it goes on? Because things will only get more complex as we go on.Okay, Wonderful. Okay, So this is the example of, uh, typical Syrian architecture. This is called the Leonard five, which was developed by young liquid.Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresThen you will have six feature maps for each philtre because one feature because one philtre will scan the entire image.So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.", 'start_time': '00:29:37', 'end_time': '00:34:08'}, {'Topic': 'Understanding CNN Feature Maps', 'transcript': "Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.okay? Okay, So there was one thing I want to visualise here. Yeah, so? So this is a typical grayscale image. So this is the original image you can see here. And this is just a zoom in version, so you can see that every pixel has a value from 0 to 2. 56 to 55. Sorry.So you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,uh, let's take something near the so you can see here. Uh, the left, the left, and the first element in this, uh,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.So, uh, we've got an answer. Which is minus 157. Yes. Uh, be clipped to zero. It will be close to zero.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.", 'start_time': '00:34:09', 'end_time': '00:39:54'}, {'Topic': 'Advanced Filter Techniques', 'transcript': "Okay, so there is another example of this image. So this is the original image. Okay, Now, if I apply, sharpen, uh around it, you can see it's got a bit sharp.And if you you stop symbol on it, it detects, uh, like horizontal edges. If I apply right Sobel, it detects vertical edges so on and so forth.is this clear? Yes, sir. Okay. so these weights are okay, So, uh, which no one is asking a question here. Uh, how? Well, normalising the pixel values affect the neural network.Um, so we should make sure you don't send it privately because those questions come to me, Uh, is not able to see it, but I've explained this, right? So when you talk about normalising the pixel values, what are you referring to? What you're talking about theapplication of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.", 'start_time': '00:39:56', 'end_time': '00:44:43'}, {'Topic': 'Convolution vs Cross-Correlation', 'transcript': "that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.Uh, so let's say for, uh, I'll take an example of this portion of this image. I'm just, uh, mathematically describing what we have just discussed. Okay,so here we are going from minus Kate. Okay, for let's say, let's say this philtre will have zero in the centre zeroth index.instead of beginning from any side, we begin from the centre. So this has, uh, zero comma zero. Uh, Index, this has, uh,minus one comma one. I could have minus one for my one. This is my new school, Uh this is minus one common minus one just to be clear.And this is, uh, one comma one. And this is one common minus one. So basically, we are saying that the loop power fromminus 1 to 1 in case of a three dimensional feature or philtre so for, Let's say. four g three or three. So Okay,the left corner will be minus 11. the corner with bottom, Yeah. mhm. uh, one here because we are going from, uh, which is, uh,so So, uh, this is the X one. And this is why? right. So, uh, but the other way around. Right. So why is pointing downwards?Yeah. So the coordinator, there will be a minus 11, left bottom. X is minus right the X coordinate ofminus one. uh this should be minus 11. okay, so Okay, So, uh, idea here is So let's say we have this original image, and we want to, uh, slide this fritter across this entire image. And I want to have an output G, which is my feature map. You could sayokay. So what I'm gonna do here is, um So starting with U N. Vehicle to minus one here in this submission,you equal to minus one and equal to minus one. So I will take the minus one minus 11 element of this, uh, this edge metrics, which is the A.Okay. And, uh, I plus Youth Index. So I am calculating for G three of three. So this is +0123 and again. 0123. So this is my G three comma three.Okay. So if I take, uh, take this philtre and, uh, make the cost cross correlation, I will have a single value, which will be substituted in the place of E here.", 'start_time': '00:44:44', 'end_time': '00:49:36'}, {'Topic': 'Mathematical Representation of CNNs', 'transcript': "Right. So what I'm looking here is that, uh, eyes here three and us minus one. And Jay is also three.This is the icon DJ and J minus one. So I'm looking at second element here. So for her 01 to zero. we want. So to buy second by second element is this so I'm multiplying, uh, small a from the philtre with this matrix A herewith a element of these, uh, metrics. and similarly, I'm just looping over. So being small capital B plus small capital C includes. So this way, this time calculating the, uh, waited waited some hereand this will be a single output, which will be replaced here in my future map. Uh, so let's see if I have this. This is my G output. So in place of E here, I will have one single value, which will be the output of this entire operation.Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.", 'start_time': '00:49:37', 'end_time': '00:54:34'}, {'Topic': 'CNN Architecture Examples', 'transcript': "Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottomto the top. Okay. So because the future has rotated and just changing the sign here, uh, will assist in that happening, soOkay, Uh, you can just explore this on your own later on. If you just try to write these expressions down and you will be able to figure out that we're just recreating the philtreand doing the cross correlation, okay? Okay, so So till now we discuss these handcrafted philtres like the blur sharpen, agitation, etcetera. But these are the things which the model learns as just described. So what we're gonna do is we're gonna visualise these features for the religion. It Okay, Uh, so let me first explain that how these, uhhow these architectures look like. Okay, so, uh, the input here is, uh, before we go into the architecture, can we just, uh, do a little bit of discussion around how the philtre size impact, the output image size, But is that coming after this?Yes. I was just trying to bring Troy. I don't have, uh Okay. Okay. So let's say religion yet We use colour images, so let's say it will be a three dimensional image.And let's say it is 2. 56 by 2. 56 with three channels of input. Okay, so now we want to, uh, involved used 32 philtres here.Okay of dimensions, Uh, three by three. Okay, So this is how you generally defining your chaos or you're open source, uh, libraries, but under the hood. Uh, what is happening is that each philtre will have dimensionsthree by three. And this three, the depth is coming from the input. because the input image has three channels as death. So you're each philtre will also have a depth of three. Okay, so what we do here is that we take small, uh,crop of size three by three hair from this bigger image. three by three by three And we just, uh, do an element wise multiplication of all these elements in this cubewith this philtre. Okay, So if there are, let's say, uh, three numbers here and three numbers in the first, uh, slice. Then you just, uh, do the cross correlation, and there would be one output.Okay. And you do same for all the layers. So for second slice here also, okay, and output of this result would be single number.this is very important to note. Okay, so after conclusion where there will be one value here. So you do this for across entire this image. So you have access right of one.so let's let's leave it to them to come up with the answer. Okay, So with the stride of one pixel means that you're shifting by one pixel to the right all the way till you get to the end of the image, right? So recognise that you get to the end of the image when the right side of your philtre reaches the edge. Okay, so there's no paddingfor those of you know what padding is. There's no padding. For those of you who don't know about padding, just don't worry about it. Just tell us what is going to be the size of the image that comes out on the other side when we do the scanning. Now the stride works left to rightand talk to bottom. right. So as you scan across, you're going one pixel at a time and going to the next position where the philtre is applied. And then when you get to the end, you shift the philtre down by one,uh, pixel and apply it again. Correct? Yes, sir. Okay. So what is going to be the size of the image that is coming out on the other end? Or the the two dimensional array that's coming out at the end? Because remember what is sayingthat the three by three by three is producing only one number, so the multilayered Perceptron is taking27 inputs and is out putting one value. Okay, So what you're getting as a result of applying this philtre is a two dimensional", 'start_time': '00:54:34', 'end_time': '01:00:18'}, {'Topic': 'Parameter Counting in CNNs', 'transcript': "matrix of numbers, and I want to know the dimensionality of that. 54. other ways, okay? there were two people speaking. So one person said to 54.And what was the other person saying? I think, uh, zero comma zero is concerned at the centre, and, uh, the other things are taken at that size in the same way you look at work,right? So, like I said, the we are resuming zero padding go padding right now. Right? So your philtre starts from the edge and takes the first three into account.right, and then it moves by one and moves by one. Right? So the size is going to be there. One answer that's been given us 254.Is that the number of rows or the number of columns, or what is to 54? I think both. Okay, Anybody else have a different answer?no sort of 54 and 54 in total Tito. in 2. 32. Okay, 32 because we've got 32 philtres. Good. Okay. I have been looking for one philtre with Excellent. Okay, so 254 by 2. 50 for 5. 32 will be the third dimension.Uh, just for this philtre Yes, output will be just a matrix. Uh, considering for just one philtre, this is just one,Uh, that's correct that we will have 32 such philtres. So for each of that philtre, we will have one,to the output. Yes. Yes. And then that will build up to 30 to do that. Yeah. Perfect. Perfect. Okay, So what happens now if we make the stride?Ooh! Okay, so now let's make the strive to what becomes the output size now? Does the output size change?instead. How much does it change? Uh, third dimension in the same 1. 27 1 27 127. So how did you come up with 1. 27?sir. And if you take in putting measures in and the philtres. I just Yes. And we We are taking a straight to that isminus Yes. And we are adding one to the and mine the eff s blossom. Okay. Do you want to write the formula they're given? You've got access toYes, Uh, like the formula, which, uh Okay, can you please repeat and I say important measure that is 256 in 2016 and a filtered site.and at that stage. the farm law of the output. The message will be and minus f s plus one. listen. so that would be a 56 minus.three dots. Bye. HM. That doesn't seems correct. It's two less 127. So now you've got 253 divided by two, right?So what happens? We've got a decimal number there. So I have that too. From the looks. you will take in digital partnership.If we have fraction, then we protect right? so Yeah. So that is the same formula. Uh, only were riding fighting out here. Right? Fighting is zero w minus scale over this. That's whywhich is fine. And then what you're saying is we are taking the interior part. So are we rounding up or are we rounding down?so if there is greater than five, then we are all being up. but now it's point. What do we do? I think running, don't you?", 'start_time': '01:00:20', 'end_time': '01:05:22'}, {'Topic': 'Feature Map Analysis', 'transcript': "Okay, so let's just take a small example of, uh, seven by seven image, right? and what is happening here when we are not doing a padding, So the first one is three by three.the philtre application. And then we're taking a stride of two, which means now we're starting from pixel, too.23. And, uh, so we're starting the numbering from zero. Right, So 0 to 6 is the pixel numbering. Okay,Right. And now we're doing a three by three. right. So the three by three the first philtre, then we're taking a stride of two.so we start from now 23 and four. And now we take another stride of two, which gives us now. four, five and six.right. So in this case, if we look at the formula, what's happening is N is seven minus three. great.stride is too so seven minus 3/2. which is three, right? So that's 4/2. That's 13, so we can see we have created three. Now the problem comes when we have an eight by eight image, right? And now we have an issue in that if we had another pixels in rows and columns.we basically not be able to do any further, right? So if we had an eight by eight image, if you can just draw that additional problem and go.Now, when we go for the stride of two, we are going over the edge, so we can't do anymore, right? So we are always looking at the number below, as the output were basically ignoring the that last follow. And that last room. Right? So we will always take the lower number out here.right. okay? So now my question is, how many parameters does the neural network have just in this layer?So who's gonna tell me that now? How many parameters? Now we've got 32 philtres. We've got a three by three philtres,right? And an RGB image. How many parameters do we need to learn in this? one pair of lives. who's gonna tell us?930 two. Sorry. nine by 30 to 1930 to 19 to 19 to 32. Okay. Any other answers? 20 7 to 32. Okay. Any other answers?thanks. Nobody else wants to suggest the answer. 20 730 to 30 two. Correct. So the reason why it's 27 by 32 and not nine by 32 it would be nine by 32 if we had a.grayscale image, right? We didn't have the channel. So you must always remember that we have got a three dimensional Fridawhere the third dimensions depth is defined by the number of input channels to that live. Okay, good. Now, what would be the number of parameters that needs to be learned? If we were not using CNN,we were actually using a multilayered percent promise. that depends on the number of notes hidden next to them. Iwant the same number of notes as I have in the hidden layer in the CNN. So how many notes do I have in the hidden layer in the CNN?trick questions. mhm. 56. Close to 56. Crusty. That is my input layer. Right? So that's 2. 56 times 2, 56 times three.that's the input Lear sites. what it was before. Before 254 by 254. right. by 32 right, and how many parameters would we have to learn?", 'start_time': '01:05:23', 'end_time': '01:11:33'}, {'Topic': 'Comparison of CNN and MLP', 'transcript': "uh, we have to do, like the four 130 two cross, uh, test is too extreme. right. So we're basically multiplying all of these, right? Because every note in the input layer must be connected to every note and the output.right, So it's 256 squared, multiplied by three. multiplied by 254 squared, multiplied by 32. right. which one is big?There's no argument, right? I mean, we are comparing a very large number of parameters here with just 27 multiplied by 32.right, and this is a huge advantage of CNN. It's the weird. sharing with sharing. That's happening. That is a hugely important aspect.Oh, CNN. Okay, so you appreciate that. And what have we talked about that as the number of parameters increases, what do we need to do? We need a lot more data to learn them.right. And so we are actually talking about unnecessarily learning a lot of weights. Whereas we know that really what we're looking for is a scan through theright. So hopefully this is clear to you that actually the CNN can be represented as a multi layer perceptron also. So the multi layer Perceptron can do the work of the CNN as we see it right now, but the number of parameters is going to be much larger.okay, and so it's much more difficult to learn the same representation comparative. Okay, so here's another question.", 'start_time': '01:11:37', 'end_time': '01:13:38'}, {'Topic': 'CNN Feature Learning', 'transcript': "Now we have a 54 by 2. 54 by 32. right, and we are again using. Now we are using a five by five philtres.So what is going to be the dimensions of the next left? 54 by 254. by 32. right. So now we're using a five by five philtre.how many such features, let's say 64. such tried stride of, mm. 124 into 1, 24 and 60 for the lesson.Mm. for 254. find us. five, divided by two plus one. so that's 249 divided by two. 1 24 +11 25 1 25 by 125 by 64.how many parameters. and what will be the shape of the philtre? you tell me. Uh, sorry. Was that good book?Uh, that's part of the number 64. 55 or 60. Uh, And so we got an answer here for the number of parameters, I think.Okay, 25 by 64. So he said it could be what we do here. pretty good. so one person's answer is 25 by 64.Don't you find it that you don't look beautiful? 25 and 32. That's right. Okay. And so they will be. Bias is also right. Yes.good point. Thank you for keeping us right there. So in the last one, also, we forgot about the biases thatso remember the bias stone is important, right? What does the bias give us gives us? It gives us a fine transformation.", 'start_time': '01:13:39', 'end_time': '01:16:41'}, {'Topic': 'Classifying Image Features', 'transcript': "Right? So we must have that constant added and also so, plus 64 there and we've got the total number of parameters yet.Okay, Good. Excellent. Okay. Uh, let's, uh, move on. I think hopefully everybody's got anybody. Got a question here? I know there are a few of you who have dealt with CNN's and done some deep learning. That does not mean that people who are not understanding this can't ask questions.Okay, So for those of you who are new to this, this is very, very important that you understand this. Okay, here's another. Okay, Let's go. There is another question I want to ask you, okay?which is the number of computations you're doing. so floating point operations, floating point operations do you need to do here? But I believe that as an exercise for you, let's carry on.okay? Okay, So next, uh, was trying to visualise these features. So? So what we have here is so he worked with it was that we took an RGB image.and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.", 'start_time': '01:16:42', 'end_time': '01:23:00'}, {'Topic': 'Feature Map Interpretations', 'transcript': "and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'start_time': '01:23:01', 'end_time': '01:28:14'}], 'session_id': [ObjectId('620e13fcfb338ccd0017f91d')], 'keywords': ['Model Predictions', 'Hyperparameters', 'Stride', 'Generalization', 'MLP', 'Convolutional Layers', 'Parameters', 'Image Analysis', 'LeNet-5', 'Pooling', 'Screen Sharing', 'Normalization', 'Sobel Filter', 'Multilayer Perceptron', 'Collaboration', 'CNN', 'Filters', 'Dimensionality', 'Backpropagation', 'Technical Setup', 'Probability', 'Downsampling', 'Activation', 'Classification', 'Feature Hierarchy', 'Deep Learning', 'Image Processing', 'Feature Maps', 'Feature Map', 'Zero Padding', 'Spatial Invariance', 'Max Pooling', 'Sobel', 'Hierarchical Learning', 'Digit Recognition', 'Weight Sharing', 'Cross-Correlation', 'Convolutional Neural Networks', 'Convolution', 'Multi-layer Perceptron', 'Natural Language Processing', 'Neurons', 'Digit Detection', 'Feature Extraction'], 'topic': 'Convolutional Neural Networks', 'assessment': ObjectId('66f3e80c3aa53898334c0618'), 'job_name': 'my-transcription-job9eddf551-62dc-446d-a5fd-5f29ed643f55', 'interaction': [{'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about what kind of architecture could be used is not addressed.', 'relevancy': '0', 'question': 'What kind of architecture could you use?', 'timestamp': '[0:16:50]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about modifying the existing neural network was not addressed.', 'relevancy': '0', 'question': 'How would you use this information to modify the existing neural network?', 'timestamp': '[0:20:06]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about hyper parameters was not addressed.', 'relevancy': '0', 'question': 'What are the hyper parameters?', 'timestamp': '[0:25:25]'}, {'status': 'answered', 'answer': 'The technical term for shift is stride.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What is the technical term for shift?', 'timestamp': '[0:25:51]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about the stride was not addressed.', 'relevancy': '0', 'question': 'What happens if we make the stride?', 'timestamp': '[1:02:11]'}, {'status': 'answered', 'answer': '930', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How many parameters does the neural network have just in this layer?', 'timestamp': '[1:09:14]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the dimensions of the next layer are not addressed.', 'relevancy': '0', 'question': 'What is going to be the dimensions of the next layer?', 'timestamp': '[1:14:20]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': "Incomplete, the question 'How many such features?' is not addressed.", 'relevancy': '0', 'question': 'How many such features?', 'timestamp': '[1:14:22]'}, {'status': 'answered', 'answer': 'It gives us a fine transformation.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What does the bias give us?', 'timestamp': '[1:16:23]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, no questions were asked or answered.', 'relevancy': '0', 'question': 'Any questions on this?', 'timestamp': '[1:27:37]'}], 'summary': 'The transcript outlines a session on Convolutional Neural Networks (CNNs), emphasizing their applications in image analysis and deep learning. It discusses a project involving an app that analyzes fridge contents and recommends recipes, along with other applications such as insect and disease detection. The session covers motivations for using CNNs, historical context, basic building blocks, backpropagation, and common architectures, including the MNIST dataset example. Key concepts include spatial invariance, feature extraction, hierarchical learning, and the significance of hyperparameters. The importance of convolutional filters for feature detection, pooling techniques for dimensionality reduction, and the distinction between cross-correlation and convolution is highlighted. The transcript also explores the efficiency of CNNs compared to Multi-Layer Perceptrons (MLPs) in terms of parameter sharing and learning complexity, as well as the role of biases and the process of visualizing features through multiple convolutional layers. Finally, it discusses the interpretation of feature maps and their contribution to image classification, illustrating how CNNs learn and abstract features for accurate recognition tasks.'}
{'_id': ObjectId('66b26b6db80f3f3035517f27'), 'file_id': ObjectId('63ac5c7a842bd60e9f2c1a3e'), 'file_name': 'Long video__1672240247-5efad25b42832eeca41d0e78.mp4', 'file_type': 'Video', 'file_path': 'add-resources/Long video__1672240247-5efad25b42832eeca41d0e78.mp4', 'runtime': '01:28:17', 'transcription_path': 'video-results/out_66b26b6db80f3f3035517f27.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 1, 854000), 'file_process_date': datetime.datetime(2024, 9, 25, 16, 15, 29, 229000), 'execution_time': 1023.090566, 'status': 'COMPLETED', 'green_line': [{'topic': 'Technical Setup', 'start_time': '00:00:23', 'end_time': '00:00:56', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'keywords': ['Technical Setup', 'Screen Sharing', 'Collaboration'], 'summary': 'The transcript involves a brief exchange concerning the technical setup for a meeting, where one participant asks another to share their screen. The conversation is informal, with some hesitations and confirmations, indicating a collaborative effort to ensure everything is functioning correctly before proceeding.'}, {'topic': 'Introduction to CNNs', 'start_time': '00:01:23', 'end_time': '00:02:40', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with me", 'keywords': ['CNN', 'Deep Learning', 'Image Analysis'], 'summary': 'The session begins with an introduction to convolutional neural networks (CNNs), where the speaker expresses excitement about starting the topic as planned. They also mention the presence of a colleague who will be joining them, suggesting a collaborative approach to the discussion.'}, {'topic': 'Deep Learning Applications', 'start_time': '00:02:41', 'end_time': '00:04:10', 'transcript': "and, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.", 'keywords': ['Deep Learning', 'Image Analysis', 'Natural Language Processing'], 'summary': 'The transcript discusses various applications of deep learning, particularly in image analysis. It highlights a project where an app was developed to photograph the contents of a fridge and identify ingredients, subsequently recommending recipes based on the findings. Additionally, it mentions other applications such as insect detection, disease detection in plants, and projects in natural language processing. The speaker notes that while convolutional neural networks (CNNs) are often associated with image analysis, their utility extends beyond this area.'}, {'topic': 'CNN Architecture Overview', 'start_time': '00:04:11', 'end_time': '00:05:51', 'transcript': "Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.", 'keywords': ['CNN', 'NLP', 'Backpropagation'], 'summary': 'The transcript outlines an overview of CNN architecture, emphasizing its applicability beyond just image data to include speech data and natural language processing (NLP). The speaker highlights the common misconception that CNNs are solely for image processing, contrasting it with recurrent neural networks typically used for speech and NLP tasks. The agenda of the lecture is introduced, which includes discussing the motivations for using CNNs, the history of CNN development, basic building blocks and layers of CNNs, backpropagation methods, and common CNN architectures along with strategies to regularize and enhance their performance.'}, {'topic': 'CNN Basics', 'start_time': '00:05:52', 'end_time': '00:06:49', 'transcript': 'Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,', 'keywords': ['CNN', 'MLP', 'Image Classification'], 'summary': 'The transcript discusses the basics of convolutional neural networks (CNNs), specifically focusing on their application to black and white images of size 28 by 28 pixels, each representing a digit from 0 to 9. It explains the process of flattening these images into a 784-dimensional vector, which can then be fed into a simple multi-layer perceptron (MLP) for classification into one of the ten digit classes. The speaker notes that this typical workflow can achieve high accuracy rates, ranging from 95% to 98%, utilizing straightforward methods.'}, {'topic': 'CNN Output and Predictions', 'start_time': '00:06:49', 'end_time': '00:09:04', 'transcript': "So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,", 'keywords': ['Convolutional Neural Network', 'Probability Distribution', 'Image Predictions'], 'summary': "The transcript discusses the output of a convolutional neural network (CNN) and its predictions, particularly focusing on a 10-dimensional output vector that represents the model's confidence in identifying various classes in an image. The speaker provides examples of how the model indicates its predictions through probability distributions for each class index. They illustrate the impact of changing the input image's dimensions and positions on the model's predictions, highlighting a significant drop in accuracy with slight shifts in the image. The speaker emphasizes the need for models to be robust against such variations in image inputs to maintain prediction accuracy."}, {'topic': 'CNN Challenges', 'start_time': '00:09:05', 'end_time': '00:10:03', 'transcript': "okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the image", 'keywords': ['Spatial Invariance', 'Translation Invariance', 'Architecture'], 'summary': 'The discussion addresses the challenges associated with convolutional neural networks (CNNs) and emphasizes the need for models that exhibit spatial invariance. The speaker highlights that a well-functioning model should maintain performance despite slight shifts or rotations in the input data, such as digits. They stress the importance of accounting for translation and rotation invariance while mentioning that flattening images can lead to a loss of critical spatial information. The speaker encourages consideration of alternative architectures that preserve this information.'}, {'topic': 'History of CNNs', 'start_time': '00:10:06', 'end_time': '00:13:36', 'transcript': "Okay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'keywords': ['CNN', 'Neocognitron', 'LeNet-5'], 'summary': "The transcript discusses the history of convolutional neural networks (CNNs), beginning with an example of a cat experiment conducted by Hubel and Wiesel in the 1950s, which investigated how neurons in the cat's brain respond to visual stimuli such as edges. The experiment revealed that certain neurons are activated by specific orientations and movements of edges, indicating a hierarchical structure in visual processing. This research laid the groundwork for future developments in CNNs, including Fukushima's 1986 architecture, the Neocognitron, which was designed for digit recognition but faced computational limitations. The 1990s saw the creation of the first successful convolutional neural network, known as LeNet-5, which demonstrated effective character recognition without significant preprocessing of data. The discussion highlights the evolution of CNNs and their foundations in early neuroscience research."}, {'topic': 'CNN Components', 'start_time': '00:13:37', 'end_time': '00:16:06', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.", 'keywords': ['Spatial Invariance', 'Multi-Layer Perceptron', 'Image Detection'], 'summary': "The speaker discusses the modification of existing neural networks to enhance their robustness to spatial invariance. They suggest a method using a modified multi-layer perceptron (MLP) to detect the presence of the digit 'zero' within images, even when introduced with translation variance. The process involves taking small parts of the image, flattening them, and scanning across the entire image to output a probability distribution indicating whether 'zero' is detected. The approach emphasizes the importance of spatial robustness, regardless of the zero's location within the image."}, {'topic': 'Spatial and Translation Invariance', 'start_time': '00:16:06', 'end_time': '00:17:13', 'transcript': "In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. Soone question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.", 'keywords': ['Spatial Invariance', 'Translation Invariance', 'Probability'], 'summary': 'The transcript discusses the concept of spatial and translation invariance in the context of identifying certain elements, specifically the number zero, within an image. The speaker explains the process of determining the presence of zero by evaluating probabilities and selecting the maximum likelihood among various outputs. This method highlights the importance of understanding how outputs are derived from probabilities, addressing potential confusion among students regarding the decision-making process involved in identifying the number.'}, {'topic': 'Feature Extraction and Hierarchy', 'start_time': '00:17:13', 'end_time': '00:19:47', 'transcript': "So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uhuh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the question", 'keywords': ['Feature Extraction', 'Hierarchical Learning', 'Multi-Layer Perceptron'], 'summary': 'The discussion focuses on feature extraction and the hierarchical approach in digit recognition. The speaker suggests that instead of analyzing an entire digit, one can break it down into smaller features to enhance the search process. For instance, identifying specific segments of a digit, such as parts that resemble a zero. The importance of the box size used for scanning and the shifting of the scanning box is highlighted, as it influences the features captured. The speaker explains the concept of multi-layer perceptrons, which build upon smaller sets of pixels and progressively learn more complex features through multiple layers, ultimately leading to accurate classification.'}, {'topic': 'Weight Sharing in CNNs', 'start_time': '00:19:54', 'end_time': '00:20:39', 'transcript': "who asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.", 'keywords': ['Weight Sharing', 'Convolutional Neural Networks', 'Multi-Level Perceptron'], 'summary': "The transcript discusses the concept of weight sharing in convolutional neural networks (CNNs), building on the audience's existing knowledge of multi-level perceptrons (MLPs). The speaker emphasizes that during the image scanning process, the same weights are used without introducing new ones for each section, which significantly reduces the total number of parameters in the model. The explanation indicates that further details will be provided in the slides."}, {'topic': 'Activation Functions', 'start_time': '00:20:40', 'end_time': '00:21:27', 'transcript': "So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.", 'keywords': ['Activation Functions', 'Multi-Layer Perceptrons', 'Non-linearity'], 'summary': 'The discussion focuses on the concept of activation functions within Multi-Layer Perceptrons (MLPs). It explains that each layer processes inputs by taking a weighted sum and applying a non-linearity, which is a fundamental aspect of neural networks. The speaker emphasizes the importance of this process and describes how it is applied in both MLPs and convolutional neural networks (CNNs) by taking subsets of larger images, flattening them, multiplying by weights, and applying activation functions.'}, {'topic': 'Hierarchical Learning in CNNs', 'start_time': '00:21:28', 'end_time': '00:22:18', 'transcript': "Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.", 'keywords': ['Hierarchical Learning', 'CNN', 'Feature Extraction'], 'summary': 'The transcript discusses the concept of hierarchical learning within convolutional neural networks (CNNs). The speaker illustrates the process of building a hierarchy through examples, explaining how outputs from different layers contribute to creating a compact representation of an image. The discussion highlights the idea of learning small features at one level and combining them to learn more complex features at subsequent levels, emphasizing the layered nature of feature extraction in CNNs.'}, {'topic': 'Hyperparameters in CNNs', 'start_time': '00:23:44', 'end_time': '00:26:04', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,", 'keywords': ['Hyperparameters', 'CNN', 'Architecture'], 'summary': 'The discussion focuses on hyperparameters in convolutional neural networks (CNNs) and their distinction from model parameters. The speaker emphasizes that hyperparameters define the architecture and other characteristics of the model, providing examples such as regularization constants and step sizes in linear regression. The conversation highlights the importance of hyperparameters like the number of hidden nodes and layers in multilayered perceptrons, as well as the size and number of filters in CNNs. The speaker encourages audience participation by asking them to identify relevant hyperparameters, reinforcing their significance in model configuration.'}, {'topic': 'Feature Maps and Filters', 'start_time': '00:26:05', 'end_time': '00:28:08', 'transcript': "uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling people", 'keywords': ['Feature Maps', 'Filters', 'Image Processing'], 'summary': 'The transcript discusses the concept of feature maps and filters in the context of convolutional neural networks. It explains how input images are transformed into compact representations through various filters that detect different types of features, such as horizontal and vertical lines, as well as curves. The speaker emphasizes the historical aspect of filters, noting that they were once handcrafted for feature extraction in image processing. The discussion highlights the transition from using multi-layer perceptrons that flatten entire images to focusing on smaller sections defined by an M by N box, which allows for more efficient feature extraction.'}, {'topic': 'Image Processing Techniques', 'start_time': '00:28:09', 'end_time': '00:29:37', 'transcript': "right? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimension", 'keywords': ['Multilayer Perceptron', 'Feature Extraction', 'Image Processing'], 'summary': 'The transcript discusses image processing techniques, focusing on the use of multilayer perceptrons for feature extraction from images. It explains how a simple multilayer perceptron consists of an input layer and an output layer, where the output performs a nonlinear transformation of the weighted sum of the inputs. The speaker emphasizes the importance of shared weights in extracting features, such as vertical or horizontal lines, from images without needing to change them. Additionally, it notes that while the current discussion is limited to grayscale images, color images would involve a three-dimensional box for feature extraction.'}, {'topic': 'Normalisation and Scaling', 'start_time': '00:41:02', 'end_time': '00:42:56', 'transcript': "application of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?", 'keywords': ['Normalization', 'Scaling', 'Cost Function'], 'summary': 'The transcript discusses the concepts of normalization and scaling in the context of neural networks, particularly focusing on how these processes affect pixel values. It explains that dividing pixel values by a constant brings their scale down to a range between 0 and 1. The speaker highlights the importance of normalizing input values in order to prevent issues with the cost function, which can become distorted when there are significant differences in input scales. By normalizing the inputs, the cost function becomes more uniform, facilitating a more direct path towards the minimum during optimization, thus speeding up the training process. The session encourages further questions about the application of these techniques.'}, {'topic': 'Learning Filters', 'start_time': '00:42:58', 'end_time': '00:44:43', 'transcript': "are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.", 'keywords': ['Filters', 'Multilayered Perceptron', 'Feature Extraction'], 'summary': 'The transcript discusses the concept of filters in neural networks, highlighting the distinction between handcrafted filters and those learned automatically by multilayered perceptrons. It emphasizes that instead of manually creating filters to extract specific features from images, neural networks can learn weights that optimize feature extraction, potentially uncovering patterns that humans cannot easily interpret. The speaker explains that the neural network minimizes the cost function to determine useful features, allowing for a vast array of filters to be learned in the process.'}, {'topic': 'Convolution vs Cross-Correlation', 'start_time': '00:51:04', 'end_time': '00:54:34', 'transcript': "find expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.", 'keywords': ['Convolution', 'Cross-Correlation', 'Back Propagation'], 'summary': 'The transcript discusses the concepts of convolution and cross-correlation, highlighting their similarities and differences. The speaker explains how convolution involves rotating the filter during calculations, whereas cross-correlation does not. Various examples are provided, including the effects of different filters like sharpen, blur, and edge detectors on an original image. The operation of flipping the filter by 180 degrees during convolution is emphasized, and the speaker clarifies that the forward pass in neural networks typically performs cross-correlation rather than convolution. The discussion aims to establish a foundation for deriving mathematical expressions for back propagation in neural networks.'}, {'topic': 'Feature Visualization in CNNs', 'start_time': '01:18:05', 'end_time': '01:28:14', 'transcript': "and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'keywords': ['Feature Maps', 'Cross-Correlation', 'Convolutional Layers'], 'summary': 'The transcript discusses feature visualization in convolutional neural networks (CNNs), focusing on the architecture of a CNN model that processes RGB images of size 24 by 24. The speaker explains the process of cross-correlation of filters with images to create feature maps, detailing the layers of the CNN and the specific filters used at each stage. As the layers progress from the initial convolution blocks with 64 filters to deeper layers with 256 and 512 filters, the feature maps become increasingly abstract, reflecting more complex features of the images. The speaker illustrates how different filters highlight specific aspects of images, such as edges and textures, and emphasizes the importance of these features in classifying images into categories. The session concludes with a summary of the feature extraction process, underscoring how CNNs can differentiate between various classes based on activated features.'}], 'yellow_line': [{'Topic': 'Technical Setup', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'start_time': '00:00:23', 'end_time': '00:00:56'}, {'Topic': 'Introduction to CNNs', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with me", 'start_time': '00:01:23', 'end_time': '00:02:40'}, {'Topic': 'Deep Learning Applications', 'transcript': "and, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.", 'start_time': '00:02:41', 'end_time': '00:04:10'}, {'Topic': 'CNN Architecture Overview', 'transcript': "Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.", 'start_time': '00:04:11', 'end_time': '00:05:51'}, {'Topic': 'CNN Basics', 'transcript': 'Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,', 'start_time': '00:05:52', 'end_time': '00:06:49'}, {'Topic': 'CNN Output and Predictions', 'transcript': "So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,", 'start_time': '00:06:49', 'end_time': '00:09:04'}, {'Topic': 'CNN Challenges', 'transcript': "okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the image", 'start_time': '00:09:05', 'end_time': '00:10:03'}, {'Topic': 'History of CNNs', 'transcript': "Okay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'start_time': '00:10:06', 'end_time': '00:13:36'}, {'Topic': 'CNN Components', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.", 'start_time': '00:13:37', 'end_time': '00:16:06'}, {'Topic': 'Spatial and Translation Invariance', 'transcript': "In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. Soone question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.", 'start_time': '00:16:06', 'end_time': '00:17:13'}, {'Topic': 'Feature Extraction and Hierarchy', 'transcript': "So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uhuh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the question", 'start_time': '00:17:13', 'end_time': '00:19:47'}, {'Topic': 'Weight Sharing in CNNs', 'transcript': "who asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.", 'start_time': '00:19:54', 'end_time': '00:20:39'}, {'Topic': 'Activation Functions', 'transcript': "So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.", 'start_time': '00:20:40', 'end_time': '00:21:27'}, {'Topic': 'Hierarchical Learning in CNNs', 'transcript': "Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.", 'start_time': '00:21:28', 'end_time': '00:22:18'}, {'Topic': 'Hyperparameters in CNNs', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,", 'start_time': '00:23:44', 'end_time': '00:26:04'}, {'Topic': 'Feature Maps and Filters', 'transcript': "uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling people", 'start_time': '00:26:05', 'end_time': '00:28:08'}, {'Topic': 'Image Processing Techniques', 'transcript': "right? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimension", 'start_time': '00:28:09', 'end_time': '00:29:37'}, {'Topic': 'Normalisation and Scaling', 'transcript': "application of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?", 'start_time': '00:41:02', 'end_time': '00:42:56'}, {'Topic': 'Learning Filters', 'transcript': "are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.", 'start_time': '00:42:58', 'end_time': '00:44:43'}, {'Topic': 'Convolution vs Cross-Correlation', 'transcript': "find expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.", 'start_time': '00:51:04', 'end_time': '00:54:34'}, {'Topic': 'Feature Visualization in CNNs', 'transcript': "and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'start_time': '01:18:05', 'end_time': '01:28:14'}], 'session_id': [ObjectId('63ac605a842bd60e9f2c1a52')], 'assessment': ObjectId('66f43851c248cb8c521536c9'), 'job_name': 'my-transcription-job82ec8759-9d50-4f32-a399-72233c1c0819', 'keywords': ['Spatial Invariance', 'Architecture', 'Probability', 'Image Classification', 'Multilayered Perceptron', 'Feature Extraction', 'LeNet-5', 'Multi-Level Perceptron', 'Normalization', 'Natural Language Processing', 'Convolution', 'Image Analysis', 'Activation Functions', 'NLP', 'Filters', 'Convolutional Neural Network', 'Collaboration', 'Multi-Layer Perceptron', 'Image Processing', 'Multilayer Perceptron', 'Image Predictions', 'Cost Function', 'Weight Sharing', 'Probability Distribution', 'MLP', 'Neocognitron', 'Hyperparameters', 'Multi-Layer Perceptrons', 'Convolutional Layers', 'CNN', 'Backpropagation', 'Screen Sharing', 'Feature Maps', 'Technical Setup', 'Translation Invariance', 'Convolutional Neural Networks', 'Image Detection', 'Scaling', 'Cross-Correlation', 'Hierarchical Learning', 'Non-linearity', 'Deep Learning', 'Back Propagation'], 'topic': 'Convolutional Neural Networks', 'interaction': [{'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question about what kind of architecture could be used is not addressed.', 'relevancy': '0', 'question': 'What kind of architecture could you use?', 'timestamp': '[0:16:50]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about modifying the existing neural network was not addressed.', 'relevancy': '0', 'question': 'How would you use this information to modify the existing neural network?', 'timestamp': '[0:20:06]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about hyper parameters was not addressed.', 'relevancy': '0', 'question': 'What are the hyper parameters?', 'timestamp': '[0:25:25]'}, {'status': 'answered', 'answer': 'The technical term for shift is stride.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What is the technical term for shift?', 'timestamp': '[0:25:51]'}, {'status': 'answered', 'answer': 'Normalising the pixel values affects the neural network by ensuring that the input layer has similar scales for each input, which helps in minimizing the cost function more effectively. It leads to a smoother cost function, allowing the gradient to move more directly towards the minimum, thus speeding up the minimization process.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How does the normalisation of pixel values affect the neural network?', 'timestamp': '[0:40:30]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about the stride was not addressed.', 'relevancy': '0', 'question': 'What happens if we make the stride?', 'timestamp': '[1:02:11]'}, {'status': 'answered', 'answer': '930', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How many parameters does the neural network have just in this layer?', 'timestamp': '[1:09:14]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the dimensions of the next layer are not addressed.', 'relevancy': '0', 'question': 'What is going to be the dimensions of the next layer?', 'timestamp': '[1:14:20]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about how many parameters needed if not using CNN is not addressed.', 'relevancy': '0', 'question': 'How many parameters will be needed if we were not using CNN?', 'timestamp': '[1:10:38]'}], 'summary': "The transcript discusses the technical setup for a meeting and introduces the topic of convolutional neural networks (CNNs), highlighting their applications in image analysis and natural language processing. It details a project involving an app that identifies fridge contents and suggests recipes, along with other applications like insect and disease detection. The architecture of CNNs is outlined, emphasizing their use for various data types, not just images. The lecture agenda includes motivations for CNNs, their historical development, basic components, backpropagation, common architectures, and performance enhancement strategies.\n\nThe basics of CNNs are illustrated using black and white images of digits, explaining the process of converting these images into vectors for classification. The output predictions of CNNs are discussed, including the importance of maintaining accuracy despite variations in input images. The need for spatial invariance in models is emphasized, along with the historical context of CNNs stemming from neuroscience research. The evolution of CNNs is traced from early experiments to successful architectures like LeNet-5.\n\nThe concept of spatial and translation invariance is explained, particularly in identifying elements like the digit 'zero'. The role of feature extraction, weight sharing, and activation functions in CNNs is clarified, illustrating how hierarchical learning enables complex feature recognition. Hyperparameters in CNNs are discussed, with examples of their significance in model configuration.\n\nThe transcript also covers normalization and scaling of pixel values for effective training of neural networks. The distinction between handcrafted and learned filters for feature extraction is highlighted. Convolution and cross-correlation are explained, noting their differences, especially in neural network applications. Feature visualization in CNNs is elaborated, showcasing how filters process images to create abstract feature maps essential for image classification, concluding with a summary of the feature extraction process in CNNs."}
{'_id': ObjectId('66b26b7db80f3f3035517f7e'), 'file_id': ObjectId('6453a645b4ac5f9afe8df7e6'), 'file_name': 'Long video__1683203649-63038872b13a93a5297cfd52.mp4', 'file_type': 'Video', 'file_path': 'course-resources/Long video__1683203649-63038872b13a93a5297cfd52.mp4', 'runtime': '01:28:17', 'transcription_path': 'video-results/out_66b26b7db80f3f3035517f7e.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 17, 237000), 'file_process_date': datetime.datetime(2024, 9, 25, 19, 6, 10, 701000), 'execution_time': 1002.844259, 'status': 'COMPLETED', 'green_line': [{'topic': 'Technical Setup', 'start_time': '00:00:23', 'end_time': '00:00:56', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'keywords': ['Technical Setup', 'Screen Sharing', 'Collaboration'], 'summary': 'The transcript captures a brief interaction regarding the technical setup for a session, where one person asks another to share their screen. The conversation is informal, with some affirmations and confirmations, indicating a collaborative effort to ensure the technical aspects are in place.'}, {'topic': 'Introduction to CNNs', 'start_time': '00:01:23', 'end_time': '00:02:56', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.", 'keywords': ['CNN', 'Image Analysis', 'Deep Learning'], 'summary': "The session begins with an introduction to convolutional neural networks (CNNs), highlighting the speaker's commitment to the topic and the presence of a colleague who has extensive experience in image analysis utilizing deep learning algorithms. The speaker indicates that the focus will be primarily on teaching the CNN aspects while assuring the audience of their continuous involvement."}, {'topic': 'Applications of Deep Learning', 'start_time': '00:02:57', 'end_time': '00:04:10', 'transcript': "To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.", 'keywords': ['Deep Learning', 'Image Analysis', 'Natural Language Processing'], 'summary': 'The transcript discusses various applications of deep learning, particularly in the context of a project that utilizes image analysis to identify ingredients in a refrigerator. The speaker describes how an app was developed for a client in California, allowing users to photograph their fridge and receive recipe recommendations based on the identified ingredients. Additionally, the speaker mentions other applications of deep learning, including insect detection, disease detection in plants, and projects in natural language processing, highlighting the versatility of convolutional neural networks beyond just image analysis.'}, {'topic': 'CNN Architecture Overview', 'start_time': '00:04:11', 'end_time': '00:06:35', 'transcript': "Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.", 'keywords': ['CNN', 'NLP', 'Backpropagation'], 'summary': 'The transcript outlines the broader applications of convolutional neural networks (CNNs) beyond just image processing, highlighting their effectiveness in speech data and natural language processing (NLP). The speaker emphasizes the need for CNNs over simpler networks for handling various types of data. The agenda for the session includes discussing the motivations behind using CNNs, a historical overview of CNN development, an introduction to their basic building blocks and layers, as well as backpropagation in CNNs. The discussion also touches on common CNN architectures and methods for regularizing or improving their performance, with a reference to a specific example involving the MNIST dataset, which consists of black and white images representing digits from 0 to 9.'}, {'topic': 'Training and Performance of CNNs', 'start_time': '00:06:36', 'end_time': '00:09:52', 'transcript': "So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?", 'keywords': ['CNN', 'Spatial Invariance', 'Generalization'], 'summary': "The transcript discusses the training and performance of convolutional neural networks (CNNs), illustrating a typical workflow that achieves high accuracy (95-98%) in image classification tasks. The speaker explains how the output of the model is structured as a probability distribution across ten dimensions, indicating the model's confidence in its predictions. They demonstrate that even slight changes to the input images can significantly affect the model's performance, highlighting the importance of robustness and generalization in CNNs. The need for spatial invariance in models is emphasized, suggesting that CNNs should be able to handle variations such as translations and rotations without losing accuracy. The speaker encourages consideration of architectural solutions to enhance model robustness."}, {'topic': 'Spatial Invariance in CNNs', 'start_time': '00:09:52', 'end_time': '00:12:47', 'transcript': "Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.", 'keywords': ['Spatial Invariance', 'Convolutional Neural Networks', 'Neural Responses'], 'summary': "The transcript discusses the concept of spatial invariance in convolutional neural networks (CNNs) and highlights the importance of preserving spatial information when processing images. It begins by explaining that flattening images can lead to a loss of critical spatial details. The speaker references historical research from the 1950s conducted by Hubel and Wiesel, who studied the neural responses of a cat's brain to various visual stimuli, specifically edges of different orientations. Their findings revealed that certain neurons are activated by specific edge movements, and some cells respond directionally. This research suggested the need for a hierarchical model to maintain spatial invariance without flattening images. The discussion sets the foundation for further advancements in CNNs, including the work of Fukushima in 1986, who developed the neocognitron model."}, {'topic': 'Historical Context of CNNs', 'start_time': '00:12:48', 'end_time': '00:13:36', 'transcript': "So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'keywords': ['CNN', 'LeNet-5', 'Character Recognition'], 'summary': 'The transcript discusses the historical context of convolutional neural networks (CNNs), highlighting their development as a machine learning architecture primarily used for digit recognition. It notes that the initial state-of-the-art models faced computational limitations that hindered their advancement. In the 1990s, a significant breakthrough occurred with the introduction of the first successful CNN architecture, known as LeNet-5, which demonstrated effective character recognition. The speaker plans to delve deeper into this architecture during the discussion.'}, {'topic': 'Model Robustness', 'start_time': '00:13:37', 'end_time': '00:16:06', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.", 'keywords': ['Robustness', 'Multi-Layer Perceptron', 'Spatial Invariance'], 'summary': "The transcript discusses enhancing the robustness of a neural network to spatial invariance by employing a modified Multi-Layer Perceptron (MLP) designed to detect the presence of the digit '0' in images. The speaker encourages the audience to consider how to adapt their existing neural networks for this purpose. They explain the process of taking a small, flattened section of an image, which consists of 400 pixels, and inputting it into the MLP to determine the likelihood of a '0' being present. By scanning the entire image with this approach, the MLP generates a probability distribution indicating the presence of '0', allowing for the identification of its location regardless of its position within the image."}, {'topic': 'Hyperparameters in CNNs', 'start_time': '00:23:44', 'end_time': '00:29:00', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.", 'keywords': ['Hyperparameters', 'Filters', 'Multilayer Perceptron'], 'summary': 'The discussion focuses on hyperparameters in convolutional neural networks (CNNs), highlighting their distinction from model parameters like weights. The speaker explains how hyperparameters define the architecture of the network, citing examples such as regularization constants and step sizes. They engage the audience in identifying hyperparameters relevant to CNNs, including the shift size, filter sizes, number of filters, and number of hidden layers. The concept of filters is elaborated upon, describing their role in extracting features from input images, such as edges and lines. The speaker contrasts the approach of multilayer perceptrons with CNNs, emphasizing the compact representation of images using filters and the significance of shared weights in feature extraction.'}, {'topic': 'Convolution and Pooling', 'start_time': '00:33:03', 'end_time': '00:35:16', 'transcript': "So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.", 'keywords': ['Feature Maps', 'Max Pooling', 'Sub-sampling'], 'summary': 'The transcript discusses the concepts of convolution and pooling within convolutional neural networks (CNNs). It describes the generation of feature maps, specifically focusing on a scenario where six filters produce six feature maps. The speaker explains the sub-sampling process, highlighting Max pooling as a common technique where a 2x2 matrix is used to identify the maximum value from the feature maps. This process effectively reduces the dimensions from 28x28 to 14x14. Additionally, the speaker touches on the fully connected layer responsible for classification into various output classes. The discussion emphasizes the architecture of CNNs, mentioning modifications that can occur across different models, and introduces the concept of volume related to feature maps.'}, {'topic': 'Feature Extraction Process', 'start_time': '00:38:14', 'end_time': '00:39:54', 'transcript': "Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.", 'keywords': ['Feature Extraction', 'Filters', 'Sobel'], 'summary': 'The transcript discusses the feature extraction process in image processing, focusing on the use of filters to generate different feature maps. It explains the concept of padding images with a black border to maintain dimensions and introduces various types of filters, including sharp and blur filters. The sharp filter enhances edges while the blur filter smooths out images by averaging surrounding pixel values. Additionally, the transcript mentions the Sobel filter, which is utilized for edge detection in different orientations, highlighting its importance in creating feature maps for effective image analysis.'}, {'topic': 'CNN Features Visualization', 'start_time': '01:18:05', 'end_time': '01:21:00', 'transcript': "and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uh", 'keywords': ['CNN', 'Feature Maps', 'Cross-Correlation'], 'summary': "The transcript discusses the visualization of CNN features, focusing on the architecture of a common CNN model that utilizes 32 filters to create feature maps from RGB images sized 24x24. The speaker explains the process of cross-correlation between filters and images, highlighting how different filters activate specific features within the images. They describe the architecture's structure, which includes multiple convolutional blocks with varying numbers of filters, and mention the importance of visualizing the output of these filters to understand what features they capture, such as grass and vertical edges in an example image of a house."}, {'topic': 'Final Thoughts and Conclusion', 'start_time': '01:27:42', 'end_time': '01:28:14', 'transcript': "Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'keywords': ['Lecture Conclusion', 'CNN', 'Audience Engagement'], 'summary': 'The lecture concludes with a summary of the session, expressing gratitude to the participants for their engagement. The speaker confirms the continuation of the topic on convolutional neural networks (CNNs) in the upcoming session on Saturday. With no further questions from the audience, the speaker officially ends the session, thanking everyone for their participation.'}], 'yellow_line': [{'Topic': 'Technical Setup', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'start_time': '00:00:23', 'end_time': '00:00:56'}, {'Topic': 'Introduction to CNNs', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.", 'start_time': '00:01:23', 'end_time': '00:02:56'}, {'Topic': 'Applications of Deep Learning', 'transcript': "To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.", 'start_time': '00:02:57', 'end_time': '00:04:10'}, {'Topic': 'CNN Architecture Overview', 'transcript': "Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.", 'start_time': '00:04:11', 'end_time': '00:06:35'}, {'Topic': 'Training and Performance of CNNs', 'transcript': "So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?", 'start_time': '00:06:36', 'end_time': '00:09:52'}, {'Topic': 'Spatial Invariance in CNNs', 'transcript': "Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.", 'start_time': '00:09:52', 'end_time': '00:12:47'}, {'Topic': 'Historical Context of CNNs', 'transcript': "So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'start_time': '00:12:48', 'end_time': '00:13:36'}, {'Topic': 'Model Robustness', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.", 'start_time': '00:13:37', 'end_time': '00:16:06'}, {'Topic': 'Hyperparameters in CNNs', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.", 'start_time': '00:23:44', 'end_time': '00:29:00'}, {'Topic': 'Convolution and Pooling', 'transcript': "So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.", 'start_time': '00:33:03', 'end_time': '00:35:16'}, {'Topic': 'Feature Extraction Process', 'transcript': "Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.", 'start_time': '00:38:14', 'end_time': '00:39:54'}, {'Topic': 'CNN Features Visualization', 'transcript': "and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uh", 'start_time': '01:18:05', 'end_time': '01:21:00'}, {'Topic': 'Final Thoughts and Conclusion', 'transcript': "Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'start_time': '01:27:42', 'end_time': '01:28:14'}], 'session_id': [ObjectId('6453a645b4ac5f9afe8df7e6')], 'assessment': ObjectId('66f45fdcc248cb8c52154173'), 'job_name': 'my-transcription-jobcc7660c8-81ac-470f-b899-e0a3baf617f3', 'keywords': ['Spatial Invariance', 'Sobel', 'Feature Extraction', 'LeNet-5', 'Audience Engagement', 'Natural Language Processing', 'Image Analysis', 'Robustness', 'NLP', 'Filters', 'Collaboration', 'Multi-Layer Perceptron', 'Neural Responses', 'Multilayer Perceptron', 'Character Recognition', 'Hyperparameters', 'Max Pooling', 'CNN', 'Backpropagation', 'Screen Sharing', 'Lecture Conclusion', 'Generalization', 'Feature Maps', 'Technical Setup', 'Convolutional Neural Networks', 'Cross-Correlation', 'Deep Learning', 'Sub-sampling'], 'topic': 'Convolutional Neural Networks', 'interaction': [{'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question about what kind of architecture could be used is not addressed.', 'relevancy': '0', 'question': 'What kind of architecture could you use?', 'timestamp': '[0:16:50]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about modifying the existing neural network was not addressed.', 'relevancy': '0', 'question': 'How would you use this information to modify the existing neural network?', 'timestamp': '[0:20:06]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about hyper parameters was not addressed.', 'relevancy': '0', 'question': 'What are the hyper parameters?', 'timestamp': '[0:25:25]'}, {'status': 'answered', 'answer': 'The technical term for shift is stride.', 'completeness': 'Complete answer.', 'relevancy': '2', 'question': 'What is the technical term for shift?', 'timestamp': '[0:25:51]'}, {'status': 'answered', 'answer': 'Normalising the pixel values affects the neural network by ensuring that the input layer has similar scales for each input, which helps in minimizing the cost function more effectively. It leads to a more rounded cost function, allowing the gradient to move more directly towards the minimum, thus speeding up the minimisation process.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How does the normalisation of pixel values affect the neural network?', 'timestamp': '[0:40:30]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about the size of the image after scanning is not addressed.', 'relevancy': '0', 'question': 'What is going to be the size of the image that comes out on the other side when we do the scanning?', 'timestamp': '[0:58:38]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about what happens if we make the stride is not addressed.', 'relevancy': '0', 'question': 'What happens now if we make the stride?', 'timestamp': '[1:02:42]'}, {'status': 'answered', 'answer': '930', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How many parameters does the neural network have just in this layer?', 'timestamp': '[1:09:14]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the dimensions of the next layer are not addressed.', 'relevancy': '0', 'question': 'What is going to be the dimensions of the next layer?', 'timestamp': '[1:14:20]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': "Incomplete, the question 'How many such features?' is not addressed.", 'relevancy': '0', 'question': 'How many such features?', 'timestamp': '[1:14:22]'}], 'summary': 'The transcript discusses a session on convolutional neural networks (CNNs) and their applications, particularly in image analysis. It describes the technical setup, collaborative efforts, and a focus on teaching CNN aspects relevant to various projects, such as an app for identifying ingredients in a refrigerator through image analysis. The session covers the versatility of CNNs in fields like insect detection, disease detection in plants, and natural language processing. Key topics include the motivations for using CNNs, a historical overview of their development, basic building blocks, backpropagation, common architectures, and methods for enhancing performance. The importance of spatial invariance and the preservation of spatial information in images is emphasized, alongside historical research that laid the groundwork for CNN advancements. The discussion includes the significance of hyperparameters, distinguishing them from model parameters, and details the feature extraction process using filters for generating feature maps. Techniques such as Max pooling and the use of specific filters like sharp, blur, and Sobel for edge detection are also explained. The architecture of CNNs is outlined, including the generation of feature maps from RGB images and the importance of visualizing filter outputs to understand captured features. The session concludes with a summary and confirmation of a follow-up discussion.'}
{'_id': ObjectId('66b26b6bb80f3f3035517f12'), 'file_id': ObjectId('632b0e993d114d88e02fd1df'), 'file_name': '1663766166-63038872b13a93a5297cfd52.mp4', 'file_type': 'Video', 'file_path': 'add-resources/1663766166-63038872b13a93a5297cfd52.mp4', 'runtime': '01:28:17', 'transcription_path': 'video-results/out_66b26b6bb80f3f3035517f12.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 58, 59, 467000), 'file_process_date': datetime.datetime(2024, 9, 25, 15, 49, 39, 101000), 'execution_time': 1023.255856, 'status': 'COMPLETED', 'green_line': [{'topic': 'Technical Setup', 'start_time': '00:00:23', 'end_time': '00:00:56', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'keywords': ['Screen Sharing', 'Technical Setup', 'Collaboration'], 'summary': 'The transcript involves a discussion about technical setup, where one participant asks another to share their screen. The conversation is informal, indicating a collaborative atmosphere as they confirm the setup is proceeding smoothly.'}, {'topic': 'Introduction to CNNs', 'start_time': '00:01:23', 'end_time': '00:02:56', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.", 'keywords': ['CNN', 'Image Analysis', 'Deep Learning'], 'summary': "The session begins with an introduction to convolutional neural networks (CNNs), highlighting the speaker's commitment to the topic and the presence of a colleague who has extensive experience in image analysis through deep learning algorithms. The speaker emphasizes that the focus will primarily be on teaching the CNN aspects of the subject while ensuring their involvement throughout the discussion."}, {'topic': 'Deep Learning Applications', 'start_time': '00:02:57', 'end_time': '00:03:42', 'transcript': 'To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,', 'keywords': ['Deep Learning', 'Image Analysis', 'Recipe Recommendation'], 'summary': 'The transcript discusses a deep learning application developed for a client in California, focusing on a project that involves image analysis. The project enables users to take a photograph of their fridge, allowing the application to identify the ingredients present. Based on the identified items, the app then recommends recipes that users can prepare, showcasing the potential of deep learning in practical, everyday scenarios.'}, {'topic': 'Deep Learning Techniques', 'start_time': '00:03:42', 'end_time': '00:04:31', 'transcript': "you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance for", 'keywords': ['Deep Learning', 'Convolutional Neural Networks', 'Natural Language Processing'], 'summary': "The transcript discusses various applications of deep learning techniques, particularly focusing on convolutional neural networks (CNNs). While CNNs are commonly associated with image analysis, the speaker emphasizes their utility in other areas such as insect detection, disease detection in plants, and natural language processing. The aim of the course is to broaden the audience's perspective on the versatility of CNNs beyond just image-related tasks."}, {'topic': 'Convolutional Neural Networks Basics', 'start_time': '00:04:32', 'end_time': '00:05:51', 'transcript': "or recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.", 'keywords': ['CNN', 'Backpropagation', 'Architecture'], 'summary': 'The lecture covers the basics of Convolutional Neural Networks (CNNs), starting with their motivations and explaining why simple networks are insufficient for processing images and other data types. It highlights the versatility of CNNs, mentioning their effectiveness in fields like speech and natural language processing (NLP). The agenda includes a historical overview of CNN development, the basic building blocks and various layers encountered in CNNs, an introduction to backpropagation techniques, and a discussion on common CNN architectures along with strategies for regularization and performance enhancement.'}, {'topic': 'CNN Architecture Overview', 'start_time': '00:05:52', 'end_time': '00:06:49', 'transcript': 'Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,', 'keywords': ['CNN', 'MLP', 'Image Classification'], 'summary': 'The transcript provides an overview of the architecture of convolutional neural networks (CNNs), specifically focusing on their application to black and white images of size 28x28 pixels, representing digits from 0 to 9. It explains the process of flattening these images into a one-dimensional vector of size 784 to feed into a simple multi-layer perceptron (MLP) for classification into one of the ten digit classes. The speaker highlights the effectiveness of this approach, noting that it can achieve accuracy rates between 95% and 98% using straightforward methodologies.'}, {'topic': 'Image Classification Techniques', 'start_time': '00:06:49', 'end_time': '00:09:52', 'transcript': "So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?", 'keywords': ['Image Classification', 'Spatial Invariance', 'Neural Network'], 'summary': "The transcript discusses the output of an image classification model, specifically focusing on its prediction capabilities based on input images. It describes a scenario where different digits are input into the neural network, highlighting how slight changes in the image's position and size drastically affect the model's predictions. The speaker notes that the model struggles with spatial invariance, pointing out that, for instance, the model misclassifies a digit due to a minor shift. The key takeaway is the need for models to achieve better generalization and robustness against variations such as translation and rotation in images. The speaker encourages the audience to think about potential architectural solutions to improve the model's performance under these conditions."}, {'topic': 'Spatial Invariance in CNNs', 'start_time': '00:09:52', 'end_time': '00:10:16', 'transcript': "Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.", 'keywords': ['Spatial Invariance', 'Convolutional Neural Networks', 'Image Processing'], 'summary': 'The discussion focuses on the concept of spatial invariance in convolutional neural networks (CNNs). It highlights the importance of maintaining spatial information when processing images, as flattening the image can lead to the loss of this crucial data. The speaker provides an example of a dog represented from various angles and sizes to illustrate the significance of preserving spatial characteristics in image analysis.'}, {'topic': 'History of CNNs', 'start_time': '00:10:17', 'end_time': '00:13:36', 'transcript': "so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'keywords': ['Convolutional Neural Networks', 'Neocognitron', 'LeNet-5'], 'summary': "The transcript discusses the historical development of convolutional neural networks (CNNs), starting from research conducted in the 1950s. It details an experiment by Hubel and Wiesel, where they studied a cat's brain responses to visual stimuli by measuring electrical impulses in response to various edge orientations. This experiment revealed that certain neurons in the cat's brain are activated by specific edges and directions. The findings indicated the need for a model that preserves spatial information and hierarchy in processing visual data. The conversation then shifts to the work of Fukushima in 1986, who developed the 'neocognitron,' an early machine learning architecture for digit recognition. Despite its success, computational limitations hindered further advancements. The 1990s saw the creation of the first successful convolutional neural network, 'LeNet-5,' which demonstrated character recognition without image flattening. The transcript sets the stage for further discussions on these architectures."}, {'topic': 'Neural Network Modifications', 'start_time': '00:13:37', 'end_time': '00:15:29', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.", 'keywords': ['Neural Network', 'MLP', 'Spatial Invariance'], 'summary': 'The speaker encourages the audience to consider how to modify an existing neural network to enhance its robustness to spatial invariance. They propose a solution involving a simple multi-layer perceptron (MLP) that detects the presence of the digit zero in an image. The speaker describes the process of shrinking the digit and introducing translation variance, explaining that they take a small part of the image, flatten it, and input it into the MLP. The MLP then scans the entire image and outputs a probability distribution indicating the likelihood of the digit zero being present, with a higher probability suggesting detection.'}, {'topic': 'Robustness in Neural Networks', 'start_time': '00:15:29', 'end_time': '00:16:22', 'transcript': "Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. So", 'keywords': ['Robustness', 'Multi-Layer Perceptron', 'Image Scanning'], 'summary': "The speaker discusses the concept of robustness in neural networks, specifically focusing on the use of a Multi-Layer Perceptron (MLP) to scan an entire image for the presence of a zero. The process involves monitoring the outputs of the model and determining if a significant output indicates the presence of a zero, thereby introducing a form of robustness that is independent of the zero's location within the image. The speaker emphasizes the significance of this scanning method and indicates plans to further develop and modify this idea."}, {'topic': 'CNN Hyperparameters', 'start_time': '00:16:22', 'end_time': '00:20:39', 'transcript': "one question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uhuh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the questionwho asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.", 'keywords': ['CNN Hyperparameters', 'Weight Sharing', 'Feature Detection'], 'summary': 'The transcript discusses the concept of CNN hyperparameters, focusing on the mechanism of determining the outputs from a convolutional neural network. The speaker explains how the model identifies the highest probability output, effectively choosing the maximum value from a set of probabilities associated with different classes. This leads to a discussion on enhancing feature detection by breaking down digits into smaller features, allowing for better classification. The importance of hierarchical feature building is emphasized, where multiple layers of perceptron work collaboratively to identify and stack features, leading to improved classification accuracy. The concept of weight sharing is also introduced, highlighting its role in reducing the total number of parameters in the model.'}, {'topic': 'Weight Sharing in CNNs', 'start_time': '00:20:40', 'end_time': '00:22:18', 'transcript': "So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.", 'keywords': ['Weight Sharing', 'Multilayer Perceptron', 'Hierarchy'], 'summary': 'The transcript discusses the concept of weight sharing in convolutional neural networks (CNNs), explaining how each layer in a multilayer perceptron (MLP) functions by taking a weighted sum of inputs and applying a non-linearity. The speaker elaborates on the process of flattening parts of an image, multiplying them by weights, and applying an activation function, similar to MLPs. They introduce the idea of building a hierarchy, where outputs from one layer serve as inputs for the next, thereby creating a compact representation of the image and enabling the learning of both simple and complex features through successive layers.'}, {'topic': 'Convolution and Feature Maps', 'start_time': '00:22:19', 'end_time': '00:23:42', 'transcript': "Okay, so you just, uh, scan. So these are the hair are different. New MLPs here. So this this MLP has, uh, one set of age. This is a new MLP. Here we are, scanning through it, okay. And then we have the final classification will happen. And so now we have sequentially added layers in one direction. We could also add, uh, complexity in the depth of it.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.right. And so, finally, you just can't get it. All of the features and you have a final classification.So this is how the idea of hair are key is taken into account from that horrible and visual experiment that we just build upon small features of the offer input and use those to classify, uh, actual image.", 'keywords': ['Convolution', 'Feature Maps', 'Multi-Layer Perceptrons'], 'summary': 'The transcript discusses the process of convolution and feature maps in the context of machine learning and image classification. It explains how multiple Multi-Layer Perceptrons (MLPs) can be utilized to scan images, each focusing on different features or classes, such as detecting various digits. The speaker describes building complexity by adding layers and combining features, ultimately leading to a final classification of the input image. This method emphasizes the importance of progressively capturing small features to enhance the classification process.'}, {'topic': 'Pooling Techniques', 'start_time': '00:23:44', 'end_time': '00:31:01', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimensionis three. So it's a M by n by three or the image that is a colour image which has got the red, green and blue.channels. right. So one way of visualising this you've got an image of some size. You are reducing the size of the image by doing the scanningright. And with every feature that you're creating is like another channel. Right? So we went from RGB Channel to another description of the same data which has a smaller X and Y axis as such of the image. But it has a depth to it, which is the number of features that have been extracted. Right. And this is a very common feature that you will see when you book shows you the more complicated structures of a CNN.You'll find that you start off with a large image with three channels and you end up with very small images, but with lots of features, lots of channels with it.Right. So this is a very, very important thing to remember when you're doing CNN's, because later on, you will see some very interesting uses of the same philtre to reduce dimensionality.", 'keywords': ['Hyperparameters', 'Filters', 'Feature Extraction'], 'summary': 'The transcript discusses pooling techniques in the context of convolutional neural networks (CNNs), focusing on hyperparameters that define the architecture of neural networks. The speaker elaborates on various hyperparameters such as step size, number of hidden nodes, and number of filters. They explain the significance of filters in feature extraction, contrasting them with handcrafted filters used in traditional image processing. The speaker also describes how filters operate on smaller sections of images, emphasizing the transition from multi-layer perceptrons to CNNs, where feature extraction becomes more efficient with reduced image dimensions and increased feature channels. Finally, the importance of understanding these concepts for dimensionality reduction in CNNs is highlighted.'}, {'topic': 'Normalization of Inputs', 'start_time': '00:31:02', 'end_time': '00:33:52', 'transcript': "Okay, so do you understand all of these concepts? the shift size. you can see that the boxes are overlapping over each other, right? And so you can have a shiftof one pixel or two pixels or whatever. So that becomes a hyper parameter. Like you said, the philtre size definitely the size of the box, the number of philtres at each layer that you're definingright, and the number of such hidden layers that are transforming the input into a smaller, more compact representation.Right is another type of parameters. So very good. And what is the shift called? What is the technical term for shift?stride. Okay, great. Excellent. Okay. Good luck. Any questions on this before it goes on? Because things will only get more complex as we go on.Okay, Wonderful. Okay, So this is the example of, uh, typical Syrian architecture. This is called the Leonard five, which was developed by young liquid.Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresThen you will have six feature maps for each philtre because one feature because one philtre will scan the entire image.So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.", 'keywords': ['Normalization', 'Feature Maps', 'Max Pooling'], 'summary': 'The transcript discusses the concepts related to the normalization of inputs in deep learning, particularly focusing on convolutional neural networks (CNNs). It highlights the importance of hyperparameters such as shift size and filter size, which affect how data is processed through the network. The speaker explains the significance of strides in the context of moving filters across images to create feature maps. They introduce the typical architecture of CNNs, referencing the LeNet-5 model, and elaborate on how multiple filters create several feature maps. Additionally, the concept of subsampling, specifically through max pooling, is explained, where the maximum value from a defined sampling region is selected to reduce dimensionality. This sets the stage for more complex topics as the discussion progresses.'}, {'topic': 'Advanced Convolution Techniques', 'start_time': '00:33:54', 'end_time': '00:39:45', 'transcript': "Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.okay? Okay, So there was one thing I want to visualise here. Yeah, so? So this is a typical grayscale image. So this is the original image you can see here. And this is just a zoom in version, so you can see that every pixel has a value from 0 to 2. 56 to 55. Sorry.So you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,uh, let's take something near the so you can see here. Uh, the left, the left, and the first element in this, uh,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.So, uh, we've got an answer. Which is minus 157. Yes. Uh, be clipped to zero. It will be close to zero.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.", 'keywords': ['Convolution', 'Feature Maps', 'Max Pooling'], 'summary': 'The transcript discusses advanced convolution techniques in the context of convolutional neural networks (CNNs). It explains the process of subsampling, where an input of 28x28 dimensions is reduced to 14x14 using a 2x2 max pooling layer. The speaker outlines the architecture of a CNN, including multiple layers such as convolutional layers, subsampling layers, and fully connected layers for classification tasks. The concept of feature maps is introduced, with emphasis on how different filters, including sharpen and blur filters, are applied to grayscale images. The importance of filters in creating feature maps is highlighted, along with examples of different Sobel filters used for edge detection. The discussion is aimed at providing a clearer understanding of how convolutional techniques contribute to image processing in CNNs.'}, {'topic': 'Feature Extraction in CNNs', 'start_time': '00:39:45', 'end_time': '00:42:36', 'transcript': "Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.Okay, so there is another example of this image. So this is the original image. Okay, Now, if I apply, sharpen, uh around it, you can see it's got a bit sharp.And if you you stop symbol on it, it detects, uh, like horizontal edges. If I apply right Sobel, it detects vertical edges so on and so forth.is this clear? Yes, sir. Okay. so these weights are okay, So, uh, which no one is asking a question here. Uh, how? Well, normalising the pixel values affect the neural network.Um, so we should make sure you don't send it privately because those questions come to me, Uh, is not able to see it, but I've explained this, right? So when you talk about normalising the pixel values, what are you referring to? What you're talking about theapplication of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,", 'keywords': ['Feature Extraction', 'Normalization', 'Sobel Filter'], 'summary': 'The transcript discusses feature extraction in convolutional neural networks (CNNs), focusing on the application of filters to images and the impact of normalization of pixel values. The speaker illustrates how different filters, such as sharpen and Sobel, highlight specific features like horizontal and vertical edges in images. A key point raised is the importance of normalizing pixel values by scaling them to a range of 0 to 1, which aids in stabilizing the training process of the neural network. This normalization helps achieve a more uniform cost function, allowing for better convergence towards an optimal solution during training.'}, {'topic': 'Mathematics of Convolution', 'start_time': '00:42:36', 'end_time': '00:44:10', 'transcript': "so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.", 'keywords': ['Convolution', 'Normalization', 'Multilayer Perceptron'], 'summary': 'The transcript discusses the mathematics behind convolution, highlighting the advantages of normalization in speeding up the minimization process. It addresses the concept of filters, explaining that the handcrafted weights used in convolution are limited to a small set. The speaker contrasts this with multilayer perceptrons, which learn weights automatically. This learning process allows neural networks to extract features from images that may not be easily interpretable by humans, as the network optimizes the cost function effectively.'}, {'topic': 'Convolution vs Cross-Correlation', 'start_time': '00:44:11', 'end_time': '00:48:11', 'transcript': "does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.Uh, so let's say for, uh, I'll take an example of this portion of this image. I'm just, uh, mathematically describing what we have just discussed. Okay,so here we are going from minus Kate. Okay, for let's say, let's say this philtre will have zero in the centre zeroth index.instead of beginning from any side, we begin from the centre. So this has, uh, zero comma zero. Uh, Index, this has, uh,minus one comma one. I could have minus one for my one. This is my new school, Uh this is minus one common minus one just to be clear.And this is, uh, one comma one. And this is one common minus one. So basically, we are saying that the loop power fromminus 1 to 1 in case of a three dimensional feature or philtre so for, Let's say. four g three or three. So Okay,the left corner will be minus 11. the corner with bottom, Yeah. mhm. uh, one here because we are going from, uh, which is, uh,so So, uh, this is the X one. And this is why? right. So, uh, but the other way around. Right. So why is pointing downwards?Yeah. So the coordinator, there will be a minus 11, left bottom. X is minus right the X coordinate of", 'keywords': ['Convolution', 'Feature Extraction', 'Cross-Correlation'], 'summary': 'The transcript discusses the concepts of convolution and cross-correlation in the context of feature extraction by neural networks. It emphasizes the automatic extraction of features that may not be easily understood by humans, illustrated through waves generated by the neural network. The speaker explains the process of learning filters that are tuned to achieve specific outcomes, such as identifying numerical characters in images. A mathematical representation of convolution is also presented, detailing the indices and dimensions of filters as they are applied to images. The speaker provides a detailed example of how these filters operate and the coordinates involved in the process.'}, {'topic': 'CNN Architecture Visualization', 'start_time': '00:48:11', 'end_time': '00:50:48', 'transcript': "minus one. uh this should be minus 11. okay, so Okay, So, uh, idea here is So let's say we have this original image, and we want to, uh, slide this fritter across this entire image. And I want to have an output G, which is my feature map. You could sayokay. So what I'm gonna do here is, um So starting with U N. Vehicle to minus one here in this submission,you equal to minus one and equal to minus one. So I will take the minus one minus 11 element of this, uh, this edge metrics, which is the A.Okay. And, uh, I plus Youth Index. So I am calculating for G three of three. So this is +0123 and again. 0123. So this is my G three comma three.Okay. So if I take, uh, take this philtre and, uh, make the cost cross correlation, I will have a single value, which will be substituted in the place of E here.Right. So what I'm looking here is that, uh, eyes here three and us minus one. And Jay is also three.This is the icon DJ and J minus one. So I'm looking at second element here. So for her 01 to zero. we want. So to buy second by second element is this so I'm multiplying, uh, small a from the philtre with this matrix A herewith a element of these, uh, metrics. and similarly, I'm just looping over. So being small capital B plus small capital C includes. So this way, this time calculating the, uh, waited waited some hereand this will be a single output, which will be replaced here in my future map. Uh, so let's see if I have this. This is my G output. So in place of E here, I will have one single value, which will be the output of this entire operation.", 'keywords': ['CNN Architecture', 'Feature Map', 'Cross-Correlation'], 'summary': 'The transcript discusses the process of visualizing CNN architecture by explaining how a filter slides over an original image to create a feature map. The speaker describes the mathematical operations involved, including cross-correlation, element-wise multiplication, and summation to derive a single output value for the feature map. The explanation includes detailed steps of indexing and looping through elements of the matrix, aiming to clarify how the filter interacts with the image data to produce the desired output.'}, {'topic': 'Layer Interactions in CNNs', 'start_time': '00:50:50', 'end_time': '00:53:23', 'transcript': "Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.", 'keywords': ['Convolution', 'Cross-Correlation', 'Backpropagation'], 'summary': 'The transcript discusses the mathematical representation of layer interactions in convolutional neural networks (CNNs), focusing on concepts such as cross-correlation and backpropagation. The speaker explains the process of applying filters to an original image, demonstrating with different types of filters like sharpen, blur, and edge detectors. An important distinction is made between convolution and cross-correlation, highlighting that convolution involves rotating the filter during calculations. A visual example is provided, illustrating the computation of the feature map using a 3x3 matrix and the dot product with elements of the input image, ultimately explaining how the filter is flipped by 180 degrees.'}, {'topic': 'Understanding Feature Maps', 'start_time': '00:53:24', 'end_time': '00:55:17', 'transcript': "okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottomto the top. Okay. So because the future has rotated and just changing the sign here, uh, will assist in that happening, so", 'keywords': ['Feature Maps', 'Cross-Correlation', 'Convolution'], 'summary': "The transcript discusses the concept of feature maps in the context of convolutional operations. It begins by illustrating a visual representation of an image where most elements are zeros, except for one, and describes how a filter is applied to this image. The speaker explains the process of cross-correlation and how it differs from convolution, noting that during the forward pass, cross-correlation is performed rather than convolution. They elaborate on the mathematical operations involved, highlighting the significance of the filter's orientation and the direction of multiplication. The discussion also touches upon the implications of these operations for backpropagation, emphasizing the need to understand the distinction between cross-correlation and convolution in deep learning."}, {'topic': 'CNN Applications', 'start_time': '00:55:18', 'end_time': '01:06:58', 'transcript': "Okay, Uh, you can just explore this on your own later on. If you just try to write these expressions down and you will be able to figure out that we're just recreating the philtreand doing the cross correlation, okay? Okay, so So till now we discuss these handcrafted philtres like the blur sharpen, agitation, etcetera. But these are the things which the model learns as just described. So what we're gonna do is we're gonna visualise these features for the religion. It Okay, Uh, so let me first explain that how these, uhhow these architectures look like. Okay, so, uh, the input here is, uh, before we go into the architecture, can we just, uh, do a little bit of discussion around how the philtre size impact, the output image size, But is that coming after this?Yes. I was just trying to bring Troy. I don't have, uh Okay. Okay. So let's say religion yet We use colour images, so let's say it will be a three dimensional image.And let's say it is 2. 56 by 2. 56 with three channels of input. Okay, so now we want to, uh, involved used 32 philtres here.Okay of dimensions, Uh, three by three. Okay, So this is how you generally defining your chaos or you're open source, uh, libraries, but under the hood. Uh, what is happening is that each philtre will have dimensionsthree by three. And this three, the depth is coming from the input. because the input image has three channels as death. So you're each philtre will also have a depth of three. Okay, so what we do here is that we take small, uh,crop of size three by three hair from this bigger image. three by three by three And we just, uh, do an element wise multiplication of all these elements in this cubewith this philtre. Okay, So if there are, let's say, uh, three numbers here and three numbers in the first, uh, slice. Then you just, uh, do the cross correlation, and there would be one output.Okay. And you do same for all the layers. So for second slice here also, okay, and output of this result would be single number.this is very important to note. Okay, so after conclusion where there will be one value here. So you do this for across entire this image. So you have access right of one.so let's let's leave it to them to come up with the answer. Okay, So with the stride of one pixel means that you're shifting by one pixel to the right all the way till you get to the end of the image, right? So recognise that you get to the end of the image when the right side of your philtre reaches the edge. Okay, so there's no paddingfor those of you know what padding is. There's no padding. For those of you who don't know about padding, just don't worry about it. Just tell us what is going to be the size of the image that comes out on the other side when we do the scanning. Now the stride works left to rightand talk to bottom. right. So as you scan across, you're going one pixel at a time and going to the next position where the philtre is applied. And then when you get to the end, you shift the philtre down by one,uh, pixel and apply it again. Correct? Yes, sir. Okay. So what is going to be the size of the image that is coming out on the other end? Or the the two dimensional array that's coming out at the end? Because remember what is sayingthat the three by three by three is producing only one number, so the multilayered Perceptron is taking27 inputs and is out putting one value. Okay, So what you're getting as a result of applying this philtre is a two dimensionalmatrix of numbers, and I want to know the dimensionality of that. 54. other ways, okay? there were two people speaking. So one person said to 54.And what was the other person saying? I think, uh, zero comma zero is concerned at the centre, and, uh, the other things are taken at that size in the same way you look at work,right? So, like I said, the we are resuming zero padding go padding right now. Right? So your philtre starts from the edge and takes the first three into account.right, and then it moves by one and moves by one. Right? So the size is going to be there. One answer that's been given us 254.Is that the number of rows or the number of columns, or what is to 54? I think both. Okay, Anybody else have a different answer?no sort of 54 and 54 in total Tito. in 2. 32. Okay, 32 because we've got 32 philtres. Good. Okay. I have been looking for one philtre with Excellent. Okay, so 254 by 2. 50 for 5. 32 will be the third dimension.Uh, just for this philtre Yes, output will be just a matrix. Uh, considering for just one philtre, this is just one,Uh, that's correct that we will have 32 such philtres. So for each of that philtre, we will have one,to the output. Yes. Yes. And then that will build up to 30 to do that. Yeah. Perfect. Perfect. Okay, So what happens now if we make the stride?Ooh! Okay, so now let's make the strive to what becomes the output size now? Does the output size change?instead. How much does it change? Uh, third dimension in the same 1. 27 1 27 127. So how did you come up with 1. 27?sir. And if you take in putting measures in and the philtres. I just Yes. And we We are taking a straight to that isminus Yes. And we are adding one to the and mine the eff s blossom. Okay. Do you want to write the formula they're given? You've got access toYes, Uh, like the formula, which, uh Okay, can you please repeat and I say important measure that is 256 in 2016 and a filtered site.and at that stage. the farm law of the output. The message will be and minus f s plus one. listen. so that would be a 56 minus.three dots. Bye. HM. That doesn't seems correct. It's two less 127. So now you've got 253 divided by two, right?So what happens? We've got a decimal number there. So I have that too. From the looks. you will take in digital partnership.If we have fraction, then we protect right? so Yeah. So that is the same formula. Uh, only were riding fighting out here. Right? Fighting is zero w minus scale over this. That's whywhich is fine. And then what you're saying is we are taking the interior part. So are we rounding up or are we rounding down?so if there is greater than five, then we are all being up. but now it's point. What do we do? I think running, don't you?Okay, so let's just take a small example of, uh, seven by seven image, right? and what is happening here when we are not doing a padding, So the first one is three by three.the philtre application. And then we're taking a stride of two, which means now we're starting from pixel, too.23. And, uh, so we're starting the numbering from zero. Right, So 0 to 6 is the pixel numbering. Okay,Right. And now we're doing a three by three. right. So the three by three the first philtre, then we're taking a stride of two.so we start from now 23 and four. And now we take another stride of two, which gives us now. four, five and six.", 'keywords': ['Convolutional Neural Networks', 'Filter Size', 'Stride'], 'summary': 'The transcript discusses the applications of convolutional neural networks (CNNs), focusing on the visualization of learned features and the impact of filter size on output image dimensions. The speaker explains the process of applying filters to images, detailing how each filter operates on a three-dimensional input (such as color images) and produces a single output value through element-wise multiplication. The conversation progresses to the concepts of stride and padding, illustrating how these parameters affect the resulting dimensions of the output matrix. The speaker engages the audience with questions about output sizes, emphasizing the importance of understanding the mathematical relationships involved, including the formula for calculating output dimensions based on filter size and stride.'}, {'topic': 'Parameter Learning in CNNs', 'start_time': '01:07:01', 'end_time': '01:09:59', 'transcript': "right. So in this case, if we look at the formula, what's happening is N is seven minus three. great.stride is too so seven minus 3/2. which is three, right? So that's 4/2. That's 13, so we can see we have created three. Now the problem comes when we have an eight by eight image, right? And now we have an issue in that if we had another pixels in rows and columns.we basically not be able to do any further, right? So if we had an eight by eight image, if you can just draw that additional problem and go.Now, when we go for the stride of two, we are going over the edge, so we can't do anymore, right? So we are always looking at the number below, as the output were basically ignoring the that last follow. And that last room. Right? So we will always take the lower number out here.right. okay? So now my question is, how many parameters does the neural network have just in this layer?So who's gonna tell me that now? How many parameters? Now we've got 32 philtres. We've got a three by three philtres,right? And an RGB image. How many parameters do we need to learn in this? one pair of lives. who's gonna tell us?930 two. Sorry. nine by 30 to 1930 to 19 to 19 to 32. Okay. Any other answers? 20 7 to 32. Okay. Any other answers?thanks. Nobody else wants to suggest the answer. 20 730 to 30 two. Correct. So the reason why it's 27 by 32 and not nine by 32 it would be nine by 32 if we had a.grayscale image, right? We didn't have the channel. So you must always remember that we have got a three dimensional Frida", 'keywords': ['Parameters', 'Stride', 'Convolutional Neural Networks'], 'summary': 'The transcript discusses the calculation of parameters in convolutional neural networks (CNNs) during the learning process. It begins with a formula involving dimensions and stride, highlighting the challenges posed by an eight by eight image and the implications of stride on parameter calculation. The speaker emphasizes the importance of considering the lower number when determining output dimensions, and then poses a question regarding the total number of parameters in a specific layer of the neural network. The discussion includes responses from participants about the number of parameters, illustrating the intricacies involved when dealing with RGB images versus grayscale images, and confirming that the correct calculation takes into account the three-dimensional nature of the filters used.'}, {'topic': 'CNN Advantages', 'start_time': '01:10:00', 'end_time': '01:12:53', 'transcript': "where the third dimensions depth is defined by the number of input channels to that live. Okay, good. Now, what would be the number of parameters that needs to be learned? If we were not using CNN,we were actually using a multilayered percent promise. that depends on the number of notes hidden next to them. Iwant the same number of notes as I have in the hidden layer in the CNN. So how many notes do I have in the hidden layer in the CNN?trick questions. mhm. 56. Close to 56. Crusty. That is my input layer. Right? So that's 2. 56 times 2, 56 times three.that's the input Lear sites. what it was before. Before 254 by 254. right. by 32 right, and how many parameters would we have to learn?uh, we have to do, like the four 130 two cross, uh, test is too extreme. right. So we're basically multiplying all of these, right? Because every note in the input layer must be connected to every note and the output.right, So it's 256 squared, multiplied by three. multiplied by 254 squared, multiplied by 32. right. which one is big?There's no argument, right? I mean, we are comparing a very large number of parameters here with just 27 multiplied by 32.right, and this is a huge advantage of CNN. It's the weird. sharing with sharing. That's happening. That is a hugely important aspect.Oh, CNN. Okay, so you appreciate that. And what have we talked about that as the number of parameters increases, what do we need to do? We need a lot more data to learn them.", 'keywords': ['CNN', 'Parameters', 'Weight Sharing'], 'summary': 'The transcript discusses the advantages of convolutional neural networks (CNNs) in terms of parameter efficiency compared to traditional multilayer perceptrons. It highlights how the number of parameters in a CNN can be significantly lower due to weight sharing, which is a crucial feature of CNNs. The speaker elaborates on the calculations involved in determining the number of learnable parameters, using specific numerical examples to illustrate the differences. The emphasis is on the dramatic reduction in parameters needed in CNNs, which allows for more efficient learning, particularly when dealing with large datasets.'}, {'topic': 'Final Remarks on CNNs', 'start_time': '01:12:55', 'end_time': '01:17:44', 'transcript': "right. And so we are actually talking about unnecessarily learning a lot of weights. Whereas we know that really what we're looking for is a scan through theright. So hopefully this is clear to you that actually the CNN can be represented as a multi layer perceptron also. So the multi layer Perceptron can do the work of the CNN as we see it right now, but the number of parameters is going to be much larger.okay, and so it's much more difficult to learn the same representation comparative. Okay, so here's another question.Now we have a 54 by 2. 54 by 32. right, and we are again using. Now we are using a five by five philtres.So what is going to be the dimensions of the next left? 54 by 254. by 32. right. So now we're using a five by five philtre.how many such features, let's say 64. such tried stride of, mm. 124 into 1, 24 and 60 for the lesson.Mm. for 254. find us. five, divided by two plus one. so that's 249 divided by two. 1 24 +11 25 1 25 by 125 by 64.how many parameters. and what will be the shape of the philtre? you tell me. Uh, sorry. Was that good book?Uh, that's part of the number 64. 55 or 60. Uh, And so we got an answer here for the number of parameters, I think.Okay, 25 by 64. So he said it could be what we do here. pretty good. so one person's answer is 25 by 64.Don't you find it that you don't look beautiful? 25 and 32. That's right. Okay. And so they will be. Bias is also right. Yes.good point. Thank you for keeping us right there. So in the last one, also, we forgot about the biases thatso remember the bias stone is important, right? What does the bias give us gives us? It gives us a fine transformation.Right? So we must have that constant added and also so, plus 64 there and we've got the total number of parameters yet.Okay, Good. Excellent. Okay. Uh, let's, uh, move on. I think hopefully everybody's got anybody. Got a question here? I know there are a few of you who have dealt with CNN's and done some deep learning. That does not mean that people who are not understanding this can't ask questions.Okay, So for those of you who are new to this, this is very, very important that you understand this. Okay, here's another. Okay, Let's go. There is another question I want to ask you, okay?which is the number of computations you're doing. so floating point operations, floating point operations do you need to do here? But I believe that as an exercise for you, let's carry on.", 'keywords': ['Multi-layer Perceptron', 'Convolutional Filters', 'Parameters'], 'summary': 'The final remarks on convolutional neural networks (CNNs) focus on their representation as multilayer perceptrons, highlighting the increased complexity and parameter count in the latter. The speaker discusses dimensionality in relation to convolutional filters, including calculations for the dimensions of outputs and the number of parameters, emphasizing the importance of biases in transformations. The session encourages questions, particularly for newcomers to CNNs and deep learning, and hints at further exercises related to floating point operations.'}, {'topic': 'Session Conclusion', 'start_time': '01:17:47', 'end_time': '01:28:14', 'transcript': "okay? Okay, So next, uh, was trying to visualise these features. So? So what we have here is so he worked with it was that we took an RGB image.and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'keywords': ['CNN', 'Feature Maps', 'Image Classification'], 'summary': 'The session concludes with a detailed discussion on visualizing features extracted from convolutional neural networks (CNNs) using RGB images and various filter configurations. The speaker explains the architecture of a CNN, particularly focusing on the use of multiple convolutional blocks, each processing the input image with different sets of filters to create feature maps. Throughout the layers, the features become increasingly abstract, making it more challenging to interpret them directly. The speaker demonstrates how filters correspond to specific features such as edges and textures in the input images, and how these features evolve through the network layers. The final output is used to classify different images, showcasing the activation of filters related to recognized patterns, such as human faces versus houses. The session ends with a confirmation of understanding and a note on the continuation of CNN topics in upcoming lectures.'}], 'yellow_line': [{'Topic': 'Technical Setup', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'start_time': '00:00:23', 'end_time': '00:00:56'}, {'Topic': 'Introduction to CNNs', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.", 'start_time': '00:01:23', 'end_time': '00:02:56'}, {'Topic': 'Deep Learning Applications', 'transcript': 'To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,', 'start_time': '00:02:57', 'end_time': '00:03:42'}, {'Topic': 'Deep Learning Techniques', 'transcript': "you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance for", 'start_time': '00:03:42', 'end_time': '00:04:31'}, {'Topic': 'Convolutional Neural Networks Basics', 'transcript': "or recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.", 'start_time': '00:04:32', 'end_time': '00:05:51'}, {'Topic': 'CNN Architecture Overview', 'transcript': 'Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,', 'start_time': '00:05:52', 'end_time': '00:06:49'}, {'Topic': 'Image Classification Techniques', 'transcript': "So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?", 'start_time': '00:06:49', 'end_time': '00:09:52'}, {'Topic': 'Spatial Invariance in CNNs', 'transcript': "Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.", 'start_time': '00:09:52', 'end_time': '00:10:16'}, {'Topic': 'History of CNNs', 'transcript': "so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'start_time': '00:10:17', 'end_time': '00:13:36'}, {'Topic': 'Neural Network Modifications', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.", 'start_time': '00:13:37', 'end_time': '00:15:29'}, {'Topic': 'Robustness in Neural Networks', 'transcript': "Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. So", 'start_time': '00:15:29', 'end_time': '00:16:22'}, {'Topic': 'CNN Hyperparameters', 'transcript': "one question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uhuh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the questionwho asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.", 'start_time': '00:16:22', 'end_time': '00:20:39'}, {'Topic': 'Weight Sharing in CNNs', 'transcript': "So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.", 'start_time': '00:20:40', 'end_time': '00:22:18'}, {'Topic': 'Convolution and Feature Maps', 'transcript': "Okay, so you just, uh, scan. So these are the hair are different. New MLPs here. So this this MLP has, uh, one set of age. This is a new MLP. Here we are, scanning through it, okay. And then we have the final classification will happen. And so now we have sequentially added layers in one direction. We could also add, uh, complexity in the depth of it.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.right. And so, finally, you just can't get it. All of the features and you have a final classification.So this is how the idea of hair are key is taken into account from that horrible and visual experiment that we just build upon small features of the offer input and use those to classify, uh, actual image.", 'start_time': '00:22:19', 'end_time': '00:23:42'}, {'Topic': 'Pooling Techniques', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimensionis three. So it's a M by n by three or the image that is a colour image which has got the red, green and blue.channels. right. So one way of visualising this you've got an image of some size. You are reducing the size of the image by doing the scanningright. And with every feature that you're creating is like another channel. Right? So we went from RGB Channel to another description of the same data which has a smaller X and Y axis as such of the image. But it has a depth to it, which is the number of features that have been extracted. Right. And this is a very common feature that you will see when you book shows you the more complicated structures of a CNN.You'll find that you start off with a large image with three channels and you end up with very small images, but with lots of features, lots of channels with it.Right. So this is a very, very important thing to remember when you're doing CNN's, because later on, you will see some very interesting uses of the same philtre to reduce dimensionality.", 'start_time': '00:23:44', 'end_time': '00:31:01'}, {'Topic': 'Normalization of Inputs', 'transcript': "Okay, so do you understand all of these concepts? the shift size. you can see that the boxes are overlapping over each other, right? And so you can have a shiftof one pixel or two pixels or whatever. So that becomes a hyper parameter. Like you said, the philtre size definitely the size of the box, the number of philtres at each layer that you're definingright, and the number of such hidden layers that are transforming the input into a smaller, more compact representation.Right is another type of parameters. So very good. And what is the shift called? What is the technical term for shift?stride. Okay, great. Excellent. Okay. Good luck. Any questions on this before it goes on? Because things will only get more complex as we go on.Okay, Wonderful. Okay, So this is the example of, uh, typical Syrian architecture. This is called the Leonard five, which was developed by young liquid.Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresThen you will have six feature maps for each philtre because one feature because one philtre will scan the entire image.So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.", 'start_time': '00:31:02', 'end_time': '00:33:52'}, {'Topic': 'Advanced Convolution Techniques', 'transcript': "Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.okay? Okay, So there was one thing I want to visualise here. Yeah, so? So this is a typical grayscale image. So this is the original image you can see here. And this is just a zoom in version, so you can see that every pixel has a value from 0 to 2. 56 to 55. Sorry.So you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,uh, let's take something near the so you can see here. Uh, the left, the left, and the first element in this, uh,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.So, uh, we've got an answer. Which is minus 157. Yes. Uh, be clipped to zero. It will be close to zero.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.", 'start_time': '00:33:54', 'end_time': '00:39:45'}, {'Topic': 'Feature Extraction in CNNs', 'transcript': "Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.Okay, so there is another example of this image. So this is the original image. Okay, Now, if I apply, sharpen, uh around it, you can see it's got a bit sharp.And if you you stop symbol on it, it detects, uh, like horizontal edges. If I apply right Sobel, it detects vertical edges so on and so forth.is this clear? Yes, sir. Okay. so these weights are okay, So, uh, which no one is asking a question here. Uh, how? Well, normalising the pixel values affect the neural network.Um, so we should make sure you don't send it privately because those questions come to me, Uh, is not able to see it, but I've explained this, right? So when you talk about normalising the pixel values, what are you referring to? What you're talking about theapplication of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,", 'start_time': '00:39:45', 'end_time': '00:42:36'}, {'Topic': 'Mathematics of Convolution', 'transcript': "so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.", 'start_time': '00:42:36', 'end_time': '00:44:10'}, {'Topic': 'Convolution vs Cross-Correlation', 'transcript': "does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.Uh, so let's say for, uh, I'll take an example of this portion of this image. I'm just, uh, mathematically describing what we have just discussed. Okay,so here we are going from minus Kate. Okay, for let's say, let's say this philtre will have zero in the centre zeroth index.instead of beginning from any side, we begin from the centre. So this has, uh, zero comma zero. Uh, Index, this has, uh,minus one comma one. I could have minus one for my one. This is my new school, Uh this is minus one common minus one just to be clear.And this is, uh, one comma one. And this is one common minus one. So basically, we are saying that the loop power fromminus 1 to 1 in case of a three dimensional feature or philtre so for, Let's say. four g three or three. So Okay,the left corner will be minus 11. the corner with bottom, Yeah. mhm. uh, one here because we are going from, uh, which is, uh,so So, uh, this is the X one. And this is why? right. So, uh, but the other way around. Right. So why is pointing downwards?Yeah. So the coordinator, there will be a minus 11, left bottom. X is minus right the X coordinate of", 'start_time': '00:44:11', 'end_time': '00:48:11'}, {'Topic': 'CNN Architecture Visualization', 'transcript': "minus one. uh this should be minus 11. okay, so Okay, So, uh, idea here is So let's say we have this original image, and we want to, uh, slide this fritter across this entire image. And I want to have an output G, which is my feature map. You could sayokay. So what I'm gonna do here is, um So starting with U N. Vehicle to minus one here in this submission,you equal to minus one and equal to minus one. So I will take the minus one minus 11 element of this, uh, this edge metrics, which is the A.Okay. And, uh, I plus Youth Index. So I am calculating for G three of three. So this is +0123 and again. 0123. So this is my G three comma three.Okay. So if I take, uh, take this philtre and, uh, make the cost cross correlation, I will have a single value, which will be substituted in the place of E here.Right. So what I'm looking here is that, uh, eyes here three and us minus one. And Jay is also three.This is the icon DJ and J minus one. So I'm looking at second element here. So for her 01 to zero. we want. So to buy second by second element is this so I'm multiplying, uh, small a from the philtre with this matrix A herewith a element of these, uh, metrics. and similarly, I'm just looping over. So being small capital B plus small capital C includes. So this way, this time calculating the, uh, waited waited some hereand this will be a single output, which will be replaced here in my future map. Uh, so let's see if I have this. This is my G output. So in place of E here, I will have one single value, which will be the output of this entire operation.", 'start_time': '00:48:11', 'end_time': '00:50:48'}, {'Topic': 'Layer Interactions in CNNs', 'transcript': "Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.", 'start_time': '00:50:50', 'end_time': '00:53:23'}, {'Topic': 'Understanding Feature Maps', 'transcript': "okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottomto the top. Okay. So because the future has rotated and just changing the sign here, uh, will assist in that happening, so", 'start_time': '00:53:24', 'end_time': '00:55:17'}, {'Topic': 'CNN Applications', 'transcript': "Okay, Uh, you can just explore this on your own later on. If you just try to write these expressions down and you will be able to figure out that we're just recreating the philtreand doing the cross correlation, okay? Okay, so So till now we discuss these handcrafted philtres like the blur sharpen, agitation, etcetera. But these are the things which the model learns as just described. So what we're gonna do is we're gonna visualise these features for the religion. It Okay, Uh, so let me first explain that how these, uhhow these architectures look like. Okay, so, uh, the input here is, uh, before we go into the architecture, can we just, uh, do a little bit of discussion around how the philtre size impact, the output image size, But is that coming after this?Yes. I was just trying to bring Troy. I don't have, uh Okay. Okay. So let's say religion yet We use colour images, so let's say it will be a three dimensional image.And let's say it is 2. 56 by 2. 56 with three channels of input. Okay, so now we want to, uh, involved used 32 philtres here.Okay of dimensions, Uh, three by three. Okay, So this is how you generally defining your chaos or you're open source, uh, libraries, but under the hood. Uh, what is happening is that each philtre will have dimensionsthree by three. And this three, the depth is coming from the input. because the input image has three channels as death. So you're each philtre will also have a depth of three. Okay, so what we do here is that we take small, uh,crop of size three by three hair from this bigger image. three by three by three And we just, uh, do an element wise multiplication of all these elements in this cubewith this philtre. Okay, So if there are, let's say, uh, three numbers here and three numbers in the first, uh, slice. Then you just, uh, do the cross correlation, and there would be one output.Okay. And you do same for all the layers. So for second slice here also, okay, and output of this result would be single number.this is very important to note. Okay, so after conclusion where there will be one value here. So you do this for across entire this image. So you have access right of one.so let's let's leave it to them to come up with the answer. Okay, So with the stride of one pixel means that you're shifting by one pixel to the right all the way till you get to the end of the image, right? So recognise that you get to the end of the image when the right side of your philtre reaches the edge. Okay, so there's no paddingfor those of you know what padding is. There's no padding. For those of you who don't know about padding, just don't worry about it. Just tell us what is going to be the size of the image that comes out on the other side when we do the scanning. Now the stride works left to rightand talk to bottom. right. So as you scan across, you're going one pixel at a time and going to the next position where the philtre is applied. And then when you get to the end, you shift the philtre down by one,uh, pixel and apply it again. Correct? Yes, sir. Okay. So what is going to be the size of the image that is coming out on the other end? Or the the two dimensional array that's coming out at the end? Because remember what is sayingthat the three by three by three is producing only one number, so the multilayered Perceptron is taking27 inputs and is out putting one value. Okay, So what you're getting as a result of applying this philtre is a two dimensionalmatrix of numbers, and I want to know the dimensionality of that. 54. other ways, okay? there were two people speaking. So one person said to 54.And what was the other person saying? I think, uh, zero comma zero is concerned at the centre, and, uh, the other things are taken at that size in the same way you look at work,right? So, like I said, the we are resuming zero padding go padding right now. Right? So your philtre starts from the edge and takes the first three into account.right, and then it moves by one and moves by one. Right? So the size is going to be there. One answer that's been given us 254.Is that the number of rows or the number of columns, or what is to 54? I think both. Okay, Anybody else have a different answer?no sort of 54 and 54 in total Tito. in 2. 32. Okay, 32 because we've got 32 philtres. Good. Okay. I have been looking for one philtre with Excellent. Okay, so 254 by 2. 50 for 5. 32 will be the third dimension.Uh, just for this philtre Yes, output will be just a matrix. Uh, considering for just one philtre, this is just one,Uh, that's correct that we will have 32 such philtres. So for each of that philtre, we will have one,to the output. Yes. Yes. And then that will build up to 30 to do that. Yeah. Perfect. Perfect. Okay, So what happens now if we make the stride?Ooh! Okay, so now let's make the strive to what becomes the output size now? Does the output size change?instead. How much does it change? Uh, third dimension in the same 1. 27 1 27 127. So how did you come up with 1. 27?sir. And if you take in putting measures in and the philtres. I just Yes. And we We are taking a straight to that isminus Yes. And we are adding one to the and mine the eff s blossom. Okay. Do you want to write the formula they're given? You've got access toYes, Uh, like the formula, which, uh Okay, can you please repeat and I say important measure that is 256 in 2016 and a filtered site.and at that stage. the farm law of the output. The message will be and minus f s plus one. listen. so that would be a 56 minus.three dots. Bye. HM. That doesn't seems correct. It's two less 127. So now you've got 253 divided by two, right?So what happens? We've got a decimal number there. So I have that too. From the looks. you will take in digital partnership.If we have fraction, then we protect right? so Yeah. So that is the same formula. Uh, only were riding fighting out here. Right? Fighting is zero w minus scale over this. That's whywhich is fine. And then what you're saying is we are taking the interior part. So are we rounding up or are we rounding down?so if there is greater than five, then we are all being up. but now it's point. What do we do? I think running, don't you?Okay, so let's just take a small example of, uh, seven by seven image, right? and what is happening here when we are not doing a padding, So the first one is three by three.the philtre application. And then we're taking a stride of two, which means now we're starting from pixel, too.23. And, uh, so we're starting the numbering from zero. Right, So 0 to 6 is the pixel numbering. Okay,Right. And now we're doing a three by three. right. So the three by three the first philtre, then we're taking a stride of two.so we start from now 23 and four. And now we take another stride of two, which gives us now. four, five and six.", 'start_time': '00:55:18', 'end_time': '01:06:58'}, {'Topic': 'Parameter Learning in CNNs', 'transcript': "right. So in this case, if we look at the formula, what's happening is N is seven minus three. great.stride is too so seven minus 3/2. which is three, right? So that's 4/2. That's 13, so we can see we have created three. Now the problem comes when we have an eight by eight image, right? And now we have an issue in that if we had another pixels in rows and columns.we basically not be able to do any further, right? So if we had an eight by eight image, if you can just draw that additional problem and go.Now, when we go for the stride of two, we are going over the edge, so we can't do anymore, right? So we are always looking at the number below, as the output were basically ignoring the that last follow. And that last room. Right? So we will always take the lower number out here.right. okay? So now my question is, how many parameters does the neural network have just in this layer?So who's gonna tell me that now? How many parameters? Now we've got 32 philtres. We've got a three by three philtres,right? And an RGB image. How many parameters do we need to learn in this? one pair of lives. who's gonna tell us?930 two. Sorry. nine by 30 to 1930 to 19 to 19 to 32. Okay. Any other answers? 20 7 to 32. Okay. Any other answers?thanks. Nobody else wants to suggest the answer. 20 730 to 30 two. Correct. So the reason why it's 27 by 32 and not nine by 32 it would be nine by 32 if we had a.grayscale image, right? We didn't have the channel. So you must always remember that we have got a three dimensional Frida", 'start_time': '01:07:01', 'end_time': '01:09:59'}, {'Topic': 'CNN Advantages', 'transcript': "where the third dimensions depth is defined by the number of input channels to that live. Okay, good. Now, what would be the number of parameters that needs to be learned? If we were not using CNN,we were actually using a multilayered percent promise. that depends on the number of notes hidden next to them. Iwant the same number of notes as I have in the hidden layer in the CNN. So how many notes do I have in the hidden layer in the CNN?trick questions. mhm. 56. Close to 56. Crusty. That is my input layer. Right? So that's 2. 56 times 2, 56 times three.that's the input Lear sites. what it was before. Before 254 by 254. right. by 32 right, and how many parameters would we have to learn?uh, we have to do, like the four 130 two cross, uh, test is too extreme. right. So we're basically multiplying all of these, right? Because every note in the input layer must be connected to every note and the output.right, So it's 256 squared, multiplied by three. multiplied by 254 squared, multiplied by 32. right. which one is big?There's no argument, right? I mean, we are comparing a very large number of parameters here with just 27 multiplied by 32.right, and this is a huge advantage of CNN. It's the weird. sharing with sharing. That's happening. That is a hugely important aspect.Oh, CNN. Okay, so you appreciate that. And what have we talked about that as the number of parameters increases, what do we need to do? We need a lot more data to learn them.", 'start_time': '01:10:00', 'end_time': '01:12:53'}, {'Topic': 'Final Remarks on CNNs', 'transcript': "right. And so we are actually talking about unnecessarily learning a lot of weights. Whereas we know that really what we're looking for is a scan through theright. So hopefully this is clear to you that actually the CNN can be represented as a multi layer perceptron also. So the multi layer Perceptron can do the work of the CNN as we see it right now, but the number of parameters is going to be much larger.okay, and so it's much more difficult to learn the same representation comparative. Okay, so here's another question.Now we have a 54 by 2. 54 by 32. right, and we are again using. Now we are using a five by five philtres.So what is going to be the dimensions of the next left? 54 by 254. by 32. right. So now we're using a five by five philtre.how many such features, let's say 64. such tried stride of, mm. 124 into 1, 24 and 60 for the lesson.Mm. for 254. find us. five, divided by two plus one. so that's 249 divided by two. 1 24 +11 25 1 25 by 125 by 64.how many parameters. and what will be the shape of the philtre? you tell me. Uh, sorry. Was that good book?Uh, that's part of the number 64. 55 or 60. Uh, And so we got an answer here for the number of parameters, I think.Okay, 25 by 64. So he said it could be what we do here. pretty good. so one person's answer is 25 by 64.Don't you find it that you don't look beautiful? 25 and 32. That's right. Okay. And so they will be. Bias is also right. Yes.good point. Thank you for keeping us right there. So in the last one, also, we forgot about the biases thatso remember the bias stone is important, right? What does the bias give us gives us? It gives us a fine transformation.Right? So we must have that constant added and also so, plus 64 there and we've got the total number of parameters yet.Okay, Good. Excellent. Okay. Uh, let's, uh, move on. I think hopefully everybody's got anybody. Got a question here? I know there are a few of you who have dealt with CNN's and done some deep learning. That does not mean that people who are not understanding this can't ask questions.Okay, So for those of you who are new to this, this is very, very important that you understand this. Okay, here's another. Okay, Let's go. There is another question I want to ask you, okay?which is the number of computations you're doing. so floating point operations, floating point operations do you need to do here? But I believe that as an exercise for you, let's carry on.", 'start_time': '01:12:55', 'end_time': '01:17:44'}, {'Topic': 'Session Conclusion', 'transcript': "okay? Okay, So next, uh, was trying to visualise these features. So? So what we have here is so he worked with it was that we took an RGB image.and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'start_time': '01:17:47', 'end_time': '01:28:14'}], 'session_id': [ObjectId('633eba15a6467d78c009eac5')], 'job_name': 'my-transcription-job0d37f2d1-9027-43db-b88f-5ba2aef9d371', 'keywords': ['Spatial Invariance', 'Architecture', 'Image Classification', 'Stride', 'Feature Extraction', 'LeNet-5', 'Normalization', 'Natural Language Processing', 'CNN Hyperparameters', 'Convolution', 'Image Analysis', 'Robustness', 'Filters', 'Collaboration', 'Multi-Layer Perceptron', 'Image Processing', 'Multilayer Perceptron', 'Image Scanning', 'Sobel Filter', 'Weight Sharing', 'MLP', 'Feature Map', 'Neocognitron', 'Hyperparameters', 'Multi-Layer Perceptrons', 'Max Pooling', 'CNN Architecture', 'CNN', 'Backpropagation', 'Screen Sharing', 'Filter Size', 'Neural Network', 'Parameters', 'Recipe Recommendation', 'Feature Maps', 'Technical Setup', 'Convolutional Neural Networks', 'Hierarchy', 'Multi-layer Perceptron', 'Cross-Correlation', 'Deep Learning', 'Convolutional Filters', 'Feature Detection'], 'topic': 'Convolutional Neural Networks', 'assessment': ObjectId('66f432e9c248cb8c5215366b'), 'interaction': [{'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about what kind of architecture could be used is not addressed.', 'relevancy': '0', 'question': 'What kind of architecture could you use?', 'timestamp': '[0:16:50]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about modifying the existing neural network was not addressed.', 'relevancy': '0', 'question': 'How would you use this information to modify the existing neural network?', 'timestamp': '[0:20:06]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about hyper parameters was not addressed.', 'relevancy': '0', 'question': 'What are the hyper parameters?', 'timestamp': '[0:25:25]'}, {'status': 'answered', 'answer': 'The technical term for shift is stride.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What is the technical term for shift?', 'timestamp': '[0:25:51]'}, {'status': 'answered', 'answer': 'Normalising the pixel values affects the neural network by ensuring that the input layer has similar scales for each input, which helps in minimizing the cost function more effectively. It leads to a smoother cost function, allowing the gradient to move more directly towards the minimum, thus speeding up the minimization process.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How does the normalisation of pixel values affect the neural network?', 'timestamp': '[0:40:30]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about what happens if we make the stride is not addressed.', 'relevancy': '0', 'question': 'What happens if we make the stride?', 'timestamp': '[1:02:42]'}, {'status': 'answered', 'answer': '930', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How many parameters does the neural network have just in this layer?', 'timestamp': '[1:09:14]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the dimensions of the next layer are not addressed.', 'relevancy': '0', 'question': 'What is going to be the dimensions of the next layer?', 'timestamp': '[1:14:20]'}, {'status': 'answered', 'answer': 'The number of parameters is discussed in the context of CNNs, with references to various calculations and comparisons, but a specific final number is not clearly stated.', 'completeness': "Incomplete, while there are discussions about parameters, a definitive answer to 'how many parameters would we have to learn?' is not provided.", 'relevancy': '1', 'question': 'How many parameters would we have to learn?', 'timestamp': '[1:11:28]'}], 'summary': "The transcript covers a comprehensive exploration of Convolutional Neural Networks (CNNs) and their applications in image analysis and deep learning. It begins with an informal setup discussion before delving into the fundamentals of CNNs, emphasizing their role in processing images, particularly in a practical application for identifying fridge ingredients and recommending recipes. The lecture highlights the versatility of CNNs beyond image tasks, touching on insect detection, plant disease identification, and natural language processing.\n\nKey topics include the architecture of CNNs, historical development from early models like the neocognitron and LeNet-5, and the importance of spatial invariance and maintaining spatial information during image processing. The discussion examines the mathematical aspects of convolution, cross-correlation, and the function of filters, which extract hierarchical features from images. It emphasizes the significance of weight sharing in reducing model parameters and improving efficiency.\n\nPooling techniques, normalization of inputs, and hyperparameter settings are explored, with a focus on filters' roles in feature extraction and the impact of stride and padding on output dimensions. The session also addresses the robustness of models to spatial variations, the calculation of parameters, and the comparison between CNNs and traditional multilayer perceptrons in terms of efficiency. The final remarks highlight the progressive complexity of features through layers and the visualization of these features, culminating in applications for image classification."}
{'_id': ObjectId('66b26ba2b80f3f3035517fc8'), 'file_id': ObjectId('659d93e0ada654fcac26ea2e'), 'file_name': 'Long video__1704825816-5efad25b42832eeca41d0e78.mp4', 'file_type': 'Video', 'file_path': 'course-resources/Long video__1704825816-5efad25b42832eeca41d0e78.mp4', 'runtime': '01:28:17', 'transcription_path': 'video-results/out_66b26ba2b80f3f3035517fc8.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 54, 355000), 'file_process_date': datetime.datetime(2024, 10, 8, 10, 14, 14, 936000), 'execution_time': 1043.138774, 'status': 'COMPLETED', 'session_id': [ObjectId('659d93e0ada654fcac26ea2e')], 'green_line': [{'topic': 'Technical Setup', 'start_time': '00:00:23', 'end_time': '00:00:56', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'keywords': ['Screen Sharing', 'Technical Setup', 'Collaboration'], 'summary': 'The transcript captures a brief interaction where one participant asks another to share their screen. There is a response confirming the action, followed by some casual conversation indicating a collaborative atmosphere. The exchange suggests a setup phase for a technical session.'}, {'topic': 'Course Introduction', 'start_time': '00:01:23', 'end_time': '00:02:40', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with me", 'keywords': ['Course Introduction', 'Convolutional Neural Networks', 'Collaboration'], 'summary': 'The course introduction begins with the speaker addressing the audience and confirming that they will start discussing convolutional neural networks (CNNs) as previously promised. The speaker also mentions the presence of a colleague, indicating a collaborative approach to the session.'}, {'topic': 'Image Analysis and Deep Learning', 'start_time': '00:02:41', 'end_time': '00:04:57', 'transcript': "and, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.", 'keywords': ['Deep Learning', 'Convolutional Neural Networks', 'Natural Language Processing'], 'summary': "The transcript discusses the application of deep learning algorithms in image analysis, highlighting the speaker's experience with convolutional neural networks (CNNs). It mentions projects related to insect and disease detection in plants, as well as work in natural language processing (NLP). The speaker aims to demonstrate that CNNs are not limited to image analysis but are also effective in handling speech data and NLP tasks, challenging the common perception that recurrent neural networks are the primary choice for these applications. The session is intended to broaden the audience's understanding of CNNs' versatility."}, {'topic': 'Applications of CNN', 'start_time': '00:03:14', 'end_time': '00:03:42', 'transcript': 'where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,', 'keywords': ['CNN', 'Image Analysis', 'Recipe Recommendation'], 'summary': 'The transcript discusses an application of convolutional neural networks (CNNs) in a practical scenario where a user can take a photograph of their fridge. The advanced image analysis developed using CNNs identifies all the ingredients present in the fridge and other kitchen cupboards. Based on this analysis, the application can then recommend recipes utilizing the identified ingredients.'}, {'topic': 'CNN Architecture and History', 'start_time': '00:04:58', 'end_time': '00:13:36', 'transcript': "sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catOkay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'keywords': ['CNN', 'Architecture', 'Backpropagation'], 'summary': 'The speaker outlines the agenda for a discussion on Convolutional Neural Networks (CNNs), starting with the motivations behind their necessity over simpler networks for image and data processing. The history of CNNs is explored, beginning from foundational studies in the 1950s by Hubble and Weasel, which influenced future research. The evolution of CNN architecture is highlighted, including significant contributions from scientists like Fukushima in the 1980s, who developed the neo-cognitron, and advancements in the 1990s with the introduction of the first successful CNN for character recognition, known as LeNet-5. The session will cover the basic building blocks, various layers of CNNs, backpropagation, and methods to enhance CNN architectures and their performance.'}, {'topic': 'Image Classification', 'start_time': '00:05:52', 'end_time': '00:09:52', 'transcript': "Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?", 'keywords': ['Image Classification', 'Spatial Invariance', 'Multi-layer Perceptron'], 'summary': "The discussion focuses on the process of image classification using a simple multi-layer perceptron to classify black and white images of digits from 0 to 9. The typical input images are sized 28 by 28 pixels, and the model can achieve high accuracy rates, around 95-98%. The speaker illustrates how a slight alteration in the inputsuch as changing the position and size of the digitscan significantly affect the model's predictions, leading to poor performance. This highlights the need for models to possess spatial invariance, allowing them to maintain accuracy despite variations in translation, rotation, and other transformations. The speaker emphasizes the importance of creating robust models that can generalize well under such conditions."}, {'topic': 'Spatial Invariance in CNN', 'start_time': '00:09:52', 'end_time': '00:20:31', 'transcript': "Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.uh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,", 'keywords': ['Spatial Invariance', 'Weight Sharing', 'Multi-Layer Perceptron'], 'summary': 'The transcript discusses the concept of spatial invariance in convolutional neural networks (CNNs). It highlights the importance of preserving spatial information when processing images, as flattening an image can lead to the loss of this critical data. The speaker illustrates this by providing examples of a dog captured from various angles and sizes. They introduce the idea of multi-layer perceptrons (MLPs) operating on small pixel neighborhoods while emphasizing the significance of weight sharing in the MLPs. This implies that the same weights are used across different sections of the image rather than introducing new weights for each area.'}, {'topic': 'Feature Hierarchy in CNN', 'start_time': '00:22:03', 'end_time': '00:23:19', 'transcript': "Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.", 'keywords': ['Feature Hierarchy', 'MLP', 'CNN'], 'summary': 'The transcript discusses the concept of feature hierarchy in convolutional neural networks (CNNs), explaining how layers of hierarchy can be constructed to learn both small and complex features from images. The speaker suggests that multiple Multi-Layer Perceptrons (MLPs) can be used for detecting different features in an image, building upon the previously learned features. The analogy of a cube is used to help visualize this hierarchical structure.'}, {'topic': 'Hyperparameters in CNN', 'start_time': '00:23:44', 'end_time': '00:26:04', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofbut we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,", 'keywords': ['Hyperparameters', 'CNN', 'Filter Size'], 'summary': 'The discussion focuses on hyperparameters in convolutional neural networks (CNNs), clarifying the difference between model parameters and hyperparameters. The speaker engages the audience by asking them to identify hyperparameters that have been discussed, such as step sizes, the number of hidden nodes, and the number of hidden layers. Other hyperparameters mentioned include filter size and the number of filters. The emphasis is on understanding these important aspects that influence the architecture and performance of CNNs.'}, {'topic': 'Feature Maps and Filter Operations', 'start_time': '00:32:22', 'end_time': '00:39:45', 'transcript': "Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresSo we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forOkay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsSo you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.", 'keywords': ['Feature Maps', 'Max Pooling', 'Filters'], 'summary': "The transcript discusses the concept of feature maps and filter operations in convolutional neural networks (CNNs). It starts by explaining how moving a box across an image generates multiple feature maps, with specific mention of using six filters to create six corresponding feature maps. The speaker introduces the term 'subsampling,' particularly focusing on the Max pooling technique, which reduces the dimensions of the feature map from 28x28 to 14x14 by taking maximum values from 2x2 samples. The architecture of a CNN is outlined, highlighting the inclusion of fully connected layers for classification into various output classes. The explanation continues with an example of a 3x3 sharpening filter and its application through element-wise multiplication to produce a single output value. The necessity of padding the input image to handle edge cases is also mentioned. Different types of filters, such as blur and Sobel filters, are introduced, emphasizing their role in feature extraction and edge detection. Overall, the session aims to clarify the terminology and operational principles of feature maps and filters in CNNs."}, {'topic': 'Convolution and Cross-Correlation', 'start_time': '00:51:43', 'end_time': '00:55:06', 'transcript': "Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottom", 'keywords': ['Convolution', 'Cross-Correlation', 'Feature Map'], 'summary': 'The transcript discusses the concepts of convolution and cross-correlation, highlighting their similarities and key differences. The speaker explains that while performing these calculations, the feature map is rotated slightly, and emphasizes that the mathematical operation being performed is actually cross-correlation, despite common misconceptions associating it with convolution. The speaker further elaborates on the methodology of cross-correlation, detailing how multiplication occurs in a specified direction with reference to a given matrix, and contrasts this with the process of convolution.'}, {'topic': 'Backpropagation in CNN', 'start_time': '00:50:50', 'end_time': '00:51:42', 'transcript': 'Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.', 'keywords': ['Backpropagation', 'Cross-Correlation', 'Filters'], 'summary': 'The discussion focuses on the mathematical representation of backpropagation in convolutional neural networks (CNNs). The speaker explains the concept of cross-correlation and how it is utilized to derive expressions for backpropagation. Examples are provided, showcasing an original image and various filters applied to it, including a sharpen filter, a blur filter, and an edge detector, illustrating the output generated from these filters.'}, {'topic': 'CNN Training and Parameter Learning', 'start_time': '00:44:01', 'end_time': '00:46:05', 'transcript': "but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.", 'keywords': ['CNN Training', 'Feature Extraction', 'Convolution'], 'summary': 'The transcript discusses the process of CNN training and parameter learning, highlighting how neural networks can automatically extract useful features from data, often beyond human comprehension. It describes the ability of the network to minimize the cost function and learn an infinite number of filters tuned for specific outcomes, like identifying digits in images. The speaker mentions a mathematical representation of this process, including terms like convolution and the use of matrices in CNNs.'}, {'topic': 'CNN Output and Classification', 'start_time': '01:24:36', 'end_time': '01:28:14', 'transcript': "right. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'keywords': ['CNN', 'Feature Maps', 'Classification'], 'summary': 'The transcript discusses the output of multiple convolution blocks in a convolutional neural network (CNN) and how these outputs can be utilized for classification tasks. Initially, the speaker explains how images are processed to extract features that enable classification, such as distinguishing between human faces and houses based on the activation of specific features. As the discussion progresses through the different layers, it is noted that the feature maps evolve from recognizing basic elements like skin and edges to more abstract representations like facial features. The speaker emphasizes that the goal is to classify images rather than identify specific individuals, demonstrating how the final output layer highlights various activated features that correspond to the categories being classified. The session concludes with an invitation for questions and a mention of the next steps in learning about CNNs.'}], 'yellow_line': [{'Topic': 'Technical Setup', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'start_time': '00:00:23', 'end_time': '00:00:56'}, {'Topic': 'Course Introduction', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with me", 'start_time': '00:01:23', 'end_time': '00:02:40'}, {'Topic': 'Image Analysis and Deep Learning', 'transcript': "and, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.", 'start_time': '00:02:41', 'end_time': '00:04:57'}, {'Topic': 'Applications of CNN', 'transcript': 'where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,', 'start_time': '00:03:14', 'end_time': '00:03:42'}, {'Topic': 'CNN Architecture and History', 'transcript': "sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catOkay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'start_time': '00:04:58', 'end_time': '00:13:36'}, {'Topic': 'Image Classification', 'transcript': "Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?", 'start_time': '00:05:52', 'end_time': '00:09:52'}, {'Topic': 'Spatial Invariance in CNN', 'transcript': "Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.uh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,", 'start_time': '00:09:52', 'end_time': '00:20:31'}, {'Topic': 'Feature Hierarchy in CNN', 'transcript': "Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.", 'start_time': '00:22:03', 'end_time': '00:23:19'}, {'Topic': 'Hyperparameters in CNN', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofbut we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,", 'start_time': '00:23:44', 'end_time': '00:26:04'}, {'Topic': 'Feature Maps and Filter Operations', 'transcript': "Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresSo we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forOkay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsSo you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.", 'start_time': '00:32:22', 'end_time': '00:39:45'}, {'Topic': 'Convolution and Cross-Correlation', 'transcript': "Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottom", 'start_time': '00:51:43', 'end_time': '00:55:06'}, {'Topic': 'Backpropagation in CNN', 'transcript': 'Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.', 'start_time': '00:50:50', 'end_time': '00:51:42'}, {'Topic': 'CNN Training and Parameter Learning', 'transcript': "but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.", 'start_time': '00:44:01', 'end_time': '00:46:05'}, {'Topic': 'CNN Output and Classification', 'transcript': "right. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'start_time': '01:24:36', 'end_time': '01:28:14'}], 'assessment': ObjectId('66f46ac1c248cb8c5215424d'), 'job_name': 'my-transcription-job6e27fa63-9292-4b80-95a7-3505e0aa6029', 'interaction': [{'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about what kind of architecture could be used is not addressed.', 'relevancy': '0', 'question': 'What kind of architecture could you use?', 'timestamp': '[0:16:50]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question about modifying the existing neural network was not addressed.', 'relevancy': '0', 'question': 'How would you use this information to modify the existing neural network?', 'timestamp': '[0:16:50]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about hyper parameters was not addressed.', 'relevancy': '0', 'question': 'What are the hyper parameters?', 'timestamp': '[0:25:25]'}, {'status': 'answered', 'answer': 'The technical term for shift is stride.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What is the technical term for shift?', 'timestamp': '[0:25:51]'}, {'status': 'answered', 'answer': 'Normalising the pixel values affects the neural network by ensuring that the input layer has similar scales for each input, which helps in minimizing the cost function more effectively. It leads to a more rounded cost function, allowing the gradient to move more directly towards the minimum, thus speeding up the minimization process.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How does the normalisation of pixel values affect the neural network?', 'timestamp': '[0:40:30]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about the stride was not addressed.', 'relevancy': '0', 'question': 'What happens if we make the stride?', 'timestamp': '[1:02:11]'}, {'status': 'answered', 'answer': '930', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How many parameters does the neural network have just in this layer?', 'timestamp': '[1:09:14]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about the size of the image that comes out on the other side was not directly answered.', 'relevancy': '0', 'question': 'What is going to be the size of the image that comes out on the other side?', 'timestamp': '[1:00:06]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about the shape of the filter is not addressed.', 'relevancy': '0', 'question': 'What will be the shape of the filter?', 'timestamp': '[1:15:33]'}], 'yellow_line_aws': [{'Topic': 'Convolutional Neural Networks (CNNs)', 'transcript': "Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,", 'start_time': '00:00:23', 'end_time': '00:09:31'}, {'Topic': 'Image Processing', 'transcript': "Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.", 'start_time': '00:00:23', 'end_time': '00:10:16'}, {'Topic': 'Neural Network Architecture', 'transcript': "And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,", 'start_time': '00:05:41', 'end_time': '00:09:04'}, {'Topic': 'Deep Learning', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meTo assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.", 'start_time': '00:01:23', 'end_time': '00:10:16'}, {'Topic': 'Feature Extraction', 'transcript': "where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,", 'start_time': '00:03:14', 'end_time': '00:09:04'}, {'Topic': 'CNN Layers', 'transcript': "sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,", 'start_time': '00:04:58', 'end_time': '00:09:04'}, {'Topic': 'CNN Architecture', 'transcript': "And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,", 'start_time': '00:05:41', 'end_time': '00:09:04'}, {'Topic': 'Image Classification', 'transcript': "where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,", 'start_time': '00:03:14', 'end_time': '00:09:04'}], 'yellow_line_aws_2': [{'Topic': 'Neural Network Architecture', 'transcript': "Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's andThen we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. Soone question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uhuh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the questionwho asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.Okay, so you just, uh, scan. So these are the hair are different. New MLPs here. So this this MLP has, uh, one set of age. This is a new MLP. Here we are, scanning through it, okay. And then we have the final classification will happen. And so now we have sequentially added layers in one direction. We could also add, uh, complexity in the depth of it.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.right. And so, finally, you just can't get it. All of the features and you have a final classification.So this is how the idea of hair are key is taken into account from that horrible and visual experiment that we just build upon small features of the offer input and use those to classify, uh, actual image.Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimensionis three. So it's a M by n by three or the image that is a colour image which has got the red, green and blue.channels. right. So one way of visualising this you've got an image of some size. You are reducing the size of the image by doing the scanningright. And with every feature that you're creating is like another channel. Right? So we went from RGB Channel to another description of the same data which has a smaller X and Y axis as such of the image. But it has a depth to it, which is the number of features that have been extracted. Right. And this is a very common feature that you will see when you book shows you the more complicated structures of a CNN.You'll find that you start off with a large image with three channels and you end up with very small images, but with lots of features, lots of channels with it.Right. So this is a very, very important thing to remember when you're doing CNN's, because later on, you will see some very interesting uses of the same philtre to reduce dimensionality.Okay, so do you understand all of these concepts? the shift size. you can see that the boxes are overlapping over each other, right? And so you can have a shiftof one pixel or two pixels or whatever. So that becomes a hyper parameter. Like you said, the philtre size definitely the size of the box, the number of philtres at each layer that you're definingright, and the number of such hidden layers that are transforming the input into a smaller, more compact representation.Right is another type of parameters. So very good. And what is the shift called? What is the technical term for shift?stride. Okay, great. Excellent. Okay. Good luck. Any questions on this before it goes on? Because things will only get more complex as we go on.Okay, Wonderful. Okay, So this is the example of, uh, typical Syrian architecture. This is called the Leonard five, which was developed by young liquid.Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresThen you will have six feature maps for each philtre because one feature because one philtre will scan the entire image.So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.okay? Okay, So there was one thing I want to visualise here. Yeah, so? So this is a typical grayscale image. So this is the original image you can see here. And this is just a zoom in version, so you can see that every pixel has a value from 0 to 2. 56 to 55. Sorry.So you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,uh, let's take something near the so you can see here. Uh, the left, the left, and the first element in this, uh,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.So, uh, we've got an answer. Which is minus 157. Yes. Uh, be clipped to zero. It will be close to zero.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.Okay, so there is another example of this image. So this is the original image. Okay, Now, if I apply, sharpen, uh around it, you can see it's got a bit sharp.And if you you stop symbol on it, it detects, uh, like horizontal edges. If I apply right Sobel, it detects vertical edges so on and so forth.is this clear? Yes, sir. Okay. so these weights are okay, So, uh, which no one is asking a question here. Uh, how? Well, normalising the pixel values affect the neural network.Um, so we should make sure you don't send it privately because those questions come to me, Uh, is not able to see it, but I've explained this, right? So when you talk about normalising the pixel values, what are you referring to? What you're talking about theapplication of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.Uh, so let's say for, uh, I'll take an example of this portion of this image. I'm just, uh, mathematically describing what we have just discussed. Okay,so here we are going from minus Kate. Okay, for let's say, let's say this philtre will have zero in the centre zeroth index.instead of beginning from any side, we begin from the centre. So this has, uh, zero comma zero. Uh, Index, this has, uh,minus one comma one. I could have minus one for my one. This is my new school, Uh this is minus one common minus one just to be clear.And this is, uh, one comma one. And this is one common minus one. So basically, we are saying that the loop power fromminus 1 to 1 in case of a three dimensional feature or philtre so for, Let's say. four g three or three. So Okay,the left corner will be minus 11. the corner with bottom, Yeah. mhm. uh, one here because we are going from, uh, which is, uh,so So, uh, this is the X one. And this is why? right. So, uh, but the other way around. Right. So why is pointing downwards?Yeah. So the coordinator, there will be a minus 11, left bottom. X is minus right the X coordinate ofminus one. uh this should be minus 11. okay, so Okay, So, uh, idea here is So let's say we have this original image, and we want to, uh, slide this fritter across this entire image. And I want to have an output G, which is my feature map. You could sayokay. So what I'm gonna do here is, um So starting with U N. Vehicle to minus one here in this submission,you equal to minus one and equal to minus one. So I will take the minus one minus 11 element of this, uh, this edge metrics, which is the A.Okay. And, uh, I plus Youth Index. So I am calculating for G three of three. So this is +0123 and again. 0123. So this is my G three comma three.Okay. So if I take, uh, take this philtre and, uh, make the cost cross correlation, I will have a single value, which will be substituted in the place of E here.Right. So what I'm looking here is that, uh, eyes here three and us minus one. And Jay is also three.This is the icon DJ and J minus one. So I'm looking at second element here. So for her 01 to zero. we want. So to buy second by second element is this so I'm multiplying, uh, small a from the philtre with this matrix A herewith a element of these, uh, metrics. and similarly, I'm just looping over. So being small capital B plus small capital C includes. So this way, this time calculating the, uh, waited waited some hereand this will be a single output, which will be replaced here in my future map. Uh, so let's see if I have this. This is my G output. So in place of E here, I will have one single value, which will be the output of this entire operation.Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottomto the top. Okay. So because the future has rotated and just changing the sign here, uh, will assist in that happening, soOkay, Uh, you can just explore this on your own later on. If you just try to write these expressions down and you will be able to figure out that we're just recreating the philtreand doing the cross correlation, okay? Okay, so So till now we discuss these handcrafted philtres like the blur sharpen, agitation, etcetera. But these are the things which the model learns as just described. So what we're gonna do is we're gonna visualise these features for the religion. It Okay, Uh, so let me first explain that how these, uhhow these architectures look like. Okay, so, uh, the input here is, uh, before we go into the architecture, can we just, uh, do a little bit of discussion around how the philtre size impact, the output image size, But is that coming after this?Yes. I was just trying to bring Troy. I don't have, uh Okay. Okay. So let's say religion yet We use colour images, so let's say it will be a three dimensional image.And let's say it is 2. 56 by 2. 56 with three channels of input. Okay, so now we want to, uh, involved used 32 philtres here.Okay of dimensions, Uh, three by three. Okay, So this is how you generally defining your chaos or you're open source, uh, libraries, but under the hood. Uh, what is happening is that each philtre will have dimensionsthree by three. And this three, the depth is coming from the input. because the input image has three channels as death. So you're each philtre will also have a depth of three. Okay, so what we do here is that we take small, uh,crop of size three by three hair from this bigger image. three by three by three And we just, uh, do an element wise multiplication of all these elements in this cubewith this philtre. Okay, So if there are, let's say, uh, three numbers here and three numbers in the first, uh, slice. Then you just, uh, do the cross correlation, and there would be one output.Okay. And you do same for all the layers. So for second slice here also, okay, and output of this result would be single number.this is very important to note. Okay, so after conclusion where there will be one value here. So you do this for across entire this image. So you have access right of one.so let's let's leave it to them to come up with the answer. Okay, So with the stride of one pixel means that you're shifting by one pixel to the right all the way till you get to the end of the image, right? So recognise that you get to the end of the image when the right side of your philtre reaches the edge. Okay, so there's no paddingfor those of you know what padding is. There's no padding. For those of you who don't know about padding, just don't worry about it. Just tell us what is going to be the size of the image that comes out on the other side when we do the scanning. Now the stride works left to rightand talk to bottom. right. So as you scan across, you're going one pixel at a time and going to the next position where the philtre is applied. And then when you get to the end, you shift the philtre down by one,uh, pixel and apply it again. Correct? Yes, sir. Okay. So what is going to be the size of the image that is coming out on the other end? Or the the two dimensional array that's coming out at the end? Because remember what is sayingthat the three by three by three is producing only one number, so the multilayered Perceptron is taking27 inputs and is out putting one value. Okay, So what you're getting as a result of applying this philtre is a two dimensionalmatrix of numbers, and I want to know the dimensionality of that. 54. other ways, okay? there were two people speaking. So one person said to 54.And what was the other person saying? I think, uh, zero comma zero is concerned at the centre, and, uh, the other things are taken at that size in the same way you look at work,right? So, like I said, the we are resuming zero padding go padding right now. Right? So your philtre starts from the edge and takes the first three into account.right, and then it moves by one and moves by one. Right? So the size is going to be there. One answer that's been given us 254.Is that the number of rows or the number of columns, or what is to 54? I think both. Okay, Anybody else have a different answer?no sort of 54 and 54 in total Tito. in 2. 32. Okay, 32 because we've got 32 philtres. Good. Okay. I have been looking for one philtre with Excellent. Okay, so 254 by 2. 50 for 5. 32 will be the third dimension.Uh, just for this philtre Yes, output will be just a matrix. Uh, considering for just one philtre, this is just one,Uh, that's correct that we will have 32 such philtres. So for each of that philtre, we will have one,to the output. Yes. Yes. And then that will build up to 30 to do that. Yeah. Perfect. Perfect. Okay, So what happens now if we make the stride?Ooh! Okay, so now let's make the strive to what becomes the output size now? Does the output size change?instead. How much does it change? Uh, third dimension in the same 1. 27 1 27 127. So how did you come up with 1. 27?sir. And if you take in putting measures in and the philtres. I just Yes. And we We are taking a straight to that isminus Yes. And we are adding one to the and mine the eff s blossom. Okay. Do you want to write the formula they're given? You've got access toYes, Uh, like the formula, which, uh Okay, can you please repeat and I say important measure that is 256 in 2016 and a filtered site.and at that stage. the farm law of the output. The message will be and minus f s plus one. listen. so that would be a 56 minus.three dots. Bye. HM. That doesn't seems correct. It's two less 127. So now you've got 253 divided by two, right?So what happens? We've got a decimal number there. So I have that too. From the looks. you will take in digital partnership.If we have fraction, then we protect right? so Yeah. So that is the same formula. Uh, only were riding fighting out here. Right? Fighting is zero w minus scale over this. That's whywhich is fine. And then what you're saying is we are taking the interior part. So are we rounding up or are we rounding down?so if there is greater than five, then we are all being up. but now it's point. What do we do? I think running, don't you?Okay, so let's just take a small example of, uh, seven by seven image, right? and what is happening here when we are not doing a padding, So the first one is three by three.the philtre application. And then we're taking a stride of two, which means now we're starting from pixel, too.23. And, uh, so we're starting the numbering from zero. Right, So 0 to 6 is the pixel numbering. Okay,Right. And now we're doing a three by three. right. So the three by three the first philtre, then we're taking a stride of two.so we start from now 23 and four. And now we take another stride of two, which gives us now. four, five and six.right. So in this case, if we look at the formula, what's happening is N is seven minus three. great.stride is too so seven minus 3/2. which is three, right? So that's 4/2. That's 13, so we can see we have created three. Now the problem comes when we have an eight by eight image, right? And now we have an issue in that if we had another pixels in rows and columns.we basically not be able to do any further, right? So if we had an eight by eight image, if you can just draw that additional problem and go.Now, when we go for the stride of two, we are going over the edge, so we can't do anymore, right? So we are always looking at the number below, as the output were basically ignoring the that last follow. And that last room. Right? So we will always take the lower number out here.right. okay? So now my question is, how many parameters does the neural network have just in this layer?So who's gonna tell me that now? How many parameters? Now we've got 32 philtres. We've got a three by three philtres,right? And an RGB image. How many parameters do we need to learn in this? one pair of lives. who's gonna tell us?930 two. Sorry. nine by 30 to 1930 to 19 to 19 to 32. Okay. Any other answers? 20 7 to 32. Okay. Any other answers?thanks. Nobody else wants to suggest the answer. 20 730 to 30 two. Correct. So the reason why it's 27 by 32 and not nine by 32 it would be nine by 32 if we had a.grayscale image, right? We didn't have the channel. So you must always remember that we have got a three dimensional Fridawhere the third dimensions depth is defined by the number of input channels to that live. Okay, good. Now, what would be the number of parameters that needs to be learned? If we were not using CNN,we were actually using a multilayered percent promise. that depends on the number of notes hidden next to them. Iwant the same number of notes as I have in the hidden layer in the CNN. So how many notes do I have in the hidden layer in the CNN?trick questions. mhm. 56. Close to 56. Crusty. That is my input layer. Right? So that's 2. 56 times 2, 56 times three.that's the input Lear sites. what it was before. Before 254 by 254. right. by 32 right, and how many parameters would we have to learn?uh, we have to do, like the four 130 two cross, uh, test is too extreme. right. So we're basically multiplying all of these, right? Because every note in the input layer must be connected to every note and the output.right, So it's 256 squared, multiplied by three. multiplied by 254 squared, multiplied by 32. right. which one is big?There's no argument, right? I mean, we are comparing a very large number of parameters here with just 27 multiplied by 32.right, and this is a huge advantage of CNN. It's the weird. sharing with sharing. That's happening. That is a hugely important aspect.Oh, CNN. Okay, so you appreciate that. And what have we talked about that as the number of parameters increases, what do we need to do? We need a lot more data to learn them.right. And so we are actually talking about unnecessarily learning a lot of weights. Whereas we know that really what we're looking for is a scan through theright. So hopefully this is clear to you that actually the CNN can be represented as a multi layer perceptron also. So the multi layer Perceptron can do the work of the CNN as we see it right now, but the number of parameters is going to be much larger.okay, and so it's much more difficult to learn the same representation comparative. Okay, so here's another question.Now we have a 54 by 2. 54 by 32. right, and we are again using. Now we are using a five by five philtres.So what is going to be the dimensions of the next left? 54 by 254. by 32. right. So now we're using a five by five philtre.how many such features, let's say 64. such tried stride of, mm. 124 into 1, 24 and 60 for the lesson.Mm. for 254. find us. five, divided by two plus one. so that's 249 divided by two. 1 24 +11 25 1 25 by 125 by 64.how many parameters. and what will be the shape of the philtre? you tell me. Uh, sorry. Was that good book?Uh, that's part of the number 64. 55 or 60. Uh, And so we got an answer here for the number of parameters, I think.Okay, 25 by 64. So he said it could be what we do here. pretty good. so one person's answer is 25 by 64.Don't you find it that you don't look beautiful? 25 and 32. That's right. Okay. And so they will be. Bias is also right. Yes.good point. Thank you for keeping us right there. So in the last one, also, we forgot about the biases thatso remember the bias stone is important, right? What does the bias give us gives us? It gives us a fine transformation.Right? So we must have that constant added and also so, plus 64 there and we've got the total number of parameters yet.Okay, Good. Excellent. Okay. Uh, let's, uh, move on. I think hopefully everybody's got anybody. Got a question here? I know there are a few of you who have dealt with CNN's and done some deep learning. That does not mean that people who are not understanding this can't ask questions.Okay, So for those of you who are new to this, this is very, very important that you understand this. Okay, here's another. Okay, Let's go. There is another question I want to ask you, okay?which is the number of computations you're doing. so floating point operations, floating point operations do you need to do here? But I believe that as an exercise for you, let's carry on.okay? Okay, So next, uh, was trying to visualise these features. So? So what we have here is so he worked with it was that we took an RGB image.and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'start_time': '00:00:23', 'end_time': '01:28:14'}, {'Topic': 'Image Processing', 'transcript': "okay? Okay, So there was one thing I want to visualise here. Yeah, so? So this is a typical grayscale image. So this is the original image you can see here. And this is just a zoom in version, so you can see that every pixel has a value from 0 to 2. 56 to 55. Sorry.So you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,uh, let's take something near the so you can see here. Uh, the left, the left, and the first element in this, uh,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.So, uh, we've got an answer. Which is minus 157. Yes. Uh, be clipped to zero. It will be close to zero.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.", 'start_time': '00:35:17', 'end_time': '00:38:39'}, {'Topic': 'Convolution and Cross Correlation', 'transcript': "Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottomto the top. Okay. So because the future has rotated and just changing the sign here, uh, will assist in that happening, soOkay, Uh, you can just explore this on your own later on. If you just try to write these expressions down and you will be able to figure out that we're just recreating the philtre", 'start_time': '00:51:43', 'end_time': '00:55:29'}, {'Topic': 'Hyperparameters', 'transcript': "Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regressionwhere we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimensionis three. So it's a M by n by three or the image that is a colour image which has got the red, green and blue.channels. right. So one way of visualising this you've got an image of some size. You are reducing the size of the image by doing the scanningright. And with every feature that you're creating is like another channel. Right? So we went from RGB Channel to another description of the same data which has a smaller X and Y axis as such of the image. But it has a depth to it, which is the number of features that have been extracted. Right. And this is a very common feature that you will see when you book shows you the more complicated structures of a CNN.You'll find that you start off with a large image with three channels and you end up with very small images, but with lots of features, lots of channels with it.Right. So this is a very, very important thing to remember when you're doing CNN's, because later on, you will see some very interesting uses of the same philtre to reduce dimensionality.Okay, so do you understand all of these concepts? the shift size. you can see that the boxes are overlapping over each other, right? And so you can have a shiftof one pixel or two pixels or whatever. So that becomes a hyper parameter. Like you said, the philtre size definitely the size of the box, the number of philtres at each layer that you're definingright, and the number of such hidden layers that are transforming the input into a smaller, more compact representation.Right is another type of parameters. So very good. And what is the shift called? What is the technical term for shift?stride. Okay, great. Excellent. Okay. Good luck. Any questions on this before it goes on? Because things will only get more complex as we go on.", 'start_time': '00:23:44', 'end_time': '00:32:05'}], 'keywords': ['Feature Maps', 'Image Classification', 'Backpropagation', 'Cross-Correlation', 'Spatial Invariance', 'Feature Map', 'Collaboration', 'Weight Sharing', 'Natural Language Processing', 'Filter Size', 'CNN', 'Multi-Layer Perceptron', 'Architecture', 'MLP', 'Hyperparameters', 'Filters', 'Deep Learning', 'Convolutional Neural Networks', 'Convolution', 'Feature Extraction', 'Screen Sharing', 'Multi-layer Perceptron', 'Technical Setup', 'Image Analysis', 'Course Introduction', 'CNN Training', 'Feature Hierarchy', 'Max Pooling', 'Classification', 'Recipe Recommendation'], 'topic': 'Convolutional Neural Networks', 'summary': 'The transcript outlines a session focused on Convolutional Neural Networks (CNNs) and their applications in image analysis and natural language processing (NLP). It discusses the collaborative setup for a technical session, emphasizing the versatility of CNNs beyond image tasks. Key topics include the history and evolution of CNN architectures, starting from foundational studies in the 1950s to significant advancements like LeNet-5 in the 1990s. The session covers the basic building blocks of CNNs, including various layers, backpropagation, and performance enhancement methods. A practical example illustrates how CNNs can analyze images of fridge contents to recommend recipes. The importance of spatial invariance is highlighted, showing how models can maintain accuracy despite variations in input. The transcript explains feature hierarchy, hyperparameters, feature maps, and filter operations, including subsampling techniques like Max pooling. The similarities and differences between convolution and cross-correlation are discussed, alongside the training process and parameter learning in CNNs, which enable automatic feature extraction. Finally, the session addresses how feature maps evolve through layers to support classification tasks, concluding with an invitation for audience questions.', 'pinecone': True}
{'_id': ObjectId('66b26b74b80f3f3035517f63'), 'file_id': ObjectId('641bd6b3a053a968d797f90c'), 'file_name': '1678339456-62fcaa4ea2bc0b6439d2306a__1679546030-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/1678339456-62fcaa4ea2bc0b6439d2306a__1679546030-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '01:37:00', 'transcription_path': 'video-results/out_66b26b74b80f3f3035517f63.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 8, 935000), 'file_process_date': datetime.datetime(2024, 9, 25, 18, 30, 50, 248000), 'execution_time': 902.711414, 'status': 'COMPLETED', 'green_line': [{'topic': 'Transportation Infrastructure', 'start_time': '00:00:14', 'end_time': '00:01:32', 'transcript': "Hi. Good morning, everyone. My name is nectar and as we all know, that transportation it as an important indicator which measures the economic and commercial progress of a country road ways. They are an important mood of transportations. Roads are indeed the backbone of transportation as the connect people and goods from one location to another.Therefore, having better maps, routes can improve the efficiency and convenience of transportation. How, since better map roots, they can help person saving time In Hume, Better map roots can help drivers find the shortest and the most efficient routes to their destinations,reducing the traffic congestion. We can know about the busy roads in advance, and we can divert the traffics hence overall, having a better map. Roots can improve the efficiency and convenience of transportation, reduced travel times and fuel consumption's, enhance public transportation, improve safety and enhanced accessibility.Therefore, D maps the play an important role in understanding the road network and navigating through it. Henceforth, good maps are essential for understanding the door network and navigating through the roads.", 'keywords': ['Transportation Infrastructure', 'Roadways', 'Mapping'], 'summary': "The speaker, Nectar, begins by highlighting the critical role of transportation infrastructure as an indicator of a country's economic progress. Emphasizing the importance of roadways, they describe roads as the backbone of transportation that connects people and goods. The discussion focuses on the significance of better maps and routes in improving transportation efficiency and convenience, helping drivers save time, reduce traffic congestion, and enhance overall travel experiences. The speaker outlines how better mapping can lead to reduced travel times and fuel consumption while improving public transportation, safety, and accessibility, ultimately underscoring the essential role that quality maps play in understanding and navigating road networks."}, {'topic': 'Map Efficiency and Features', 'start_time': '00:01:33', 'end_time': '00:02:44', 'transcript': 'So we may be wondering, why are we talking about roads and maps? Because that is what our passin project is all about. Hi. Welcome to Passion Project Road Seen Analysis presentation. This is the objective of this presentation is to have a better quality of match.and to be able to navigate easily since the roads and India, they are poor and have poor infrastructure. So we will be focusing on better objective on bettering the quality of maths next flight least.next light. so let us know. Discuss what kind of features will be extracting and how will be re achieving our objective.road leader. Extraction from satellite is very important for a variety of applications, such as for urban planning, transportation management and disaster response. If we know what kind of features are being extracted from satellite using the image processing techniques, we can know better how to improve our quality of images. But latest first discuss what kind of features we are extracting. So', 'keywords': ['Satellite Imagery', 'Image Processing', 'Road Feature Extraction'], 'summary': 'The presentation focuses on the importance of roads and maps within the context of a passion project aimed at improving map quality and navigation in India, where infrastructure is lacking. The speaker emphasizes the need for better mapping objectives and discusses the extraction of road features from satellite imagery. This data is crucial for various applications, including urban planning, transportation management, and disaster response. The speaker highlights how understanding the features extracted through image processing techniques can lead to enhancements in image quality.'}, {'topic': 'Satellite Image Feature Extraction', 'start_time': '00:02:44', 'end_time': '00:05:21', 'transcript': 'these are the following features that are satellite provides the road centerline. A road centre line is an imaginary line that runs down the centre of a road or the street. It is considered as the made a point of the road and is used as a reference line for navigation, road design and other purposes. Road with How can Be Major a Road withwe can measure the road, wait by using the edge detection algorithms and then measuring the distances between them. Lane markings. Lane markings are such solid and dash lines and can also be extracted from the satellite images. Road surface types. They determined the condition of the road surface, such as portholes, cracks and other death. TEX This can be in whosefor road maintenance focuses road intersections. Their intersection between the roads can be by identifying the points where two roads meet road direction. The direction can be better mind by analysing the orientation of the road centerline road curvature. The curvature of the road can be calculated by analysing the shape of the road centre lineroad network. The entire road network in an area can be extracted by identifying all the road centre lines and connecting them to perform a network.These features and be used for various applications such as urban planning, traffic management and road safety analysis. Branson Jinyan knows how the work on the feature extraction the next flight. We are going to discuss about what kind of problems are there. While we are trying to extract the features. Next light, pleaseThese are the problems that are faced while we are trying to track images from the satellite, the first Ingles resolution. Now we all know what resolution is a resolution there first to the level of the mail that can be seen in any image, which is typically measured in metres per fixed.So higher resolution image can provide more detailed information about the roads, such as the presence of the lane markings, signs and other important features.Conversely, a lower resolution images may not be enough to provide accurate the tails and extract all the road features and maybe less accurate. So the extraction of images using the resolution is always a trade off between accuracy and cost', 'keywords': ['Satellite Images', 'Feature Extraction', 'Image Resolution'], 'summary': 'The transcript discusses various features that satellite images can provide for road analysis. It explains the concept of a road centerline, which serves as a reference for navigation and road design. The extraction of lane markings, road surface types, road intersections, road direction, road curvature, and the overall road network is highlighted as essential for applications in urban planning, traffic management, and road safety analysis. The speaker also addresses challenges in feature extraction from satellite images, particularly focusing on the impact of image resolution on the accuracy of the extracted details, noting that higher resolution images yield more precise information while lower resolutions may compromise detail.'}, {'topic': 'Challenges in Satellite Imaging', 'start_time': '00:05:21', 'end_time': '00:07:10', 'transcript': "occlusion occlusion. It refers to when the objects such as building or trees or vehicles the partially or completely obstruct the view of the roads and the satellite images. This makes it difficult to extract accurate information about the gold features, such as it's with curvature and other important details.Lightning conditions. The lightning conditions at the time the image was captured can highly affect the quality and the clarity of the image, which in turn can affect the accuracy of feature extraction process. For example, they major star you captured during the low light conditions such as at dusk or dawn TV darker and may have more Sha Jews, which can make it difficult to distinguish the roads from surrounding objects.Conversely, the images captured during bribed the light conditions maybe more. Blair and which can make it difficult to accurately extract road featuresvariability. It refers to the natural variations that occurring. The physical environment, such as changes and weather's seasons and vegetation is, for example, during the winter seasons, our roads may be covered with snow and alleys, making it difficult to extractor road road features activating. Similarly, during the rainy season, the roads may be covered with water making, with distinguish making a difficult to be able to distinguish between the water body and the roots.The next problem that we face is the noise satellite A majors. They can be affected by noise such as atmospheric interference and censor noise, which can reduce the quality of the image and making it more district cult to accurately identify road features. Next, Lighty", 'keywords': ['Satellite Imaging', 'Occlusion', 'Noise'], 'summary': 'The transcript discusses various challenges faced in satellite imaging, particularly focusing on occlusion, lighting conditions, variability, and noise. Occlusion occurs when objects like buildings, trees, or vehicles obstruct the view of roads, complicating the extraction of accurate information. Lighting conditions at the time of image capture can significantly impact clarity and quality, with low light leading to difficulties in distinguishing roads. Variability refers to natural environmental changes, such as seasonal effects like snow or rain, which can obscure road features. Additionally, noise from atmospheric interference and sensor issues can further degrade image quality, making feature identification more challenging.'}, {'topic': 'Road Infrastructure Issues', 'start_time': '00:07:12', 'end_time': '00:07:59', 'transcript': 'my way or highway. What does this mean? This just means that all Indian roads we have a poor infrastructures. We are. When we are driving, it is difficult to analyse that. Are we going to move onto a highway or we have to take some others neat.So the poor road infrastructures can lead to damage and declaration of roads, which can make them more difficult to identify and satellite images. For example, portholes, cracks and other form of the damages can fill it a visual noise and the satellite images, making it difficult to be able to get futures accurately so we can improve the quality of the features extracted from the satellite images that will be explained in the later slides by Mafia Dupin.', 'keywords': ['Road Infrastructure', 'Satellite Images', 'Feature Extraction'], 'summary': 'The discussion addresses the poor state of road infrastructure in India, highlighting the challenges faced when driving and the difficulties in analyzing road conditions for maintenance. It explains how damaged roads, such as those with potholes and cracks, create visual noise in satellite images, complicating the extraction of accurate features. The speaker mentions that further improvements in feature extraction from satellite images will be covered in later slides.'}, {'topic': 'Image Enhancement Techniques', 'start_time': '00:08:03', 'end_time': '00:10:22', 'transcript': 'thank you. So here some techniques that can enhance the details of the road network and make it easy to identify road features. So we have an image enhancement sharpening, immediate fuse. Um, object detection and roll placer. And your reference,Um, and next time. so image enhancement. This is the process of improving the quality of image captured by satellite techniques can be improved. The overall quality and visual quality of a satellite image in a road scene. Analysts. It is important to be able to identify road features. Clearly image so contents and houseman techniques can be used to enhance the details of the road network and make it easier to identify these features.So we have a history. Graham Equalisation is a technique used to improve the contests of image by redistributing the pixel intensity in a way that utilised the full range of values available in the image. Dis techniques can help to bring out more details in the road network, and making it is gives you to identify road featuresnext time. so second techniques is a shopping. This is a technique for enhancing the edge and details in the image, making it appear very clearly and mortifying. This can be very useful for identify objects and feature on the roads such as al Blaine markings and traffic signs. So here we can use a low pass philtre and bypass philtre. Lupus Philtre is the type of frequency to main kilter that is used for smoothing the imageand hyper spent is a diaper for frequency two men philtre that is used for sharpening the image backslide.so we have image fusion, so these techniques can be used to combine satellite images with other sources, such as a road maps and GPS data. So image prisoner method creates a high resolution image for more detail monetary. So this can help to improve the overall accuracy of a road feature extraction and provide additional context for the our satellite emission.', 'keywords': ['Image Enhancement', 'Histogram Equalization', 'Image Fusion'], 'summary': 'The transcript discusses various image enhancement techniques aimed at improving the details of road networks for better feature identification. It highlights several methods including sharpening, image fusion, object detection, and histogram equalization. Histogram equalization is described as a technique that redistributes pixel intensity to enhance contrast, making road features more discernible. Sharpening techniques enhance edges and details, which aid in recognizing road markings and traffic signs. The use of low-pass and high-pass filters is mentioned, with low-pass filters smoothing images and high-pass filters sharpening them. Additionally, image fusion techniques combine satellite images with other data sources like road maps and GPS for higher resolution and accuracy in road feature extraction.'}, {'topic': 'Object Detection in Imaging', 'start_time': '00:10:23', 'end_time': '00:11:25', 'transcript': 'next, right? so object detection. So object detection algorithms have proven to be our efficient in automatically identify road features such as a road centre, live lane marking and road intersection in satellite image. Using a deep learning algorithms can be trained on a larger sets on a satellite imaginary and allow them to learn and improve their accuracy by over time.So doing so that they can efficiently automate the process of a vote future extraction and saving double time and improve efficiencynext. so we have a road Taser sore. Otis is designed to automatically expect the map road networks from high resolution aerial imagery. The roadways algorithm use our conversion. CNN algorithms to analyse identified groups said the algorithm clears a vector map that can be used for a directive for purpose improving GPS navigation, mapping Aaron development and helping to plan and new road in construction.', 'keywords': ['Object Detection', 'Deep Learning', 'CNN'], 'summary': 'The transcript discusses the advancements in object detection algorithms, particularly their efficiency in automatically identifying road features like road centers, lane markings, and intersections from satellite imagery. It highlights the use of deep learning algorithms trained on extensive satellite image datasets, which enhances their accuracy over time. The speaker introduces a specific tool, the Road Taser, which utilizes CNN algorithms to extract and analyze road networks from high-resolution aerial images. This tool creates vector maps that can aid in GPS navigation, urban planning, and road construction projects.'}, {'topic': 'Geolocation and Reference', 'start_time': '00:11:26', 'end_time': '00:12:08', 'transcript': 'so next light. Sergio referencing when working the image that, like location information, it is our responsibility to assign a location to them. The process is commonly referred zero fencing, which involves the use of a mathematical procedure to determine the location of the image. So zero fencing can be done manually or automatically, and involves referencing the image to known locations and set of coordinates.So once the references completing the image will be contained, all the necessary location informations along it to be accurately placed on the map.', 'keywords': ['Geolocation', 'Zero Fencing', 'Image Referencing'], 'summary': 'The discussion focuses on the importance of geolocation and reference in the context of images. The speaker explains the process of zero fencing, which involves assigning location information to images using a mathematical procedure. This can be carried out either manually or automatically by referencing the image to known locations and coordinates. Once the referencing is complete, the image will contain all necessary location information, allowing it to be accurately placed on a map.'}, {'topic': 'Remote Sensing Overview', 'start_time': '00:12:35', 'end_time': '00:15:31', 'transcript': "you in our no project, we are basically held from the satellite for finding very good and accurate image. So first of all, we're we are trying to understand working satellites. The satellite is nothing, Burton of that. They floated around the orbit of bigger, objective and satellite are the object. The Earth, sun and most of the collateral bodies and the satellites aremedical into two parts in first of first days, natural at light, antagonistic man made satellites. and B m move from next night. imagesthe state like we made it. It's one of the most powerful and important to will be have for monitoring our earth. And we are tracking their physical environments like water, air, land and vegetation and changing human strengths. A first the Globe.next like and there are some types of satellites, such as national satellite and artificial satellites, and in our individual side, light it is it can. in the few parts like low earth orbit, medium Earth orbit in station and your bid and really electrical orbits. This orbits two for the U. S. Soil in distance,different type of distance such as 500 kilometre to 2000 kilometres and move and so on. And in our project, we can helps with the satellite from Elio Low Earth orbit that can be helpful for finding the better team. It's for our art.place night next side. and there is a Connexion from stations. Earthy Station is a collection of equipment installed on the earth. Such face that enable communication works of or move the earth Stations should be in a position to control the satellites. A fetish drift from this of death, and it's subjected to any kind of truck from the external post to can have a set up from the earth surface, which include this partsG C, A transmitter and transparent some stations and a duplex by distance kind of circuits. We are very capable to send any kind of message to our satellites, and after the after we can send the signal from two satellite, it can be easily transmit from the Earth Station and became the save that kind of signals from the satellites.", 'keywords': ['Remote Sensing', 'Satellites', 'Earth Observation'], 'summary': "The transcript provides an overview of remote sensing, focusing on the role of satellites in obtaining accurate images of the Earth. It explains the functioning of satellites, which orbit various celestial bodies, including the Earth and the Sun. The discussion highlights the difference between natural and man-made satellites and the significance of these satellites in monitoring the Earth's physical environment, such as water, air, land, and vegetation. It also details the different types of orbitslow Earth orbit, medium Earth orbit, and geostationary orbitand emphasizes the importance of ground stations that facilitate communication with satellites. These ground stations are equipped to send messages and control the satellites, ensuring effective data transmission."}, {'topic': 'Active vs Passive Sensors', 'start_time': '00:17:52', 'end_time': '00:19:29', 'transcript': "warning everyone, I I'm going to explain how to get images from satellite. But before that, I would like to explain the satellite census. So satellite census, these other special equipment that helps in detecting and mapping this office of So in this we have active sensors and passive census. So active sensors arethose they have, which have their own source of light. So they omit radiations in the directions of the target to be investigated. The senses are then detect and measure the indications that is reflected back from the target. So in this we have two examples, like the leader sensors and radar sentence. So in leader senses a light detection andchanging. So we use laser to measure the distance between the census and the Earth's office so they can create a high detail. The three d major's of the earth's surface and in the radar sensors are radar detection, and ranging they use is the radio waves to penetrate through clouds and vegetation to capture the images from the Earth's office andabout a passive census. Are they? Use of the day? Did act natural radiations that is reflected by the object. So in this we have two examples. Optical and census and thermal census. So optical senses ofthe census can capture high resolution images of the Earth's office. It detects the visible light and need infrared equivalent, which can be which can help distinguish different types. Offices such as Concrete and and the", 'keywords': ['Active Sensors', 'Passive Sensors', 'LiDAR'], 'summary': "The transcript explains the distinction between active and passive sensors used for obtaining images from satellites. Active sensors have their own light source and emit radiation towards the target, measuring the reflected signals; examples include LiDAR and radar sensors. LiDAR utilizes lasers to create detailed 3D maps of the Earth's surface, while radar uses radio waves to penetrate clouds and vegetation. In contrast, passive sensors detect natural radiation reflected from objects, including optical sensors that capture high-resolution images by detecting visible and near-infrared light, aiding in differentiating materials like concrete."}, {'topic': 'Data Acquisition from Satellites', 'start_time': '00:19:30', 'end_time': '00:23:32', 'transcript': "and the thermal sensors are those. These type of sensors can detect the temperature of the Earth example like concrete roads and assault roots. We have the different temperature than surrounding education's. So coming under the next line. So how to get satellite images? So will be using these type of data sources so some of them are free and some of them are paid. So let's suppose a in art project will be using Sentinel Hub.So what is a B? So is application in the face. It is a set of rules and protocols that allows a different source different er soft red application to communicate with each other. Okay, so provides a wide range of functionalities such as data search and discoveries, leader down, state up processing and data analysis. So in the data search, Discovery users can or surge the satellite image by location by time,and they can use the parameters as well and in the data download or users can download the data in the various warm. It's such as if JP G and PNG format and in the data processing uses can apply processing algorithm to the data like image classification filtering enhancement. And in the data analysis, users can perform various analysis task on the data such as the time series analysis, change detection and vegetation indicate populations.So the next slide as sentinel hub be printed. It provides a various endpoints. Okay, so first of all we have which we should know what is in points. These other unique quarrels are the mattresses. So in this, like four search and discovery, we can use these A peas. These n points for download. We can use these AP. These are n points for processing. The can use these.So now the steps to upstage obtain that this image Okay, So first you have to sign. You have to sign up for the Sentinel hub account and obtain an and this key will get you from the configuration of settings in the Sentinel hub and then import the request library.in your vitals. Okay, so the request library this module allow you to send the http request and then set up the A P and point Ural and the query parameters. So the this is a you and it should be like this. And these are the query parameters. Sowith means like request, The request is said to get map, which means or that it request to get a map. Image layer Brands is there is set to brands, which means it's specified. The Sentinel, huh? Blares from the from which we retrieve the data. Okay. And B B box is the nothing. Just a latitude minimum. This is a latitude minimum. This is a long and your minimum. This is a lad, Egil Maximum andand time is set to like a starting start date and the ended and form. It is said to image, which means it requests for a tough image vetters with and hide it requests in the pixel. image in the pixel. So CRS is the specified coordinate reference system for the requested image and show low is said to falls. A show log is nothing just aspecify whether to display the Sentinel on the corporate image. So we hear so here to be centre decided to falls. We don't want to show the local so key which means or the specify the key to authenticate the request you should replace with this Europe be here with your own sentinel hubby Paki So coming under the next slide various.", 'keywords': ['Satellite Imagery', 'API', 'Data Processing'], 'summary': "The transcript discusses the process of data acquisition from satellites, specifically focusing on thermal sensors that detect Earth's temperature variations, such as those on concrete roads. It outlines the methods for obtaining satellite images, mentioning both free and paid data sources, including the use of Sentinel Hub. The speaker explains the application programming interface (API) that facilitates communication between different software applications and describes its functionalities, such as data search, download, processing, and analysis. Users can search for satellite images by location and time, download them in various formats, apply processing algorithms, and perform analyses like time series analysis and change detection. The transcript details the steps to obtain satellite images, including signing up for a Sentinel Hub account, obtaining an API key, and using the request library to send HTTP requests with specific query parameters. The importance of correctly setting parameters like latitude, longitude, time, and the coordinate reference system is emphasized, as well as the need to authenticate requests with the API key."}, {'topic': 'Recommendation Systems in Literature', 'start_time': '00:33:48', 'end_time': '00:41:23', 'transcript': "the my over to dirty air for Coke analysis. Hi. Good morning, everyone. My name is for lovey dovey and today were present Ingle report on Literature Review on our Passion project That is air for book analysis,so one second. So it is the overview that the topics were covering today on this literature review in Productive in Production Problem statement A most of project type ofOh, yes, you are. Is corn. type of method data set, model and algorithms that we are going to use in that we're going to study in this little to review our director a relation metrics reviewed peppering references, so the introduction a aired official intelligence has rapidly become a vital tool for the development of recommendation systems in various domains.Book recommendation system are no exception to this trend. With the exponential growth of digital libraries in on 10 bookstores, there is a vast amount of data available about books and renders ibe scrapbook. Recommendation systems can leverage distorted provide personalised recommendations. Losers. These rescues systems can help traders discovered they might not have otherwise increasing their reading, enjoyment and engagement.In this literature of you, we have examined recent research is on a base book recommendation systems. We have focused on the algorithms and techniques used to build these systems, as well as the data sets and eve elation metrics news. To measure their accuracy. This review aims to provide a comprehensive overview of the current state of our in based book recommendation as well as highlights areas for future research.book recommendation systems have a voice over time from nine you'll to compute computerised systems. With the advent of book recommendation, systems have become more advanced and personalised. This literature will explores the current state of the search for reputation suspense.So the aim of the project. The goal for a for book recommendation is to develop an intelligence system that can recommend book the users based on their interest preferences and past trading. Thethe system should be able to analyse large amount of data, including rules use, a rating reviews and browsing history to make accurate and personalised recommendations. In addition, the system should continuously learn and adapt to the users changing preferences. And we're we're ensuring that the recommendations remainder 11th overtime. Ultimately, the goal is to help users discovered new books that they will enjoy and from what early love of reading.Next, This problem statement from from the research paper papers, we have foundered various problems statement, a problem that we face in making the recommendation system I am discussing here in the recommendation system. The problem is trying to recommend the finest book peach user according to his interest and another problem in this system is data's per city and cold startBetter sparse. Pretty. It means that the it is why displayed And it has Nelle values. And missing well is we have to.and next problem is cold. Start. This problem occurs than a new user enter in the system and new our new item. catalogue. In that case, we don't know about the liking and this likes of the users, but we don't know the rating about the new item that we have added in theso there are method to to use in the air for book analysis. First one is collaborate differently, elaborate, defaulting that there can philtre out items that a user might like on the basis of reactions by similar users. It is it works by searching a large group of people and fining small a shit of music taste similar to political. For example,if I have to. Users, users and both have washed same would have Time book and have given the same reiterating smoke ratings like five star ratings. And if my our users have another book, another which is not being read by the users be yet.So on the on the basis that they have, like the previous book that they both have, like the previous books. On that basis, I will recommend the book right bye. Eighth only will be recommended to the user. Be so This is a collaborative filtering, and it has closed, and guns pros areno need of the main knowledge and serpent guilty. It means that model can help users discovered new interest as well. In isolation the M L System may not know the user is interested in, and given I am, I might still recommend it because similar users are interested in. Coal Stat and Fresh Items and Userspersonalnexus Content based recommendation system Content Business Recommendation Filtering uses item features to recommend other similar items towards the user likes based on the previous actions. In that case, if a user has like a joiner of moments, then the next will be next book will be recommended by the Joyner governments only This So this is this is also a problem because it will give honest Efe recommendationsNext Knowledge based Filtering Recommendation System Knowledge base system when it makes recommendation based not on a Hughes aerating history, but on specific Eurest made by the users. For example, if I am searching for the house and I am using philtres like a price of the house and 22 rooms or three rooms through. These are this is the example of knowledge base fielding.So here, a post No interaction that unaided usually high fidelity that after, UM users Self reporting need user does not need to be careful with Prime Minister.hybrid filtering method. It is basically a combination of both the above method content, which in collaborative politic matter it is a complex model which take a mint product based on your history and as well as the million users like you. Some organisations that use this method like Facebook, the short news which is important for you and for others also in and the same miss news bailing done too.So this is the attack float. That recommendation system can be. can be made by three techniques. Content based collaborative hybrid Collaborative has touched model based in memory, wished and in model, which we have a blistering association techniques gaijin a new", 'keywords': ['Recommendation Systems', 'Collaborative Filtering', 'Content-Based Filtering'], 'summary': 'The presentation discusses a literature review focused on recommendation systems for books, highlighting the growing importance of artificial intelligence in developing such systems. The speaker outlines the project goals, which include analyzing user preferences and past reading habits to provide personalized book recommendations. Various challenges are addressed, such as the cold start problem and data sparsity. Different recommendation techniques are explored, including collaborative filtering, content-based filtering, knowledge-based filtering, and hybrid methods. The aim is to improve user experience by helping them discover new books tailored to their interests.'}, {'topic': 'Evaluation Metrics for Recommendations', 'start_time': '00:59:44', 'end_time': '01:01:15', 'transcript': 'evaluation metrics is mattresses evaluation. Matrices is used to measure the quality of the statistical or machine learning model. The most commonly used evaluation metrics is confusion metrics.It is basically n cross in Matrix that represents rose as true classification of a given piece of data and column represents the predicted classification of the data.and the further points in that our accuracy precision recall an escort. So, first of all, the creator confusion matrix of two by two, which contains positive and negative values for the actual and the predicted values. So the chorus is accuracy is a comment in elevation of metrics for classification problems. It is the number of correct predictions made as a issue of all predicted predictions made precision.precision is. also known as positive predictive value. It is the proportion of positive cases that were correctly identified, recalled recalled, is the fraction of samples from one class, which are predicted correctly by the model. It is calculated by crew positives divided by the sum of true positives and false negatives. F Man score is the harmonic mean of the precision and recall, where efforts called reaches at its best value at one and closed at zero.', 'keywords': ['Evaluation Metrics', 'Confusion Matrix', 'Precision'], 'summary': 'The transcript discusses evaluation metrics used to assess the quality of statistical or machine learning models, with a focus on the confusion matrix. It explains that the confusion matrix is a two-by-two table that compares true classifications to predicted classifications, highlighting key metrics such as accuracy, precision, recall, and F1 score. Accuracy is described as the ratio of correct predictions to total predictions, while precision (or positive predictive value) measures the proportion of true positive cases among all predicted positives. Recall represents the fraction of actual positive cases correctly identified by the model, calculated using true positives and false negatives. The F1 score is defined as the harmonic mean of precision and recall, achieving its best value at one. The explanation provides a foundational understanding of these metrics essential for evaluating classification problems.'}, {'topic': 'Book Recommendation Algorithms', 'start_time': '00:41:36', 'end_time': '00:46:10', 'transcript': "So our next topic, it's mortals and all the algorithm that we have started during the literature review, no less craft based recommendation system a key U P M. Attention enhanced a Knowledge aware user reference murder book recommendations, a using opinion leader mining and book recommendation in system using came ins and go with them and book recommendation system using support on commission over too difficult.Thank you. Believe Good morning, everyone. So can you please a show next light? Levy. okay? Knowledge graph based Recommendation system Knowledge graph is a hack Oh genius graft based method in which nod represent entities of interest and who's edges represent relationship between the entity. It is represented by three D model that is at Artie at stands for happed R Stands for Relations and T Stands 40 Book and they're attribute can be mapped into knowledge half. To understand the mutual relationship between the books,it is divided into three parts here. I'm just giving an overview of its type in embedded based method were grouped up on the basis of how the knowledge graph based embedded system is loan, while Fourth Connexion based mattered. We differentiate them according to how to model the Connexion patron in a knowledge graph and the four propagation based method we distinguished based on which type of entity is defying in the propagationprocess. Next Lively's okay, Embedded this method It main goal is to create dance representation of book user Graf in a continuous low donation vectors is aIt has further three types. First one is to stage level learning. In this, we have two more jewels. Was twenties recommend er first one is M padded Mondial, and second one is recommendation models in Embedded Module A. We work on and Pretty and relationship How Entity and Relations Loan and in recommendation module usurp reference book is.lawn in recommendation module and with the combination of these two. an output and output will be product prediction, prediction of output will be given and in the second join learning amethod it is and to end joint M bag. In this, we join these two module that we have discussed in the previous two stage level Ernie that is the embedded plus. recommendation model. We worked with it together using feature learning process and for tax jewel and visual features, we use photo and coda.the thought than third one is multi task learning method item in the user item interaction by partials a half and they associate ID entities in the knowledge graph unlikely to share similar structure. Therefore, the trans spring of low level featuresbetween item and entities is helpful for facilitating the improvement of recommendation system instead of feet feeding. No lead craft into the recommendation will do. These two models are independent and are connected with crows and compressed unit to share knowledge.next life, please. a. Here we have compared these three embedded based method a two stage learning level advantages, easy to implement and availability. And this distant this advantages improper embedding Next one is joint learning it is and to and learning. The that is the advantage of the joint learning and its disadvantages. Fine tune, weight of different of just the function. Last one is multi task learning it is also into and learning", 'keywords': ['Recommendation Algorithms', 'Knowledge Graph', 'Embedded Methods'], 'summary': 'The transcript discusses various book recommendation algorithms, starting with an introduction to knowledge graph-based recommendation systems. It explains that knowledge graphs represent entities as nodes and their relationships as edges, depicted in a 3D model. The speaker outlines different methods including embedded-based methods, connection-based methods, and propagation-based methods, detailing how they classify and differentiate these approaches. The embedded-based method focuses on creating dense representations of book-user relationships through continuous low-dimensional vectors, with three types mentioned: stage-level learning, joint learning, and multi-task learning. Each type employs specific techniques to improve recommendations by leveraging the relationships within the knowledge graph. The discussion concludes with a comparison of the advantages and disadvantages of the different methods.'}, {'topic': 'Knowledge Graphs in Recommendations', 'start_time': '00:51:30', 'end_time': '00:53:47', 'transcript': "Good morning, everyone. SoMa next algorithm we have seen in the research papers was attention enhanced knowledge aware user preference model.So in the earliest light, as we saw that the knowledge craft is used to do used to reduce status, Par City and Cole start problems in recommend a system. But, however, when incorporating entities from the knowledge graph to use, represent users, most existing powers works. Most existing works are unaware of the relationships between entities and users, resulting in poor recommendation results.so to address this problem, a k u p m. Was introduced. It aims at addressing this past problem in recommended system by incorporating entities from a knowledge graph to in for user's potential interests. It iterative Lee extends a user's historical interactions.Entities along relations in the knowledge graph to introduce much external knowledge. Next, it fakers out the most related part of the incorporated entities based on depicting Enter enter the interaction in entered entity interactions among entities.These are the two types of entity interactions which we are seeing here. The inter entity interaction is where we see the importance of an entity that variousa lot when included in different entity sets. Due to the interactions among entities with respect to the user, enter entity interaction for a certain users and entity may show different characteristics when involved in different interactions. So more specifically, if you want to say that it a space, a self attention network is utilised to capture both these enterand Indra and the interactions two and connect the relations space to obtain suitable characteristics. So this model is obtained to incorporate entities and figure out the unrelated ones so over to Sunil.", 'keywords': ['Knowledge Graphs', 'Recommendation Systems', 'User Preferences'], 'summary': "The presentation discusses the integration of knowledge graphs into recommendation systems, specifically focusing on an attention-enhanced knowledge-aware user preference model. The speaker highlights the limitations of existing models that fail to consider the relationships between entities and users, leading to suboptimal recommendations. To address this, the introduced model iteratively incorporates entities from knowledge graphs to infer user interests, leveraging historical interactions. Two types of entity interactions are explored: inter-entity interactions, which assess the importance of entities across different sets, and entity-user interactions, which reveal varying characteristics for users and entities within different contexts. A self-attention network is employed to capture these interactions and connect relationships effectively, aiming to enhance the model's ability to discern relevant entities."}, {'topic': 'Chatbot Applications in Healthcare', 'start_time': '01:06:16', 'end_time': '01:10:11', 'transcript': "one's parish northern. is Ms Crane visible? yes. so warm. Good morning to the support Security and interns. Today we are going to walk you through our passion project charter boats, which is going to be focused towards the healthcare deLone.Joe decide along with damage on a lodge, Akhil, and to fall before our literature review, we're not going to explore essentially what a charge work is.how do the work? And more importantly, what are the benefits and limitations in the medical sector, then will talk about L P before moving one to the grinning in Providence that are being used to build chat boards.now for us being privileged enough to have a family doctor or a physician chat about mathematics. Not sound not useful, but think of those who can't given receive primary treatments. They have to struggle to long queues, someplace doctors might not be available or, at other times patients. Nicotine delayed appointmentsImagine poor world poor oldest person who is not able to afford regular shackles to keep the symptoms in cheque. Now to address this issue during the next four months, we are going to build a chat board that can diagnose diseases, provide treatment options and therefore give wide access to medical advice.moving forward at the root. The aim of every chat board has to make how two months converse now for the charge people. To do this, it makes use of it and an LP to understand the users query and in turn, generate an automated response In a friendly. Now I will pass on the mike, too.the working of the chattered is. there in 19. States. First one is in proposing. The first step in the working of a chatter is to understand the user in good, which will be the form of text or voice. The chair port uses various input processing technique extract 11 information from the user in Buddhist searches, intendingin today's in condense. This information is then passed within next days, which is natural. Leg replaces the natural econ courses in this state. The champ, all with, um, to analyse the user input and identify the in 10 went behind.and after that we got to stay out. Put condition when the chair port has understood the user intended in contest it 100 appropriate response.next. next like Why do we knew when you've been in champion? because of his is calamity that dollar increase in volume, request or intention without a decreasing in performance cause effective the measure.prison for the possibility is the Handles and Raj volume of. inquiry and day save the business a significant amount of money on stopping average. Giving Abby letting in the chain put can provide the assistant customer into 24 to 7. This make a valuable for the business.", 'keywords': ['Chatbot', 'Healthcare', 'Natural Language Processing'], 'summary': "The transcript discusses the development of a chatbot aimed at improving healthcare access and efficiency. It begins with a warm greeting and an introduction to the team working on the project. The focus is on exploring what chatbots are, how they function, and their advantages and limitations in the medical sector. The speaker emphasizes the potential of chatbots to assist individuals who struggle to access healthcare services, such as those facing long wait times or financial constraints. The team plans to build a chatbot that can diagnose diseases and suggest treatment options, thereby providing broader access to medical advice. The process involves natural language processing (NLP) to understand user queries and generate appropriate responses. The speaker highlights the chatbot's capability to handle high volumes of inquiries while maintaining performance, ultimately saving costs for businesses and offering 24/7 assistance to customers."}, {'topic': 'Mental Health Chatbots', 'start_time': '01:10:14', 'end_time': '01:11:40', 'transcript': "way we have heard about what is a champ, what and how it benefits us so that start about mental health issue.as you know, like everyone around us that some mental pressure and we keep it a secret like we don't We have our own privacy. So some of us even don't don't discuss with Dr So and in this chat about helps to the rapidly evolving there and also benefit in this.issue. So there is a, you know, a charge like it give nous data like the bottles in mental health issues like it imperatives travel if you are going to mental health care providers or it can also uncertain the certain mental health questions.So it also increases customer's privacy like if you are not. 10 enough to share. This was with some human, and it is constantly evolve, so it in the crowded to use its m L. L.", 'keywords': ['Mental Health', 'Chatbots', 'Privacy'], 'summary': 'The transcript discusses the role of mental health chatbots in addressing mental health issues. It highlights how many individuals experience mental pressure but often keep it secret due to privacy concerns, making it challenging to discuss with professionals. The speaker emphasizes that chatbots can provide a beneficial alternative, offering data on mental health issues while ensuring user privacy. They mention the evolving nature of these chatbots and their ability to assist users in navigating questions related to mental health care.'}, {'topic': 'Challenges in Chatbot Design', 'start_time': '01:11:40', 'end_time': '01:13:18', 'transcript': "power trading and production purposes purposes, so it makes it more precise. on to the next slide. we have some challenges and limitations, like talk about this complex interface so engine parts can have a complex interface, like toif any old in person is expressing this feature so that that can be complex for them to deal with the enterprise. Sometimes it can be time consuming,so inch airports can take some. Sometimes they can take, you know, time to predict the output, and it all depends on the algorithms and data.It also has issue of high installation course. It all depends on the infrastructure, and it is having a challenge or limitation of, plus decision making skills like A. It all depends on Data's and data and algorithms were using.So the less the data. And there will be limited responses to other issues like meat beat, memory storage and processing and at last near is a issue of privacy and security.probe. It is a common issue, like if you are using a payment a gateway in a chain port interfaced so it can be attacked on.", 'keywords': ['Chatbot Design', 'Algorithm', 'Privacy and Security'], 'summary': 'The transcript discusses various challenges and limitations associated with chatbot design. It highlights issues such as complex interfaces that can be difficult for users to navigate, time-consuming prediction processes that depend on algorithms and data, as well as high installation costs linked to infrastructure requirements. Additionally, it addresses the importance of decision-making skills in relation to data usage, noting that limited data can lead to restricted responses. Other challenges mentioned include memory storage, processing limitations, and significant concerns regarding privacy and security, especially in contexts like payment gateways.'}, {'topic': 'Natural Language Processing in Chatbots', 'start_time': '01:14:26', 'end_time': '01:16:28', 'transcript': "Naxalite. so feed out of impact for that. it's natural language processing that we just discussed deeply. De plane is a part. That bus was noodle left to be in relation with input and with the spot of the output another the box biassed the statementone north and grand to extract the level in verse from the data. a stay of ideas Basically be it of each term How many occurred but the centres input is given and water the birds the country.another one is also came as me more support. The crucial that the finding the hyper plane in space class by the classes against So the live leeches, also by Davis for chamber as per gatehouse stars is natural language.and the NLP like daily, which contains package to make Chan port understand and reply to it with accurate response.One more is so it has different schools, libraries and community for being programme. is another like the calculation. So this is all about, and next I will hand over to to", 'keywords': ['Natural Language Processing', 'Chatbots', 'Hyperplane'], 'summary': 'The transcript discusses the role of natural language processing (NLP) in chatbots, highlighting its importance in understanding and generating human-like responses. It mentions the concept of hyperplanes for classifying input data and emphasizes the significance of libraries and community support in NLP development. The speaker also refers to various tools available for enhancing chatbot capabilities, indicating a focus on practical applications in programming and response accuracy.'}, {'topic': 'Research Papers on Chatbots', 'start_time': '01:16:31', 'end_time': '01:22:22', 'transcript': "So let's discuss some of the research papers for previously created chair ports. We may take references from them, and we can understand what all are the models they used and what all are the technology they used. So the first to research paper, which I am going to referee a medial in this chat board. They huge these models and created a abbreviation understanding chair Birdmeans many people don't understand are the medical terms and the medical abbreviations. So basically this chat, but will help them to understand what the term for the over mentioned in their trip option for the doctor mentioned will what it means. So it will help them to understand the abbreviations of the medical medical industry and the second one idea Iin this chat board, we we provide them the symptoms, which what all we are facing, and the chamber will ask some of the question, and it will match your data to the database that they have previously stored. So they will first match that suggest Yadav possible disease, which you are facing and reminisce and treatment also,and let's discuss some of the live models they used. They used will be most probably they used the N. L. P Park, and previously one of my friend also described it, so I will go to the next slide page.so moving on to next people. named age and about design during an epidemic like so. in Covent Times, it falls very much stressful, like the logged on think and we can go out and and we also we're not able to meet our doctor physically. So the the other proposed this chair, which can help patients or a person who isnot contracting to prove it like it. you know, tell him about the precautions we need today. So for patients, it can be effective, like in can. GE information. Like what if you are contracted to prevent or and alsothe person is contracted to covert or not for the security of the infection and respected that the chat board can, you know, paying the doctor that this case is serious, so it alerts and they used AM and Mrs Artificial intelligence mark of language.and the use techniques like NLP Pattern determination and were babies for text to speech and space to tax conversation. trusted. Well, I already mentioned the waiters and the president of 10question portions like it is a, you know, a rule based court vacancy. So moving on the next it is context one childbirth for health purposes using D planning so as an incidence that they used deep learningor neural networks in the proposed model. trained their model like their data set using neural networksso they can reason being they can, you know, predict more. Besides disguised outcomes for the uses they used their leader sent for, the used adjacent Final 40 leader said that they created. andalso some of the matches like Pickling Lancaster, Stember, Back of Words and and W These all help to understand the semantics and, you know, entities in the input provided by the So these all help in Over Champ or to understand what the user, daily bonds and reply with resigns and most welcome.so one. paper is a medical chan port on this paper. Not proposed a child, not for cancelling you. Normally, questions of regarding the medical terms like if new, have any kind of medical restriction and you are not able to understand that. Then this charge of any help you out. Suddenly it also Reno provide isoutputs like it? You don't know what is the medical doses of certain drugs or medicines according to the age, So it can also help in thatalso, as I said earlier and you know, answer simple queries. and they used SPM, famous as PM. Al Gore is, um, for theproposed model, and they used the heart disease data set for predicting heart disease for patients and", 'keywords': ['Chatbot', 'Natural Language Processing', 'Deep Learning'], 'summary': "The transcript discusses various research papers related to chatbots, particularly those designed to assist in the medical field. The speaker highlights the importance of understanding medical terms and abbreviations, which a chatbot can help clarify for users. They describe a chatbot that matches user-reported symptoms with a database to suggest possible diseases and treatments. The use of Natural Language Processing (NLP) techniques and artificial intelligence is emphasized, particularly in the context of providing medical information during the COVID-19 pandemic. The speaker also mentions the application of deep learning and neural networks to enhance the chatbot's predictive capabilities, allowing it to understand user input better and provide accurate responses. Several models and methodologies used in these research papers are referenced, including the use of datasets for training the chatbots."}, {'topic': 'Medical Chatbots and AI', 'start_time': '01:22:23', 'end_time': '01:23:48', 'transcript': 'humans. and they also used on nine pays. Google is These are for, you know, text to speech and speech to text.transformation. Vernon. and other languages for understanding semantic sign words. And so they can, you know, predictChris ised outcomes. so over to election. Um next is of farm. Obata. Personally, you score the general medicine port quarter Children and support in this.in the work, we contradict the the parents in parents of Children are confused the roses of the medicine, thenfor over decades, helping the losses of the medicine and Indies. in this is champion to grieve is the library of left rightpersonnel with them and Nash, 11. next, say, Chris. so there is our that International Journal of Engineering. gr.', 'keywords': ['AI', 'Medical Chatbots', 'Text to Speech'], 'summary': 'The transcript discusses the application of AI in medical chatbots, highlighting their use in transforming text to speech and vice versa, as well as understanding semantic signs in various languages. The speaker touches on the predictive capabilities of these technologies for medical outcomes and reflects on the role of medical professionals in supporting confused parents of children regarding medical practices. The narrative also mentions the ongoing efforts over decades in the field of medicine, with references to specific journals and initiatives.'}, {'topic': 'Decision-Making in Chatbots', 'start_time': '01:23:49', 'end_time': '01:25:46', 'transcript': "title track for Medical the 1000. trying to overcome the limitations to holy law conversations now speed of response and respond on his pattern. Guest temple so digits the uses bag of US model technique uses the documents the list ofher separation model is proposed for with data that is the after the trail has been an holiday. Tha it tests user. It usually would be behind of last frame bust and then predict last for put based on intense of bird. Splishthis class is compared to entice towards is on the leader in your own security modelling and then it restaurants these so how they the the the news of andanother cheque. for. is published by Amity ST. they used their not try to reputation. However, the voting of the papers interest has been in this recording them minus andalso the the decision. The the steps like to organisation and then Stoppard's mobile and future extraction the usual and so they can play the bit of each term how times the and then disposed they", 'keywords': ['Chatbots', 'Decision-Making', 'Bag-of-Words Model'], 'summary': 'The transcript discusses decision-making in chatbots, focusing on techniques to improve response speed and pattern recognition. It mentions the use of a bag-of-words model and a separation model for processing user data. The speaker highlights the importance of predicting responses based on user intent and compares different methodologies in chatbot design. The discussion also touches upon the research from Amity ST, which focuses on enhancing decision-making processes within chatbots and the integration of various terms and concepts related to chatbot functionality.'}, {'topic': 'Chatbot Frameworks and Interfaces', 'start_time': '01:26:05', 'end_time': '01:27:08', 'transcript': "assigns, you know, open sewers, chair bird framework. Which is mostly, you know, nowt. Insp used for chat about development. So it has simple interface and it requires minimum court, including skills so animal can, you know, reusing.easily. So it has have two components like basically, it is are also Anna Lou, that Israel's a natural and with understanding and AsakuraSo they have their own purpose. Like if, you know, I you asked something or given input to. the chair part. Then according to the input, it will transfer from it so that I can understand it. Police and then using the end any little. But it will do. Is it will, you know, separate of all the intense but the user ponds and entities for its own understanding and using rasac cool.", 'keywords': ['Chatbot Frameworks', 'Natural Language Understanding', 'User Input Processing'], 'summary': "The transcript discusses chatbot frameworks and their interfaces, particularly focusing on a framework that simplifies chatbot development. It highlights the framework's user-friendly interface, which requires minimal coding skills, making it accessible for developers. The framework consists of two main components: natural language understanding and another that processes user input. The speaker explains how the chatbot interprets user queries, categorizing intents and entities to enhance understanding and response accuracy."}, {'topic': 'Data Handling and Model Deployment', 'start_time': '01:28:33', 'end_time': '01:36:40', 'transcript': "gives out the most favourable out out to use it. so that this is worth three proposed. We are going to use this parasol train book.so that's all Mount it and on to the next life. So let's discuss some of the which we are going to take to make a charm. Or basically we are going to. First of all, we are going to collect the data and if there is any change needed in the data, we have to do that. After that, we can do featuring the nearing minced. We take the points which, based on which we can predict our and after that we can make a model.mammal and trainer model and we can deploy it to the user. And after that, if there is any update Asian needed, we can do that. And that's all from our side. We would love to hear their regeni suggestion needed. We can make changes in our presentation. Thank you so much.a question, although. to the peace. any mentis, I would go on us. Any one of you. If you're her want to say something? Forgive your suggestions, Will back to the teams.not from my it was. okay, I think both. So for all the teams, the presentation was quite good. I like that. The team collaborationYou didn't lock in between when one was speaking in the next turn. It's going so there are few of tents that I would like to mention her.A for book analysts and chat about people. You you have, I think, read papers and know the understanding of the models, what people have used and what you guys are going to use in your project.So for the champion. you. You people have turned the literature review so far. Have you started working on the data?no. will be working starting from next. house. So what from the next week to the task is like first, what kind of data you are going to download and what is detained that is in your mind?That's the task. Will decided to collectively decide with the help government. Is that which day does it we are going to use for a modellike merchant value under a soft network? So that data scientists, but we are going to decide. school taken. But you now have a little understanding of the chat board that I'm. I'm hoping that the research papers have been You don't understand, grace. It's the same item for a rifle book analysis team. You guys also have quite Laker explained, the different methodology and their news cases and limitations.So next task is to start with the date is it? the scene analysis. I really like the motivation you guys started with. But there was in between symbol that you have already explained the things and then later on European explaining. So the battle research part was a little mist.If I am OK, roads and analysis people. so yoga isn't started reading. The research papers regarding your broken are. Yes, ma'am, wehave started. So this was not visible at your presentation. You might have read the papers, but it happened because it might be your like, first presentation you're giving sothe things that I was looking for. what is the literature review that we want to present? Right? So first of all, we should know about the projectthat we are going to start. Okay, let us a book analysis, Chat Bo Crow Road Sing analysis. So the world's itself are huge to understand, Rod seen analysis like a few people are talking about the satellite imagery in the different data. Sites are different. Methodologies are you are still learningthe methodology, parts, machine learning and deep learning. I am not saying that in detail. You will understand right now in the literature review. But the fingers first be understand what is our problem now, what people have done on this problem, What is their contributions so far? What are the methods they have used?What method? What is the limitation and what we can do for our project? There is always a loophole. There is always some kind of limitation dipping. The people have done so far in the research related to any topic that you're working on the different projects.So our task is to understand what people have turned and what are the methodology models weekend use for the data trying. So the understanding part for the data set. Also, there are different kinds of status. Is what is the latest export thatgoing to use? Will it be a different bands will be a different tax data will be a point data, vector data, any kind of data. So the understanding is quite huge to start with. If if you understand the data from the beginning, then the applying models work. What are the different models that will be helpful for our will be useful?I have this point is for all of that. anyway, you guys did the Thank you. Um okay, but start working. Start working on the next part because we see that the time is like now, already March, April May. So you might have already, like 2.5.month within that start working on the data sent extract, the data said. Start using the methodology models because by the time they will be finishing out marshal, any partisan and we will be finishing are planning on and in all these mortals androgynous. So that will be helpful for you guys to one district, two", 'keywords': ['Data Handling', 'Model Deployment', 'Feature Selection'], 'summary': 'The transcript focuses on the process of data handling and model deployment in a project setting. It outlines the steps involved, starting with data collection and necessary preprocessing, followed by feature selection and model training. The discussion emphasizes the importance of collaboration among team members and the need for feedback on presentations. The speaker encourages participants to conduct literature reviews and understand existing methodologies relevant to their projects. They highlight the significance of comprehending the data types and potential limitations of previous research to inform their own work. The urgency of progressing with data extraction and methodology application is also stressed, as the timeline for the project is approaching.'}], 'yellow_line': [{'Topic': 'Transportation Infrastructure', 'transcript': "Hi. Good morning, everyone. My name is nectar and as we all know, that transportation it as an important indicator which measures the economic and commercial progress of a country road ways. They are an important mood of transportations. Roads are indeed the backbone of transportation as the connect people and goods from one location to another.Therefore, having better maps, routes can improve the efficiency and convenience of transportation. How, since better map roots, they can help person saving time In Hume, Better map roots can help drivers find the shortest and the most efficient routes to their destinations,reducing the traffic congestion. We can know about the busy roads in advance, and we can divert the traffics hence overall, having a better map. Roots can improve the efficiency and convenience of transportation, reduced travel times and fuel consumption's, enhance public transportation, improve safety and enhanced accessibility.Therefore, D maps the play an important role in understanding the road network and navigating through it. Henceforth, good maps are essential for understanding the door network and navigating through the roads.", 'start_time': '00:00:14', 'end_time': '00:01:32'}, {'Topic': 'Map Efficiency and Features', 'transcript': 'So we may be wondering, why are we talking about roads and maps? Because that is what our passin project is all about. Hi. Welcome to Passion Project Road Seen Analysis presentation. This is the objective of this presentation is to have a better quality of match.and to be able to navigate easily since the roads and India, they are poor and have poor infrastructure. So we will be focusing on better objective on bettering the quality of maths next flight least.next light. so let us know. Discuss what kind of features will be extracting and how will be re achieving our objective.road leader. Extraction from satellite is very important for a variety of applications, such as for urban planning, transportation management and disaster response. If we know what kind of features are being extracted from satellite using the image processing techniques, we can know better how to improve our quality of images. But latest first discuss what kind of features we are extracting. So', 'start_time': '00:01:33', 'end_time': '00:02:44'}, {'Topic': 'Satellite Image Feature Extraction', 'transcript': 'these are the following features that are satellite provides the road centerline. A road centre line is an imaginary line that runs down the centre of a road or the street. It is considered as the made a point of the road and is used as a reference line for navigation, road design and other purposes. Road with How can Be Major a Road withwe can measure the road, wait by using the edge detection algorithms and then measuring the distances between them. Lane markings. Lane markings are such solid and dash lines and can also be extracted from the satellite images. Road surface types. They determined the condition of the road surface, such as portholes, cracks and other death. TEX This can be in whosefor road maintenance focuses road intersections. Their intersection between the roads can be by identifying the points where two roads meet road direction. The direction can be better mind by analysing the orientation of the road centerline road curvature. The curvature of the road can be calculated by analysing the shape of the road centre lineroad network. The entire road network in an area can be extracted by identifying all the road centre lines and connecting them to perform a network.These features and be used for various applications such as urban planning, traffic management and road safety analysis. Branson Jinyan knows how the work on the feature extraction the next flight. We are going to discuss about what kind of problems are there. While we are trying to extract the features. Next light, pleaseThese are the problems that are faced while we are trying to track images from the satellite, the first Ingles resolution. Now we all know what resolution is a resolution there first to the level of the mail that can be seen in any image, which is typically measured in metres per fixed.So higher resolution image can provide more detailed information about the roads, such as the presence of the lane markings, signs and other important features.Conversely, a lower resolution images may not be enough to provide accurate the tails and extract all the road features and maybe less accurate. So the extraction of images using the resolution is always a trade off between accuracy and cost', 'start_time': '00:02:44', 'end_time': '00:05:21'}, {'Topic': 'Challenges in Satellite Imaging', 'transcript': "occlusion occlusion. It refers to when the objects such as building or trees or vehicles the partially or completely obstruct the view of the roads and the satellite images. This makes it difficult to extract accurate information about the gold features, such as it's with curvature and other important details.Lightning conditions. The lightning conditions at the time the image was captured can highly affect the quality and the clarity of the image, which in turn can affect the accuracy of feature extraction process. For example, they major star you captured during the low light conditions such as at dusk or dawn TV darker and may have more Sha Jews, which can make it difficult to distinguish the roads from surrounding objects.Conversely, the images captured during bribed the light conditions maybe more. Blair and which can make it difficult to accurately extract road featuresvariability. It refers to the natural variations that occurring. The physical environment, such as changes and weather's seasons and vegetation is, for example, during the winter seasons, our roads may be covered with snow and alleys, making it difficult to extractor road road features activating. Similarly, during the rainy season, the roads may be covered with water making, with distinguish making a difficult to be able to distinguish between the water body and the roots.The next problem that we face is the noise satellite A majors. They can be affected by noise such as atmospheric interference and censor noise, which can reduce the quality of the image and making it more district cult to accurately identify road features. Next, Lighty", 'start_time': '00:05:21', 'end_time': '00:07:10'}, {'Topic': 'Road Infrastructure Issues', 'transcript': 'my way or highway. What does this mean? This just means that all Indian roads we have a poor infrastructures. We are. When we are driving, it is difficult to analyse that. Are we going to move onto a highway or we have to take some others neat.So the poor road infrastructures can lead to damage and declaration of roads, which can make them more difficult to identify and satellite images. For example, portholes, cracks and other form of the damages can fill it a visual noise and the satellite images, making it difficult to be able to get futures accurately so we can improve the quality of the features extracted from the satellite images that will be explained in the later slides by Mafia Dupin.', 'start_time': '00:07:12', 'end_time': '00:07:59'}, {'Topic': 'Image Enhancement Techniques', 'transcript': 'thank you. So here some techniques that can enhance the details of the road network and make it easy to identify road features. So we have an image enhancement sharpening, immediate fuse. Um, object detection and roll placer. And your reference,Um, and next time. so image enhancement. This is the process of improving the quality of image captured by satellite techniques can be improved. The overall quality and visual quality of a satellite image in a road scene. Analysts. It is important to be able to identify road features. Clearly image so contents and houseman techniques can be used to enhance the details of the road network and make it easier to identify these features.So we have a history. Graham Equalisation is a technique used to improve the contests of image by redistributing the pixel intensity in a way that utilised the full range of values available in the image. Dis techniques can help to bring out more details in the road network, and making it is gives you to identify road featuresnext time. so second techniques is a shopping. This is a technique for enhancing the edge and details in the image, making it appear very clearly and mortifying. This can be very useful for identify objects and feature on the roads such as al Blaine markings and traffic signs. So here we can use a low pass philtre and bypass philtre. Lupus Philtre is the type of frequency to main kilter that is used for smoothing the imageand hyper spent is a diaper for frequency two men philtre that is used for sharpening the image backslide.so we have image fusion, so these techniques can be used to combine satellite images with other sources, such as a road maps and GPS data. So image prisoner method creates a high resolution image for more detail monetary. So this can help to improve the overall accuracy of a road feature extraction and provide additional context for the our satellite emission.', 'start_time': '00:08:03', 'end_time': '00:10:22'}, {'Topic': 'Object Detection in Imaging', 'transcript': 'next, right? so object detection. So object detection algorithms have proven to be our efficient in automatically identify road features such as a road centre, live lane marking and road intersection in satellite image. Using a deep learning algorithms can be trained on a larger sets on a satellite imaginary and allow them to learn and improve their accuracy by over time.So doing so that they can efficiently automate the process of a vote future extraction and saving double time and improve efficiencynext. so we have a road Taser sore. Otis is designed to automatically expect the map road networks from high resolution aerial imagery. The roadways algorithm use our conversion. CNN algorithms to analyse identified groups said the algorithm clears a vector map that can be used for a directive for purpose improving GPS navigation, mapping Aaron development and helping to plan and new road in construction.', 'start_time': '00:10:23', 'end_time': '00:11:25'}, {'Topic': 'Geolocation and Reference', 'transcript': 'so next light. Sergio referencing when working the image that, like location information, it is our responsibility to assign a location to them. The process is commonly referred zero fencing, which involves the use of a mathematical procedure to determine the location of the image. So zero fencing can be done manually or automatically, and involves referencing the image to known locations and set of coordinates.So once the references completing the image will be contained, all the necessary location informations along it to be accurately placed on the map.', 'start_time': '00:11:26', 'end_time': '00:12:08'}, {'Topic': 'Remote Sensing Overview', 'transcript': "you in our no project, we are basically held from the satellite for finding very good and accurate image. So first of all, we're we are trying to understand working satellites. The satellite is nothing, Burton of that. They floated around the orbit of bigger, objective and satellite are the object. The Earth, sun and most of the collateral bodies and the satellites aremedical into two parts in first of first days, natural at light, antagonistic man made satellites. and B m move from next night. imagesthe state like we made it. It's one of the most powerful and important to will be have for monitoring our earth. And we are tracking their physical environments like water, air, land and vegetation and changing human strengths. A first the Globe.next like and there are some types of satellites, such as national satellite and artificial satellites, and in our individual side, light it is it can. in the few parts like low earth orbit, medium Earth orbit in station and your bid and really electrical orbits. This orbits two for the U. S. Soil in distance,different type of distance such as 500 kilometre to 2000 kilometres and move and so on. And in our project, we can helps with the satellite from Elio Low Earth orbit that can be helpful for finding the better team. It's for our art.place night next side. and there is a Connexion from stations. Earthy Station is a collection of equipment installed on the earth. Such face that enable communication works of or move the earth Stations should be in a position to control the satellites. A fetish drift from this of death, and it's subjected to any kind of truck from the external post to can have a set up from the earth surface, which include this partsG C, A transmitter and transparent some stations and a duplex by distance kind of circuits. We are very capable to send any kind of message to our satellites, and after the after we can send the signal from two satellite, it can be easily transmit from the Earth Station and became the save that kind of signals from the satellites.", 'start_time': '00:12:35', 'end_time': '00:15:31'}, {'Topic': 'Active vs Passive Sensors', 'transcript': "warning everyone, I I'm going to explain how to get images from satellite. But before that, I would like to explain the satellite census. So satellite census, these other special equipment that helps in detecting and mapping this office of So in this we have active sensors and passive census. So active sensors arethose they have, which have their own source of light. So they omit radiations in the directions of the target to be investigated. The senses are then detect and measure the indications that is reflected back from the target. So in this we have two examples, like the leader sensors and radar sentence. So in leader senses a light detection andchanging. So we use laser to measure the distance between the census and the Earth's office so they can create a high detail. The three d major's of the earth's surface and in the radar sensors are radar detection, and ranging they use is the radio waves to penetrate through clouds and vegetation to capture the images from the Earth's office andabout a passive census. Are they? Use of the day? Did act natural radiations that is reflected by the object. So in this we have two examples. Optical and census and thermal census. So optical senses ofthe census can capture high resolution images of the Earth's office. It detects the visible light and need infrared equivalent, which can be which can help distinguish different types. Offices such as Concrete and and the", 'start_time': '00:17:52', 'end_time': '00:19:29'}, {'Topic': 'Data Acquisition from Satellites', 'transcript': "and the thermal sensors are those. These type of sensors can detect the temperature of the Earth example like concrete roads and assault roots. We have the different temperature than surrounding education's. So coming under the next line. So how to get satellite images? So will be using these type of data sources so some of them are free and some of them are paid. So let's suppose a in art project will be using Sentinel Hub.So what is a B? So is application in the face. It is a set of rules and protocols that allows a different source different er soft red application to communicate with each other. Okay, so provides a wide range of functionalities such as data search and discoveries, leader down, state up processing and data analysis. So in the data search, Discovery users can or surge the satellite image by location by time,and they can use the parameters as well and in the data download or users can download the data in the various warm. It's such as if JP G and PNG format and in the data processing uses can apply processing algorithm to the data like image classification filtering enhancement. And in the data analysis, users can perform various analysis task on the data such as the time series analysis, change detection and vegetation indicate populations.So the next slide as sentinel hub be printed. It provides a various endpoints. Okay, so first of all we have which we should know what is in points. These other unique quarrels are the mattresses. So in this, like four search and discovery, we can use these A peas. These n points for download. We can use these AP. These are n points for processing. The can use these.So now the steps to upstage obtain that this image Okay, So first you have to sign. You have to sign up for the Sentinel hub account and obtain an and this key will get you from the configuration of settings in the Sentinel hub and then import the request library.in your vitals. Okay, so the request library this module allow you to send the http request and then set up the A P and point Ural and the query parameters. So the this is a you and it should be like this. And these are the query parameters. Sowith means like request, The request is said to get map, which means or that it request to get a map. Image layer Brands is there is set to brands, which means it's specified. The Sentinel, huh? Blares from the from which we retrieve the data. Okay. And B B box is the nothing. Just a latitude minimum. This is a latitude minimum. This is a long and your minimum. This is a lad, Egil Maximum andand time is set to like a starting start date and the ended and form. It is said to image, which means it requests for a tough image vetters with and hide it requests in the pixel. image in the pixel. So CRS is the specified coordinate reference system for the requested image and show low is said to falls. A show log is nothing just aspecify whether to display the Sentinel on the corporate image. So we hear so here to be centre decided to falls. We don't want to show the local so key which means or the specify the key to authenticate the request you should replace with this Europe be here with your own sentinel hubby Paki So coming under the next slide various.", 'start_time': '00:19:30', 'end_time': '00:23:32'}, {'Topic': 'Recommendation Systems in Literature', 'transcript': "the my over to dirty air for Coke analysis. Hi. Good morning, everyone. My name is for lovey dovey and today were present Ingle report on Literature Review on our Passion project That is air for book analysis,so one second. So it is the overview that the topics were covering today on this literature review in Productive in Production Problem statement A most of project type ofOh, yes, you are. Is corn. type of method data set, model and algorithms that we are going to use in that we're going to study in this little to review our director a relation metrics reviewed peppering references, so the introduction a aired official intelligence has rapidly become a vital tool for the development of recommendation systems in various domains.Book recommendation system are no exception to this trend. With the exponential growth of digital libraries in on 10 bookstores, there is a vast amount of data available about books and renders ibe scrapbook. Recommendation systems can leverage distorted provide personalised recommendations. Losers. These rescues systems can help traders discovered they might not have otherwise increasing their reading, enjoyment and engagement.In this literature of you, we have examined recent research is on a base book recommendation systems. We have focused on the algorithms and techniques used to build these systems, as well as the data sets and eve elation metrics news. To measure their accuracy. This review aims to provide a comprehensive overview of the current state of our in based book recommendation as well as highlights areas for future research.book recommendation systems have a voice over time from nine you'll to compute computerised systems. With the advent of book recommendation, systems have become more advanced and personalised. This literature will explores the current state of the search for reputation suspense.So the aim of the project. The goal for a for book recommendation is to develop an intelligence system that can recommend book the users based on their interest preferences and past trading. Thethe system should be able to analyse large amount of data, including rules use, a rating reviews and browsing history to make accurate and personalised recommendations. In addition, the system should continuously learn and adapt to the users changing preferences. And we're we're ensuring that the recommendations remainder 11th overtime. Ultimately, the goal is to help users discovered new books that they will enjoy and from what early love of reading.Next, This problem statement from from the research paper papers, we have foundered various problems statement, a problem that we face in making the recommendation system I am discussing here in the recommendation system. The problem is trying to recommend the finest book peach user according to his interest and another problem in this system is data's per city and cold startBetter sparse. Pretty. It means that the it is why displayed And it has Nelle values. And missing well is we have to.and next problem is cold. Start. This problem occurs than a new user enter in the system and new our new item. catalogue. In that case, we don't know about the liking and this likes of the users, but we don't know the rating about the new item that we have added in theso there are method to to use in the air for book analysis. First one is collaborate differently, elaborate, defaulting that there can philtre out items that a user might like on the basis of reactions by similar users. It is it works by searching a large group of people and fining small a shit of music taste similar to political. For example,if I have to. Users, users and both have washed same would have Time book and have given the same reiterating smoke ratings like five star ratings. And if my our users have another book, another which is not being read by the users be yet.So on the on the basis that they have, like the previous book that they both have, like the previous books. On that basis, I will recommend the book right bye. Eighth only will be recommended to the user. Be so This is a collaborative filtering, and it has closed, and guns pros areno need of the main knowledge and serpent guilty. It means that model can help users discovered new interest as well. In isolation the M L System may not know the user is interested in, and given I am, I might still recommend it because similar users are interested in. Coal Stat and Fresh Items and Userspersonalnexus Content based recommendation system Content Business Recommendation Filtering uses item features to recommend other similar items towards the user likes based on the previous actions. In that case, if a user has like a joiner of moments, then the next will be next book will be recommended by the Joyner governments only This So this is this is also a problem because it will give honest Efe recommendationsNext Knowledge based Filtering Recommendation System Knowledge base system when it makes recommendation based not on a Hughes aerating history, but on specific Eurest made by the users. For example, if I am searching for the house and I am using philtres like a price of the house and 22 rooms or three rooms through. These are this is the example of knowledge base fielding.So here, a post No interaction that unaided usually high fidelity that after, UM users Self reporting need user does not need to be careful with Prime Minister.hybrid filtering method. It is basically a combination of both the above method content, which in collaborative politic matter it is a complex model which take a mint product based on your history and as well as the million users like you. Some organisations that use this method like Facebook, the short news which is important for you and for others also in and the same miss news bailing done too.So this is the attack float. That recommendation system can be. can be made by three techniques. Content based collaborative hybrid Collaborative has touched model based in memory, wished and in model, which we have a blistering association techniques gaijin a new", 'start_time': '00:33:48', 'end_time': '00:41:23'}, {'Topic': 'Evaluation Metrics for Recommendations', 'transcript': 'evaluation metrics is mattresses evaluation. Matrices is used to measure the quality of the statistical or machine learning model. The most commonly used evaluation metrics is confusion metrics.It is basically n cross in Matrix that represents rose as true classification of a given piece of data and column represents the predicted classification of the data.and the further points in that our accuracy precision recall an escort. So, first of all, the creator confusion matrix of two by two, which contains positive and negative values for the actual and the predicted values. So the chorus is accuracy is a comment in elevation of metrics for classification problems. It is the number of correct predictions made as a issue of all predicted predictions made precision.precision is. also known as positive predictive value. It is the proportion of positive cases that were correctly identified, recalled recalled, is the fraction of samples from one class, which are predicted correctly by the model. It is calculated by crew positives divided by the sum of true positives and false negatives. F Man score is the harmonic mean of the precision and recall, where efforts called reaches at its best value at one and closed at zero.', 'start_time': '00:59:44', 'end_time': '01:01:15'}, {'Topic': 'Book Recommendation Algorithms', 'transcript': "So our next topic, it's mortals and all the algorithm that we have started during the literature review, no less craft based recommendation system a key U P M. Attention enhanced a Knowledge aware user reference murder book recommendations, a using opinion leader mining and book recommendation in system using came ins and go with them and book recommendation system using support on commission over too difficult.Thank you. Believe Good morning, everyone. So can you please a show next light? Levy. okay? Knowledge graph based Recommendation system Knowledge graph is a hack Oh genius graft based method in which nod represent entities of interest and who's edges represent relationship between the entity. It is represented by three D model that is at Artie at stands for happed R Stands for Relations and T Stands 40 Book and they're attribute can be mapped into knowledge half. To understand the mutual relationship between the books,it is divided into three parts here. I'm just giving an overview of its type in embedded based method were grouped up on the basis of how the knowledge graph based embedded system is loan, while Fourth Connexion based mattered. We differentiate them according to how to model the Connexion patron in a knowledge graph and the four propagation based method we distinguished based on which type of entity is defying in the propagationprocess. Next Lively's okay, Embedded this method It main goal is to create dance representation of book user Graf in a continuous low donation vectors is aIt has further three types. First one is to stage level learning. In this, we have two more jewels. Was twenties recommend er first one is M padded Mondial, and second one is recommendation models in Embedded Module A. We work on and Pretty and relationship How Entity and Relations Loan and in recommendation module usurp reference book is.lawn in recommendation module and with the combination of these two. an output and output will be product prediction, prediction of output will be given and in the second join learning amethod it is and to end joint M bag. In this, we join these two module that we have discussed in the previous two stage level Ernie that is the embedded plus. recommendation model. We worked with it together using feature learning process and for tax jewel and visual features, we use photo and coda.the thought than third one is multi task learning method item in the user item interaction by partials a half and they associate ID entities in the knowledge graph unlikely to share similar structure. Therefore, the trans spring of low level featuresbetween item and entities is helpful for facilitating the improvement of recommendation system instead of feet feeding. No lead craft into the recommendation will do. These two models are independent and are connected with crows and compressed unit to share knowledge.next life, please. a. Here we have compared these three embedded based method a two stage learning level advantages, easy to implement and availability. And this distant this advantages improper embedding Next one is joint learning it is and to and learning. The that is the advantage of the joint learning and its disadvantages. Fine tune, weight of different of just the function. Last one is multi task learning it is also into and learning", 'start_time': '00:41:36', 'end_time': '00:46:10'}, {'Topic': 'Knowledge Graphs in Recommendations', 'transcript': "Good morning, everyone. SoMa next algorithm we have seen in the research papers was attention enhanced knowledge aware user preference model.So in the earliest light, as we saw that the knowledge craft is used to do used to reduce status, Par City and Cole start problems in recommend a system. But, however, when incorporating entities from the knowledge graph to use, represent users, most existing powers works. Most existing works are unaware of the relationships between entities and users, resulting in poor recommendation results.so to address this problem, a k u p m. Was introduced. It aims at addressing this past problem in recommended system by incorporating entities from a knowledge graph to in for user's potential interests. It iterative Lee extends a user's historical interactions.Entities along relations in the knowledge graph to introduce much external knowledge. Next, it fakers out the most related part of the incorporated entities based on depicting Enter enter the interaction in entered entity interactions among entities.These are the two types of entity interactions which we are seeing here. The inter entity interaction is where we see the importance of an entity that variousa lot when included in different entity sets. Due to the interactions among entities with respect to the user, enter entity interaction for a certain users and entity may show different characteristics when involved in different interactions. So more specifically, if you want to say that it a space, a self attention network is utilised to capture both these enterand Indra and the interactions two and connect the relations space to obtain suitable characteristics. So this model is obtained to incorporate entities and figure out the unrelated ones so over to Sunil.", 'start_time': '00:51:30', 'end_time': '00:53:47'}, {'Topic': 'Chatbot Applications in Healthcare', 'transcript': "one's parish northern. is Ms Crane visible? yes. so warm. Good morning to the support Security and interns. Today we are going to walk you through our passion project charter boats, which is going to be focused towards the healthcare deLone.Joe decide along with damage on a lodge, Akhil, and to fall before our literature review, we're not going to explore essentially what a charge work is.how do the work? And more importantly, what are the benefits and limitations in the medical sector, then will talk about L P before moving one to the grinning in Providence that are being used to build chat boards.now for us being privileged enough to have a family doctor or a physician chat about mathematics. Not sound not useful, but think of those who can't given receive primary treatments. They have to struggle to long queues, someplace doctors might not be available or, at other times patients. Nicotine delayed appointmentsImagine poor world poor oldest person who is not able to afford regular shackles to keep the symptoms in cheque. Now to address this issue during the next four months, we are going to build a chat board that can diagnose diseases, provide treatment options and therefore give wide access to medical advice.moving forward at the root. The aim of every chat board has to make how two months converse now for the charge people. To do this, it makes use of it and an LP to understand the users query and in turn, generate an automated response In a friendly. Now I will pass on the mike, too.the working of the chattered is. there in 19. States. First one is in proposing. The first step in the working of a chatter is to understand the user in good, which will be the form of text or voice. The chair port uses various input processing technique extract 11 information from the user in Buddhist searches, intendingin today's in condense. This information is then passed within next days, which is natural. Leg replaces the natural econ courses in this state. The champ, all with, um, to analyse the user input and identify the in 10 went behind.and after that we got to stay out. Put condition when the chair port has understood the user intended in contest it 100 appropriate response.next. next like Why do we knew when you've been in champion? because of his is calamity that dollar increase in volume, request or intention without a decreasing in performance cause effective the measure.prison for the possibility is the Handles and Raj volume of. inquiry and day save the business a significant amount of money on stopping average. Giving Abby letting in the chain put can provide the assistant customer into 24 to 7. This make a valuable for the business.", 'start_time': '01:06:16', 'end_time': '01:10:11'}, {'Topic': 'Mental Health Chatbots', 'transcript': "way we have heard about what is a champ, what and how it benefits us so that start about mental health issue.as you know, like everyone around us that some mental pressure and we keep it a secret like we don't We have our own privacy. So some of us even don't don't discuss with Dr So and in this chat about helps to the rapidly evolving there and also benefit in this.issue. So there is a, you know, a charge like it give nous data like the bottles in mental health issues like it imperatives travel if you are going to mental health care providers or it can also uncertain the certain mental health questions.So it also increases customer's privacy like if you are not. 10 enough to share. This was with some human, and it is constantly evolve, so it in the crowded to use its m L. L.", 'start_time': '01:10:14', 'end_time': '01:11:40'}, {'Topic': 'Challenges in Chatbot Design', 'transcript': "power trading and production purposes purposes, so it makes it more precise. on to the next slide. we have some challenges and limitations, like talk about this complex interface so engine parts can have a complex interface, like toif any old in person is expressing this feature so that that can be complex for them to deal with the enterprise. Sometimes it can be time consuming,so inch airports can take some. Sometimes they can take, you know, time to predict the output, and it all depends on the algorithms and data.It also has issue of high installation course. It all depends on the infrastructure, and it is having a challenge or limitation of, plus decision making skills like A. It all depends on Data's and data and algorithms were using.So the less the data. And there will be limited responses to other issues like meat beat, memory storage and processing and at last near is a issue of privacy and security.probe. It is a common issue, like if you are using a payment a gateway in a chain port interfaced so it can be attacked on.", 'start_time': '01:11:40', 'end_time': '01:13:18'}, {'Topic': 'Natural Language Processing in Chatbots', 'transcript': "Naxalite. so feed out of impact for that. it's natural language processing that we just discussed deeply. De plane is a part. That bus was noodle left to be in relation with input and with the spot of the output another the box biassed the statementone north and grand to extract the level in verse from the data. a stay of ideas Basically be it of each term How many occurred but the centres input is given and water the birds the country.another one is also came as me more support. The crucial that the finding the hyper plane in space class by the classes against So the live leeches, also by Davis for chamber as per gatehouse stars is natural language.and the NLP like daily, which contains package to make Chan port understand and reply to it with accurate response.One more is so it has different schools, libraries and community for being programme. is another like the calculation. So this is all about, and next I will hand over to to", 'start_time': '01:14:26', 'end_time': '01:16:28'}, {'Topic': 'Research Papers on Chatbots', 'transcript': "So let's discuss some of the research papers for previously created chair ports. We may take references from them, and we can understand what all are the models they used and what all are the technology they used. So the first to research paper, which I am going to referee a medial in this chat board. They huge these models and created a abbreviation understanding chair Birdmeans many people don't understand are the medical terms and the medical abbreviations. So basically this chat, but will help them to understand what the term for the over mentioned in their trip option for the doctor mentioned will what it means. So it will help them to understand the abbreviations of the medical medical industry and the second one idea Iin this chat board, we we provide them the symptoms, which what all we are facing, and the chamber will ask some of the question, and it will match your data to the database that they have previously stored. So they will first match that suggest Yadav possible disease, which you are facing and reminisce and treatment also,and let's discuss some of the live models they used. They used will be most probably they used the N. L. P Park, and previously one of my friend also described it, so I will go to the next slide page.so moving on to next people. named age and about design during an epidemic like so. in Covent Times, it falls very much stressful, like the logged on think and we can go out and and we also we're not able to meet our doctor physically. So the the other proposed this chair, which can help patients or a person who isnot contracting to prove it like it. you know, tell him about the precautions we need today. So for patients, it can be effective, like in can. GE information. Like what if you are contracted to prevent or and alsothe person is contracted to covert or not for the security of the infection and respected that the chat board can, you know, paying the doctor that this case is serious, so it alerts and they used AM and Mrs Artificial intelligence mark of language.and the use techniques like NLP Pattern determination and were babies for text to speech and space to tax conversation. trusted. Well, I already mentioned the waiters and the president of 10question portions like it is a, you know, a rule based court vacancy. So moving on the next it is context one childbirth for health purposes using D planning so as an incidence that they used deep learningor neural networks in the proposed model. trained their model like their data set using neural networksso they can reason being they can, you know, predict more. Besides disguised outcomes for the uses they used their leader sent for, the used adjacent Final 40 leader said that they created. andalso some of the matches like Pickling Lancaster, Stember, Back of Words and and W These all help to understand the semantics and, you know, entities in the input provided by the So these all help in Over Champ or to understand what the user, daily bonds and reply with resigns and most welcome.so one. paper is a medical chan port on this paper. Not proposed a child, not for cancelling you. Normally, questions of regarding the medical terms like if new, have any kind of medical restriction and you are not able to understand that. Then this charge of any help you out. Suddenly it also Reno provide isoutputs like it? You don't know what is the medical doses of certain drugs or medicines according to the age, So it can also help in thatalso, as I said earlier and you know, answer simple queries. and they used SPM, famous as PM. Al Gore is, um, for theproposed model, and they used the heart disease data set for predicting heart disease for patients and", 'start_time': '01:16:31', 'end_time': '01:22:22'}, {'Topic': 'Medical Chatbots and AI', 'transcript': 'humans. and they also used on nine pays. Google is These are for, you know, text to speech and speech to text.transformation. Vernon. and other languages for understanding semantic sign words. And so they can, you know, predictChris ised outcomes. so over to election. Um next is of farm. Obata. Personally, you score the general medicine port quarter Children and support in this.in the work, we contradict the the parents in parents of Children are confused the roses of the medicine, thenfor over decades, helping the losses of the medicine and Indies. in this is champion to grieve is the library of left rightpersonnel with them and Nash, 11. next, say, Chris. so there is our that International Journal of Engineering. gr.', 'start_time': '01:22:23', 'end_time': '01:23:48'}, {'Topic': 'Decision-Making in Chatbots', 'transcript': "title track for Medical the 1000. trying to overcome the limitations to holy law conversations now speed of response and respond on his pattern. Guest temple so digits the uses bag of US model technique uses the documents the list ofher separation model is proposed for with data that is the after the trail has been an holiday. Tha it tests user. It usually would be behind of last frame bust and then predict last for put based on intense of bird. Splishthis class is compared to entice towards is on the leader in your own security modelling and then it restaurants these so how they the the the news of andanother cheque. for. is published by Amity ST. they used their not try to reputation. However, the voting of the papers interest has been in this recording them minus andalso the the decision. The the steps like to organisation and then Stoppard's mobile and future extraction the usual and so they can play the bit of each term how times the and then disposed they", 'start_time': '01:23:49', 'end_time': '01:25:46'}, {'Topic': 'Chatbot Frameworks and Interfaces', 'transcript': "assigns, you know, open sewers, chair bird framework. Which is mostly, you know, nowt. Insp used for chat about development. So it has simple interface and it requires minimum court, including skills so animal can, you know, reusing.easily. So it has have two components like basically, it is are also Anna Lou, that Israel's a natural and with understanding and AsakuraSo they have their own purpose. Like if, you know, I you asked something or given input to. the chair part. Then according to the input, it will transfer from it so that I can understand it. Police and then using the end any little. But it will do. Is it will, you know, separate of all the intense but the user ponds and entities for its own understanding and using rasac cool.", 'start_time': '01:26:05', 'end_time': '01:27:08'}, {'Topic': 'Data Handling and Model Deployment', 'transcript': "gives out the most favourable out out to use it. so that this is worth three proposed. We are going to use this parasol train book.so that's all Mount it and on to the next life. So let's discuss some of the which we are going to take to make a charm. Or basically we are going to. First of all, we are going to collect the data and if there is any change needed in the data, we have to do that. After that, we can do featuring the nearing minced. We take the points which, based on which we can predict our and after that we can make a model.mammal and trainer model and we can deploy it to the user. And after that, if there is any update Asian needed, we can do that. And that's all from our side. We would love to hear their regeni suggestion needed. We can make changes in our presentation. Thank you so much.a question, although. to the peace. any mentis, I would go on us. Any one of you. If you're her want to say something? Forgive your suggestions, Will back to the teams.not from my it was. okay, I think both. So for all the teams, the presentation was quite good. I like that. The team collaborationYou didn't lock in between when one was speaking in the next turn. It's going so there are few of tents that I would like to mention her.A for book analysts and chat about people. You you have, I think, read papers and know the understanding of the models, what people have used and what you guys are going to use in your project.So for the champion. you. You people have turned the literature review so far. Have you started working on the data?no. will be working starting from next. house. So what from the next week to the task is like first, what kind of data you are going to download and what is detained that is in your mind?That's the task. Will decided to collectively decide with the help government. Is that which day does it we are going to use for a modellike merchant value under a soft network? So that data scientists, but we are going to decide. school taken. But you now have a little understanding of the chat board that I'm. I'm hoping that the research papers have been You don't understand, grace. It's the same item for a rifle book analysis team. You guys also have quite Laker explained, the different methodology and their news cases and limitations.So next task is to start with the date is it? the scene analysis. I really like the motivation you guys started with. But there was in between symbol that you have already explained the things and then later on European explaining. So the battle research part was a little mist.If I am OK, roads and analysis people. so yoga isn't started reading. The research papers regarding your broken are. Yes, ma'am, wehave started. So this was not visible at your presentation. You might have read the papers, but it happened because it might be your like, first presentation you're giving sothe things that I was looking for. what is the literature review that we want to present? Right? So first of all, we should know about the projectthat we are going to start. Okay, let us a book analysis, Chat Bo Crow Road Sing analysis. So the world's itself are huge to understand, Rod seen analysis like a few people are talking about the satellite imagery in the different data. Sites are different. Methodologies are you are still learningthe methodology, parts, machine learning and deep learning. I am not saying that in detail. You will understand right now in the literature review. But the fingers first be understand what is our problem now, what people have done on this problem, What is their contributions so far? What are the methods they have used?What method? What is the limitation and what we can do for our project? There is always a loophole. There is always some kind of limitation dipping. The people have done so far in the research related to any topic that you're working on the different projects.So our task is to understand what people have turned and what are the methodology models weekend use for the data trying. So the understanding part for the data set. Also, there are different kinds of status. Is what is the latest export thatgoing to use? Will it be a different bands will be a different tax data will be a point data, vector data, any kind of data. So the understanding is quite huge to start with. If if you understand the data from the beginning, then the applying models work. What are the different models that will be helpful for our will be useful?I have this point is for all of that. anyway, you guys did the Thank you. Um okay, but start working. Start working on the next part because we see that the time is like now, already March, April May. So you might have already, like 2.5.month within that start working on the data sent extract, the data said. Start using the methodology models because by the time they will be finishing out marshal, any partisan and we will be finishing are planning on and in all these mortals androgynous. So that will be helpful for you guys to one district, two", 'start_time': '01:28:33', 'end_time': '01:36:40'}], 'session_id': [ObjectId('641bd6eaa053a968d797f90f')], 'assessment': ObjectId('66f45800c248cb8c521540ed'), 'job_name': 'my-transcription-jobfb3d9d3e-a85e-43a9-bdb5-5bb176344995', 'keywords': ['User Preferences', 'Healthcare', 'Confusion Matrix', 'Natural Language Understanding', 'Feature Extraction', 'Bag-of-Words Model', 'Natural Language Processing', 'Evaluation Metrics', 'Geolocation', 'Satellite Imagery', 'Chatbots', 'Knowledge Graph', 'Chatbot Design', 'Recommendation Systems', 'Active Sensors', 'Collaborative Filtering', 'AI', 'Model Deployment', 'Histogram Equalization', 'Remote Sensing', 'Decision-Making', 'Content-Based Filtering', 'Chatbot', 'Mapping', 'LiDAR', 'Recommendation Algorithms', 'Satellite Imaging', 'Image Processing', 'Chatbot Frameworks', 'Road Infrastructure', 'Image Fusion', 'Medical Chatbots', 'Noise', 'API', 'Satellite Images', 'Occlusion', 'Privacy and Security', 'Road Feature Extraction', 'Privacy', 'User Input Processing', 'Hyperplane', 'CNN', 'Image Referencing', 'Earth Observation', 'Satellites', 'Data Processing', 'Embedded Methods', 'Roadways', 'Mental Health', 'Zero Fencing', 'Precision', 'Object Detection', 'Data Handling', 'Transportation Infrastructure', 'Passive Sensors', 'Image Enhancement', 'Algorithm', 'Feature Selection', 'Deep Learning', 'Image Resolution', 'Text to Speech', 'Knowledge Graphs'], 'topic': 'Natural Language Processing and Healthcare', 'interaction': [{'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about improving the quality of images extracted from satellites was not addressed.', 'relevancy': '0', 'question': 'How can we improve the quality of images extracted from satellite?', 'timestamp': '[0:12:36]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about features extracted from satellite using image processing techniques is not addressed.', 'relevancy': '0', 'question': 'What kind of features are being extracted from satellite using the image processing techniques?', 'timestamp': '[0:12:36]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about problems faced while extracting features from satellite images was not addressed.', 'relevancy': '0', 'question': 'What are the problems faced while trying to extract features from satellite images?', 'timestamp': '[0:12:36]'}, {'status': 'answered', 'answer': 'Active sensors are those that have their own source of light and emit radiations in the direction of the target to be investigated, while passive sensors use natural radiation that is reflected by the object.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What is the difference between active sensors and passive sensors?', 'timestamp': '[0:17:24]'}, {'status': 'answered', 'answer': 'The student explains how to get satellite images by using various data sources, including free and paid options, and mentions using Sentinel Hub for accessing satellite data.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How do we get satellite images?', 'timestamp': '[0:17:24]'}, {'status': 'answered', 'answer': 'The steps to obtain satellite images include signing up for a Sentinel Hub account, obtaining an API key, importing the request library, setting up the API endpoint URL and query parameters, making a GET request to the API endpoint with the query parameters, and checking the status code of the response to ensure the request was successful.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What are the steps to obtain satellite images?', 'timestamp': '[0:17:24]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the significance of longitude and latitude in satellite imagery is not addressed.', 'relevancy': '0', 'question': 'What is the significance of longitude and latitude in satellite imagery?', 'timestamp': '[0:24:14]'}, {'status': 'answered', 'answer': "The student mentioned that satellites can be categorized into natural and man-made satellites, and they discussed various types of satellites and their orbits, including low Earth orbit and medium Earth orbit. They also talked about remote sensing and the use of satellites for monitoring the Earth's physical environment.", 'completeness': 'Complete, the student provided a detailed explanation of different types of satellites and their functions.', 'relevancy': '2', 'question': 'What are the different types of satellites?', 'timestamp': '[0:12:36]'}, {'status': 'answered', 'answer': 'The challenges and limitations of chatbots in the medical sector include complex interfaces, time-consuming processes, high installation costs, limited decision-making skills due to insufficient data, memory storage and processing issues, and privacy and security concerns.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What are the challenges and limitations of chatbots in the medical sector?', 'timestamp': '[1:10:16]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about models used in previous research papers for chatbots is not addressed.', 'relevancy': '0', 'question': 'What are the models used in previous research papers for chatbots?', 'timestamp': '[1:16:33]'}, {'status': 'answered', 'answer': 'The benefits of using chatbots for mental health issues include providing privacy for users who may not want to discuss their issues with a human, offering rapid responses, and utilizing machine learning to improve accuracy in understanding and responding to mental health queries.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What are the benefits of using chatbots for mental health issues?', 'timestamp': '[1:10:16]'}], 'summary': 'The transcript discusses the critical role of transportation infrastructure in economic progress, focusing on the importance of roads and maps for enhancing transportation efficiency and convenience. Better mapping can reduce travel times, fuel consumption, and improve public transportation, safety, and accessibility. The extraction of road features from satellite imagery is highlighted as essential for urban planning, transportation management, and disaster response. Challenges in feature extraction include image resolution, occlusion, lighting conditions, variability, and noise, which can complicate accurate information gathering. Various image enhancement techniques like sharpening, image fusion, and histogram equalization are introduced to improve road detail identification. The advancements in object detection algorithms and the tool "Road Taser," which utilizes CNN algorithms for road network analysis, are mentioned. The discussion also covers remote sensing, satellite functions, and the distinction between active and passive sensors. Various image acquisition methods and the use of APIs for satellite data access are outlined. The importance of recommendation systems in artificial intelligence is discussed, including challenges like the cold start problem and data sparsity, along with different recommendation techniques and evaluation metrics. The integration of knowledge graphs into recommendation systems and the development of an attention-enhanced user preference model are explored, focusing on user-entity interactions. The role of chatbots in healthcare accessibility and mental health is emphasized, including their design challenges and the importance of natural language processing. The transcript also covers research on medical chatbots and the application of AI and deep learning to improve chatbot predictive capabilities. Finally, it discusses decision-making in chatbots, data handling, and model deployment processes, stressing the significance of collaboration and understanding existing methodologies.'}
{'_id': ObjectId('66b26b61b80f3f3035517ee9'), 'file_id': ObjectId('620e1838fb338ccd0017f91e'), 'file_name': '1645090869-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/1645090869-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '00:59:02', 'transcription_path': 'video-results/out_66b26b61b80f3f3035517ee9.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 58, 49, 476000), 'file_process_date': datetime.datetime(2024, 10, 3, 15, 39, 13, 245000), 'execution_time': 585.2046, 'status': 'COMPLETED', 'green_line': [{'topic': 'Introduction to Supervised Learning', 'start_time': '00:00:03', 'end_time': '00:01:32', 'transcript': "uh everyone. Good evening, sir. are you all doing? Okay, so today we're gonna start on. a new topic as promised.and the topic that we're gonna start on is supervised learning. so shame on screen. super. so, as we have talked about previously, um,", 'keywords': ['Supervised Learning', 'Machine Learning', 'Data Analysis'], 'summary': 'The session begins with a greeting and an introduction to the new topic of supervised learning. The speaker expresses enthusiasm for the topic and references prior discussions, indicating a continuity in the learning process.'}, {'topic': 'Supervised Learning Concepts', 'start_time': '00:01:33', 'end_time': '00:02:21', 'transcript': "supervised learning is. where we are given a target variable. and we're also given and then put Vector XAnd what we are aiming to do here is essentially estimate the probability of why, given things. we have looked at logistic regression.and it's variants with L one and L two Regularisation. We have looked at naive Bayes. as to potential classification algorithms.", 'keywords': ['Supervised Learning', 'Logistic Regression', 'Naive Bayes'], 'summary': 'The transcript discusses supervised learning, defining it as a method where a target variable is provided alongside input vectors. The objective is to estimate the probability of the target variable based on the input data. The speaker mentions the exploration of logistic regression and its variants, including L1 and L2 regularization, as well as naive Bayes as classification algorithms.'}, {'topic': 'Classification Algorithms', 'start_time': '00:02:22', 'end_time': '00:04:48', 'transcript': "um where y is categorical. and when y is continuous, we have looked at linear regression. So what we're gonna do is we're gonna extend on that and look at a few other algorithms. Um, and, uh, let's start off with one called decision trees.Why not Elizabeth? and with the logistic regression. What we have basically said is we learn the probability of why is equal to one.And we are assuming that there are two sets here. So we are defining this decision boundary and everything on one side belongs to one class, and everything on the other side belongs to another class.", 'keywords': ['Classification Algorithms', 'Decision Trees', 'Logistic Regression'], 'summary': 'The transcript discusses classification algorithms, specifically focusing on the distinction between categorical and continuous outcomes, with a reference to linear regression for continuous variables. The speaker introduces decision trees as a classification method and briefly mentions logistic regression, explaining the concept of learning the probability of a binary outcome (y = 1). They describe the establishment of a decision boundary that separates two classes, where all points on one side belong to one class and all on the other side belong to another class.'}, {'topic': 'Decision Trees', 'start_time': '00:03:00', 'end_time': '00:06:06', 'transcript': "so if we look at what the basic problem is that we're trying to identify. We're basically saying that we havea space defined by a number of input variables. and baby. Yeah, have some positive instances in here or whatever the concept of interest is. I mean, they have some negative instances also. And essentially, what we're trying to do is find a setor instances that are positive examples of the concept we are trying to learn. So the concept that we are trying to learn, uh, could be simply people who deserve to get a bank loan. Rightnow, in identifying this set, we've said that Well, this is really only our training data. uh, for which we have labels here. And what we really want to learn is for the population.What is the definition of this set and the language we use? what describing the set is what discriminates between.Um, with the decision trees, what we are saying is that this language that we have is, uh, this junction.of injunctions. okay. And so, essentially, what we mean by that is um Yeah. something here. Oh! Yeah.what we are. assuming here is that the language allows us to define these tree like structures. where if we look at", 'keywords': ['Decision Trees', 'Training Data', 'Positive Instances'], 'summary': 'The transcript discusses the fundamental problems in identifying positive instances within a defined space of input variables, particularly in the context of decision trees. The speaker explains the goal of finding a set of instances that represent positive examples of a concept, using the example of individuals deserving a bank loan. They clarify that the training data consists of labeled examples, while the ultimate aim is to generalize this understanding to the broader population. The discussion highlights the use of a specific language that can describe these instances through tree-like structures, which is a key aspect of decision trees.'}, {'topic': 'Decision Tree Structure', 'start_time': '00:06:07', 'end_time': '00:08:31', 'transcript': "this tree here we have given data that consists of a number of inputs. So the data looks like this. We've seen this before in the naive Bayes algorithm where we're trying to predict whether somebody should play tennis, which is ry attribute. And all of these attributes here are variables. Here are our input variablesand for simplicity. We are resuming that all of these this data is discreet data, no continuous values. Uh, but of course, everything that we say can be extended to continuous attributes as well. And we will continue to, uh, dip into continuous variables and how they are treated throughout the treatment of decision trees.But essentially, if you look at what's happening here is these trees have two types of notes. These are called decision nodes.that contain one of the input variables and emanating from the decision node. Our branches and each of these branches are associated with a unique value.of the attribute of the random variable that is, you know, stored or associated with the decision note.and then we have these other types of notes called leaf nodes. and what we have here is stored the probability of why the nextand we label these leaf nodes where one of the values. Unique values of the output variable. Right. So this is the unique value.of why. which clearly is going to be that value. That has a higher probability, right? So we have why that can take values. Yes and no. And the fact that we are labelling this note as a no means that the probability of wise, you know, given X is greater than the probability of Y is equal to yes,", 'keywords': ['Decision Tree', 'Discrete Variables', 'Classification'], 'summary': "The transcript explains the structure of decision trees in the context of a classification problem, specifically predicting whether someone should play tennis based on various input attributes. It highlights that the data consists of discrete variables, and notes the potential to extend the discussion to continuous variables. The tree is described as having two types of nodes: decision nodes, which represent input variables and lead to branches associated with unique attribute values, and leaf nodes, which store the probability of the output variable. The leaf nodes are labeled with the value that has a higher probability, indicating the classification outcome, such as 'yes' or 'no'."}, {'topic': 'Decision Boundaries', 'start_time': '00:08:32', 'end_time': '00:12:18', 'transcript': "given x. And so as we travel down the street to a leaf node, what we are getting is essentially a conjunction of predicates here, right? So what we're saying if we travel down this path here,what we're saying is that its outlook is equal to reign. and wind is equal to strong. then. play tennis is equal to no right. So it's a conjunction of these two constraints that we are putting on the object of interest, which is a dayAnd so if we look at describing what would be a day where we would not be interested in instinct and so will not be playing tennis, we can then say, Well, we can travel us down this path here.or we could travel down this path to get to the other leaf note, which has the value knowing it. And so we are now saying that this is a definition of play. Tennessee, equal to no, is a disjunction of injunctions where the second conjunction here is outlook.is equal to Sonny. and humidity. is equal to high, and these are days where you would not want to play tennis.okay? now, if we actually look at this data we could come up with. Another definition of a tennis is no, which would also be a disjunction of conjunctions.But we could essentially create that very easily by saying Well, if outlook is equal to sunny and temperature is equal to heart and humidity is equal to hideand when does equal two week? which is one conjunction. and then we could go or outlook is equal to sunny. Temperature is equal to heart, humidity is equal to high and when does equal to strong.right, So now we have a disjunction. of these two conjunctions. and you can see how we could extend that then for every one of the records that have the label no associated with it, and we would get a perfect classifier.right, So we just go and identify each of these objects. as days where you would not pay Dennis. But these are very differentdecisions, because what we are saying here is in this example, which is also a conjunction of this, uh, disjunction of conjunctions. You're basically saying that if you had five records that were labelled No. And we're treating not playing tennis as a positive instance here and then we havenegative instances here. What we're drawing is a very tight decision boundary around each of the instances within our training data.", 'keywords': ['Decision Boundaries', 'Conjunctions', 'Classification'], 'summary': "The transcript discusses the concept of decision boundaries in the context of a classification problem, specifically related to playing tennis based on weather conditions. It explains how as one traverses a decision tree to reach a leaf node, they are essentially creating a conjunction of predicates that define the conditions under which one would not play tennis. The speaker illustrates this with examples, such as specific combinations of outlook, wind strength, temperature, and humidity that lead to a decision of 'no' for playing tennis. Furthermore, the idea of disjunctions of conjunctions is introduced, showing how multiple rules can be combined to form a more comprehensive classifier. The speaker emphasizes the importance of drawing tight decision boundaries around instances in the training data to improve classification accuracy."}, {'topic': 'Generalization and Overfitting', 'start_time': '00:12:21', 'end_time': '00:13:22', 'transcript': "and saying Those are positive instances and this is really an example of growth to learning. where we are essentially saying that you have a population teamof which you have a subset of that population. Uh, oops. you have a subset of the population, which is the training data and out of that training data, we're saying we're selecting all of those instances that are no and saying that those are the only days on which you would not let Dennisso any other data points that are not in our training data would be considered to be negative instance.right, which is a very tight and strength that's been defined where we are saying that everything else in the population that we haven't you is actually going to be a negative instance according to this model.", 'keywords': ['Generalization', 'Overfitting', 'Training Data'], 'summary': 'The transcript discusses the concepts of generalization and overfitting in the context of machine learning. It describes the process of defining positive instances within a population and how a subset of that population, referred to as training data, is utilized. The speaker explains that instances not included in the training data are classified as negative instances, highlighting the limitations and strict definitions that arise from this modeling approach.'}, {'topic': 'Thresholds in Decision Trees', 'start_time': '00:13:24', 'end_time': '00:16:24', 'transcript': "alternatively, what we're doing here is creating a much more genetic model. where, And this is where I'm gonna flip flop between categorical and numeric.uh, descriptions. What we're doing here is we're saying, if we had positive instances like this and negative instances all around here,what we would do is, we would say, decide to firstly split on the X to attribute. and we would define.uh, decision. Boundary here where we are saying everything above this threshold. is positive and everything below this threshold is negative,right? So if it's less than, say, threshold to which is this value here? we would enable it as negative instance. And then, of course, anything above threshold to Clearly we have positive and negative instances here. So wewe might define a threshold out here, which is Threshold one. And so now what we're doing is we're splitting my next one and saying anything less space than threshold one.is going to be a positive instance. and everything that is greater than Threshold one is going to be a negative.and recognise the fact that this is true only whenever we have values greater than threshold. So actually, this year this decision boundary ends in this partition of the data. And then we would notice that Well, when the threshold is less than the one, we still have annegative couple of negative instances here. So we will actually now define a new threshold on X one as well. But what we are doing is something much more sensible. Here We have genetic boundaries defined where we are essentially saying that I'm not creating a very strict boundary around these positive instances. I'm leaving a lot of space here where I could see other positive instances as well. Soin this particular case here, I have created a much more general decision boundary than what I was able to do when I was not learning a tree and just learning any old disjunction of conjunctions, Right, so that was a little small there. So what we had was a couple of positive instances. We had negative instances here", 'keywords': ['Decision Trees', 'Thresholds', 'Classification'], 'summary': 'The transcript discusses the concept of thresholds in decision trees, highlighting the creation of a more generalized model for classification tasks. It explains the process of defining decision boundaries based on categorical and numeric attributes, where instances are classified as positive or negative depending on their values relative to specified thresholds. The speaker illustrates how to establish these thresholds, demonstrating that positive instances are identified above a certain threshold while negative instances fall below it. The discussion emphasizes the importance of creating broader decision boundaries to accommodate variations in the data, allowing for a more flexible and generalized classification approach.'}, {'topic': 'Induction and Decision Trees', 'start_time': '00:16:28', 'end_time': '00:18:16', 'transcript': "Yeah, and here and what we had done there was to say, the first draught type short here. threshold to define the next to.And then we are going to define threshold here on X one, which is special one, and we might then define.now the threshold here, which is around the threshold three and we end up with next to less than threshold, too.It's all negative. Here we go x one. this is for greater than equal to Threshold two. And then we have left than threshold one redder than the threshold to threshold one storey, Uh, where we are saying anything greater than Threshold one is negative. And then we go and split again on X one, where we're saying anything less than Threshold three is negativeand we have positive when it's greater than a threshold, right? And so we are creating a much more generalised model.compared to when we were just speaking up about the positive instances and creating essentially very tight boundaries around it, saying these are you positive", 'keywords': ['Decision Trees', 'Thresholds', 'Induction'], 'summary': 'The transcript discusses the process of defining thresholds for decision trees in the context of induction. It explains how to establish different thresholds (threshold one, two, and three) for variable X1 to categorize instances into positive and negative groups. The speaker emphasizes the iterative approach of splitting the data based on these thresholds to create a more generalized model, contrasting it with earlier methods that tightly bound positive instances.'}, {'topic': 'Stopping Criteria for Splitting', 'start_time': '00:18:16', 'end_time': '00:20:02', 'transcript': "now to achieve? this. rather than this kind of decision boundary. What we do here in Decision Tree inductionis we say we're going to define a space of decision trees where that space could actually be very, very large. So we can't again enumerate those, but we want to grow those trees from scratch. So given some data, how can we growthe tree out of this? Right? And the way we would do that is we would start off first with just a singleego leaf note. And what would be the label it with? We would label it with the most frequent value that play tennis can take, which is yes. And so we would give it a label. Yes, though, or we would recognise the fact that we havein our example, nine yeses and five knows. And so we would recognise the fact that we erect actually going to get our predictions incorrect five out of 14 times.And this is, of course, on the training data. But we're using the training data to estimate what the underlying distribution of yeses and nos and so we would expect that we would have an error rate of five or 14.", 'keywords': ['Decision Tree', 'Induction', 'Error Rate'], 'summary': "The transcript discusses the process of decision tree induction and the challenges of defining a space for decision trees due to its vastness. It explains the initial step of growing a decision tree from a single leaf node, which is labeled with the most frequent outcome from the dataset, in this case, 'yes' for playing tennis. The speaker notes the distribution of outcomes, highlighting that there are nine 'yes' and five 'no' responses, leading to an expected error rate when making predictions based on training data."}, {'topic': 'Entropy and Information Gain', 'start_time': '00:20:04', 'end_time': '00:22:04', 'transcript': "Now what we want to do now is to say, are any of my input variables able to? reduce the uncertainty about my prediction. Right? So one of the comments that I've made previously is that all that we are doing in machine learning is trying to findthe use of our input variables to reduce. to reduce the variance in our output. Variable now variants we typically think of. And we have a continuous variable. Here we have a categorical variable, but the equivalent would be where we are sayingthat we are in the worst case scenario in a situation where we have a uniform distribution on play tennisand it is impossible at this point. and for us to make any prediction on whether we should play tennis or not, without seeing some evidence valuable. Why? Because we have an equal probability of being correct and wrong. So as any kind of betting person, you would say the uncertainty of winning is too high here You wouldn't want to get. And the idea is that if we can actually look at some evidence and getthis distribution to get skewed soul so that we have a much higher probability of yes and a small probability of no, we'd be much more confident about predicting that we should play tennis. And on the other hand, if we got it to skew the other way, we'd be much more confident to predict that we should not play tennis, Right, So this is what we want to achieve.This is essentially the kind of distribution we have so much closer to, uh, this uniform district contribution of yes and no.", 'keywords': ['Entropy', 'Information Gain', 'Prediction'], 'summary': 'The speaker discusses the concept of entropy and information gain in the context of machine learning, focusing on how input variables can reduce uncertainty in predictions. They highlight the importance of understanding the distribution of outcomes, using a play tennis example to illustrate the challenge of making predictions with a uniform probability distribution. The goal is to skew the distribution in favor of one outcome to increase confidence in predictions, thereby reducing variance in the output variable.'}, {'topic': 'Splitting Criteria', 'start_time': '00:22:05', 'end_time': '00:24:16', 'transcript': "So the question is, how do we actually define the value of a split right? So if we look at where we're starting from, we're starting from a tree that has only one note, which is a leaf node and we are looking at all of our input Variables, x one x two x three and x fourAnd the question is. are any of these capable of creating a tree structure? where we are better off with predicting now that we know the value of one of these verySo this is what we are essentially looking to choose from. so somehow what we need to do to make this decisionis to have some metric. That's as this attribute is better than this attribute to make this choice of what we should split on, right? Like we've made the decision here, obviously using some data that splitting an outlook is better than splitting on with.So that's one key question that we need to answer. The other question that we need to answer is that every one of our input variables is going to have a different card analogy, right? The number of variables values it has it takes.and you can see here that with every decision on splitting the data, we are actually partitioning the data down these two parts, or maybe more than two parts if you know, because we have a branch for every unique value of this attribute that we're splitting on.So there's always going to be less data available for us at the next level, where we would again make a decision on whether we can further partition the data to improve our chances of accurately predicting whether we should play tennis or not.", 'keywords': ['Splitting Criteria', 'Decision Trees', 'Cardinality'], 'summary': 'The discussion focuses on the concept of splitting criteria within decision trees, highlighting how to define the value of a split when starting with a single leaf node. The speaker emphasizes the importance of evaluating various input variables (x1, x2, x3, x4) to determine which attribute can create a better tree structure for prediction. The need for a metric to compare attributes for splitting decisions is stressed, along with the acknowledgment that each input variable has different cardinalities. As the data is split, the partitioning process is described, demonstrating how each decision reduces the amount of data available for subsequent splits, ultimately influencing the accuracy of predictions, such as whether to play tennis or not.'}, {'topic': 'Tree Structure Preferences', 'start_time': '00:24:17', 'end_time': '00:26:28', 'transcript': "Right? And so the question that arises is, should we have a preference for bushy or tall trees? What are bushy trees? Basically, where we choose an attribute that partitions the data into many partitions because it has a lot of unique values. The disadvantage of doing that is that each of these partitions could potentially be very small now because we havegot lots of politicians and any decisions on splitting that we make here are gonna be on less data and therefore statistically unreliable,right. But this is a bushy tree and then at all tree is one where we don't actually do lots of partitions at any one level. But we continue then to make partitions, to get into a scenario where we have a skewed distribution, and so we get what are called poultry.right. And the question is, should we go for tall? Should we go for bushy? We've already talked about bushy is a bad idea because we would potentially have a little data and can't make for the kind of splits. Uh, and of course, some of this, um the the the value that is coming out in terms ofum, seeing your partitions here. Uh, when I said your partitions, I mean, one is that that actually contain a majority of one class rather than the other, could be more an artefact of the fact that we have split the data into smaller pieces rather than actually truly information carrying, uh, attributes like X. And so we need to figure out what is preferred. Typically, what was found empirically was that tall decision trees are better.But at the same time, the question arises is if we have very tall decision trees, then understanding the real pattern becomes difficult because you have very long pathways to travel done.", 'keywords': ['Decision Trees', 'Data Partitioning', 'Statistical Reliability'], 'summary': 'The discussion revolves around the preference between bushy and tall trees in decision tree structures. Bushy trees involve choosing attributes that create many partitions due to numerous unique values, which can lead to small and statistically unreliable data subsets. In contrast, tall trees avoid excessive partitioning at each level, which can result in a skewed distribution. The speaker emphasizes that bushy trees may not be ideal due to the risk of insufficient data for accurate splits, while tall trees, although generally preferred, can complicate the understanding of underlying patterns due to their longer pathways. Empirical evidence suggests that tall decision trees tend to perform better, but their complexity poses challenges in interpreting the data effectively.'}, {'topic': 'Inductive Bias and Decision Trees', 'start_time': '00:26:30', 'end_time': '00:27:39', 'transcript': "The other question that we need to ask ourselves is, how do we decide when to stop the splitting right? So, ideally, we'd want to stop the splitting whenever each of our leave notes has only one.um, output very good value. because at that point we would believe that we have 100% confidence in predicting yes if it's all yeses, right? So, ideally, we'd want to stop when we have a pure partition. But of course, it's not necessarily that we can achieve that because there might be some noise in the data. Andof course, we've also talked about the fact that as we move down this tree, there's lesser data here. So the question is, are we starting to over fit the databy actually learning a tree structure that truly represents the same result as the rote learning that we had seen here, right?", 'keywords': ['Decision Trees', 'Overfitting', 'Data Partitioning'], 'summary': 'The transcript discusses the concept of stopping criteria in decision trees, focusing on the importance of achieving a pure partition where each leaf node has only one output value. The speaker emphasizes the ideal scenario of stopping when there is 100% confidence in predictions, particularly when all outcomes are positive. However, they also highlight the challenges posed by noise in the data and the risk of overfitting as the data decreases further down the tree. The speaker raises concerns about whether the tree structure learned truly reflects the results or if it merely represents rote learning.'}, {'topic': 'Handling Missing Values', 'start_time': '00:27:40', 'end_time': '00:28:15', 'transcript': "So when do we stop? Splitting the tree is another important piece. And then finally, because the tree structure we have a real problem if we have missing values. Right? So if we actually created a tree like this, and then we were to make a prediction on a day where you know whether we can play tennis or not. And we actually had our sensor that computed the value of outlook was point.We won't even know which path to take down here, right? So how do we deal with that scenario? Is another question that we need to answer.", 'keywords': ['Missing Values', 'Decision Tree', 'Prediction'], 'summary': 'The transcript discusses the challenges posed by missing values in decision tree structures, particularly in the context of making predictions. It highlights the confusion and uncertainty that arises when a prediction requires information that is not available, such as the outlook for a day when deciding if tennis can be played. The speaker emphasizes the importance of addressing this issue to ensure accurate decision-making.'}, {'topic': 'Information Gain Calculation', 'start_time': '00:28:16', 'end_time': '00:30:43', 'transcript': "So for the first piece of what is uh, over there that we could choose our attribute to split on. Uh, we use a metric called entropy.Right. And it comes from, uh, information. Hear this concept of entropy and essentially what we How we are calculating entropy is we're saying that if we have the two classes for yes and noand say this it has, you know, yes, has a probability of 0.75. In fact, let's just make 0.5 and no has a probability of 0.5.then entropy is computed as minus 0.5 lots of 0.5 minus 0.5 log of 0.5. It's the probabilities that we are seen for you. Yes and no.And we can see here that essentially, this is equal to minus log of 0.5. And of course, the minus log to the best two of 0.5 is actually one.So whenever there is complete uncertainty in the distribution, the entropy value here gives us the largest value possible. And then as one of our values,values becomes more probable. So as we go to the extremes here. right, so recognise that this is a Bernoulli distribution and p I here is the probability of success, the one parameter that we have. So if we are saying that a success is getting a yes, then what we're saying is whenever the probability of yes is very low or very high close to one,the entropy goes to zero, so we can think of entropy as a measure of disorder. or uncertainty. right and", 'keywords': ['Entropy', 'Information Gain', 'Probability'], 'summary': "The transcript discusses the concept of entropy as a metric used for attribute selection in information gain calculation. It explains how entropy is computed using probabilities for two classes, 'yes' and 'no'. The speaker illustrates this with an example where both classes have equal probabilities of 0.5, leading to the maximum entropy value. It is described that as the probabilities for one class become more certain, the entropy value decreases, approaching zero. The speaker emphasizes that entropy serves as a measure of disorder or uncertainty in a distribution, particularly in the context of Bernoulli distributions."}, {'topic': 'Gain Ratio and Attribute Selection', 'start_time': '00:30:45', 'end_time': '00:32:49', 'transcript': "we can think of any attribute x one. that partitions the data into a number of partitions. right. So actually, to stick to the technology that we have here, let's not call it X one. Let's just call the attribute A that has a number of values that can take.and we've got these partitions here. now we can calculate the entropy. at the parent node level, we can calculate the entropy for each other partitions.that are generated by selecting one of the values that they can take. and we now need to combine these entropy is in somewhere and hopefully, uh, you know, get a measure of the overall entropy.that has produced given our observation of a So essentially, what we are doing is we will calculate the Zen trapeze and take the waited some of these n trapeze.across all the values that the attribute they can take and what is the weight the weight is. the size of the partitionas a percentage of the overall data in here. right. So this here is a weighted average of the n trapeze at each of the partitions, and the rates are essentially accounting for how much of the data partition.goes down each of these branches. and taking this waited some away from the entropy. Here is what is referred to as information, okay?", 'keywords': ['Entropy', 'Gain Ratio', 'Attribute Selection'], 'summary': "The transcript discusses the concept of gain ratio and attribute selection in data partitioning. It explains how an attribute, referred to as A, can create multiple partitions of data. The speaker describes the process of calculating entropy at the parent node level and for each partition generated by the attribute's values. A method to combine these entropy values into an overall measure is presented, emphasizing the importance of weighted averages based on the size of each partition relative to the total data. The final outcome is referred to as information, which is derived from the weighted sum of the entropies across the partitions."}, {'topic': 'Final Decisions and Tree Growth', 'start_time': '00:32:50', 'end_time': '00:35:56', 'transcript': "this metric here. Okay, so it's really saying, How much have I been able to reduce my uncertainty or disorder in my data with regard to the class labelby getting to know the value of an attribute? right. So, in a way, what we are now what we've got is the ability to rank attributesthat are in our input vector based on how much information game they provide. if we know the value of that attribute.right. And so out here we can. For the data that you had seen, we had yeses and nos we had nine yesesand by nose. and so we are able to calculate the entropy. The entropy is high. It's close to one. And now what we're looking at isfor each of our input variables. So outlook had three values sunny, overcast and rain temperature had hot, mild and coal cool. And for each of the partitions of our training data, we're now looking at the distribution.of the class level, the variable y right for each value here. And so we are able to calculate the entropy we can see for the case of outlookwhen we have the value overcast. right, we have only Yes. here? Yes. Here. Yes, here and yes, here. So we only haveplay tennis equal to Yes. So we've got a pure partition. And the entropy is therefore zero. And for the other two values sunny and rain. We actually have a close to uniform distribution of Yes and no. So we have a high introduce. The entropy is actually increased.in those two partitions compared to what it was in the overall data. But we now have a partition of data where we have zero energy.and when we then cheque. You have the values here. and when we now take the um and when we now take into account the wets associated with these. So there were basically four instances that were overcast and five I think of Sonny and five of Rain. We end up with an information gain of 0.25.Compared to that, we end up with an information gain for temperature of 0.029. Community is 0.151 and 0.04. Right, So just to make sure", 'keywords': ['Entropy', 'Information Gain', 'Decision Trees'], 'summary': "The transcript discusses the concept of entropy in relation to decision trees and how it quantifies the uncertainty or disorder in the data concerning class labels. It explains the process of ranking input attributes based on the information they provide, particularly in a dataset with binary outcomes (yes/no). The speaker illustrates this with examples from a dataset containing attributes such as outlook and temperature, calculating the entropy for different partitions of the data. The example highlights that certain attribute values, like 'overcast', result in a pure partition with zero entropy, while others such as 'sunny' and 'rain' produce higher entropy due to a more uniform distribution of yes and no outcomes. The discussion concludes with a comparison of information gains for different attributes."}, {'topic': 'ID3 Algorithm Overview', 'start_time': '00:35:56', 'end_time': '00:38:15', 'transcript': "that we are clear on how this is calculated, let's take the value of wind. we have out here or wind is strong.when wind is strong, we have 123, 45 and six. We have three records of yes and three records of no. And that's why the entropy ends up one. So we have six records here, and we have eight records here where we have to nose and six yeses.And so what we're saying is it's 8/14 times 0.81 plus 6/14 into one, which is the entropy after the partitioning, and we're subtracting that fromthe overall entropy of 0.94. Okay, so what we could see here is the fact that I can't seem to see the last piece here. Okay, here we are. Sowhat we can see here is the information gain and the algorithm that induces these trees fix the attribute that gets the maximum information game. So it's a greedy.algorithm just like radiant descent. That's saying I'm going to move in my third space of all trees from a situation where I had just a single leaf node, which I was giving a label of. Yes, because there were nine years is to it.I am now going to move to a tree that consists of outlook. at the root note and three branches. for each of the three values of Outlook, which now contain three partitions of data.", 'keywords': ['ID3 Algorithm', 'Entropy', 'Information Gain'], 'summary': "The transcript provides an overview of the ID3 algorithm, focusing on the calculation of entropy and information gain in decision tree construction. The speaker explains how the entropy is determined based on records of 'yes' and 'no' responses related to wind conditions. They detail the process of partitioning data and calculating the information gain by comparing the overall entropy with the entropy after partitioning. The algorithm is described as greedy, akin to gradient descent, as it seeks to maximize information gain by selecting the optimal attribute to split the data, ultimately leading to a decision tree structure."}, {'topic': 'Tree Building Process', 'start_time': '00:38:17', 'end_time': '00:39:37', 'transcript': "the first one? No, is the most likely outcome. Just slightly. The third one yes, is the most likely outcome, just slightly and then overcast. The overwhelming answer is yes.And I have now essentially moved in my third space, where every node in my third space as a tree I've moved from a tree that said just yes to every classified every instance as a positive date. Tennis to now a tree where we actually make some predictions that I know.and in the next situation, I am now going to look at whether I can add another decision node to either of these two notes because this one is pure, so I can't actually add any value by further growing this treeright, and I'm going to follow the same process here. right. So I'm I'm traversing through the space of trees where each operatorin that search spaces, allowing me to add a little more debt to the tree to try and reduce the overall entropy of the overall uncertainty in making a prediction.", 'keywords': ['Decision Trees', 'Entropy', 'Predictions'], 'summary': 'The transcript discusses the tree building process in the context of decision trees used for predictions. The speaker explains the transition from a simplistic tree that classifies every instance positively to a more nuanced approach that includes making predictions. They describe the process of adding decision nodes to optimize the tree structure, focusing on reducing entropy and uncertainty in predictions as they traverse the search space of trees.'}, {'topic': 'Decision Tree Algorithms', 'start_time': '00:39:39', 'end_time': '00:40:46', 'transcript': 'okay? so the I d three algorithm, which was created by a guy called Ross Quinlan for his PhD. uh, was really the first decision tree algorithm that was developed. And actually there was an alternative called cart that was also developed around the same time by videoRheiman. another famous statistician. And there were a couple of other variants also of these. But, uh, you know, these are the two contenders that really cannot survive. There was another one developed by Yvonne Practical.who is from the Joseph, uh, Stefan Institute in Slovenia. But these two are typically the ones that we see in existence today, and I D three has gone through a number of iterations. So I d three became C 4.5 which is now I think, known as C 5.0 so you might see references heroes.', 'keywords': ['Decision Tree', 'ID3', 'CART'], 'summary': 'The transcript discusses the history and development of decision tree algorithms, focusing on the ID3 algorithm created by Ross Quinlan during his PhD. It highlights the emergence of alternative algorithms such as CART developed by another statistician, Leo Breiman, and mentions other variants, while emphasizing that ID3 and CART are the primary contenders still in use. The speaker notes that ID3 has evolved into C4.5, which is now often referred to as C5.0, indicating the ongoing advancements in this area.'}, {'topic': 'Inductive Bias in Learning', 'start_time': '00:40:48', 'end_time': '00:42:10', 'transcript': "So let's look at I d three. So what does I did? Three Do it gets a set of data and a set of target attribute. We're not set of target attributes one target attribute, which is why?and a set of attributes, which is the input set of attributes available. And what does it do? It creates a root node for the tree.And then, if all of the examples here are positive, then it ends the function, giving a label positiveto that root node, which was a leaf node. And if all the examples are negative, then does the opposite, it gives a label of negative to the root note, and that note is all that we have in terms of belief note for the street.If neither of these two is true, then it cheques for whether there are attributes. in this list here that we can potentially split our data on.and if there are no attributes left, then it returns the single naughty tree route. right and says I'm going to label it with the most common value available.", 'keywords': ['Inductive Bias', 'Decision Tree', 'Root Node'], 'summary': 'The transcript discusses the process of creating a decision tree in the context of inductive bias in learning. It explains how the algorithm operates on a dataset with a single target attribute and multiple input attributes. The tree construction begins with a root node, which is labeled positive if all examples are positive, or negative if all are negative. If neither condition is met, the algorithm checks for potential attributes to split the data. If no attributes remain, it labels the root node with the most common value from the dataset.'}, {'topic': 'Recursive Tree Construction', 'start_time': '00:42:12', 'end_time': '00:45:24', 'transcript': "or the target attribute within examples. but examples is that training dead. But now what it does, it starts to recursive Li try and build this tree, right? So what it's doing is if there are attributes that it can split on, then it looks for the attribute that best classifies examples. And as we have seen, we've seen one example of that which is information.uh, game. right being an attribute that decides on which attribute is the best attribute is the one with maximuminformation. and it then assigns that attribute as the root attribute for the tree, and for each possible value of that attribute, it creates a branchand those examples. in our data set that has been passed into this function that have a particular value V I associated with it. That subset is passed down that branch.now, if this subset is empty, So how do we get the subset to be empty notice? Here we are saying for every possible value of aright, So we're actually looking at the domain of air and creating a branch for every one of these values that can take.Now, the reason why it can be empty is that we could be expanding this tree here right where we've actually, uh, already split an outlook.And when outlook is raining temperature. Yeah, it only takes two values. Uh, medium temperature or hot.Not cold. There is no data. They're cold. But what we are saying is in that scenario, even the cold does not exist in a training data. We will still create a branch, and we'll assign it a value. And what assign value to be assigned to it? The most common value of the target Attribute in examples, right?and this is a little messed up. This needs to be out here. So this is the else part of this. If so, if it's not empty,then we call the idea three. function again. Recursive Lee, where we are passing to it. Only this partition of data that contains those valuesassociated with the FBI and the target attribute remains unchanged. And what do we do? We actually remove the attribute that has already been used here as the root right, So we have the coercively continuing to partition.", 'keywords': ['Recursive Tree', 'Information Gain', 'Decision Tree'], 'summary': 'The transcript discusses the process of recursive tree construction in machine learning. It explains how the algorithm attempts to build a decision tree by recursively splitting the dataset based on attributes that best classify the examples. The speaker highlights the significance of the information gain metric for determining the best attribute to split on, which becomes the root of the tree. For each possible value of this attribute, branches are created, and subsets of data are directed down these branches. The speaker also notes that even if a subset for a certain value is empty, a branch is still created, assigning it the most common value of the target attribute from the training data. The recursion continues by calling the tree construction function again with the relevant partition of data while removing the already used attribute from consideration.'}, {'topic': 'Bias in Induction', 'start_time': '00:45:25', 'end_time': '00:48:20', 'transcript': "and generate the tree similar to what we saw previous. Okay, so it's a very, very simple algorithm. and this brings us to an important concept of inductive bias.so the process of induction. is what the process where we say we have specific instances. of the concept of interest,and from that we are generalising. generalising. two. uh, theory of some form. that we can learn from these specific instances, right? So there's this process. Induction is the process of generalising, from specific instances to a concept description of some kindright now when we do induction. we have to be cognisant of, firstly, the language that we use for describing these theories. You know what we are saying by theory Here is really the model.right. So the language that we use to define this model in the case that we are dealing with right now is we are saying that it's going to be,uh, disjunction. off conjunctions. And as we have said earlier, remember when we have two classes plus and minus Really, what we're trying to define is the set of instancesthat are positive instances. And of course, everything else is a negative instance, right? And so we are really trying to define this set,and we have seen that the disjunction of conjunctions is actually capable of describing any of these sets. So if we have a finite population of size n.we are essentially doing a search in the power set of the population of which they are going to be in the power set. They're going to betwo to the power of end. subsets, right? And we are essentially trying to evaluate which of these subsetsis. the true set of interest of positive instances, right? And so what we're saying here is that we can define any set using a disjunction of conjunction. So,", 'keywords': ['Inductive Bias', 'Induction', 'Disjunction of Conjunctions'], 'summary': 'The transcript discusses the concept of inductive bias in the context of induction. It explains that induction involves generalizing from specific instances to form a theory or model. The speaker emphasizes the importance of the language used to describe these theories, particularly noting that the model in question is represented as a disjunction of conjunctions. They elaborate on how this approach allows for the definition of positive and negative instances within a finite population, ultimately indicating the method of searching through the power set of the population to identify the true set of positive instances.'}, {'topic': 'Preference Bias in Decision Trees', 'start_time': '00:48:21', 'end_time': '00:50:27', 'transcript': "in general, the language that is being used as no bias within it compare that with linear regression where we are seeing the expected value of Y.is equal to beat a zero, plus the direct sigh. In that scenario, we are definitely putting a strong restriction onlanguage where we are saying that the curve that we can fit is got to be Libya, right? And so this kind of, uh, language restriction is what is referred to as a restriction bias.and an alternative is what is called a preference bias, which is related to how we search the space of all hypotheses.right. And so when we do a greedy search of the kind that we have just done in decision trees where we are saying I'm going to start to grow my treeand I'm going to choose an attribute at a time that maximises My information came. I'm doing a greedy search here. I'm defining a reference on one type of three as opposed to another type of tree.right and an important reference bias is this thing called Occam's Razor, which says that we should prefer simplest hypotheses that fit the data well.right. And so when we talked about Regularisation for lasso and rigid aggression. What were we doing there? We were essentially giving a preference to simpler hypothesis where we were able to drive that coefficient for attributes that are not really relevant to what we're trying to predict down towards zero.", 'keywords': ['Preference Bias', 'Decision Trees', "Occam's Razor"], 'summary': "The transcript discusses preference bias in decision trees, contrasting it with linear regression. It explains that linear regression imposes a strong restriction on the language used, known as restriction bias, whereas preference bias pertains to the method of hypothesis space search. The speaker highlights the greedy search method used in decision trees, which involves selecting attributes that maximize information gain. They introduce Occam's Razor, advocating for simpler hypotheses that fit the data well. The discussion also touches on regularization techniques like lasso and ridge regression, which promote simpler models by reducing the coefficients of irrelevant attributes towards zero."}, {'topic': 'Overfitting and Regularization', 'start_time': '00:50:30', 'end_time': '00:53:10', 'transcript': "okay, so hopefully from the perspective of the process of induction. you understand that we have to have a bias of some sort?Why we have to have a bias If we actually used an unrestricted language like we are doing here a disjunction of conjunctions.we would essentially over fit. right because we would actually learn. the positive instances and just take those instances and take a disjunction of those which would mean that in our test dataif we had five positive instances, x one x two x three and x four and x five We would essentially find the set consisting of x one x 22 x five and said these are the only positive instances possible in the population, and this would be a perfect match to attend training data,right? Not that state of training together, but it will be a hopeless match on unseen data, right, because there will always be other positive instances that we haven't seen.So to avoid us learning certain types of hypothesis, we add in, uh, preference bias that says, I want to bias my search to the population of all hypothesisin such a way that I learnt. a better model, right? This is a good model. It fits the training data perfectly.but it's not going to generalise beyond the training, right. And so we create this preference where we are avoiding learning these kinds of trees.Right? So, uh, you know, this is kind of a necessary evil in any kind of induction. and so with neural networks. Also where we are saying that it's actually a universal approximate or it can approximate any function as long as we give it enough nodes to learn, Umwe are still creating a search bias where we're using this greedy approach to searching, which we are hoping is going to avoid overfitting right? And so we are adding in regularisation and such the likes of that to minimise the probability of overfitting this otherwise highly expressive language.", 'keywords': ['Overfitting', 'Regularization', 'Bias'], 'summary': 'The transcript discusses the concepts of overfitting and regularization in the context of machine learning. It emphasizes the necessity of having a bias in the learning process to prevent overfitting, which occurs when a model learns only from the positive instances in the training data. This leads to a perfect match with the training set but fails to generalize to unseen data. The speaker explains the importance of introducing preference bias to improve model performance and ensure better generalization. They also touch on the notion that neural networks, while capable of approximating any function given enough nodes, still require careful consideration of search bias and regularization techniques to mitigate the risk of overfitting.'}, {'topic': 'Heuristics in Decision Trees', 'start_time': '00:53:14', 'end_time': '00:57:13', 'transcript': "now to add to some of the heuristics within the search. What Quinlan found was that information gained was biassed and it was biassed towards.attributes that had many values, so it basically resulted in poetry. and, as we said earlier, bushy trees, beans quicker, partitioning into small subsetsand the probability of these subsets being pure just by definition of them being smaller subset is much higher and therefore it's better for us to try and avoid such early partitioning.And so what do you did? Was he defined a new metric called gain ratio were given an attribute? A where we were considering doing a split of our sample of data as so That's the sample.and that is an attribute. where earlier we were just using the information gain to make a decision on whether to partition or a or some other attribute.he divided it by this metrical split information. and if we look at split information what we're doing here is we're saying that attribute a has C values that it takes so domains of sides seeand each of the s eyes, other partitions. created. bye value. Let's say a I write So a takes values a one a two to a c and s I is the partition that has the value ai with it. Remember, this is within the training, right?So in effect, this here is the probability of a is equal to a I. And so what we've got here is nothing other than probability ofis equal to a I log probability of a is equal to a I. So that's actually entropy. But the entropy here is being calculated not on theoutput variable y. It's been calculated on a And why are we thinking that is useful? Well, if we have an attribute, athat has uniform distribution. in our data across all of its many values. We are going to get a set of smallpartitions, right associated with each of our values a one a two a C. If, on the other hand, we had our attribute A which was primarily to values even and a two and the other values, even though there were c of them were very rare.What we are saying is, well, you know, we're still really the effective number of values that is taking is really to it's not see right because there's this very small partitions that gets skimmed off the data, but we still have a small number of large partitions that are getting propagated through the tree.so we would prefer not to use a if we had a distribution that helped us a real blow in terms of all of us.", 'keywords': ['Heuristics', 'Decision Trees', 'Gain Ratio'], 'summary': 'The transcript discusses heuristics in decision trees, particularly focusing on a discovery by Quinlan regarding the bias in information gain towards attributes with numerous values. This bias can lead to the creation of bushy trees that partition data into smaller subsets, which inherently have a higher probability of being pure. To address this issue, Quinlan introduced a new metric called gain ratio, which modifies the traditional information gain metric by incorporating split information. The explanation delves into how this gain ratio is calculated based on the probability of an attribute taking on specific values and its implications on the purity of partitions. It emphasizes the importance of choosing attributes wisely based on their distribution, suggesting that attributes with a uniform distribution across many values may lead to smaller, less informative partitions, while attributes with a concentrated distribution are more effective.'}, {'topic': 'Conclusion and Future Topics', 'start_time': '00:57:14', 'end_time': '00:59:00', 'transcript': "of the partitions becoming small, and we would rather use if it was effectively lower. Cardinality attribute right? And so remember entropy out here would be one, and the entropy here would be less than one. And so when we divide by less than one, what happens here?the gain ratio will be higher than the information gain. When we divide by one, we are in a way dampening down the possibility of a being chosen.if it's going to create these many partitions out, right? So this using it gain ratio rather than information gain actually tookwhere this virus that was otherwise associated with attributes that have any values associated with it. And so this book behaviour of the tree actually, uhand the way by using this information. Any questions on any of this? We come to the end of time, so I'll carry on from here in the next lecture. But any questions on what has been discussed at?no. I have a different question. Uh, will we be doing your decision, please? you were radiant boosted ensemble model,you'll be doing random forest and radiant boosted decision trees. Okay, Well, if there's no questions, I let you go to you tomorrow.", 'keywords': ['Gain Ratio', 'Entropy', 'Decision Trees'], 'summary': 'The transcript concludes with a discussion on the effectiveness of using gain ratio over information gain when evaluating partitions in decision trees. The speaker explains how entropy values influence the gain ratio, noting that a lower entropy can lead to a higher gain ratio. The conversation touches on the tree behavior in relation to attributes and values, and addresses questions from the audience regarding future topics, including decision trees and ensemble models such as random forests and gradient boosted decision trees. The session wraps up with an invitation for further questions and a note on continuing the discussion in the next lecture.'}], 'yellow_line': [{'Topic': 'Introduction to Supervised Learning', 'transcript': "uh everyone. Good evening, sir. are you all doing? Okay, so today we're gonna start on. a new topic as promised.and the topic that we're gonna start on is supervised learning. so shame on screen. super. so, as we have talked about previously, um,", 'start_time': '00:00:03', 'end_time': '00:01:32'}, {'Topic': 'Supervised Learning Concepts', 'transcript': "supervised learning is. where we are given a target variable. and we're also given and then put Vector XAnd what we are aiming to do here is essentially estimate the probability of why, given things. we have looked at logistic regression.and it's variants with L one and L two Regularisation. We have looked at naive Bayes. as to potential classification algorithms.", 'start_time': '00:01:33', 'end_time': '00:02:21'}, {'Topic': 'Classification Algorithms', 'transcript': "um where y is categorical. and when y is continuous, we have looked at linear regression. So what we're gonna do is we're gonna extend on that and look at a few other algorithms. Um, and, uh, let's start off with one called decision trees.Why not Elizabeth? and with the logistic regression. What we have basically said is we learn the probability of why is equal to one.And we are assuming that there are two sets here. So we are defining this decision boundary and everything on one side belongs to one class, and everything on the other side belongs to another class.", 'start_time': '00:02:22', 'end_time': '00:04:48'}, {'Topic': 'Decision Trees', 'transcript': "so if we look at what the basic problem is that we're trying to identify. We're basically saying that we havea space defined by a number of input variables. and baby. Yeah, have some positive instances in here or whatever the concept of interest is. I mean, they have some negative instances also. And essentially, what we're trying to do is find a setor instances that are positive examples of the concept we are trying to learn. So the concept that we are trying to learn, uh, could be simply people who deserve to get a bank loan. Rightnow, in identifying this set, we've said that Well, this is really only our training data. uh, for which we have labels here. And what we really want to learn is for the population.What is the definition of this set and the language we use? what describing the set is what discriminates between.Um, with the decision trees, what we are saying is that this language that we have is, uh, this junction.of injunctions. okay. And so, essentially, what we mean by that is um Yeah. something here. Oh! Yeah.what we are. assuming here is that the language allows us to define these tree like structures. where if we look at", 'start_time': '00:03:00', 'end_time': '00:06:06'}, {'Topic': 'Decision Tree Structure', 'transcript': "this tree here we have given data that consists of a number of inputs. So the data looks like this. We've seen this before in the naive Bayes algorithm where we're trying to predict whether somebody should play tennis, which is ry attribute. And all of these attributes here are variables. Here are our input variablesand for simplicity. We are resuming that all of these this data is discreet data, no continuous values. Uh, but of course, everything that we say can be extended to continuous attributes as well. And we will continue to, uh, dip into continuous variables and how they are treated throughout the treatment of decision trees.But essentially, if you look at what's happening here is these trees have two types of notes. These are called decision nodes.that contain one of the input variables and emanating from the decision node. Our branches and each of these branches are associated with a unique value.of the attribute of the random variable that is, you know, stored or associated with the decision note.and then we have these other types of notes called leaf nodes. and what we have here is stored the probability of why the nextand we label these leaf nodes where one of the values. Unique values of the output variable. Right. So this is the unique value.of why. which clearly is going to be that value. That has a higher probability, right? So we have why that can take values. Yes and no. And the fact that we are labelling this note as a no means that the probability of wise, you know, given X is greater than the probability of Y is equal to yes,", 'start_time': '00:06:07', 'end_time': '00:08:31'}, {'Topic': 'Decision Boundaries', 'transcript': "given x. And so as we travel down the street to a leaf node, what we are getting is essentially a conjunction of predicates here, right? So what we're saying if we travel down this path here,what we're saying is that its outlook is equal to reign. and wind is equal to strong. then. play tennis is equal to no right. So it's a conjunction of these two constraints that we are putting on the object of interest, which is a dayAnd so if we look at describing what would be a day where we would not be interested in instinct and so will not be playing tennis, we can then say, Well, we can travel us down this path here.or we could travel down this path to get to the other leaf note, which has the value knowing it. And so we are now saying that this is a definition of play. Tennessee, equal to no, is a disjunction of injunctions where the second conjunction here is outlook.is equal to Sonny. and humidity. is equal to high, and these are days where you would not want to play tennis.okay? now, if we actually look at this data we could come up with. Another definition of a tennis is no, which would also be a disjunction of conjunctions.But we could essentially create that very easily by saying Well, if outlook is equal to sunny and temperature is equal to heart and humidity is equal to hideand when does equal two week? which is one conjunction. and then we could go or outlook is equal to sunny. Temperature is equal to heart, humidity is equal to high and when does equal to strong.right, So now we have a disjunction. of these two conjunctions. and you can see how we could extend that then for every one of the records that have the label no associated with it, and we would get a perfect classifier.right, So we just go and identify each of these objects. as days where you would not pay Dennis. But these are very differentdecisions, because what we are saying here is in this example, which is also a conjunction of this, uh, disjunction of conjunctions. You're basically saying that if you had five records that were labelled No. And we're treating not playing tennis as a positive instance here and then we havenegative instances here. What we're drawing is a very tight decision boundary around each of the instances within our training data.", 'start_time': '00:08:32', 'end_time': '00:12:18'}, {'Topic': 'Generalization and Overfitting', 'transcript': "and saying Those are positive instances and this is really an example of growth to learning. where we are essentially saying that you have a population teamof which you have a subset of that population. Uh, oops. you have a subset of the population, which is the training data and out of that training data, we're saying we're selecting all of those instances that are no and saying that those are the only days on which you would not let Dennisso any other data points that are not in our training data would be considered to be negative instance.right, which is a very tight and strength that's been defined where we are saying that everything else in the population that we haven't you is actually going to be a negative instance according to this model.", 'start_time': '00:12:21', 'end_time': '00:13:22'}, {'Topic': 'Thresholds in Decision Trees', 'transcript': "alternatively, what we're doing here is creating a much more genetic model. where, And this is where I'm gonna flip flop between categorical and numeric.uh, descriptions. What we're doing here is we're saying, if we had positive instances like this and negative instances all around here,what we would do is, we would say, decide to firstly split on the X to attribute. and we would define.uh, decision. Boundary here where we are saying everything above this threshold. is positive and everything below this threshold is negative,right? So if it's less than, say, threshold to which is this value here? we would enable it as negative instance. And then, of course, anything above threshold to Clearly we have positive and negative instances here. So wewe might define a threshold out here, which is Threshold one. And so now what we're doing is we're splitting my next one and saying anything less space than threshold one.is going to be a positive instance. and everything that is greater than Threshold one is going to be a negative.and recognise the fact that this is true only whenever we have values greater than threshold. So actually, this year this decision boundary ends in this partition of the data. And then we would notice that Well, when the threshold is less than the one, we still have annegative couple of negative instances here. So we will actually now define a new threshold on X one as well. But what we are doing is something much more sensible. Here We have genetic boundaries defined where we are essentially saying that I'm not creating a very strict boundary around these positive instances. I'm leaving a lot of space here where I could see other positive instances as well. Soin this particular case here, I have created a much more general decision boundary than what I was able to do when I was not learning a tree and just learning any old disjunction of conjunctions, Right, so that was a little small there. So what we had was a couple of positive instances. We had negative instances here", 'start_time': '00:13:24', 'end_time': '00:16:24'}, {'Topic': 'Induction and Decision Trees', 'transcript': "Yeah, and here and what we had done there was to say, the first draught type short here. threshold to define the next to.And then we are going to define threshold here on X one, which is special one, and we might then define.now the threshold here, which is around the threshold three and we end up with next to less than threshold, too.It's all negative. Here we go x one. this is for greater than equal to Threshold two. And then we have left than threshold one redder than the threshold to threshold one storey, Uh, where we are saying anything greater than Threshold one is negative. And then we go and split again on X one, where we're saying anything less than Threshold three is negativeand we have positive when it's greater than a threshold, right? And so we are creating a much more generalised model.compared to when we were just speaking up about the positive instances and creating essentially very tight boundaries around it, saying these are you positive", 'start_time': '00:16:28', 'end_time': '00:18:16'}, {'Topic': 'Stopping Criteria for Splitting', 'transcript': "now to achieve? this. rather than this kind of decision boundary. What we do here in Decision Tree inductionis we say we're going to define a space of decision trees where that space could actually be very, very large. So we can't again enumerate those, but we want to grow those trees from scratch. So given some data, how can we growthe tree out of this? Right? And the way we would do that is we would start off first with just a singleego leaf note. And what would be the label it with? We would label it with the most frequent value that play tennis can take, which is yes. And so we would give it a label. Yes, though, or we would recognise the fact that we havein our example, nine yeses and five knows. And so we would recognise the fact that we erect actually going to get our predictions incorrect five out of 14 times.And this is, of course, on the training data. But we're using the training data to estimate what the underlying distribution of yeses and nos and so we would expect that we would have an error rate of five or 14.", 'start_time': '00:18:16', 'end_time': '00:20:02'}, {'Topic': 'Entropy and Information Gain', 'transcript': "Now what we want to do now is to say, are any of my input variables able to? reduce the uncertainty about my prediction. Right? So one of the comments that I've made previously is that all that we are doing in machine learning is trying to findthe use of our input variables to reduce. to reduce the variance in our output. Variable now variants we typically think of. And we have a continuous variable. Here we have a categorical variable, but the equivalent would be where we are sayingthat we are in the worst case scenario in a situation where we have a uniform distribution on play tennisand it is impossible at this point. and for us to make any prediction on whether we should play tennis or not, without seeing some evidence valuable. Why? Because we have an equal probability of being correct and wrong. So as any kind of betting person, you would say the uncertainty of winning is too high here You wouldn't want to get. And the idea is that if we can actually look at some evidence and getthis distribution to get skewed soul so that we have a much higher probability of yes and a small probability of no, we'd be much more confident about predicting that we should play tennis. And on the other hand, if we got it to skew the other way, we'd be much more confident to predict that we should not play tennis, Right, So this is what we want to achieve.This is essentially the kind of distribution we have so much closer to, uh, this uniform district contribution of yes and no.", 'start_time': '00:20:04', 'end_time': '00:22:04'}, {'Topic': 'Splitting Criteria', 'transcript': "So the question is, how do we actually define the value of a split right? So if we look at where we're starting from, we're starting from a tree that has only one note, which is a leaf node and we are looking at all of our input Variables, x one x two x three and x fourAnd the question is. are any of these capable of creating a tree structure? where we are better off with predicting now that we know the value of one of these verySo this is what we are essentially looking to choose from. so somehow what we need to do to make this decisionis to have some metric. That's as this attribute is better than this attribute to make this choice of what we should split on, right? Like we've made the decision here, obviously using some data that splitting an outlook is better than splitting on with.So that's one key question that we need to answer. The other question that we need to answer is that every one of our input variables is going to have a different card analogy, right? The number of variables values it has it takes.and you can see here that with every decision on splitting the data, we are actually partitioning the data down these two parts, or maybe more than two parts if you know, because we have a branch for every unique value of this attribute that we're splitting on.So there's always going to be less data available for us at the next level, where we would again make a decision on whether we can further partition the data to improve our chances of accurately predicting whether we should play tennis or not.", 'start_time': '00:22:05', 'end_time': '00:24:16'}, {'Topic': 'Tree Structure Preferences', 'transcript': "Right? And so the question that arises is, should we have a preference for bushy or tall trees? What are bushy trees? Basically, where we choose an attribute that partitions the data into many partitions because it has a lot of unique values. The disadvantage of doing that is that each of these partitions could potentially be very small now because we havegot lots of politicians and any decisions on splitting that we make here are gonna be on less data and therefore statistically unreliable,right. But this is a bushy tree and then at all tree is one where we don't actually do lots of partitions at any one level. But we continue then to make partitions, to get into a scenario where we have a skewed distribution, and so we get what are called poultry.right. And the question is, should we go for tall? Should we go for bushy? We've already talked about bushy is a bad idea because we would potentially have a little data and can't make for the kind of splits. Uh, and of course, some of this, um the the the value that is coming out in terms ofum, seeing your partitions here. Uh, when I said your partitions, I mean, one is that that actually contain a majority of one class rather than the other, could be more an artefact of the fact that we have split the data into smaller pieces rather than actually truly information carrying, uh, attributes like X. And so we need to figure out what is preferred. Typically, what was found empirically was that tall decision trees are better.But at the same time, the question arises is if we have very tall decision trees, then understanding the real pattern becomes difficult because you have very long pathways to travel done.", 'start_time': '00:24:17', 'end_time': '00:26:28'}, {'Topic': 'Inductive Bias and Decision Trees', 'transcript': "The other question that we need to ask ourselves is, how do we decide when to stop the splitting right? So, ideally, we'd want to stop the splitting whenever each of our leave notes has only one.um, output very good value. because at that point we would believe that we have 100% confidence in predicting yes if it's all yeses, right? So, ideally, we'd want to stop when we have a pure partition. But of course, it's not necessarily that we can achieve that because there might be some noise in the data. Andof course, we've also talked about the fact that as we move down this tree, there's lesser data here. So the question is, are we starting to over fit the databy actually learning a tree structure that truly represents the same result as the rote learning that we had seen here, right?", 'start_time': '00:26:30', 'end_time': '00:27:39'}, {'Topic': 'Handling Missing Values', 'transcript': "So when do we stop? Splitting the tree is another important piece. And then finally, because the tree structure we have a real problem if we have missing values. Right? So if we actually created a tree like this, and then we were to make a prediction on a day where you know whether we can play tennis or not. And we actually had our sensor that computed the value of outlook was point.We won't even know which path to take down here, right? So how do we deal with that scenario? Is another question that we need to answer.", 'start_time': '00:27:40', 'end_time': '00:28:15'}, {'Topic': 'Information Gain Calculation', 'transcript': "So for the first piece of what is uh, over there that we could choose our attribute to split on. Uh, we use a metric called entropy.Right. And it comes from, uh, information. Hear this concept of entropy and essentially what we How we are calculating entropy is we're saying that if we have the two classes for yes and noand say this it has, you know, yes, has a probability of 0.75. In fact, let's just make 0.5 and no has a probability of 0.5.then entropy is computed as minus 0.5 lots of 0.5 minus 0.5 log of 0.5. It's the probabilities that we are seen for you. Yes and no.And we can see here that essentially, this is equal to minus log of 0.5. And of course, the minus log to the best two of 0.5 is actually one.So whenever there is complete uncertainty in the distribution, the entropy value here gives us the largest value possible. And then as one of our values,values becomes more probable. So as we go to the extremes here. right, so recognise that this is a Bernoulli distribution and p I here is the probability of success, the one parameter that we have. So if we are saying that a success is getting a yes, then what we're saying is whenever the probability of yes is very low or very high close to one,the entropy goes to zero, so we can think of entropy as a measure of disorder. or uncertainty. right and", 'start_time': '00:28:16', 'end_time': '00:30:43'}, {'Topic': 'Gain Ratio and Attribute Selection', 'transcript': "we can think of any attribute x one. that partitions the data into a number of partitions. right. So actually, to stick to the technology that we have here, let's not call it X one. Let's just call the attribute A that has a number of values that can take.and we've got these partitions here. now we can calculate the entropy. at the parent node level, we can calculate the entropy for each other partitions.that are generated by selecting one of the values that they can take. and we now need to combine these entropy is in somewhere and hopefully, uh, you know, get a measure of the overall entropy.that has produced given our observation of a So essentially, what we are doing is we will calculate the Zen trapeze and take the waited some of these n trapeze.across all the values that the attribute they can take and what is the weight the weight is. the size of the partitionas a percentage of the overall data in here. right. So this here is a weighted average of the n trapeze at each of the partitions, and the rates are essentially accounting for how much of the data partition.goes down each of these branches. and taking this waited some away from the entropy. Here is what is referred to as information, okay?", 'start_time': '00:30:45', 'end_time': '00:32:49'}, {'Topic': 'Final Decisions and Tree Growth', 'transcript': "this metric here. Okay, so it's really saying, How much have I been able to reduce my uncertainty or disorder in my data with regard to the class labelby getting to know the value of an attribute? right. So, in a way, what we are now what we've got is the ability to rank attributesthat are in our input vector based on how much information game they provide. if we know the value of that attribute.right. And so out here we can. For the data that you had seen, we had yeses and nos we had nine yesesand by nose. and so we are able to calculate the entropy. The entropy is high. It's close to one. And now what we're looking at isfor each of our input variables. So outlook had three values sunny, overcast and rain temperature had hot, mild and coal cool. And for each of the partitions of our training data, we're now looking at the distribution.of the class level, the variable y right for each value here. And so we are able to calculate the entropy we can see for the case of outlookwhen we have the value overcast. right, we have only Yes. here? Yes. Here. Yes, here and yes, here. So we only haveplay tennis equal to Yes. So we've got a pure partition. And the entropy is therefore zero. And for the other two values sunny and rain. We actually have a close to uniform distribution of Yes and no. So we have a high introduce. The entropy is actually increased.in those two partitions compared to what it was in the overall data. But we now have a partition of data where we have zero energy.and when we then cheque. You have the values here. and when we now take the um and when we now take into account the wets associated with these. So there were basically four instances that were overcast and five I think of Sonny and five of Rain. We end up with an information gain of 0.25.Compared to that, we end up with an information gain for temperature of 0.029. Community is 0.151 and 0.04. Right, So just to make sure", 'start_time': '00:32:50', 'end_time': '00:35:56'}, {'Topic': 'ID3 Algorithm Overview', 'transcript': "that we are clear on how this is calculated, let's take the value of wind. we have out here or wind is strong.when wind is strong, we have 123, 45 and six. We have three records of yes and three records of no. And that's why the entropy ends up one. So we have six records here, and we have eight records here where we have to nose and six yeses.And so what we're saying is it's 8/14 times 0.81 plus 6/14 into one, which is the entropy after the partitioning, and we're subtracting that fromthe overall entropy of 0.94. Okay, so what we could see here is the fact that I can't seem to see the last piece here. Okay, here we are. Sowhat we can see here is the information gain and the algorithm that induces these trees fix the attribute that gets the maximum information game. So it's a greedy.algorithm just like radiant descent. That's saying I'm going to move in my third space of all trees from a situation where I had just a single leaf node, which I was giving a label of. Yes, because there were nine years is to it.I am now going to move to a tree that consists of outlook. at the root note and three branches. for each of the three values of Outlook, which now contain three partitions of data.", 'start_time': '00:35:56', 'end_time': '00:38:15'}, {'Topic': 'Tree Building Process', 'transcript': "the first one? No, is the most likely outcome. Just slightly. The third one yes, is the most likely outcome, just slightly and then overcast. The overwhelming answer is yes.And I have now essentially moved in my third space, where every node in my third space as a tree I've moved from a tree that said just yes to every classified every instance as a positive date. Tennis to now a tree where we actually make some predictions that I know.and in the next situation, I am now going to look at whether I can add another decision node to either of these two notes because this one is pure, so I can't actually add any value by further growing this treeright, and I'm going to follow the same process here. right. So I'm I'm traversing through the space of trees where each operatorin that search spaces, allowing me to add a little more debt to the tree to try and reduce the overall entropy of the overall uncertainty in making a prediction.", 'start_time': '00:38:17', 'end_time': '00:39:37'}, {'Topic': 'Decision Tree Algorithms', 'transcript': 'okay? so the I d three algorithm, which was created by a guy called Ross Quinlan for his PhD. uh, was really the first decision tree algorithm that was developed. And actually there was an alternative called cart that was also developed around the same time by videoRheiman. another famous statistician. And there were a couple of other variants also of these. But, uh, you know, these are the two contenders that really cannot survive. There was another one developed by Yvonne Practical.who is from the Joseph, uh, Stefan Institute in Slovenia. But these two are typically the ones that we see in existence today, and I D three has gone through a number of iterations. So I d three became C 4.5 which is now I think, known as C 5.0 so you might see references heroes.', 'start_time': '00:39:39', 'end_time': '00:40:46'}, {'Topic': 'Inductive Bias in Learning', 'transcript': "So let's look at I d three. So what does I did? Three Do it gets a set of data and a set of target attribute. We're not set of target attributes one target attribute, which is why?and a set of attributes, which is the input set of attributes available. And what does it do? It creates a root node for the tree.And then, if all of the examples here are positive, then it ends the function, giving a label positiveto that root node, which was a leaf node. And if all the examples are negative, then does the opposite, it gives a label of negative to the root note, and that note is all that we have in terms of belief note for the street.If neither of these two is true, then it cheques for whether there are attributes. in this list here that we can potentially split our data on.and if there are no attributes left, then it returns the single naughty tree route. right and says I'm going to label it with the most common value available.", 'start_time': '00:40:48', 'end_time': '00:42:10'}, {'Topic': 'Recursive Tree Construction', 'transcript': "or the target attribute within examples. but examples is that training dead. But now what it does, it starts to recursive Li try and build this tree, right? So what it's doing is if there are attributes that it can split on, then it looks for the attribute that best classifies examples. And as we have seen, we've seen one example of that which is information.uh, game. right being an attribute that decides on which attribute is the best attribute is the one with maximuminformation. and it then assigns that attribute as the root attribute for the tree, and for each possible value of that attribute, it creates a branchand those examples. in our data set that has been passed into this function that have a particular value V I associated with it. That subset is passed down that branch.now, if this subset is empty, So how do we get the subset to be empty notice? Here we are saying for every possible value of aright, So we're actually looking at the domain of air and creating a branch for every one of these values that can take.Now, the reason why it can be empty is that we could be expanding this tree here right where we've actually, uh, already split an outlook.And when outlook is raining temperature. Yeah, it only takes two values. Uh, medium temperature or hot.Not cold. There is no data. They're cold. But what we are saying is in that scenario, even the cold does not exist in a training data. We will still create a branch, and we'll assign it a value. And what assign value to be assigned to it? The most common value of the target Attribute in examples, right?and this is a little messed up. This needs to be out here. So this is the else part of this. If so, if it's not empty,then we call the idea three. function again. Recursive Lee, where we are passing to it. Only this partition of data that contains those valuesassociated with the FBI and the target attribute remains unchanged. And what do we do? We actually remove the attribute that has already been used here as the root right, So we have the coercively continuing to partition.", 'start_time': '00:42:12', 'end_time': '00:45:24'}, {'Topic': 'Bias in Induction', 'transcript': "and generate the tree similar to what we saw previous. Okay, so it's a very, very simple algorithm. and this brings us to an important concept of inductive bias.so the process of induction. is what the process where we say we have specific instances. of the concept of interest,and from that we are generalising. generalising. two. uh, theory of some form. that we can learn from these specific instances, right? So there's this process. Induction is the process of generalising, from specific instances to a concept description of some kindright now when we do induction. we have to be cognisant of, firstly, the language that we use for describing these theories. You know what we are saying by theory Here is really the model.right. So the language that we use to define this model in the case that we are dealing with right now is we are saying that it's going to be,uh, disjunction. off conjunctions. And as we have said earlier, remember when we have two classes plus and minus Really, what we're trying to define is the set of instancesthat are positive instances. And of course, everything else is a negative instance, right? And so we are really trying to define this set,and we have seen that the disjunction of conjunctions is actually capable of describing any of these sets. So if we have a finite population of size n.we are essentially doing a search in the power set of the population of which they are going to be in the power set. They're going to betwo to the power of end. subsets, right? And we are essentially trying to evaluate which of these subsetsis. the true set of interest of positive instances, right? And so what we're saying here is that we can define any set using a disjunction of conjunction. So,", 'start_time': '00:45:25', 'end_time': '00:48:20'}, {'Topic': 'Preference Bias in Decision Trees', 'transcript': "in general, the language that is being used as no bias within it compare that with linear regression where we are seeing the expected value of Y.is equal to beat a zero, plus the direct sigh. In that scenario, we are definitely putting a strong restriction onlanguage where we are saying that the curve that we can fit is got to be Libya, right? And so this kind of, uh, language restriction is what is referred to as a restriction bias.and an alternative is what is called a preference bias, which is related to how we search the space of all hypotheses.right. And so when we do a greedy search of the kind that we have just done in decision trees where we are saying I'm going to start to grow my treeand I'm going to choose an attribute at a time that maximises My information came. I'm doing a greedy search here. I'm defining a reference on one type of three as opposed to another type of tree.right and an important reference bias is this thing called Occam's Razor, which says that we should prefer simplest hypotheses that fit the data well.right. And so when we talked about Regularisation for lasso and rigid aggression. What were we doing there? We were essentially giving a preference to simpler hypothesis where we were able to drive that coefficient for attributes that are not really relevant to what we're trying to predict down towards zero.", 'start_time': '00:48:21', 'end_time': '00:50:27'}, {'Topic': 'Overfitting and Regularization', 'transcript': "okay, so hopefully from the perspective of the process of induction. you understand that we have to have a bias of some sort?Why we have to have a bias If we actually used an unrestricted language like we are doing here a disjunction of conjunctions.we would essentially over fit. right because we would actually learn. the positive instances and just take those instances and take a disjunction of those which would mean that in our test dataif we had five positive instances, x one x two x three and x four and x five We would essentially find the set consisting of x one x 22 x five and said these are the only positive instances possible in the population, and this would be a perfect match to attend training data,right? Not that state of training together, but it will be a hopeless match on unseen data, right, because there will always be other positive instances that we haven't seen.So to avoid us learning certain types of hypothesis, we add in, uh, preference bias that says, I want to bias my search to the population of all hypothesisin such a way that I learnt. a better model, right? This is a good model. It fits the training data perfectly.but it's not going to generalise beyond the training, right. And so we create this preference where we are avoiding learning these kinds of trees.Right? So, uh, you know, this is kind of a necessary evil in any kind of induction. and so with neural networks. Also where we are saying that it's actually a universal approximate or it can approximate any function as long as we give it enough nodes to learn, Umwe are still creating a search bias where we're using this greedy approach to searching, which we are hoping is going to avoid overfitting right? And so we are adding in regularisation and such the likes of that to minimise the probability of overfitting this otherwise highly expressive language.", 'start_time': '00:50:30', 'end_time': '00:53:10'}, {'Topic': 'Heuristics in Decision Trees', 'transcript': "now to add to some of the heuristics within the search. What Quinlan found was that information gained was biassed and it was biassed towards.attributes that had many values, so it basically resulted in poetry. and, as we said earlier, bushy trees, beans quicker, partitioning into small subsetsand the probability of these subsets being pure just by definition of them being smaller subset is much higher and therefore it's better for us to try and avoid such early partitioning.And so what do you did? Was he defined a new metric called gain ratio were given an attribute? A where we were considering doing a split of our sample of data as so That's the sample.and that is an attribute. where earlier we were just using the information gain to make a decision on whether to partition or a or some other attribute.he divided it by this metrical split information. and if we look at split information what we're doing here is we're saying that attribute a has C values that it takes so domains of sides seeand each of the s eyes, other partitions. created. bye value. Let's say a I write So a takes values a one a two to a c and s I is the partition that has the value ai with it. Remember, this is within the training, right?So in effect, this here is the probability of a is equal to a I. And so what we've got here is nothing other than probability ofis equal to a I log probability of a is equal to a I. So that's actually entropy. But the entropy here is being calculated not on theoutput variable y. It's been calculated on a And why are we thinking that is useful? Well, if we have an attribute, athat has uniform distribution. in our data across all of its many values. We are going to get a set of smallpartitions, right associated with each of our values a one a two a C. If, on the other hand, we had our attribute A which was primarily to values even and a two and the other values, even though there were c of them were very rare.What we are saying is, well, you know, we're still really the effective number of values that is taking is really to it's not see right because there's this very small partitions that gets skimmed off the data, but we still have a small number of large partitions that are getting propagated through the tree.so we would prefer not to use a if we had a distribution that helped us a real blow in terms of all of us.", 'start_time': '00:53:14', 'end_time': '00:57:13'}, {'Topic': 'Conclusion and Future Topics', 'transcript': "of the partitions becoming small, and we would rather use if it was effectively lower. Cardinality attribute right? And so remember entropy out here would be one, and the entropy here would be less than one. And so when we divide by less than one, what happens here?the gain ratio will be higher than the information gain. When we divide by one, we are in a way dampening down the possibility of a being chosen.if it's going to create these many partitions out, right? So this using it gain ratio rather than information gain actually tookwhere this virus that was otherwise associated with attributes that have any values associated with it. And so this book behaviour of the tree actually, uhand the way by using this information. Any questions on any of this? We come to the end of time, so I'll carry on from here in the next lecture. But any questions on what has been discussed at?no. I have a different question. Uh, will we be doing your decision, please? you were radiant boosted ensemble model,you'll be doing random forest and radiant boosted decision trees. Okay, Well, if there's no questions, I let you go to you tomorrow.", 'start_time': '00:57:14', 'end_time': '00:59:00'}], 'assessment': ObjectId('66f3f10427e03e5e7a798e93'), 'session_id': [ObjectId('620e18bdfb338ccd0017f921')], 'job_name': 'my-transcription-job25c3c016-d328-4ad8-a897-97f1e12dea62', 'keywords': ['Prediction', 'Decision Tree', 'Decision Boundaries', 'Overfitting', 'Classification Algorithms', 'CART', "Occam's Razor", 'Logistic Regression', 'Training Data', 'Thresholds', 'Regularization', 'Discrete Variables', 'Missing Values', 'Data Partitioning', 'Predictions', 'Root Node', 'Bias', 'Positive Instances', 'Disjunction of Conjunctions', 'Splitting Criteria', 'Cardinality', 'Heuristics', 'Entropy', 'ID3', 'Classification', 'Data Analysis', 'Supervised Learning', 'Machine Learning', 'Statistical Reliability', 'Information Gain', 'ID3 Algorithm', 'Generalization', 'Error Rate', 'Induction', 'Inductive Bias', 'Probability', 'Naive Bayes', 'Recursive Tree', 'Decision Trees', 'Gain Ratio', 'Preference Bias', 'Attribute Selection', 'Conjunctions'], 'topic': 'Decision Trees and Classification Algorithms', 'interaction': [{'status': 'answered', 'answer': 'The question is, how do we actually define the value of a split? We use a metric called entropy to calculate the uncertainty in the distribution of classes and determine how much information we gain by knowing the value of an attribute.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How do we actually define the value of a split?', 'timestamp': '[0:50:00]'}, {'status': 'answered', 'answer': 'Typically, what was found empirically was that tall decision trees are better. But at the same time, the question arises is if we have very tall decision trees, then understanding the real pattern becomes difficult because you have very long pathways to travel down.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Should we have a preference for bushy or tall trees?', 'timestamp': '[0:50:00]'}, {'status': 'answered', 'answer': 'The question of when to stop splitting the tree is discussed, indicating that ideally, we want to stop when each of our leaf nodes has only one output value, but it may not always be achievable due to noise in the data.', 'completeness': 'Complete answer, as it addresses the question directly and provides context about the challenges involved.', 'relevancy': '2', 'question': 'When do we stop splitting the tree?', 'timestamp': '[0:50:00]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question about dealing with missing values is not addressed.', 'relevancy': '0', 'question': 'How do we deal with missing values?', 'timestamp': '[0:50:00]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question about any questions was not addressed.', 'relevancy': '0', 'question': 'Any questions on any of this?', 'timestamp': '[0:58:37]'}], 'summary': 'The paragraph discusses supervised learning, defining it as a method where a target variable is paired with input vectors to estimate its probability based on the input data. It explores logistic regression, naive Bayes, and decision trees as classification algorithms, emphasizing the differences between categorical and continuous outcomes, with a focus on creating decision boundaries that separate classes. The structure of decision trees is explained, highlighting decision nodes, leaf nodes, and the importance of defining thresholds for classifying instances. The concepts of entropy and information gain are introduced, illustrating how they are used to determine the best attributes for splitting data. The importance of avoiding overfitting and ensuring generalization is stressed, alongside the challenges posed by noisy data and missing values. The discussion includes the ID3 algorithm and its evolution to C4.5, emphasizing the recursive nature of decision tree construction and the significance of inductive bias. Preference bias in decision tree search methods is contrasted with linear regression, and the gain ratio is presented as a solution to the bias towards attributes with many values. Overall, the transcript provides a comprehensive overview of decision trees, their construction, evaluation metrics, and the theoretical foundations of supervised learning.'}
{'_id': ObjectId('66b26b72b80f3f3035517f52'), 'file_id': '63edf13ac83b0e0eca0a7baf', 'file_name': 'Python Course at TBS Catch Up (2023-02-09 17_24 GMT+5_30)__1676538165-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/Python Course at TBS Catch Up (2023-02-09 17_24 GMT+5_30)__1676538165-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '00:47:17', 'transcription_path': 'video-results/out_66b26b72b80f3f3035517f52.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 6, 963000), 'file_process_date': datetime.datetime(2024, 9, 25, 16, 31, 18, 426000), 'execution_time': 601.977931, 'status': 'COMPLETED', 'green_line': [{'topic': 'Machine Learning Concepts', 'start_time': '00:00:00', 'end_time': '00:14:20', 'transcript': "basic idea in machine learning is the fact that you have some process that's going on in the real world. Right? So let's say, are you interested inuh, bet on anybody winning, right, because the possibilities are very similar. So, in effect, what we're doing here is a form of very simple machine learning. We have datathis data is about matches that have been played in the past, right? We're using those experiences so we can think of this data as experiencesfrom which we want to learn. Uh, some information, some knowledge that can help us make decisions. Right.So if we look at data that has a binary outcome like this, you can either win or not win. Do you know, from a probability perspective, what kind of probability distribution This is,um, your own. Have you heard of a Bernoulli distribution? Okay, So, essentially, a Bernoulli distributionis the probability distribution Where the variable that we are you know, tracking uh is a binary variable,right? And so what we're saying is the probability of a win is some value theatre, and the probability of not winningis therefore right, And this is essentially a Bernoulli distribution. And we say that we have one parameter, right? So this thing here, the theatre is called a parameter.And what we are saying is that once we have determined that the event that we are tracking here in the dataBernoulli distribution. We have essentially said that there is some kind of functional form. that we have settled on, right? In this case, the functional form. Is this here now? What do we mean by functional form,You know, from maps function something that takes inputs and maps it too. Kind of right. And so here, what we're saying is, given an input which can either be a win or not win, we are wanting to map it onto a, uh, an actual value of probability.Right. So we have decided, because this variable is binary, that the function will be a Bernoulli distribution.Okay, So what we want to do is given some data. this data has been generated by some real world process.where the real world process in our case is a cricket match. right. And in the past, whenever cricket matches have been played between Indiaand Pakistan, we have seen an outcome right and that's the experiences that we have now. On the whole, the outcome of a new cricket match taking place tomorrow is unknown to us.Yeah, right. To make a prediction, however, we need to be able to estimate this particular parameter theatre.actual process that runs in the real world is we have made an assumption that it follows anomaly distribution, and based on that assumption, we have a parameter which is an unknown, and we are basically trying to learn what that value could be. And that's the process of estimation.Yeah, right now, imagine a scenario where your data had 52 wins for India, but you randomly chose theatre to be 0.1.Okay. Now the question is Is this a good model of the real world process? No, no. Why is it not? Because your expectation is that if theatre was truly 0.1 then out of n matches that you watched, you would expect to win.Be once. Yeah, right. But you're actually seeing out of 100 matches. You're saying 52. So you need a way to measurehow good your current estimate of theatre actually is. And in machine learning, we call that a cost function.you know, the the world is an uncertain place and we can think of the probability of a win which takes a value between zero and one. Right. So this probability of it has to be between zero and one. Those are the conditions of probability. But we don't know what that value is before we see any data.Okay, so in a way, what we could say is that the actual value three to itself. which can take values between zero and one. There is an equal probability of any of the values of theatrebeing the right parameter value here. Right before we have seen any data. the Value Theatre could take the value zero where we are saying that India has no chance of ever winning. Or it could take a value of one where we are saying India will always been or somewhere in between the true value of what is the probability in a random match between India and Pakistan? Win. It could be any value in here, right? So we call this a uniform distribution,okay, right. So, in a way, what we're saying is that we started off with what was our prior belief. in theatre, right? And we call that the probability of theatre and we are saying that that's a uniform distribution where every value has an equal. Probert. Now that we have seen the data which will call D,we now say we want to update. this probability, and we call it a posterior probability, okay? where we write it like a conditional probability, given that data exists Now, what is our belief in theatre?This is Yeah. Okay. And what we would say here is that somewhere from this prior belief, we have updated our belief in the distribution of theatre.And given that we have seen these 5th 100 matches, out of which India won 52 we are going to start expecting some kind of a distribution that looks like this,right? We're now kind of getting a much higher probability of theta taking values somewhere between 0.5 and 0.6. Right? So it does have a possibility. Still, because we've only seen 100 matches and remember that a probability isreally defined at the limit way. We've seen lots and lots of frequentist IQ data. Can we be confident that we are converging towards the true likelihood of the true probability of an event? Okay,right. So it's actually what we are trying to do is we start off by having some prior belief in what a parameter value could be. And if we don't have any data, we can assume it's a uniform distributionand then As we get data, we update our belief in theatre and get Earth, um, distribution that has a lower variance in it. Right out here, the variances right across the board here.Whereas now we're saying there is a lesser variance. We know that between maybe 0.4 and 0.6 because we've seen some data. And as we see more data, we keep updating that belief and we get to a point where now we have very low variance, and variance is a bad thing,right? So it's more concentrated that it's more concentrated, right? And so that's what we're saying. So high variance means less knowledge.Right? So the whole idea here in machine learning is about learning some probability distribution using in data that is given to us, which we call training data.right. So we are providing data about experiences that have happened in the past, presuming that we are updating our understanding of various parameter values and we're reducing the uncertainty around what that parameter value could be.Makes sense. Yeah. So you have now got this problem where you want to predict whether India wins or Pakistan wins. And you can see that, you know, on the whole, looking at historical data, it seems like both of them are a good match with each other.", 'keywords': ['Machine Learning', 'Bernoulli Distribution', 'Posterior Probability'], 'summary': "The transcript discusses fundamental concepts in machine learning, focusing on the process of learning from real-world data, particularly in the context of predicting outcomes in cricket matches. It explains how past match data serves as experiences to build knowledge and make informed decisions. The speaker introduces the Bernoulli distribution, emphasizing its relevance in modeling binary outcomes such as winning or losing. The parameter theta is highlighted as crucial in estimating the probability of winning, and the importance of assessing the model's accuracy through cost functions is mentioned. The concept of prior and posterior probabilities is elaborated, illustrating how initial beliefs about probabilities can be updated with new data to reduce uncertainty. The discussion culminates in the idea that continuous data updates lead to a refined understanding of outcomes, ultimately aiding in making predictions about future matches."}, {'topic': 'Betting Scenario', 'start_time': '00:00:08', 'end_time': '00:06:08', 'transcript': "cricket? Uh, okay, So let's say we have a cricket match that's gonna happen. Right? Um, in India and Pakistan,and, uh, you as an individual, uh, have to now, uh Voyager all of your savings in your life on the match.Uh, so let's say, uh, you know, India Pakistan have played multiple times. So the obvious thing that you might think of doing is to look at historical data and you will notice that, uh, India one, maybe 52% of matches in the past and 48% of matches. India lost okay or didn't win. So, given the scenario,uh, one question that you would ask yourself is should I bet on India right at this point. And if we forget about our, uh, nationalistic pride, uh, and think in terms of just, you know, as a rational human being, uh, chances are that you would decide that you don't want to,the number of Indian winds. Yeah. So maybe 50 to 100 Basic, Right? Right. Okay, Now, why are we calling this an estimate?We're calling this an estimate, because what we are resuming is that that real world processes controlled by this kind of a Bernoulli distribution, right, and what we have seen are just sample outcomes.We don't really know what that real world processes parameter is. Theatre? Yeah, from the data, we are trying to come up with an idea of what that parameter value is. Right. So it's an estimate of what the", 'keywords': ['Betting', 'Estimation', 'Bernoulli Distribution'], 'summary': 'The transcript discusses a betting scenario centered around a cricket match between India and Pakistan. The speaker highlights the importance of historical data in making betting decisions, noting that India has won approximately 52% of past matches against Pakistan. They pose the question of whether one should bet on India, suggesting that rational analysis might lead to skepticism about placing a bet based solely on past performance. The concept of estimation is introduced, explaining that the outcomes observed are samples from a Bernoulli distribution, and the true parameter governing the real-world process remains unknown. This emphasizes the need for careful consideration before making betting decisions based on historical win rates.'}, {'topic': 'Probability Distribution', 'start_time': '00:01:56', 'end_time': '00:09:08', 'transcript': "So if we look at data that has a binary outcome like this, you can either win or not win. Do you know, from a probability perspective, what kind of probability distribution This is,um, your own. Have you heard of a Bernoulli distribution? Okay, So, essentially, a Bernoulli distributionis the probability distribution Where the variable that we are you know, tracking uh is a binary variable,right? And so what we're saying is the probability of a win is some value theatre, and the probability of not winningis therefore right, And this is essentially a Bernoulli distribution. And we say that we have one parameter, right? So this thing here, the theatre is called a parameter.And what we are saying is that once we have determined that the event that we are tracking here in the dataRight. So we have decided, because this variable is binary, that the function will be a Bernoulli distribution.being the right parameter value here. Right before we have seen any data. the Value Theatre could take the value zero where we are saying that India has no chance of ever winning. Or it could take a value of one where we are saying India will always been or somewhere in between the true value of what is the probability in a random match between India and Pakistan? Win. It could be any value in here, right? So we call this a uniform distribution,", 'keywords': ['Bernoulli Distribution', 'Binary Outcome', 'Probability'], 'summary': 'The transcript discusses the concept of probability distributions, focusing specifically on the Bernoulli distribution, which is relevant for binary outcomes such as winning or not winning. The speaker explains that in a Bernoulli distribution, the tracked variable is binary, and the probability of winning is represented by a parameter (theta). They elaborate that this parameter can take any value between 0 and 1, indicating the likelihood of winning in a scenario, such as a match between India and Pakistan. The discussion highlights the importance of defining the Bernoulli distribution based on the nature of the data being analyzed.'}, {'topic': 'Bernoulli Distribution', 'start_time': '00:02:11', 'end_time': '00:04:04', 'transcript': "um, your own. Have you heard of a Bernoulli distribution? Okay, So, essentially, a Bernoulli distributionis the probability distribution Where the variable that we are you know, tracking uh is a binary variable,right? And so what we're saying is the probability of a win is some value theatre, and the probability of not winningis therefore right, And this is essentially a Bernoulli distribution. And we say that we have one parameter, right? So this thing here, the theatre is called a parameter.Right. So we have decided, because this variable is binary, that the function will be a Bernoulli distribution.", 'keywords': ['Bernoulli Distribution', 'Binary Variable', 'Probability'], 'summary': 'The transcript provides an overview of the Bernoulli distribution, which is defined as the probability distribution for a binary variable. The speaker explains that this distribution is characterized by a single parameter, denoted as theta, which represents the probability of a particular outcome, such as a win. The complementary probability, representing the opposite outcome (not winning), is also derived from this parameter. Overall, the Bernoulli distribution is framed as a simple yet fundamental concept in probability theory.'}, {'topic': 'Estimation and Parameters', 'start_time': '00:04:04', 'end_time': '00:06:31', 'transcript': "Okay. And we want to estimate this parameter. So the functional form determines the parameters, the unknowns that we want to estimate. And in this case, there's only one parameter, which is theatre.Okay, So what we want to do is given some data. this data has been generated by some real world process.Yeah, right. To make a prediction, however, we need to be able to estimate this particular parameter theatre.Now you know how to do that, right? We've been told that if you have a binary outcome and you see, uh, India having 152 out of the 100 observations you have, you can calculate Peter is essentially are over. And where art is,the number of Indian winds. Yeah. So maybe 50 to 100 Basic, Right? Right. Okay, Now, why are we calling this an estimate?We're calling this an estimate, because what we are resuming is that that real world processes controlled by this kind of a Bernoulli distribution, right, and what we have seen are just sample outcomes.We don't really know what that real world processes parameter is. Theatre? Yeah, from the data, we are trying to come up with an idea of what that parameter value is. Right. So it's an estimate of what theactual process that runs in the real world is we have made an assumption that it follows anomaly distribution, and based on that assumption, we have a parameter which is an unknown, and we are basically trying to learn what that value could be. And that's the process of estimation.", 'keywords': ['Estimation', 'Parameter', 'Bernoulli Distribution'], 'summary': "The transcript discusses the process of estimating parameters in a statistical context, specifically focusing on a single parameter known as 'theta.' The speaker explains that the functional form of a model determines the parameters to estimate and emphasizes the necessity of using real-world data generated by a specific process to make predictions. An example is provided using a binary outcome, where the speaker illustrates how to calculate theta from observed data, notably referencing the number of successes in a Bernoulli distribution. The importance of recognizing that the observed outcomes are merely samples from a larger process is highlighted, reinforcing that the estimation aims to infer the actual parameter value from these samples."}, {'topic': 'Decision Making', 'start_time': '00:01:00', 'end_time': '00:13:44', 'transcript': "uh, one question that you would ask yourself is should I bet on India right at this point. And if we forget about our, uh, nationalistic pride, uh, and think in terms of just, you know, as a rational human being, uh, chances are that you would decide that you don't want to,and Pakistan, we have seen an outcome right and that's the experiences that we have now. On the whole, the outcome of a new cricket match taking place tomorrow is unknown to us.Yeah, right. To make a prediction, however, we need to be able to estimate this particular parameter theatre.we now say we want to update. this probability, and we call it a posterior probability, okay? where we write it like a conditional probability, given that data exists Now, what is our belief in theatre?right. So it's actually what we are trying to do is we start off by having some prior belief in what a parameter value could be. And if we don't have any data, we can assume it's a uniform distributionRight? So the whole idea here in machine learning is about learning some probability distribution using in data that is given to us, which we call training data.", 'keywords': ['Decision Making', 'Posterior Probability', 'Machine Learning'], 'summary': 'The transcript discusses decision-making in the context of betting on cricket matches, particularly focusing on the comparison between India and Pakistan. It emphasizes the uncertainty of outcomes and the necessity of updating beliefs about probabilities based on available data. The speaker explains the concept of posterior probability, describing how prior beliefs about a parameter can be adjusted with evidence, which is foundational in machine learning where learning probability distributions from training data is essential.'}, {'topic': 'Cost Function', 'start_time': '00:07:18', 'end_time': '00:07:18', 'transcript': "how good your current estimate of theatre actually is. And in machine learning, we call that a cost function.Be once. Yeah, right. But you're actually seeing out of 100 matches. You're saying 52. So you need a way to measure", 'keywords': ['Cost Function', 'Machine Learning', 'Estimation'], 'summary': 'The transcript discusses the concept of a cost function in machine learning, which serves as a metric to evaluate the accuracy of estimates made by a model. The speaker illustrates this by referencing a scenario where an estimate is compared to actual outcomes, highlighting the need for a structured way to measure performance.'}, {'topic': 'Prior and Posterior Probability', 'start_time': '00:08:40', 'end_time': '00:10:07', 'transcript': "being the right parameter value here. Right before we have seen any data. the Value Theatre could take the value zero where we are saying that India has no chance of ever winning. Or it could take a value of one where we are saying India will always been or somewhere in between the true value of what is the probability in a random match between India and Pakistan? Win. It could be any value in here, right? So we call this a uniform distribution,okay, right. So, in a way, what we're saying is that we started off with what was our prior belief. in theatre, right? And we call that the probability of theatre and we are saying that that's a uniform distribution where every value has an equal. Probert. Now that we have seen the data which will call D,we now say we want to update. this probability, and we call it a posterior probability, okay? where we write it like a conditional probability, given that data exists Now, what is our belief in theatre?This is Yeah. Okay. And what we would say here is that somewhere from this prior belief, we have updated our belief in the distribution of theatre.", 'keywords': ['Prior Probability', 'Posterior Probability', 'Uniform Distribution'], 'summary': "The transcript discusses the concepts of prior and posterior probability in the context of statistical inference. It explains how prior beliefs about a parameter value (denoted as 'theatre') can range from zero to one, representing the likelihood of an event, such as India's chances of winning a match. The speaker introduces the idea of a uniform distribution for prior beliefs, where each value has an equal probability. After observing data (referred to as 'D'), the speaker explains how to update these beliefs to form a posterior probability, which is expressed as a conditional probability based on the observed data, thereby refining the understanding of the parameter based on new evidence."}, {'topic': 'Conditional Probability', 'start_time': '00:19:01', 'end_time': '00:19:51', 'transcript': "and we are now seeing, given these values of the variables, what is the probability of outcome is equal to win, so this conditional probability distribution is also a BernoulliWhat is going to be the outcome of this match is what we want to know. Okay, so what kind of conditional distribution is this Probability distribution is this. It's a conditional probability distribution, right? But of course a conditional probability is also simply a probability distribution. It's just that we have observed some variablesthat we need to estimate, because what we are saying is that this probability is some value theatre, which is dependent on Coley and Sharma's emotional state.", 'keywords': ['Conditional Probability', 'Bernoulli Distribution', 'Probability Distribution'], 'summary': 'The transcript discusses the concept of conditional probability, particularly in the context of estimating the probability of an outcome (win) given certain observed variable values. It notes that this specific conditional probability distribution can be classified as a Bernoulli distribution. The speaker emphasizes that while this is a conditional probability distribution, it is fundamentally a probability distribution that reflects dependencies on observed variables, such as the emotional state of individuals involved in the event.'}, {'topic': 'Logistic Regression', 'start_time': '00:28:55', 'end_time': '00:44:06', 'transcript': "okay? and that is essentially what we have drawn here is the decision boundary that is defined by a machine learning method called logisticregression. Okay? Okay, So this whole idea of this functional form is to define a very simple decision boundarywe will win the match. right. So what we have done here is essentially looked at a very simple approach toinput. right. And so a neural network is nothing but. an extension of logistic regression. We're creating intermediate calculations that approximate these decision boundaries very complex decisions", 'keywords': ['Logistic Regression', 'Decision Boundary', 'Neural Network'], 'summary': 'The transcript discusses logistic regression and its role in defining decision boundaries in machine learning. It highlights the simplicity of this method and how it serves as a foundational concept for more complex models like neural networks. The speaker elaborates on the functional form of logistic regression, emphasizing its ability to create simple yet effective decision boundaries, which are essential for making predictions in various contexts.'}, {'topic': 'Neural Networks', 'start_time': '00:41:48', 'end_time': '00:43:45', 'transcript': "So we are learning the parameters for each of these four lines together collectively to create performance right and performance being the accuracy with which we can define the region where in their wins.and this computational graph. that we have just defined here. he's Golda Mural. network. Okay, because we can think of it as our brain consisting of neurons, each of these notes and neurons. Neurons get inputs and they produce an output the fire whenever they get enough electric current to them from the inputs. Okay, so this is the equivalent of the output from this neuron,layer which man? the layer of four notes here. Yeah, the intermediate layers of community. Right. And so we're just saying that we have now determined, uh, defined a computational graph for network where there is a flow of information from", 'keywords': ['Neural Network', 'Computational Graph', 'Neuron'], 'summary': "The transcript discusses the learning of parameters in a neural network, focusing on how collective performance is achieved through accuracy in defining regions of output. The speaker likens the neural network to the human brain, explaining that neurons receive inputs, produce outputs, and 'fire' when stimulated by sufficient electric current. They describe the computational graph that has been defined, illustrating the flow of information through the network and the arrangement of the layers, including intermediate layers."}, {'topic': 'Image Classification', 'start_time': '00:33:58', 'end_time': '00:36:19', 'transcript': "protect the plant. Now, if you think of an image, an image is essentially rather boring. Lee got this kind of shape to it. It's a digital photograph, and so we get a coloured digital photograph by having three channels. The red,along the red, the green and the blue channels. And when we mix those intensities, we get some colour. Okay, Right. So, in effect, if we want to learn a function that can classify this image into disease or non disease,we're learning a function again that now takes an image and maps it to, uh, zero zero or one, right? Yeah.And so our input is now 3 million values a million value channel. Right? So we have 3 million. So we are thinking of a 3 million dimensional space which we as humans can't even fathom, and each point there is an image.and we are now classifying it as whether it is a disease or non diseased. Okay, right. And so it's impossible for us to be able to figure out in that three dimensional space. What is the actual decision? Boundary Look like the shape of the", 'keywords': ['Image Classification', 'Digital Photograph', 'High-Dimensional Space'], 'summary': 'The speaker discusses the concept of image classification, explaining that an image is represented as a digital photograph with three color channels: red, green, and blue. By mixing the intensities of these channels, we obtain various colors. The goal is to learn a function that classifies images as either diseased or non-diseased, which involves mapping the image data, represented as 3 million values in a high-dimensional space, to binary outputs (0 or 1). The challenges of visualizing and determining decision boundaries in this complex space are highlighted.'}, {'topic': 'Natural Language Processing', 'start_time': '00:45:54', 'end_time': '00:46:03', 'transcript': 'into their data, and then we can do what is called natural language processing, trying to understand the semantics behind what is being said.', 'keywords': ['Natural Language Processing', 'Semantics', 'Data Integration'], 'summary': 'The speaker discusses the integration of data for the purpose of natural language processing (NLP), focusing on the importance of understanding the semantics behind the spoken or written content.'}, {'topic': 'Session Summary and Future Discussions', 'start_time': '00:45:11', 'end_time': '00:47:16', 'transcript': "to be. Okay. Yeah. So that's a world wind tour through, uh, machine learning. We will, um, you know, kind of have more of these sessions where we will, um uh, discuss this further. We will make available to your recordings right of these sessions so that you can go through that in your own time, come back with questions,accession, and we will now start looking at Well, we've just seen how photographs it converted into data, right? Because they're basically, like I said, 3 million pixels in that example. People look at ways in which we can convert textYou're very intelligent. Okay, great. Alright. So, virus. So, um, you know what we'll do is is a weekly cadence a good way to kind of run this. We meet up like this and we talk about machine learning. In the meantime, we give you some, uh, you know, Buyten and some videos to watch also so that you can get up to speed with that. And we will discussions either around theory or through some courtto give you some semblance of how the theory translates into gold. And how do we solve different types of problems inthis way? Okay, Okay. Alright, Samara, take care. Thank you for organising this and, uh you know, hopefully we will get to some really exciting cool stuff to do.Alright, alright, Goodbye.", 'keywords': ['Machine Learning', 'Data Conversion', 'Pixels'], 'summary': 'The session provides a summary of discussions on machine learning and outlines plans for future sessions. The speaker mentions the importance of recording these sessions for participants to review at their convenience and encourages them to return with questions. The discussion touches on how photographs can be converted into data, highlighting the concept of pixels. The speaker suggests a weekly meeting cadence for ongoing discussions and mentions providing supplementary materials, such as videos, to enhance understanding of machine learning theory and its practical applications. The session concludes with a note of appreciation for the organizer and anticipation for future learning opportunities.'}], 'yellow_line': [{'Topic': 'Machine Learning Concepts', 'transcript': "basic idea in machine learning is the fact that you have some process that's going on in the real world. Right? So let's say, are you interested inuh, bet on anybody winning, right, because the possibilities are very similar. So, in effect, what we're doing here is a form of very simple machine learning. We have datathis data is about matches that have been played in the past, right? We're using those experiences so we can think of this data as experiencesfrom which we want to learn. Uh, some information, some knowledge that can help us make decisions. Right.So if we look at data that has a binary outcome like this, you can either win or not win. Do you know, from a probability perspective, what kind of probability distribution This is,um, your own. Have you heard of a Bernoulli distribution? Okay, So, essentially, a Bernoulli distributionis the probability distribution Where the variable that we are you know, tracking uh is a binary variable,right? And so what we're saying is the probability of a win is some value theatre, and the probability of not winningis therefore right, And this is essentially a Bernoulli distribution. And we say that we have one parameter, right? So this thing here, the theatre is called a parameter.And what we are saying is that once we have determined that the event that we are tracking here in the dataBernoulli distribution. We have essentially said that there is some kind of functional form. that we have settled on, right? In this case, the functional form. Is this here now? What do we mean by functional form,You know, from maps function something that takes inputs and maps it too. Kind of right. And so here, what we're saying is, given an input which can either be a win or not win, we are wanting to map it onto a, uh, an actual value of probability.Right. So we have decided, because this variable is binary, that the function will be a Bernoulli distribution.Okay, So what we want to do is given some data. this data has been generated by some real world process.where the real world process in our case is a cricket match. right. And in the past, whenever cricket matches have been played between Indiaand Pakistan, we have seen an outcome right and that's the experiences that we have now. On the whole, the outcome of a new cricket match taking place tomorrow is unknown to us.Yeah, right. To make a prediction, however, we need to be able to estimate this particular parameter theatre.actual process that runs in the real world is we have made an assumption that it follows anomaly distribution, and based on that assumption, we have a parameter which is an unknown, and we are basically trying to learn what that value could be. And that's the process of estimation.Yeah, right now, imagine a scenario where your data had 52 wins for India, but you randomly chose theatre to be 0.1.Okay. Now the question is Is this a good model of the real world process? No, no. Why is it not? Because your expectation is that if theatre was truly 0.1 then out of n matches that you watched, you would expect to win.Be once. Yeah, right. But you're actually seeing out of 100 matches. You're saying 52. So you need a way to measurehow good your current estimate of theatre actually is. And in machine learning, we call that a cost function.you know, the the world is an uncertain place and we can think of the probability of a win which takes a value between zero and one. Right. So this probability of it has to be between zero and one. Those are the conditions of probability. But we don't know what that value is before we see any data.Okay, so in a way, what we could say is that the actual value three to itself. which can take values between zero and one. There is an equal probability of any of the values of theatrebeing the right parameter value here. Right before we have seen any data. the Value Theatre could take the value zero where we are saying that India has no chance of ever winning. Or it could take a value of one where we are saying India will always been or somewhere in between the true value of what is the probability in a random match between India and Pakistan? Win. It could be any value in here, right? So we call this a uniform distribution,okay, right. So, in a way, what we're saying is that we started off with what was our prior belief. in theatre, right? And we call that the probability of theatre and we are saying that that's a uniform distribution where every value has an equal. Probert. Now that we have seen the data which will call D,we now say we want to update. this probability, and we call it a posterior probability, okay? where we write it like a conditional probability, given that data exists Now, what is our belief in theatre?This is Yeah. Okay. And what we would say here is that somewhere from this prior belief, we have updated our belief in the distribution of theatre.And given that we have seen these 5th 100 matches, out of which India won 52 we are going to start expecting some kind of a distribution that looks like this,right? We're now kind of getting a much higher probability of theta taking values somewhere between 0.5 and 0.6. Right? So it does have a possibility. Still, because we've only seen 100 matches and remember that a probability isreally defined at the limit way. We've seen lots and lots of frequentist IQ data. Can we be confident that we are converging towards the true likelihood of the true probability of an event? Okay,right. So it's actually what we are trying to do is we start off by having some prior belief in what a parameter value could be. And if we don't have any data, we can assume it's a uniform distributionand then As we get data, we update our belief in theatre and get Earth, um, distribution that has a lower variance in it. Right out here, the variances right across the board here.Whereas now we're saying there is a lesser variance. We know that between maybe 0.4 and 0.6 because we've seen some data. And as we see more data, we keep updating that belief and we get to a point where now we have very low variance, and variance is a bad thing,right? So it's more concentrated that it's more concentrated, right? And so that's what we're saying. So high variance means less knowledge.Right? So the whole idea here in machine learning is about learning some probability distribution using in data that is given to us, which we call training data.right. So we are providing data about experiences that have happened in the past, presuming that we are updating our understanding of various parameter values and we're reducing the uncertainty around what that parameter value could be.Makes sense. Yeah. So you have now got this problem where you want to predict whether India wins or Pakistan wins. And you can see that, you know, on the whole, looking at historical data, it seems like both of them are a good match with each other.", 'start_time': '00:00:00', 'end_time': '00:14:20'}, {'Topic': 'Betting Scenario', 'transcript': "cricket? Uh, okay, So let's say we have a cricket match that's gonna happen. Right? Um, in India and Pakistan,and, uh, you as an individual, uh, have to now, uh Voyager all of your savings in your life on the match.Uh, so let's say, uh, you know, India Pakistan have played multiple times. So the obvious thing that you might think of doing is to look at historical data and you will notice that, uh, India one, maybe 52% of matches in the past and 48% of matches. India lost okay or didn't win. So, given the scenario,uh, one question that you would ask yourself is should I bet on India right at this point. And if we forget about our, uh, nationalistic pride, uh, and think in terms of just, you know, as a rational human being, uh, chances are that you would decide that you don't want to,the number of Indian winds. Yeah. So maybe 50 to 100 Basic, Right? Right. Okay, Now, why are we calling this an estimate?We're calling this an estimate, because what we are resuming is that that real world processes controlled by this kind of a Bernoulli distribution, right, and what we have seen are just sample outcomes.We don't really know what that real world processes parameter is. Theatre? Yeah, from the data, we are trying to come up with an idea of what that parameter value is. Right. So it's an estimate of what the", 'start_time': '00:00:08', 'end_time': '00:06:08'}, {'Topic': 'Probability Distribution', 'transcript': "So if we look at data that has a binary outcome like this, you can either win or not win. Do you know, from a probability perspective, what kind of probability distribution This is,um, your own. Have you heard of a Bernoulli distribution? Okay, So, essentially, a Bernoulli distributionis the probability distribution Where the variable that we are you know, tracking uh is a binary variable,right? And so what we're saying is the probability of a win is some value theatre, and the probability of not winningis therefore right, And this is essentially a Bernoulli distribution. And we say that we have one parameter, right? So this thing here, the theatre is called a parameter.And what we are saying is that once we have determined that the event that we are tracking here in the dataRight. So we have decided, because this variable is binary, that the function will be a Bernoulli distribution.being the right parameter value here. Right before we have seen any data. the Value Theatre could take the value zero where we are saying that India has no chance of ever winning. Or it could take a value of one where we are saying India will always been or somewhere in between the true value of what is the probability in a random match between India and Pakistan? Win. It could be any value in here, right? So we call this a uniform distribution,", 'start_time': '00:01:56', 'end_time': '00:09:08'}, {'Topic': 'Bernoulli Distribution', 'transcript': "um, your own. Have you heard of a Bernoulli distribution? Okay, So, essentially, a Bernoulli distributionis the probability distribution Where the variable that we are you know, tracking uh is a binary variable,right? And so what we're saying is the probability of a win is some value theatre, and the probability of not winningis therefore right, And this is essentially a Bernoulli distribution. And we say that we have one parameter, right? So this thing here, the theatre is called a parameter.Right. So we have decided, because this variable is binary, that the function will be a Bernoulli distribution.", 'start_time': '00:02:11', 'end_time': '00:04:04'}, {'Topic': 'Estimation and Parameters', 'transcript': "Okay. And we want to estimate this parameter. So the functional form determines the parameters, the unknowns that we want to estimate. And in this case, there's only one parameter, which is theatre.Okay, So what we want to do is given some data. this data has been generated by some real world process.Yeah, right. To make a prediction, however, we need to be able to estimate this particular parameter theatre.Now you know how to do that, right? We've been told that if you have a binary outcome and you see, uh, India having 152 out of the 100 observations you have, you can calculate Peter is essentially are over. And where art is,the number of Indian winds. Yeah. So maybe 50 to 100 Basic, Right? Right. Okay, Now, why are we calling this an estimate?We're calling this an estimate, because what we are resuming is that that real world processes controlled by this kind of a Bernoulli distribution, right, and what we have seen are just sample outcomes.We don't really know what that real world processes parameter is. Theatre? Yeah, from the data, we are trying to come up with an idea of what that parameter value is. Right. So it's an estimate of what theactual process that runs in the real world is we have made an assumption that it follows anomaly distribution, and based on that assumption, we have a parameter which is an unknown, and we are basically trying to learn what that value could be. And that's the process of estimation.", 'start_time': '00:04:04', 'end_time': '00:06:31'}, {'Topic': 'Decision Making', 'transcript': "uh, one question that you would ask yourself is should I bet on India right at this point. And if we forget about our, uh, nationalistic pride, uh, and think in terms of just, you know, as a rational human being, uh, chances are that you would decide that you don't want to,and Pakistan, we have seen an outcome right and that's the experiences that we have now. On the whole, the outcome of a new cricket match taking place tomorrow is unknown to us.Yeah, right. To make a prediction, however, we need to be able to estimate this particular parameter theatre.we now say we want to update. this probability, and we call it a posterior probability, okay? where we write it like a conditional probability, given that data exists Now, what is our belief in theatre?right. So it's actually what we are trying to do is we start off by having some prior belief in what a parameter value could be. And if we don't have any data, we can assume it's a uniform distributionRight? So the whole idea here in machine learning is about learning some probability distribution using in data that is given to us, which we call training data.", 'start_time': '00:01:00', 'end_time': '00:13:44'}, {'Topic': 'Cost Function', 'transcript': "how good your current estimate of theatre actually is. And in machine learning, we call that a cost function.Be once. Yeah, right. But you're actually seeing out of 100 matches. You're saying 52. So you need a way to measure", 'start_time': '00:07:18', 'end_time': '00:07:18'}, {'Topic': 'Prior and Posterior Probability', 'transcript': "being the right parameter value here. Right before we have seen any data. the Value Theatre could take the value zero where we are saying that India has no chance of ever winning. Or it could take a value of one where we are saying India will always been or somewhere in between the true value of what is the probability in a random match between India and Pakistan? Win. It could be any value in here, right? So we call this a uniform distribution,okay, right. So, in a way, what we're saying is that we started off with what was our prior belief. in theatre, right? And we call that the probability of theatre and we are saying that that's a uniform distribution where every value has an equal. Probert. Now that we have seen the data which will call D,we now say we want to update. this probability, and we call it a posterior probability, okay? where we write it like a conditional probability, given that data exists Now, what is our belief in theatre?This is Yeah. Okay. And what we would say here is that somewhere from this prior belief, we have updated our belief in the distribution of theatre.", 'start_time': '00:08:40', 'end_time': '00:10:07'}, {'Topic': 'Conditional Probability', 'transcript': "and we are now seeing, given these values of the variables, what is the probability of outcome is equal to win, so this conditional probability distribution is also a BernoulliWhat is going to be the outcome of this match is what we want to know. Okay, so what kind of conditional distribution is this Probability distribution is this. It's a conditional probability distribution, right? But of course a conditional probability is also simply a probability distribution. It's just that we have observed some variablesthat we need to estimate, because what we are saying is that this probability is some value theatre, which is dependent on Coley and Sharma's emotional state.", 'start_time': '00:19:01', 'end_time': '00:19:51'}, {'Topic': 'Logistic Regression', 'transcript': "okay? and that is essentially what we have drawn here is the decision boundary that is defined by a machine learning method called logisticregression. Okay? Okay, So this whole idea of this functional form is to define a very simple decision boundarywe will win the match. right. So what we have done here is essentially looked at a very simple approach toinput. right. And so a neural network is nothing but. an extension of logistic regression. We're creating intermediate calculations that approximate these decision boundaries very complex decisions", 'start_time': '00:28:55', 'end_time': '00:44:06'}, {'Topic': 'Neural Networks', 'transcript': "So we are learning the parameters for each of these four lines together collectively to create performance right and performance being the accuracy with which we can define the region where in their wins.and this computational graph. that we have just defined here. he's Golda Mural. network. Okay, because we can think of it as our brain consisting of neurons, each of these notes and neurons. Neurons get inputs and they produce an output the fire whenever they get enough electric current to them from the inputs. Okay, so this is the equivalent of the output from this neuron,layer which man? the layer of four notes here. Yeah, the intermediate layers of community. Right. And so we're just saying that we have now determined, uh, defined a computational graph for network where there is a flow of information from", 'start_time': '00:41:48', 'end_time': '00:43:45'}, {'Topic': 'Image Classification', 'transcript': "protect the plant. Now, if you think of an image, an image is essentially rather boring. Lee got this kind of shape to it. It's a digital photograph, and so we get a coloured digital photograph by having three channels. The red,along the red, the green and the blue channels. And when we mix those intensities, we get some colour. Okay, Right. So, in effect, if we want to learn a function that can classify this image into disease or non disease,we're learning a function again that now takes an image and maps it to, uh, zero zero or one, right? Yeah.And so our input is now 3 million values a million value channel. Right? So we have 3 million. So we are thinking of a 3 million dimensional space which we as humans can't even fathom, and each point there is an image.and we are now classifying it as whether it is a disease or non diseased. Okay, right. And so it's impossible for us to be able to figure out in that three dimensional space. What is the actual decision? Boundary Look like the shape of the", 'start_time': '00:33:58', 'end_time': '00:36:19'}, {'Topic': 'Natural Language Processing', 'transcript': 'into their data, and then we can do what is called natural language processing, trying to understand the semantics behind what is being said.', 'start_time': '00:45:54', 'end_time': '00:46:03'}, {'Topic': 'Session Summary and Future Discussions', 'transcript': "to be. Okay. Yeah. So that's a world wind tour through, uh, machine learning. We will, um, you know, kind of have more of these sessions where we will, um uh, discuss this further. We will make available to your recordings right of these sessions so that you can go through that in your own time, come back with questions,accession, and we will now start looking at Well, we've just seen how photographs it converted into data, right? Because they're basically, like I said, 3 million pixels in that example. People look at ways in which we can convert textYou're very intelligent. Okay, great. Alright. So, virus. So, um, you know what we'll do is is a weekly cadence a good way to kind of run this. We meet up like this and we talk about machine learning. In the meantime, we give you some, uh, you know, Buyten and some videos to watch also so that you can get up to speed with that. And we will discussions either around theory or through some courtto give you some semblance of how the theory translates into gold. And how do we solve different types of problems inthis way? Okay, Okay. Alright, Samara, take care. Thank you for organising this and, uh you know, hopefully we will get to some really exciting cool stuff to do.Alright, alright, Goodbye.", 'start_time': '00:45:11', 'end_time': '00:47:16'}], 'session_id': [], 'assessment': ObjectId('66f43bb6c248cb8c5215372a'), 'job_name': 'my-transcription-jobfba750b5-d528-41ec-887f-5be3d0d72a7a', 'keywords': ['Probability', 'Image Classification', 'Bernoulli Distribution', 'Parameter', 'Natural Language Processing', 'Data Integration', 'Decision Boundary', 'Decision Making', 'Betting', 'Estimation', 'Pixels', 'High-Dimensional Space', 'Posterior Probability', 'Logistic Regression', 'Computational Graph', 'Digital Photograph', 'Cost Function', 'Probability Distribution', 'Binary Outcome', 'Binary Variable', 'Neuron', 'Uniform Distribution', 'Conditional Probability', 'Neural Network', 'Machine Learning', 'Prior Probability', 'Data Conversion', 'Semantics'], 'topic': 'Machine Learning and Probability', 'interaction': [{'status': 'answered', 'answer': 'The probability distribution being referred to is a Bernoulli distribution.', 'completeness': 'Complete', 'relevancy': '2', 'question': 'Do you know, from a probability perspective, what kind of probability distribution this is?', 'timestamp': '[0:01:57]'}, {'status': 'answered', 'answer': 'The functional form determines the parameters, the unknowns that we want to estimate.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What do we mean by functional form?', 'timestamp': '[0:03:38]'}, {'status': 'answered', 'answer': 'No, it is not a good model of the real world process because your expectation is that if theta was truly 0.1, then out of n matches that you watched, you would expect to win. However, you are actually seeing out of 100 matches, you are saying 52.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Is this a good model of the real world process?', 'timestamp': '[0:06:47]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question about data from multiple sources is not addressed.', 'relevancy': '0', 'question': 'What if we got the data from multiple sources, what do we do?', 'timestamp': '[0:14:21]'}, {'status': 'answered', 'answer': "It's a conditional probability distribution, right? But of course a conditional probability is also simply a probability distribution. It's just that we have observed some variables and we are now seeing, given these values of the variables, what is the probability of outcome is equal to win, so this conditional probability distribution is also a Bernoulli.", 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What kind of conditional distribution is this?', 'timestamp': '[0:18:45]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': "Incomplete, the question 'What is better in this case?' is not addressed.", 'relevancy': '0', 'question': 'What is better in this case?', 'timestamp': '[0:21:55]'}, {'status': 'answered', 'answer': 'We need more than that, right? But essentially, what we are saying is, instead of learning an infinite number of theta values, we need to now only learn better zero better one and better to from the data.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': "So essentially, in this case, we're gonna need a minimum of three kms values to find the equation very expression?", 'timestamp': '[0:22:43]'}, {'status': 'answered', 'answer': "There's uncertainty in any prediction.", 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'When are we going to be uncertain about our prediction?', 'timestamp': '[0:27:43]'}, {'status': 'answered', 'answer': 'Yes, we can absolutely use the equation of the circle itself, but the problem is that our input data is rarely two dimensional.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': "Isn't that some sort of functional form in which we can just use the equation of the circle itself?", 'timestamp': '[0:33:00]'}, {'status': 'answered', 'answer': 'It translates to us coming up with a different functional form for the additional probability distribution.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What does that really translate to?', 'timestamp': '[0:32:20]'}, {'status': 'answered', 'answer': "So what we're saying is, if either of these two fires out of one, then it is an area where India is going to win and our prediction becomes right.", 'completeness': 'Complete answer', 'relevancy': '2', 'question': "So what we're saying is, if either of these two fires out of one, then it is an area where India is going to win?", 'timestamp': '[0:44:08]'}], 'summary': "The transcript covers fundamental machine learning concepts, focusing on learning from real-world data to predict cricket match outcomes. It introduces the Bernoulli distribution for modeling binary outcomes, emphasizing the parameter theta for estimating win probabilities and the necessity of assessing model accuracy through cost functions. The discussion includes prior and posterior probabilities, illustrating how initial beliefs can be updated with new data to improve predictions. A betting scenario involving India and Pakistan highlights the importance of historical data in decision-making, raising skepticism about relying solely on past performance. The transcript explains the Bernoulli distribution's characteristics, the significance of estimating parameters from observed data, and the need for caution when interpreting outcomes as samples from a broader process. It also emphasizes decision-making uncertainty and the role of posterior probabilities in adjusting beliefs based on evidence. The concepts of conditional probability and logistic regression are discussed, with logistic regression serving as a foundational model for more complex systems. The session concludes with a focus on neural networks, image classification, and natural language processing, while also planning future discussions and supplementary materials for enhanced understanding."}
{'_id': ObjectId('66b26b74b80f3f3035517f61'), 'file_id': ObjectId('641a8bf1a053a968d797f8ac'), 'file_name': 'Test_Transcription__1679461355-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/Test_Transcription__1679461355-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '00:50:31', 'transcription_path': 'video-results/out_66b26b74b80f3f3035517f61.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 8, 698000), 'file_process_date': datetime.datetime(2024, 9, 25, 18, 11, 58, 931000), 'execution_time': 481.586925, 'status': 'COMPLETED', 'green_line': [{'topic': 'Capacity Planning Overview', 'start_time': '00:00:03', 'end_time': '00:00:21', 'transcript': 'Okay, So hello, everyone on this Iman Alyssa. So today will be conducting session on two topics. One is capacity planning, and the second is the road map in Jiro. So try to cover capacity planning within the first half an hour span and then will continue with the road map injera,', 'keywords': ['Capacity Planning', 'Jira', 'Roadmap'], 'summary': 'The session begins with a greeting from the speaker, Alyssa, who outlines the agenda for the day, focusing on two main topics: capacity planning and the roadmap in Jira. The speaker plans to dedicate the first half hour to discussing capacity planning before moving on to the Jira roadmap.'}, {'topic': 'Capacity Planning Definition', 'start_time': '00:00:22', 'end_time': '00:00:52', 'transcript': "so the festival bodies capacity planning. So, according to the definition that is given here, is capacity planning is the process of identifying how many hours a project or task will require too demanding whether or not your team has the available bans it to complete it and then coordinating that work for maximum efficiency. So what it exactly means is instead offer. You know, I'm just guessing that how much offer can be done.", 'keywords': ['Capacity Planning', 'Resource Management', 'Efficiency'], 'summary': 'The transcript defines capacity planning as the process of determining the number of hours needed for a project or task and assessing whether the team has the available resources to complete it. It emphasizes the importance of coordinating work for maximum efficiency rather than making arbitrary guesses about workload capacity.'}, {'topic': 'Capacity Planning Process', 'start_time': '00:00:52', 'end_time': '00:03:30', 'transcript': "Capacity planning is a complete process in which we are actually identifying the number of work hours that a person on already member in the scrum team can put in and the maximum work that can be achieved with within the spring time frame. For example, if it is a two week spent, then what is the maximum number of effective work hours that each of the resource can give? So that determines the capacityand er It also includes things like, you know, complexity of the storey, and also it's like if it is a very complex storey, then definitely the storey point is more and so that's the reason the efficiency or the, you know work hours will be more and if it is a a medium or lesser complex than definitely the number of our covers required will be lives. So everything of this we take into consideration along witha, for example, a team member out of 15 days. Or to explain that the stand a strength, he will be only for the next two days or last two days. Whatever. Okay, so his effective days will be around eight days, right? So they'll also consider that that okay, he is actually available for eight days, and according to its, his work hours will be calculated.So So this is telling that and then add up the individual capacity to calculate the team's overall capacity. So the complete work covers for each of the team members in adding of all each team members complete work hours. We can make the full capacity of the T right that aghast on your team's overall capacity, which is maximum amount of work that you can pile on their plate before you have over extended them, which we don't want.So this is the basic things are going forward with some more points on capacity planning. It's like on tapestry. Planning helps the team understand the amount of productive engineering time available in a sprint. For example, To perform capacity planning for energy team, you must gather each teammembers availability and time of, as I said regarding their holidays or leaves, you know, I said about the leaves. If there is holidays during those springtime, then definitely we also considered that. And that time of will be for everybody. That is part of the strength.", 'keywords': ['Capacity Planning', 'Scrum Team', 'Work Hours'], 'summary': "The transcript provides an overview of the capacity planning process within a scrum team, detailing how to identify the number of work hours each member can contribute within a sprint. It emphasizes the importance of calculating the maximum effective work hours based on team members' availability, complexity of tasks, and potential time off. The speaker explains that by assessing individual capacities, the overall capacity of the team can be determined, ensuring that the workload does not exceed what the team can handle. This process aids in understanding the productive engineering time available for each sprint, taking into account factors such as holidays and leaves."}, {'topic': 'Estimating Work Hours', 'start_time': '00:03:58', 'end_time': '00:06:37', 'transcript': "So once you have that information, you move into the planning stage. That's very will prioritise task and scheduled those hours so that work is completed by the intended deadline. So capacity means you will root the project plan expectations in reality. So we are not keeping anything for, you know, guess work rather than you're optimistic guesses about what team can churn. Oh, this is the basic thing about capacity. The next comes the ways to estimate so.if a some of you guys are working currently on sprint based projects or even if you are not, I think you must be familiar with things like estimation of the storeys. So how do we do the estimates? So the most common thing that we currently laid to is Storey pointing right?So this is just a just in which I am trying to explain to Otis Storey pointing. So there are a couple of methods that we tried to estimate there's old school, May 3rd storey point, May 3rd storey count and hybrid matters. The most common method is the storey appointments or which we normally deal in storey pointing. Also, there are two ways of Storey pointing that this T shirt sizing and the Fibonacci series oneso again a T shirt sizing, which is like small, medium large Axl, this is not that much used and the Fib Unity series, which is the most commonly used currently on storey pointing.So how is this done? For example? It's a very simple storey and we do not have anything to explore or lots of understanding. Then it will be a storey 0.1 or two, so here. The series is given of it wrong. And sorry I didn't cheque that out. It will be one told 357 notches. Cities. Okay, so if it is a simple one will give a one or two pointers.that a storey pointing is done along with the whole team. As you know, there are grooming sessions during which the whole team sits together, understands the storey and then, as per everybody is voting that is decided whether that storeys and easy one then will give an auto. If it is a medium complex storey will give it a three if it is more complex than it is a five and if it is extremely complicated and very, very difficult will give it eight.So most of the times we tried to break down eight point of storeys into lesser points. Like, you know, two models of three and five. Okay, one storey of three points, another of five points. So body A. This is the way of just, you know, deciding which storey is of how much difficulty level", 'keywords': ['Work Estimation', 'Story Pointing', 'Agile Project Management'], 'summary': 'The transcript discusses the process of estimating work hours in project planning, emphasizing the importance of grounding project expectations in reality to avoid unrealistic assumptions about team productivity. It introduces various estimation methods, particularly focusing on story pointing, which is a popular technique in agile project management. The speaker explains different approaches to story pointing, including T-shirt sizing and the Fibonacci series, detailing how the team collaboratively assesses the complexity of tasks during grooming sessions. The complexity levels are assigned numeric values based on collective input, facilitating a structured estimation process.'}, {'topic': 'Capacity Planning Techniques', 'start_time': '00:06:40', 'end_time': '00:08:49', 'transcript': "So this is just a rough or in a very simple what can is it? A table which is showing how we are doing the capacity planning, though in other real instance are in show you how it issues showing. So the normally we have two ways of doing this capacity planning.Either we do we have a template of Axl shit temperate in which we put in the work hours or else we can donate directly through. So how we are putting a tear in the simple largest explained to him So these are the name of the resources that are part of those Graham.So although people are names are written one other work days for which, for example, this is showing that it is a to experience that why that's why it is 10 days. Okay, In the two weeks we have 10 days, then we have categorised each type of work. Okay, so here you can see the availablenumber of days. Okay, So for example, this person don't have any vacation or anything else. So that's why he is completely available for all the 10 days and his complete work hours is 7010 into seven sewing plans. Seven hours. I am sorrysomething is here in miss Okay, He So we are considering here seven work hours per day. That's the reason we're have given a den into 7. 3070 of us. Okay, then the second person, as you can see here, he has a vacation of one day. Right? So that's the reason his effective days is only nine.And hence the calculation that is coming. It's nine into seven. That is an an hours per day of her, which comes to 63. So in this way, all the team's effort or work hours is calculated, and the total comes to around 3 15 hours.So this is a basic capacity plan, so I'll just give you a glimpse of the actual ones, which we normally use, so it's a bit more complicated than what you have seen, so", 'keywords': ['Capacity Planning', 'Resource Availability', 'Work Hours'], 'summary': 'The transcript discusses capacity planning techniques, specifically highlighting a simple table used for capacity planning. It explains two methods for capacity planning: using a template in Excel to input work hours or calculating directly. The speaker describes how resources are categorized, with emphasis on availability and work hours. For instance, one resource is available for 10 days while another has a vacation day, affecting their total work hours. The total effective work hours for the team is calculated at approximately 315 hours, and the speaker hints at more complex actual capacity planning methods used in practice.'}, {'topic': 'Benefits of Capacity Planning', 'start_time': '00:02:15', 'end_time': '00:20:01', 'transcript': "So what is the benefit of this? So the benefit of this is that you know, we are not keeping anything for, you know, like Cobb, depending on the chance of completion. It's like a sure shot. What they are projecting, what they are planning, what we are focusing, we are able to achieve it. So that is the main benefit of compactD planning. When we do capacity planning in a proper weight and there is very less chance that the gold will be missed or, you know, the maximum among the work we are able to achieve, rather than if we are not doing any capacity planning and randomly taking into work the new know Most of the time it's like we miss on the target and there are storeys which will spill over and you know there will be a chaos with industry.of more like the developer. How much hours they spend? The tester, How much I was Davis pen And how much is the total hours? So accordingly you know, open the Pakis parking on this storey as well as this storey as well as this Storey said the complete fire cover should come to near about 36 so we can keep a track. Okay Addition of all these storeys will come to around 36 right? So you can get the totally here.So next comes is the advantages of capacity planning. So I want to just zoom out. You can get a you. so so for the advantages. So first of all, it is avoid burnout. So what is about team won out is like, you know, the Arges piling work on somebody. And we exactly do not have any idea that whether that person will be able to do or not, or whether he is stretching more just to, you know, fulfil the work and to awe do not want want to stumped him to function like that. We want the work to be done. But also it's not like a person is, you know, working late nights and weekends just to compete. We do not one that can be a planning properly,and we are able to estimate that. Okay, we have a delivery in the state. And so if they are planning in this way, our definitely will meet our posts will meet her deliberated. So this will help to do the work effectively without any stress on the team bus. It is the main thing, like so taking steps to get for understanding of your teams at Children positive in she won't overwhelm them with too many tasks and responsibilities and also support them in managing their time by prioritising the most impactful.then sent more realistic deadlines again the same thing. So it's like something which they can achieve. It's not like a career piling them on, and then at the end of the strength of, even if they are trying their level best, they are not able to achieve so Yah, we do not want that. So get details about availability straight from your team. You will get a much needed reality. Cheques on the Dugan manage deadline expectations according to what your team can actually produce,then the third point is identify skin sock shortages. So by evaluating your team's capacity and planning work in advance, it's easier to spot if projects require skills that your team doesn't have. Accounting for that early allows you to take proactive action, such as training someone on your team. Outsourcing attacks are changing the scope of the project, so I think this is very self explanatory. So when we are planning ahead, so we in.So what is the You know what is lacking and what will blockers in achieving our booths? All this identification will not come once we have jumped into the sprint, so it will come before you have actually taken the work, so you can project it and you can, you know, avoid that. And whatever you are committing, you will be able to deliver. That's the most important thing, right?", 'keywords': ['Capacity Planning', 'Team Burnout', 'Skill Shortages'], 'summary': 'The transcript discusses the benefits of capacity planning in project management, highlighting its role in ensuring that goals are met without overwhelming team members. It emphasizes the importance of proper planning to avoid burnout by distributing tasks realistically and understanding team availability. The speaker explains that effective capacity planning allows for better tracking of hours spent by developers and testers, reducing chaos and missed targets. Key advantages include avoiding team burnout, identifying skill shortages in advance, and managing deadlines based on actual team capabilities, allowing for proactive measures such as training or outsourcing where needed.'}, {'topic': 'Challenges in Capacity Planning', 'start_time': '00:20:03', 'end_time': '00:22:55', 'transcript': "so the challenges of capacity planning said stuff to understand band with. So, yeah, it is tough to understand band with because, you know, view we are projecting that. Okay, this person can do this much hours. It may be that Okay, that person, even if for he is mentioning that I will need three hours of world,Sometimes something happens and he is getting stuck and he needs another more two hours. It's actually not three hours. It's actually five hours. So in that way, when we are calculating everything we are considering, Okay, this work will only take three hours, but actually it is taking more. So this type of difficulty comes.And so that's why it is written. It's tough to understand band with, and though we have a solution to this, which is like the always came buffer hours, as I told you so, that that will take care of this and the gritty or whatever. So your team's bandits is always evolving as projects change and team members leave or join the ranks. So this is another challenge, right? Because, you know, team members are leaving and joining in the middle of this print and also that definitely impacts it.So plus, you need to rely on people's honesty about the current again. The same thing as I told a work may take more a work may take less. So that is also restriction all of that making a challenging to get a firm grasp on just how much capacity your team has available to tackle new work and request, particularly if you have a team full of high achievers always believed that they can takemore. Okay, the more often you have, you talked your team about their most three teams to it weekly, the easier it will get for you to be realist. So as an venue work with a certain team. You know, maybe in the first print your capacity may not be a perfect, but as and when you work on a multiple sprints, you know, like erafter first a Ken than third and consecutive sprint. Then you get the more better grasp on how much each person's capacities is. And if you were, you know, if you are committing more than that, also can district or if you are committing less than also that also you can increase it, so we will get a more realistic idea. Changes will throw you off track. They're gonna risk associated with them.The project and enforcement circumstances, from sense in seasonality to industry changes, will throw wrenches senior plans when you need to try to account for all these potentials. At best, capacity planning isn't always so straight forward. Planning in a cushion, even if it's just an extra day or two, will help you roll with the punches without things running of Paris. So again, this is something it it is likeeven if you are planning, there may be some hindrances, but you know it's much better to go with capacity than without capacity. Then it is like completely chaos, and", 'keywords': ['Capacity Planning', 'Bandwidth', 'Team Dynamics'], 'summary': 'The transcript discusses the various challenges associated with capacity planning in project management. It highlights the difficulty of accurately estimating the bandwidth of team members, as tasks often take longer than projected due to unforeseen circumstances. This uncertainty complicates the ability to determine the actual capacity available for new work. The speaker mentions the dynamic nature of team composition, with members joining and leaving, which further affects capacity assessments. To mitigate these challenges, the importance of regular communication and updates with the team is emphasized, allowing for a more realistic understanding of individual capacities over time. Additionally, the speaker advises incorporating buffer time into planning to accommodate potential disruptions caused by changing project demands or external factors. Ultimately, the discussion underscores the complexities of capacity planning and the necessity of proactive strategies to maintain project efficiency.'}, {'topic': 'Best Practices in Capacity Planning', 'start_time': '00:22:55', 'end_time': '00:24:56', 'transcript': "there is no planning and all if you're doing any, you know, starting or sprint without the capacity, so you will have to engage in some hard conversations again. This is a part of capacity and a tapestry. Planning is only useful if you though something with the information you identify that can involve turning down projects due to lack of bandwidth, adjusting a reducing expectations, pushing out deadlines. It's always better to say no than too serious and not to deliver. So this is the most inPorton part, you know. So capacity planning is for this reason only that you know what you are committing. You should be able to deliver. And if you you are saying like you are able to predict that, Okay, if this much of a commitment I'm giving, I will not be able to deliver than it's better to mention that beforehand rather than taking that one and then not delivering. So that's the mainpurpose of the president planning the next is capital planning. Best Praxis is so some of the tapestry planning West practises are sorry. So learn from past projects. Okay, so this is the main our thing, you know, and a capacity in the first sprint that Udo will never be perfect. It will be a kind of Okay,we are just trying to see. But as and when the A growth, the capacity planning for the future strengths on the next prince will definitely be better and will have a better idea about the amount of work which we should take and will be able to complete. Have honest conversations with Team OK song in here. The you know, transparency is very important, though Scram, Master and theA team member should be completely true with each other so that the another's come. Master understands the limitations of the developer of the tester and also the developer, and the tester truly identifies water. The actual bar covers that he or she is putting, which will again, you know, help us in doing a good capacity.", 'keywords': ['Capacity Planning', 'Transparency', 'Team Communication'], 'summary': 'The transcript discusses best practices in capacity planning, emphasizing the importance of understanding and managing team capacity to avoid overcommitment. It highlights the necessity of engaging in honest conversations about project capabilities, including the potential need to turn down projects or adjust expectations based on bandwidth. The speaker stresses that accurate capacity planning is crucial for making informed commitments and delivering on them, encouraging teams to learn from past projects to improve future planning. Transparency among team members and the Scrum Master is deemed essential for accurately assessing workloads and ensuring successful project execution.'}, {'topic': 'Roadmap Planning Introduction', 'start_time': '00:32:45', 'end_time': '00:34:46', 'transcript': "so I think we are five minutes more. So can we moved to the road map. okay? So now moving ahead with the road maps of what is roadmap? Okay, so road mapping, Jill A software. Our team level roadmaps useful for planning large basis of work several months in advance. A terrific level within a single project. Simple planning and dependency management features help your team's visualise and manage work better. So what is exactly a roadmap is nothing but a planning feature in bet. You know, you canput in all the epics and under native storeys, and you can see the complete picture of like, for example, in which sprint you will be able to complete what feature Sova. Normally, you know the identify features okay, will do this by this April end will do this feature by maybe June will do this feature so fnothing will be clearly visible. If we are using a Roadmaster of Witch spring, we will be able to complete feature one will sprint will be able to complete feature too. So this was kind of a projection. So how does it look into looks like this? Okay, so here you can see, I justSo here you can see a all the storeys that the left side are the epics. It is showing the epics. And these are the things the storeys that you will be able to complete stating the months you residency, the months in which month border the things that we can complete, right?so maybe this epic will be able to complete in the month of December. The second epic will be able to again complete in December the cross team effort epic they will be completing by November. So this other projections that have been made right and the the strike type of things will also be explaining this is kind of dependence is that's right slinking here.", 'keywords': ['Roadmap', 'Epics', 'Dependency Management'], 'summary': 'The transcript discusses the concept of roadmap planning within a software development context. It explains that roadmaps are essential for planning large projects several months in advance, aiding teams in visualizing and managing their work. The speaker highlights that a roadmap allows for the organization of epics and user stories, providing a clear overview of which features will be completed in specific sprints. The importance of visual projections for team coordination and dependency management is emphasized, with examples given of how different epics can be scheduled for completion in various months.'}, {'topic': 'Creating a Roadmap', 'start_time': '00:34:49', 'end_time': '00:38:30', 'transcript': "so far, the key concepts of ethics. Okay, so for I'm in for creating a road map, things that you need to know at the Buddhism and epic is a large body of us that can be broken down into individual tasks required to ship of feature. The world probe becomes a child issue of the epic. Sometimes owner spending epics are displayed as collard bus onthe road map. As I showed you, it was so of epics Are you know again? As I said, like a feature, you there is a feature. Okay, So if that feature is a small feature, if it is a big feature than again, features will be broken down. But if it is a small features that you can't convert into an epic,so just you will create an epic, and underneath it you will again create storeys of that in order to achieve that feature, what other things you need to what other steps you need to do border the storeys that need to be turning out to create that feature in order to complete that feature. So that is epics. So as again, as I said to you, So these are the epics, this whatever icon you are saying in the left, those are epic aiglons.and these are, though, things depicted in coloured bars. what is a child issue again? As I said, under need the epic the create storeys. So the storeys are nothing but child issues. Child issues can be created directly from the road map and administered within the epic the belonged So the storeys that will create under the epic an honest child issues the most common childish you a storeys, tasks and bugs. Okay, but you can create new issue types to represent different type of work for your team's quickly move issues to other tipping and reorder issues or epics by dragging and dropping themdirectly from your road map. So this is kind of saying how you are able to do that. Okay, so you can see the screenshot here. So this is a bug. So under name this epic, which is group booking experience. So they are trying to create a bag or a storey or a tusk. Okay,next to start and dude is the length of the bar on the road map for alleged at the start and due date set for Europe. Pick setting dates for your epic helps to communicate plans with the team and provide visual visibility to external stakeholders. Informed dependence in mapping and helped the resource management. So yeah, so start and doodles are very important. In order to project when you will be able to complete the feature or the epic,you're starting a due date of each of the storeys or child into issues matter, you know, so that you are able to understand. OK, completely a get this epic we will be able to complete in the stand this epic. This temps of this feature will be done by this time Fring.So this is depicting being depicted here. As you can see, the the the the thing that the Yeah. So So far epic when you are putting her start date and the due date So that is kind of you know, high level but in a storey is you know, when you are taking up storeys we normally understand that this storey will be completing in this print trade even if it's a storey you were expecting", 'keywords': ['Roadmap', 'Epics', 'Child Issues'], 'summary': 'The transcript discusses the process of creating a roadmap, particularly in the context of managing features and epics in project management. It explains that epics are large bodies of work that can be divided into smaller tasks needed to complete a feature. These tasks are referred to as child issues or stories. The speaker emphasizes the importance of visual representation on the roadmap, including how to manage and reorder issues efficiently. Additionally, the significance of start and due dates for epics and stories is highlighted, as they aid in planning and resource management. The discussion also touches on the flexibility of creating new issue types and the ability to communicate plans to the team and stakeholders effectively.'}, {'topic': 'Managing Dependencies in Roadmap', 'start_time': '00:40:03', 'end_time': '00:41:34', 'transcript': "What is displaced. Add or remove dependency in progress. Views and filtered expressed doubled to specific time. Frame on the fly is a leave you a road map. Bye weeks months of it Sasuke Zara features that we can use for the road maps, abilities and view setting feature is that then there is the dependency So what is dependency is like you know one storey you will be able to startThere are some times this situation's right In other storey the you will be able to start when you have completed the storey again there will be like a storey See you can be able to start menu of computers the storey So these kind of dependence is of these things These are dependencies and the dependencies were also one kind of You can sit blockers right, Unless and until you complete Storey eh? You cannot start storey pright. So this can be, you know, Mom, this can be shown in the road map dependency Management is critical for teams. When dependence is our visualised and well mapped, a team can adapt and plan for alternative parts. Indira Software You can easily show the relationship between epics by mapping dependence is directly from the road.So this is the way. As I told you, these things show that dependencies. Okay, So for example, once this is done, you can be able to do this. Okay? Say it's mentioned, Bill. Cheque out Experience blocks this. So you have to do this epic bill cheque out experience first, and then only you can be able to do the improve U M U S lite score.", 'keywords': ['Dependency Management', 'Roadmap', 'Visualisation'], 'summary': 'The transcript discusses the management of dependencies in project roadmaps, emphasizing the importance of visualizing and mapping these dependencies for effective team planning. It explains how dependencies can act as blockers, where certain tasks cannot commence until others are completed. The speaker illustrates this concept with examples, highlighting that by clearly mapping dependencies, teams can adapt and identify alternative paths for project execution. The discussion also touches on the relationship between epics and how understanding these dependencies is critical for seamless project management.'}, {'topic': 'Roadmap Tracking and Reporting', 'start_time': '00:41:35', 'end_time': '00:43:38', 'transcript': "this on owners at the dependency. Right? This one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back? This is a plan. And the kind of things can I say that this is a plan the way ofyeah, you You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.I understand. But bear, can I Is there a way of being the actual that being in claim are going with the plan or not? If we look at the very first effect which is going to be completed by first week of April, the lower? Yes. So let's get extent in actual it gets extended by that same one month's end of April. How can I see thatwe are? Then you have to. Then you have to change the due date, right? Then it will show you have to change the due. Did that Okay. We are not able to achieve by this time frame we have extended it. Then it will again show you the actual do. Didthat time thing can? Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reportsat Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what weactually you ST road map you can see Like, for example, you are saying that it is epically an audible to complete by the time we haveestimated the an audible to complete rate. So then again you have to bow and I manually changing, told the due date that we have right. Then you will be able to see the actual it. It's something you have to do it then only will be able to project. It is like not like it'll automatically change and show it, er themselves. It will", 'keywords': ['Roadmap', 'Dependencies', 'Project Tracking'], 'summary': 'The conversation revolves around roadmap tracking and reporting, focusing on the challenges of aligning actual work progress with planned schedules. The speaker discusses the importance of creating a roadmap that includes dependencies for effective planning. They address questions about how to monitor whether the ongoing work is adhering to the initial plan or if adjustments are needed due to delays, exemplified by a project expected to finish by the end of April. The speaker explains that updating due dates is essential to reflect the current status accurately, emphasizing that manual intervention is required to maintain visibility of both estimated and actual timelines.'}, {'topic': 'Roadmap Features', 'start_time': '00:44:32', 'end_time': '00:47:45', 'transcript': "so again and other feature is sure and exports of whatever road matter of created, you will be able to share and export the road map. So sandy, a roadmap directly from Gina to from here a software by typing in news animal innocently copy to grab the roadmap, your export year old map and just the timeline views Star date and in dates before expecting it as an image. So this is like some of the features of road map.create a roadmap injera software. So one of the steps to create a roadmap, Najera software creator, knew Gina Software Project or go to an existing project and then navigate to the side bag and click roadmap. Okay, not if they're not showing saying your roadmap have enabled the road map in the board setting. So again there's a Y.And here, if you are not able to see the roadmap tap than definitely in the board sitting, you need to go and enable it. So people who are comfortable Najera will be understanding what I'm talking about. But if people who are not having hand from Nigeria, they may find it difficult in reading this and understanding that.Then click plus create a pick on the road map to create a picks directly on your road map. If he roadmap is empty, simply start typing to create right name, year epic and hit Enter. You can double click into epics at any time from your road map to add information such a start and ended assigning attachment and more at child issues to European from the road map by clickingnext to the epic name. Okay, select the type of childish uses in the drop down on the named Asia and of the covered it right in a single single points. Few tips for or Mac creation visualise dependence is between epics by creating or removing dependence ceilings directly on Iroda. So this thing for this thing, you actually need to work with the team, right?the product owner as well as the team members both are very important for creating year proper road map in with all the details. Keep your old man up today by adjusting the length of the epic or slide the epic to change the start and due dates. Okay,So again, as I said on that, you can change the started do days. You know, if you something happened and you are not able to complete on the mention time or whatever time the timeframe has registered or shifted. So then you can definitely change the start in. And when work is assigned to team members in Gina, they can easily see how theywork ladders up to epics. Okay, so, yes. So they there is, so this, actually, I have we haven't used much, so we normally have road maps which will project. But here, this is a feature. They're saying that the other team members can also see, like how their work is getting completed. Party. I am not with NGOs. This on very common confirm. I'm not really sure about this", 'keywords': ['Roadmap Creation', 'Gina Software', 'Epics'], 'summary': "The transcript discusses various features of a roadmap creation tool within a software called 'Gina.' It explains how users can share and export roadmaps, navigate the software to create new roadmaps, and manage existing projects. Users are advised to enable roadmap settings in board settings if they cannot see the roadmap feature. The process of creating epics within the roadmap is detailed, including adding information such as start and end dates, assigning attachments, and managing child issues. The importance of collaboration between the product owner and team members for effective roadmap creation is emphasized, along with tips for visualizing dependencies and updating timelines as project needs change."}, {'topic': 'Conclusion and Questions', 'start_time': '00:48:53', 'end_time': '00:50:23', 'transcript': "So that's all from my side. Any other questions here? for any in any questions still. anyone. any questions on this, so I will be sharing, I think. I think for 100 shared this. topic with you If you don't have this p pity than definitely this slide show for a financial she's shared with you both the capacity as well as this. Soa roadmap ting So far handed, we share with the people who have joined here. not are not can go ahead and share this but Ariel so that people can go through it and the in future, if they have anything, they can get back to me. Hand indefinitely, discussso intense, guys. Any other questions? Thank you. Thanks times a lot. of frustration. And I including the feedback An assessment form with the recording on, please. Thank you.Thank you.", 'keywords': ['Feedback', 'Slideshow', 'Engagement'], 'summary': 'The transcript concludes with a summary of the discussion and invites questions from the audience. The speaker mentions sharing additional materials, including a slideshow related to the topic. They encourage participants to reach out with any further inquiries and express gratitude for the engagement. A note regarding feedback and an assessment form is also included, along with a reminder about the recording of the session.'}], 'yellow_line': [{'Topic': 'Capacity Planning Overview', 'transcript': 'Okay, So hello, everyone on this Iman Alyssa. So today will be conducting session on two topics. One is capacity planning, and the second is the road map in Jiro. So try to cover capacity planning within the first half an hour span and then will continue with the road map injera,', 'start_time': '00:00:03', 'end_time': '00:00:21'}, {'Topic': 'Capacity Planning Definition', 'transcript': "so the festival bodies capacity planning. So, according to the definition that is given here, is capacity planning is the process of identifying how many hours a project or task will require too demanding whether or not your team has the available bans it to complete it and then coordinating that work for maximum efficiency. So what it exactly means is instead offer. You know, I'm just guessing that how much offer can be done.", 'start_time': '00:00:22', 'end_time': '00:00:52'}, {'Topic': 'Capacity Planning Process', 'transcript': "Capacity planning is a complete process in which we are actually identifying the number of work hours that a person on already member in the scrum team can put in and the maximum work that can be achieved with within the spring time frame. For example, if it is a two week spent, then what is the maximum number of effective work hours that each of the resource can give? So that determines the capacityand er It also includes things like, you know, complexity of the storey, and also it's like if it is a very complex storey, then definitely the storey point is more and so that's the reason the efficiency or the, you know work hours will be more and if it is a a medium or lesser complex than definitely the number of our covers required will be lives. So everything of this we take into consideration along witha, for example, a team member out of 15 days. Or to explain that the stand a strength, he will be only for the next two days or last two days. Whatever. Okay, so his effective days will be around eight days, right? So they'll also consider that that okay, he is actually available for eight days, and according to its, his work hours will be calculated.So So this is telling that and then add up the individual capacity to calculate the team's overall capacity. So the complete work covers for each of the team members in adding of all each team members complete work hours. We can make the full capacity of the T right that aghast on your team's overall capacity, which is maximum amount of work that you can pile on their plate before you have over extended them, which we don't want.So this is the basic things are going forward with some more points on capacity planning. It's like on tapestry. Planning helps the team understand the amount of productive engineering time available in a sprint. For example, To perform capacity planning for energy team, you must gather each teammembers availability and time of, as I said regarding their holidays or leaves, you know, I said about the leaves. If there is holidays during those springtime, then definitely we also considered that. And that time of will be for everybody. That is part of the strength.", 'start_time': '00:00:52', 'end_time': '00:03:30'}, {'Topic': 'Estimating Work Hours', 'transcript': "So once you have that information, you move into the planning stage. That's very will prioritise task and scheduled those hours so that work is completed by the intended deadline. So capacity means you will root the project plan expectations in reality. So we are not keeping anything for, you know, guess work rather than you're optimistic guesses about what team can churn. Oh, this is the basic thing about capacity. The next comes the ways to estimate so.if a some of you guys are working currently on sprint based projects or even if you are not, I think you must be familiar with things like estimation of the storeys. So how do we do the estimates? So the most common thing that we currently laid to is Storey pointing right?So this is just a just in which I am trying to explain to Otis Storey pointing. So there are a couple of methods that we tried to estimate there's old school, May 3rd storey point, May 3rd storey count and hybrid matters. The most common method is the storey appointments or which we normally deal in storey pointing. Also, there are two ways of Storey pointing that this T shirt sizing and the Fibonacci series oneso again a T shirt sizing, which is like small, medium large Axl, this is not that much used and the Fib Unity series, which is the most commonly used currently on storey pointing.So how is this done? For example? It's a very simple storey and we do not have anything to explore or lots of understanding. Then it will be a storey 0.1 or two, so here. The series is given of it wrong. And sorry I didn't cheque that out. It will be one told 357 notches. Cities. Okay, so if it is a simple one will give a one or two pointers.that a storey pointing is done along with the whole team. As you know, there are grooming sessions during which the whole team sits together, understands the storey and then, as per everybody is voting that is decided whether that storeys and easy one then will give an auto. If it is a medium complex storey will give it a three if it is more complex than it is a five and if it is extremely complicated and very, very difficult will give it eight.So most of the times we tried to break down eight point of storeys into lesser points. Like, you know, two models of three and five. Okay, one storey of three points, another of five points. So body A. This is the way of just, you know, deciding which storey is of how much difficulty level", 'start_time': '00:03:58', 'end_time': '00:06:37'}, {'Topic': 'Capacity Planning Techniques', 'transcript': "So this is just a rough or in a very simple what can is it? A table which is showing how we are doing the capacity planning, though in other real instance are in show you how it issues showing. So the normally we have two ways of doing this capacity planning.Either we do we have a template of Axl shit temperate in which we put in the work hours or else we can donate directly through. So how we are putting a tear in the simple largest explained to him So these are the name of the resources that are part of those Graham.So although people are names are written one other work days for which, for example, this is showing that it is a to experience that why that's why it is 10 days. Okay, In the two weeks we have 10 days, then we have categorised each type of work. Okay, so here you can see the availablenumber of days. Okay, So for example, this person don't have any vacation or anything else. So that's why he is completely available for all the 10 days and his complete work hours is 7010 into seven sewing plans. Seven hours. I am sorrysomething is here in miss Okay, He So we are considering here seven work hours per day. That's the reason we're have given a den into 7. 3070 of us. Okay, then the second person, as you can see here, he has a vacation of one day. Right? So that's the reason his effective days is only nine.And hence the calculation that is coming. It's nine into seven. That is an an hours per day of her, which comes to 63. So in this way, all the team's effort or work hours is calculated, and the total comes to around 3 15 hours.So this is a basic capacity plan, so I'll just give you a glimpse of the actual ones, which we normally use, so it's a bit more complicated than what you have seen, so", 'start_time': '00:06:40', 'end_time': '00:08:49'}, {'Topic': 'Benefits of Capacity Planning', 'transcript': "So what is the benefit of this? So the benefit of this is that you know, we are not keeping anything for, you know, like Cobb, depending on the chance of completion. It's like a sure shot. What they are projecting, what they are planning, what we are focusing, we are able to achieve it. So that is the main benefit of compactD planning. When we do capacity planning in a proper weight and there is very less chance that the gold will be missed or, you know, the maximum among the work we are able to achieve, rather than if we are not doing any capacity planning and randomly taking into work the new know Most of the time it's like we miss on the target and there are storeys which will spill over and you know there will be a chaos with industry.of more like the developer. How much hours they spend? The tester, How much I was Davis pen And how much is the total hours? So accordingly you know, open the Pakis parking on this storey as well as this storey as well as this Storey said the complete fire cover should come to near about 36 so we can keep a track. Okay Addition of all these storeys will come to around 36 right? So you can get the totally here.So next comes is the advantages of capacity planning. So I want to just zoom out. You can get a you. so so for the advantages. So first of all, it is avoid burnout. So what is about team won out is like, you know, the Arges piling work on somebody. And we exactly do not have any idea that whether that person will be able to do or not, or whether he is stretching more just to, you know, fulfil the work and to awe do not want want to stumped him to function like that. We want the work to be done. But also it's not like a person is, you know, working late nights and weekends just to compete. We do not one that can be a planning properly,and we are able to estimate that. Okay, we have a delivery in the state. And so if they are planning in this way, our definitely will meet our posts will meet her deliberated. So this will help to do the work effectively without any stress on the team bus. It is the main thing, like so taking steps to get for understanding of your teams at Children positive in she won't overwhelm them with too many tasks and responsibilities and also support them in managing their time by prioritising the most impactful.then sent more realistic deadlines again the same thing. So it's like something which they can achieve. It's not like a career piling them on, and then at the end of the strength of, even if they are trying their level best, they are not able to achieve so Yah, we do not want that. So get details about availability straight from your team. You will get a much needed reality. Cheques on the Dugan manage deadline expectations according to what your team can actually produce,then the third point is identify skin sock shortages. So by evaluating your team's capacity and planning work in advance, it's easier to spot if projects require skills that your team doesn't have. Accounting for that early allows you to take proactive action, such as training someone on your team. Outsourcing attacks are changing the scope of the project, so I think this is very self explanatory. So when we are planning ahead, so we in.So what is the You know what is lacking and what will blockers in achieving our booths? All this identification will not come once we have jumped into the sprint, so it will come before you have actually taken the work, so you can project it and you can, you know, avoid that. And whatever you are committing, you will be able to deliver. That's the most important thing, right?", 'start_time': '00:02:15', 'end_time': '00:20:01'}, {'Topic': 'Challenges in Capacity Planning', 'transcript': "so the challenges of capacity planning said stuff to understand band with. So, yeah, it is tough to understand band with because, you know, view we are projecting that. Okay, this person can do this much hours. It may be that Okay, that person, even if for he is mentioning that I will need three hours of world,Sometimes something happens and he is getting stuck and he needs another more two hours. It's actually not three hours. It's actually five hours. So in that way, when we are calculating everything we are considering, Okay, this work will only take three hours, but actually it is taking more. So this type of difficulty comes.And so that's why it is written. It's tough to understand band with, and though we have a solution to this, which is like the always came buffer hours, as I told you so, that that will take care of this and the gritty or whatever. So your team's bandits is always evolving as projects change and team members leave or join the ranks. So this is another challenge, right? Because, you know, team members are leaving and joining in the middle of this print and also that definitely impacts it.So plus, you need to rely on people's honesty about the current again. The same thing as I told a work may take more a work may take less. So that is also restriction all of that making a challenging to get a firm grasp on just how much capacity your team has available to tackle new work and request, particularly if you have a team full of high achievers always believed that they can takemore. Okay, the more often you have, you talked your team about their most three teams to it weekly, the easier it will get for you to be realist. So as an venue work with a certain team. You know, maybe in the first print your capacity may not be a perfect, but as and when you work on a multiple sprints, you know, like erafter first a Ken than third and consecutive sprint. Then you get the more better grasp on how much each person's capacities is. And if you were, you know, if you are committing more than that, also can district or if you are committing less than also that also you can increase it, so we will get a more realistic idea. Changes will throw you off track. They're gonna risk associated with them.The project and enforcement circumstances, from sense in seasonality to industry changes, will throw wrenches senior plans when you need to try to account for all these potentials. At best, capacity planning isn't always so straight forward. Planning in a cushion, even if it's just an extra day or two, will help you roll with the punches without things running of Paris. So again, this is something it it is likeeven if you are planning, there may be some hindrances, but you know it's much better to go with capacity than without capacity. Then it is like completely chaos, and", 'start_time': '00:20:03', 'end_time': '00:22:55'}, {'Topic': 'Best Practices in Capacity Planning', 'transcript': "there is no planning and all if you're doing any, you know, starting or sprint without the capacity, so you will have to engage in some hard conversations again. This is a part of capacity and a tapestry. Planning is only useful if you though something with the information you identify that can involve turning down projects due to lack of bandwidth, adjusting a reducing expectations, pushing out deadlines. It's always better to say no than too serious and not to deliver. So this is the most inPorton part, you know. So capacity planning is for this reason only that you know what you are committing. You should be able to deliver. And if you you are saying like you are able to predict that, Okay, if this much of a commitment I'm giving, I will not be able to deliver than it's better to mention that beforehand rather than taking that one and then not delivering. So that's the mainpurpose of the president planning the next is capital planning. Best Praxis is so some of the tapestry planning West practises are sorry. So learn from past projects. Okay, so this is the main our thing, you know, and a capacity in the first sprint that Udo will never be perfect. It will be a kind of Okay,we are just trying to see. But as and when the A growth, the capacity planning for the future strengths on the next prince will definitely be better and will have a better idea about the amount of work which we should take and will be able to complete. Have honest conversations with Team OK song in here. The you know, transparency is very important, though Scram, Master and theA team member should be completely true with each other so that the another's come. Master understands the limitations of the developer of the tester and also the developer, and the tester truly identifies water. The actual bar covers that he or she is putting, which will again, you know, help us in doing a good capacity.", 'start_time': '00:22:55', 'end_time': '00:24:56'}, {'Topic': 'Roadmap Planning Introduction', 'transcript': "so I think we are five minutes more. So can we moved to the road map. okay? So now moving ahead with the road maps of what is roadmap? Okay, so road mapping, Jill A software. Our team level roadmaps useful for planning large basis of work several months in advance. A terrific level within a single project. Simple planning and dependency management features help your team's visualise and manage work better. So what is exactly a roadmap is nothing but a planning feature in bet. You know, you canput in all the epics and under native storeys, and you can see the complete picture of like, for example, in which sprint you will be able to complete what feature Sova. Normally, you know the identify features okay, will do this by this April end will do this feature by maybe June will do this feature so fnothing will be clearly visible. If we are using a Roadmaster of Witch spring, we will be able to complete feature one will sprint will be able to complete feature too. So this was kind of a projection. So how does it look into looks like this? Okay, so here you can see, I justSo here you can see a all the storeys that the left side are the epics. It is showing the epics. And these are the things the storeys that you will be able to complete stating the months you residency, the months in which month border the things that we can complete, right?so maybe this epic will be able to complete in the month of December. The second epic will be able to again complete in December the cross team effort epic they will be completing by November. So this other projections that have been made right and the the strike type of things will also be explaining this is kind of dependence is that's right slinking here.", 'start_time': '00:32:45', 'end_time': '00:34:46'}, {'Topic': 'Creating a Roadmap', 'transcript': "so far, the key concepts of ethics. Okay, so for I'm in for creating a road map, things that you need to know at the Buddhism and epic is a large body of us that can be broken down into individual tasks required to ship of feature. The world probe becomes a child issue of the epic. Sometimes owner spending epics are displayed as collard bus onthe road map. As I showed you, it was so of epics Are you know again? As I said, like a feature, you there is a feature. Okay, So if that feature is a small feature, if it is a big feature than again, features will be broken down. But if it is a small features that you can't convert into an epic,so just you will create an epic, and underneath it you will again create storeys of that in order to achieve that feature, what other things you need to what other steps you need to do border the storeys that need to be turning out to create that feature in order to complete that feature. So that is epics. So as again, as I said to you, So these are the epics, this whatever icon you are saying in the left, those are epic aiglons.and these are, though, things depicted in coloured bars. what is a child issue again? As I said, under need the epic the create storeys. So the storeys are nothing but child issues. Child issues can be created directly from the road map and administered within the epic the belonged So the storeys that will create under the epic an honest child issues the most common childish you a storeys, tasks and bugs. Okay, but you can create new issue types to represent different type of work for your team's quickly move issues to other tipping and reorder issues or epics by dragging and dropping themdirectly from your road map. So this is kind of saying how you are able to do that. Okay, so you can see the screenshot here. So this is a bug. So under name this epic, which is group booking experience. So they are trying to create a bag or a storey or a tusk. Okay,next to start and dude is the length of the bar on the road map for alleged at the start and due date set for Europe. Pick setting dates for your epic helps to communicate plans with the team and provide visual visibility to external stakeholders. Informed dependence in mapping and helped the resource management. So yeah, so start and doodles are very important. In order to project when you will be able to complete the feature or the epic,you're starting a due date of each of the storeys or child into issues matter, you know, so that you are able to understand. OK, completely a get this epic we will be able to complete in the stand this epic. This temps of this feature will be done by this time Fring.So this is depicting being depicted here. As you can see, the the the the thing that the Yeah. So So far epic when you are putting her start date and the due date So that is kind of you know, high level but in a storey is you know, when you are taking up storeys we normally understand that this storey will be completing in this print trade even if it's a storey you were expecting", 'start_time': '00:34:49', 'end_time': '00:38:30'}, {'Topic': 'Managing Dependencies in Roadmap', 'transcript': "What is displaced. Add or remove dependency in progress. Views and filtered expressed doubled to specific time. Frame on the fly is a leave you a road map. Bye weeks months of it Sasuke Zara features that we can use for the road maps, abilities and view setting feature is that then there is the dependency So what is dependency is like you know one storey you will be able to startThere are some times this situation's right In other storey the you will be able to start when you have completed the storey again there will be like a storey See you can be able to start menu of computers the storey So these kind of dependence is of these things These are dependencies and the dependencies were also one kind of You can sit blockers right, Unless and until you complete Storey eh? You cannot start storey pright. So this can be, you know, Mom, this can be shown in the road map dependency Management is critical for teams. When dependence is our visualised and well mapped, a team can adapt and plan for alternative parts. Indira Software You can easily show the relationship between epics by mapping dependence is directly from the road.So this is the way. As I told you, these things show that dependencies. Okay, So for example, once this is done, you can be able to do this. Okay? Say it's mentioned, Bill. Cheque out Experience blocks this. So you have to do this epic bill cheque out experience first, and then only you can be able to do the improve U M U S lite score.", 'start_time': '00:40:03', 'end_time': '00:41:34'}, {'Topic': 'Roadmap Tracking and Reporting', 'transcript': "this on owners at the dependency. Right? This one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back? This is a plan. And the kind of things can I say that this is a plan the way ofyeah, you You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.I understand. But bear, can I Is there a way of being the actual that being in claim are going with the plan or not? If we look at the very first effect which is going to be completed by first week of April, the lower? Yes. So let's get extent in actual it gets extended by that same one month's end of April. How can I see thatwe are? Then you have to. Then you have to change the due date, right? Then it will show you have to change the due. Did that Okay. We are not able to achieve by this time frame we have extended it. Then it will again show you the actual do. Didthat time thing can? Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reportsat Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what weactually you ST road map you can see Like, for example, you are saying that it is epically an audible to complete by the time we haveestimated the an audible to complete rate. So then again you have to bow and I manually changing, told the due date that we have right. Then you will be able to see the actual it. It's something you have to do it then only will be able to project. It is like not like it'll automatically change and show it, er themselves. It will", 'start_time': '00:41:35', 'end_time': '00:43:38'}, {'Topic': 'Roadmap Features', 'transcript': "so again and other feature is sure and exports of whatever road matter of created, you will be able to share and export the road map. So sandy, a roadmap directly from Gina to from here a software by typing in news animal innocently copy to grab the roadmap, your export year old map and just the timeline views Star date and in dates before expecting it as an image. So this is like some of the features of road map.create a roadmap injera software. So one of the steps to create a roadmap, Najera software creator, knew Gina Software Project or go to an existing project and then navigate to the side bag and click roadmap. Okay, not if they're not showing saying your roadmap have enabled the road map in the board setting. So again there's a Y.And here, if you are not able to see the roadmap tap than definitely in the board sitting, you need to go and enable it. So people who are comfortable Najera will be understanding what I'm talking about. But if people who are not having hand from Nigeria, they may find it difficult in reading this and understanding that.Then click plus create a pick on the road map to create a picks directly on your road map. If he roadmap is empty, simply start typing to create right name, year epic and hit Enter. You can double click into epics at any time from your road map to add information such a start and ended assigning attachment and more at child issues to European from the road map by clickingnext to the epic name. Okay, select the type of childish uses in the drop down on the named Asia and of the covered it right in a single single points. Few tips for or Mac creation visualise dependence is between epics by creating or removing dependence ceilings directly on Iroda. So this thing for this thing, you actually need to work with the team, right?the product owner as well as the team members both are very important for creating year proper road map in with all the details. Keep your old man up today by adjusting the length of the epic or slide the epic to change the start and due dates. Okay,So again, as I said on that, you can change the started do days. You know, if you something happened and you are not able to complete on the mention time or whatever time the timeframe has registered or shifted. So then you can definitely change the start in. And when work is assigned to team members in Gina, they can easily see how theywork ladders up to epics. Okay, so, yes. So they there is, so this, actually, I have we haven't used much, so we normally have road maps which will project. But here, this is a feature. They're saying that the other team members can also see, like how their work is getting completed. Party. I am not with NGOs. This on very common confirm. I'm not really sure about this", 'start_time': '00:44:32', 'end_time': '00:47:45'}, {'Topic': 'Conclusion and Questions', 'transcript': "So that's all from my side. Any other questions here? for any in any questions still. anyone. any questions on this, so I will be sharing, I think. I think for 100 shared this. topic with you If you don't have this p pity than definitely this slide show for a financial she's shared with you both the capacity as well as this. Soa roadmap ting So far handed, we share with the people who have joined here. not are not can go ahead and share this but Ariel so that people can go through it and the in future, if they have anything, they can get back to me. Hand indefinitely, discussso intense, guys. Any other questions? Thank you. Thanks times a lot. of frustration. And I including the feedback An assessment form with the recording on, please. Thank you.Thank you.", 'start_time': '00:48:53', 'end_time': '00:50:23'}], 'session_id': [ObjectId('641a8c21a053a968d797f8af')], 'assessment': ObjectId('66f4533dc248cb8c5215403b'), 'job_name': 'my-transcription-joba7396ca9-db9d-4fe5-bbb6-1d06e0d2955a', 'keywords': ['Project Tracking', 'Work Hours', 'Visualisation', 'Slideshow', 'Team Communication', 'Work Estimation', 'Team Burnout', 'Story Pointing', 'Capacity Planning', 'Roadmap Creation', 'Gina Software', 'Epics', 'Feedback', 'Resource Management', 'Child Issues', 'Bandwidth', 'Jira', 'Roadmap', 'Dependency Management', 'Scrum', 'Skill Shortages', 'Scrum Team', 'Agile Project Management', 'Engagement', 'Dependencies', 'Resource Availability', 'Team Dynamics', 'Transparency', 'Efficiency'], 'topic': 'Agile Project Management', 'interaction': [{'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How did you come to this cream? The app that', 'timestamp': '[0:28:08]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Can you go back to the queen like the Yeah. So what does this mean, Ours? Out of expected 38 hours.', 'timestamp': '[0:31:46]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Is there a way of I can see side by side how my actual work is going on? Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back?', 'timestamp': '[0:41:40]'}, {'status': 'answered', 'answer': "You can see your plan by using the roadmap feature, but it won't automatically show you previous due dates. You need to manually adjust the due dates to reflect any changes.", 'completeness': 'Complete answer, it addresses the question about seeing the plan and explains the manual adjustment needed.', 'relevancy': '2', 'question': "Is there a way of what I've planned earlier and halted actual right now, Is there a way of I can see that this is a plan?", 'timestamp': '[0:42:49]'}], 'summary': "The session covers two main topics: capacity planning and the roadmap in Jira. Capacity planning is defined as determining the hours needed for a project while assessing team resource availability to maximize efficiency. The process involves calculating individual contributions within a sprint, considering factors like task complexity and team availability. Estimation methods, particularly story pointing, are discussed, highlighting techniques like T-shirt sizing and the Fibonacci series for task complexity assessment. A simple table for capacity planning is introduced, alongside methods for categorizing resources based on availability, which impacts total effective work hours.\n\nThe benefits of capacity planning in project management are emphasized, including avoiding team burnout and ensuring realistic task distribution. Challenges such as accurately estimating team bandwidth and dynamic team composition are addressed, with a focus on the necessity of regular communication and buffer time in planning. Best practices highlight the importance of transparency and realistic project commitments.\n\nThe session also delves into roadmap planning, explaining its role in organizing large projects and managing features and epics. The creation of a roadmap involves visual representation of tasks, start and due dates, and managing dependencies that can impact project execution. The discussion covers tracking and reporting on roadmaps, emphasizing the need for regular updates to maintain alignment with actual progress.\n\nA roadmap creation tool within the software 'Gina' is detailed, including features for sharing, exporting, and managing projects. Collaboration between product owners and team members is deemed essential for effective roadmap creation. The session concludes with a summary and an invitation for questions, along with a note on feedback and additional materials related to the topics discussed."}
{'_id': ObjectId('66b26b73b80f3f3035517f59'), 'file_id': ObjectId('64006263f521b8e83e39f95e'), 'file_name': '1677585013-6389d2cbb352ac0640395521__1677746781-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/1677585013-6389d2cbb352ac0640395521__1677746781-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '00:50:31', 'transcription_path': 'video-results/out_66b26b73b80f3f3035517f59.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 7, 752000), 'file_process_date': datetime.datetime(2024, 8, 23, 17, 24, 27, 870000), 'execution_time': 363.48053, 'status': 'COMPLETE', 'green_line': [{'topic': 'Capacity Planning Overview', 'start_time': '00:00:03', 'end_time': '00:00:21', 'transcript': 'Okay, So hello, everyone on this Iman Alyssa. So today will be conducting session on two topics. One is capacity planning, and the second is the road map in Jiro. So try to cover capacity planning within the first half an hour span and then will continue with the road map injera,', 'keywords': ['Capacity Planning', 'Roadmap', 'JIRA'], 'summary': 'The session begins with an introduction by Iman Alyssa, who outlines the agenda covering two main topics: capacity planning and the roadmap in JIRA. The speaker aims to focus on capacity planning during the first half of the session, indicating a structured approach to the topics.'}, {'topic': 'Capacity Planning Process', 'start_time': '00:00:22', 'end_time': '00:03:58', 'transcript': "so the festival bodies capacity planning. So, according to the definition that is given here, is capacity planning is the process of identifying how many hours a project or task will require too demanding whether or not your team has the available bans it to complete it and then coordinating that work for maximum efficiency. So what it exactly means is instead offer. You know, I'm just guessing that how much offer can be done.Capacity planning is a complete process in which we are actually identifying the number of work hours that a person on already member in the scrum team can put in and the maximum work that can be achieved with within the spring time frame. For example, if it is a two week spent, then what is the maximum number of effective work hours that each of the resource can give? So that determines the capacityand er It also includes things like, you know, complexity of the storey, and also it's like if it is a very complex storey, then definitely the storey point is more and so that's the reason the efficiency or the, you know work hours will be more and if it is a a medium or lesser complex than definitely the number of our covers required will be lives. So everything of this we take into consideration along witha, for example, a team member out of 15 days. Or to explain that the stand a strength, he will be only for the next two days or last two days. Whatever. Okay, so his effective days will be around eight days, right? So they'll also consider that that okay, he is actually available for eight days, and according to its, his work hours will be calculated.So what is the benefit of this? So the benefit of this is that you know, we are not keeping anything for, you know, like Cobb, depending on the chance of completion. It's like a sure shot. What they are projecting, what they are planning, what we are focusing, we are able to achieve it. So that is the main benefit of compactD planning. When we do capacity planning in a proper weight and there is very less chance that the gold will be missed or, you know, the maximum among the work we are able to achieve, rather than if we are not doing any capacity planning and randomly taking into work the new know Most of the time it's like we miss on the target and there are storeys which will spill over and you know there will be a chaos with industry.So this is the basic things are going forward with some more points on capacity planning. It's like on tapestry. Planning helps the team understand the amount of productive engineering time available in a sprint. For example, To perform capacity planning for energy team, you must gather each teammembers availability and time of, as I said regarding their holidays or leaves, you know, I said about the leaves. If there is holidays during those springtime, then definitely we also considered that. And that time of will be for everybody. That is part of the strength.So So this is telling that and then add up the individual capacity to calculate the team's overall capacity. So the complete work covers for each of the team members in adding of all each team members complete work hours. We can make the full capacity of the T right that aghast on your team's overall capacity, which is maximum amount of work that you can pile on their plate before you have over extended them, which we don't want.", 'keywords': ['Capacity Planning', 'Sprint', 'Scrum Team', 'Work Hours', 'Task Complexity', 'Team Capacity'], 'summary': 'The transcript discusses the capacity planning process, defining it as a method for determining the number of hours required for a project or task and assessing whether a team has the necessary bandwidth to complete it efficiently. It emphasizes the importance of accurately identifying work hours for each member of a scrum team within a given sprint timeframe, such as two weeks, and how factors like task complexity influence the required hours. The speaker highlights the need to consider individual availability, including holidays and leaves, to calculate the overall team capacity. Proper capacity planning leads to better project outcomes, minimizing the chances of missing goals and preventing chaos in task management. It ultimately aims to ensure that the team is neither overburdened nor underutilized, optimizing productivity.'}, {'topic': 'Capacity Estimation Techniques', 'start_time': '00:03:58', 'end_time': '00:06:37', 'transcript': "So once you have that information, you move into the planning stage. That's very will prioritise task and scheduled those hours so that work is completed by the intended deadline. So capacity means you will root the project plan expectations in reality. So we are not keeping anything for, you know, guess work rather than you're optimistic guesses about what team can churn. Oh, this is the basic thing about capacity. The next comes the ways to estimate so.if a some of you guys are working currently on sprint based projects or even if you are not, I think you must be familiar with things like estimation of the storeys. So how do we do the estimates? So the most common thing that we currently laid to is Storey pointing right?So this is just a just in which I am trying to explain to Otis Storey pointing. So there are a couple of methods that we tried to estimate there's old school, May 3rd storey point, May 3rd storey count and hybrid matters. The most common method is the storey appointments or which we normally deal in storey pointing. Also, there are two ways of Storey pointing that this T shirt sizing and the Fibonacci series oneso again a T shirt sizing, which is like small, medium large Axl, this is not that much used and the Fib Unity series, which is the most commonly used currently on storey pointing.So how is this done? For example? It's a very simple storey and we do not have anything to explore or lots of understanding. Then it will be a storey 0.1 or two, so here. The series is given of it wrong. And sorry I didn't cheque that out. It will be one told 357 notches. Cities. Okay, so if it is a simple one will give a one or two pointers.that a storey pointing is done along with the whole team. As you know, there are grooming sessions during which the whole team sits together, understands the storey and then, as per everybody is voting that is decided whether that storeys and easy one then will give an auto. If it is a medium complex storey will give it a three if it is more complex than it is a five and if it is extremely complicated and very, very difficult will give it eight.So most of the times we tried to break down eight point of storeys into lesser points. Like, you know, two models of three and five. Okay, one storey of three points, another of five points. So body A. This is the way of just, you know, deciding which storey is of how much difficulty level", 'keywords': ['Capacity Estimation', 'Project Management', 'Story Pointing', 'Agile', 'T-shirt Sizing', 'Fibonacci Series'], 'summary': 'The transcript discusses capacity estimation techniques in project management, emphasizing the importance of planning and realistic expectations for project timelines. It highlights the process of task prioritization and scheduling to meet deadlines, while avoiding guesswork. The speaker introduces various estimation methods, particularly focusing on story pointing, which is commonly used in agile frameworks. They explain the different approaches to story pointing, including T-shirt sizing and the Fibonacci series, detailing how teams collaboratively estimate the complexity of user stories during grooming sessions. The speaker provides examples of scoring user stories based on their complexity, illustrating how simpler stories might receive lower scores while more complicated ones are broken down into smaller, manageable parts.'}, {'topic': 'Capacity Planning Tools', 'start_time': '00:06:40', 'end_time': '00:08:49', 'transcript': "So this is just a rough or in a very simple what can is it? A table which is showing how we are doing the capacity planning, though in other real instance are in show you how it issues showing. So the normally we have two ways of doing this capacity planning.Either we do we have a template of Axl shit temperate in which we put in the work hours or else we can donate directly through. So how we are putting a tear in the simple largest explained to him So these are the name of the resources that are part of those Graham.So although people are names are written one other work days for which, for example, this is showing that it is a to experience that why that's why it is 10 days. Okay, In the two weeks we have 10 days, then we have categorised each type of work. Okay, so here you can see the availablenumber of days. Okay, So for example, this person don't have any vacation or anything else. So that's why he is completely available for all the 10 days and his complete work hours is 7010 into seven sewing plans. Seven hours. I am sorrysomething is here in miss Okay, He So we are considering here seven work hours per day. That's the reason we're have given a den into 7. 3070 of us. Okay, then the second person, as you can see here, he has a vacation of one day. Right? So that's the reason his effective days is only nine.And hence the calculation that is coming. It's nine into seven. That is an an hours per day of her, which comes to 63. So in this way, all the team's effort or work hours is calculated, and the total comes to around 3 15 hours.So this is a basic capacity plan, so I'll just give you a glimpse of the actual ones, which we normally use, so it's a bit more complicated than what you have seen, so", 'keywords': ['Capacity Planning', 'Work Hours', 'Resources', 'Vacation', 'Effective Days'], 'summary': 'The transcript discusses the basics of capacity planning tools, specifically highlighting a simple table used for tracking work hours. The speaker explains two methods for capacity planning: using a template and direct input. They detail how resources are categorized, showing the availability of individuals based on their scheduled workdays and any vacations. For instance, one person is available for all 10 days while another has a vacation day, impacting their total work hours. The speaker emphasizes the calculation process for determining total team work hours, culminating in a total of approximately 315 hours. They also hint at more complex capacity planning tools used in practice.'}, {'topic': 'Capacity Planning Benefits', 'start_time': '00:08:57', 'end_time': '00:13:50', 'transcript': "not able to. I was able to see this. it's the said this light show. right. the thinking, okay? so went above this one. Is it so now unable to? You guys were able to say this.it's better than before. Yeah, literally. Can you zoom? And I don't think it's a numbing with resume.Maybe you have to come out on the slide show and land new China. There's an option to. consume you never screams as well.There is a plus sign the next two years. Aargh! Point on ya, hon. Just under Insert Manu Under in 30 days a zoo Michael.just take on the drop down arrow and them. Zuman. Okay. Okay. Lydia. Thank you, Yah! so Yeah. So this is actually some sort of a real life capacity planning sheet that we are actually using. So it's a bit more complex than what I show new as a unit sister format, you can seeSo here you can say everything is mentioned. Who are the team members? What are the total number of this string shot is not full. So because I couldn't take it in a single stream. So there are some more few more members the chairman sing here. So this is train shot with, I mean part of the scrum team, not the full. As you can see from here, all the members are being seenso here that the members are there. So total spring daisy A mentioning water, the holidays. If there is any any leads for any of the resources, what on the actual days. So what are the actual days means what at the days that they are actually working per day hours. So here we have taken six tapesix hours per day and we keep two hours for buffer. Usually that is assigned because, you know, we do have several meetings when we are part of the sprint or a scam. We have several meetings. So that's why be assigned belief to ask per day for this kind of activities, meeting activities and other, you know.Connexion, connecting with the your team members and also effective work hours. This six. So accordingly of what is the number of hours per person gets is 36 hours for the full sprint, which is two week Sprint Reich.So hearing you can see for 68 here we have another small thing where we are calculating the total death effort, complete depth effort of work hours and the queue way work hours. Okay, so 20 for is the Dever covers and 140 for Solly. It's percent estimate. Whatever 135 you ever coveredalong with, we have another. okay? becoming Dombeck 50 person, 100%. Okay, so yeah, along that we have a few more things, like, you know, what is the available capacity? What is the time estimate and capacity utilisation. Capacity remaining. So, for example, a person has 36 capacity. But as per the storey points, we are able to assign only 30 work hours, so he will have a remaining capacity of 5% or fivein which he can accommodate any ad host stance or anything that comes in between. So those kind of things are also there. So here we can monitor which team member has got the, you know, his capacities move than his actual available capacity or it is lesser. And if if he has any banned with left, where we can take on", 'keywords': ['Capacity Planning', 'Team Members', 'Work Hours', 'Sprint', 'Buffer Time', 'Capacity Utilization'], 'summary': "The transcript discusses the complexities of capacity planning within a team setting. It highlights the importance of tracking team members' availability, workload, and capacity utilization during a sprint. The speaker elaborates on a capacity planning sheet used in real-life scenarios, detailing team member roles, total work hours, and the allocation of buffer time for meetings and collaborative activities. They explain how to calculate available capacity versus assigned work, emphasizing the need for monitoring each member's workload to ensure efficient resource allocation and to accommodate any unexpected tasks that may arise. The overall focus is on optimizing team performance through effective capacity planning."}, {'topic': 'Challenges in Capacity Planning', 'start_time': '00:13:51', 'end_time': '00:23:50', 'transcript': "one Moting here is like here is the like, for example, here having all the team members and then So we are calculating here. The total devours the total Q hours. So he are out of these members. The people that are mentioned in yellow are testing team people, so the addition of all these peoplewe will be able to calculate the the way of us. And similarly, the addition of all these people that are in grade are the other deaf people. So the damper cars were able to calculate separately, and then we have the total bar covers. But yeah, this thing, whatever is the total, is it? It's coming here and we're getting the total were covers for Q and the for deaf and also for the team, So this is the way so.some of them things like. so long. Also, you know, though, didn't use this one much, but sometimes also from this. whatever data we are giving, we can also culprit velocity here. Or we can project the velocity that we will be able to achieve, okay?sahib. department in this manually, or is it through the era? So I am telling youth of this Excel sheet is actually mental manually. But we do have a G option of it doesn't happen like this. I will show you the gene option as after we have discussed. So I told him in to his red wine, raise the Excel sheet, which is a manual thing, which we do right. This is the one and also may have a Gina option which have issued.Sorry, Mon Amis. However question So withdrawing the screen on the right hand side where you have listed down the storey numbers and the name of the other way of doing the capacity Planning, however, know like this is the same capacity. So here now we are register jotting down the storeys that will be covering in the spread ride for every sprint before starting the spring. We aredoing a capacity planning, right? So the upcoming streamed We are listing down all the storeys that we will do in this train. And who will work on this print. Right? So for example, if this storey is being done by the developer Dipak So the package will have here his workouts. How many work of us even allocated? For example, out of his total capacity of 36 he will just give three hours for this. And then again there will besome Barca was for the tested as well they will give. Maybe they will give two hours. Okay, so that is the reason the invention ing it. Storey buys how much a storey points or how much Barca will not store ippon. Sorry hours breakdown actually right at the breakdown and the the task, right? Completely a ride. So every storeys we are breaking down. We're taking the hours considering the hours that will beof more like the developer. How much hours they spend? The tester, How much I was Davis pen And how much is the total hours? So accordingly you know, open the Pakis parking on this storey as well as this storey as well as this Storey said the complete fire cover should come to near about 36 so we can keep a track. Okay Addition of all these storeys will come to around 36 right? So you can get the totally here.So next comes is the advantages of capacity planning. So I want to just zoom out. You can get a you. so so for the advantages. So first of all, it is avoid burnout. So what is about team won out is like, you know, the Arges piling work on somebody. And we exactly do not have any idea that whether that person will be able to do or not, or whether he is stretching more just to, you know, fulfil the work and to awe do not want want to stumped him to function like that. We want the work to be done. But also it's not like a person is, you know, working late nights and weekends just to compete. We do not one that can be a planning properly,and we are able to estimate that. Okay, we have a delivery in the state. And so if they are planning in this way, our definitely will meet our posts will meet her deliberated. So this will help to do the work effectively without any stress on the team bus. It is the main thing, like so taking steps to get for understanding of your teams at Children positive in she won't overwhelm them with too many tasks and responsibilities and also support them in managing their time by prioritising the most impactful.then sent more realistic deadlines again the same thing. So it's like something which they can achieve. It's not like a career piling them on, and then at the end of the strength of, even if they are trying their level best, they are not able to achieve so Yah, we do not want that. So get details about availability straight from your team. You will get a much needed reality. Cheques on the Dugan manage deadline expectations according to what your team can actually produce,then the third point is identify skin sock shortages. So by evaluating your team's capacity and planning work in advance, it's easier to spot if projects require skills that your team doesn't have. Accounting for that early allows you to take proactive action, such as training someone on your team. Outsourcing attacks are changing the scope of the project, so I think this is very self explanatory. So when we are planning ahead, so we in.So what is the You know what is lacking and what will blockers in achieving our booths? All this identification will not come once we have jumped into the sprint, so it will come before you have actually taken the work, so you can project it and you can, you know, avoid that. And whatever you are committing, you will be able to deliver. That's the most important thing, right?so the challenges of capacity planning said stuff to understand band with. So, yeah, it is tough to understand band with because, you know, view we are projecting that. Okay, this person can do this much hours. It may be that Okay, that person, even if for he is mentioning that I will need three hours of world,Sometimes something happens and he is getting stuck and he needs another more two hours. It's actually not three hours. It's actually five hours. So in that way, when we are calculating everything we are considering, Okay, this work will only take three hours, but actually it is taking more. So this type of difficulty comes.And so that's why it is written. It's tough to understand band with, and though we have a solution to this, which is like the always came buffer hours, as I told you so, that that will take care of this and the gritty or whatever. So your team's bandits is always evolving as projects change and team members leave or join the ranks. So this is another challenge, right? Because, you know, team members are leaving and joining in the middle of this print and also that definitely impacts it.So plus, you need to rely on people's honesty about the current again. The same thing as I told a work may take more a work may take less. So that is also restriction all of that making a challenging to get a firm grasp on just how much capacity your team has available to tackle new work and request, particularly if you have a team full of high achievers always believed that they can takemore. Okay, the more often you have, you talked your team about their most three teams to it weekly, the easier it will get for you to be realist. So as an venue work with a certain team. You know, maybe in the first print your capacity may not be a perfect, but as and when you work on a multiple sprints, you know, like erafter first a Ken than third and consecutive sprint. Then you get the more better grasp on how much each person's capacities is. And if you were, you know, if you are committing more than that, also can district or if you are committing less than also that also you can increase it, so we will get a more realistic idea. Changes will throw you off track. They're gonna risk associated with them.The project and enforcement circumstances, from sense in seasonality to industry changes, will throw wrenches senior plans when you need to try to account for all these potentials. At best, capacity planning isn't always so straight forward. Planning in a cushion, even if it's just an extra day or two, will help you roll with the punches without things running of Paris. So again, this is something it it is likeeven if you are planning, there may be some hindrances, but you know it's much better to go with capacity than without capacity. Then it is like completely chaos, andthere is no planning and all if you're doing any, you know, starting or sprint without the capacity, so you will have to engage in some hard conversations again. This is a part of capacity and a tapestry. Planning is only useful if you though something with the information you identify that can involve turning down projects due to lack of bandwidth, adjusting a reducing expectations, pushing out deadlines. It's always better to say no than too serious and not to deliver. So this is the most inPorton part, you know. So capacity planning is for this reason only that you know what you are committing. You should be able to deliver. And if you you are saying like you are able to predict that, Okay, if this much of a commitment I'm giving, I will not be able to deliver than it's better to mention that beforehand rather than taking that one and then not delivering. So that's the main", 'keywords': ['Capacity Planning', 'Team Management', 'Workload Allocation', 'Burnout Prevention', 'Bandwidth', 'Skill Shortages', 'Sprints'], 'summary': "The transcript discusses the challenges and methodologies associated with capacity planning within teams. It begins with the importance of calculating total hours worked by team members, highlighting the roles of developers and testers. The speaker explains how to effectively allocate tasks and hours for each team member to avoid burnout and ensure realistic deadlines are set. The advantages of proper capacity planning are outlined, including the prevention of team burnout, identification of skill shortages, and the ability to manage workload expectations. Challenges such as understanding bandwidth, reliance on team members' honesty, and the evolving nature of team composition are also addressed. The speaker emphasizes the need for ongoing communication with the team to refine capacity estimates over multiple sprints. Additionally, the need to remain adaptable to changes and to prepare for potential disruptions in capacity is discussed, stressing that it is better to decline projects than to overcommit and underdeliver."}, {'topic': 'Best Practices in Capacity Planning', 'start_time': '00:23:50', 'end_time': '00:25:42', 'transcript': "purpose of the president planning the next is capital planning. Best Praxis is so some of the tapestry planning West practises are sorry. So learn from past projects. Okay, so this is the main our thing, you know, and a capacity in the first sprint that Udo will never be perfect. It will be a kind of Okay,we are just trying to see. But as and when the A growth, the capacity planning for the future strengths on the next prince will definitely be better and will have a better idea about the amount of work which we should take and will be able to complete. Have honest conversations with Team OK song in here. The you know, transparency is very important, though Scram, Master and theA team member should be completely true with each other so that the another's come. Master understands the limitations of the developer of the tester and also the developer, and the tester truly identifies water. The actual bar covers that he or she is putting, which will again, you know, help us in doing a good capacity.so get the necessary details up front. So when a project request some across comes across your desk as thoughtful questions to make sure you grass the INS and out awards being requested, you can also create a brief. So it is again. It's like you are predictingthings as per year, you know? you're taking all the details from the team. So as a schoolmaster we tried to take in okay voting. Stand with. Done what? Things cannot be done. And if things cannot be done, what part of it can be done? What part of it cannot be done and accordingly will chalk out the plant like so this is states thatso. This is kind of a flow A charge Stating of what? We are putting it all together so they can go through. It is just", 'keywords': ['Capacity Planning', 'Scrum', 'Team Communication', 'Project Management'], 'summary': "The transcript discusses best practices in capacity planning, emphasizing the importance of learning from past projects to improve future planning. It highlights that initial capacity estimates may not be perfect but can improve with experience and team transparency. Honest communication between team members and the Scrum Master is crucial for understanding each other's limitations and capabilities. The speaker suggests gathering necessary details upfront when project requests arise and recommends asking thoughtful questions to grasp the project's requirements fully. The importance of planning based on realistic assessments of what can be accomplished is also emphasized."}, {'topic': 'Roadmapping Introduction', 'start_time': '00:32:45', 'end_time': '00:33:19', 'transcript': "so I think we are five minutes more. So can we moved to the road map. okay? So now moving ahead with the road maps of what is roadmap? Okay, so road mapping, Jill A software. Our team level roadmaps useful for planning large basis of work several months in advance. A terrific level within a single project. Simple planning and dependency management features help your team's visualise and manage work better. So what is exactly a roadmap is nothing but a planning feature in bet. You know, you can", 'keywords': ['Roadmapping', 'Planning', 'Dependency Management'], 'summary': 'The discussion transitions to the concept of roadmapping, highlighting its importance in planning large projects several months ahead. The speaker emphasizes that team-level roadmaps are particularly useful for visualizing and managing work effectively. They describe a roadmap as a planning feature that aids in simple planning and dependency management within a project.'}, {'topic': 'Roadmap Features and Usage', 'start_time': '00:33:19', 'end_time': '00:36:37', 'transcript': "put in all the epics and under native storeys, and you can see the complete picture of like, for example, in which sprint you will be able to complete what feature Sova. Normally, you know the identify features okay, will do this by this April end will do this feature by maybe June will do this feature so fnothing will be clearly visible. If we are using a Roadmaster of Witch spring, we will be able to complete feature one will sprint will be able to complete feature too. So this was kind of a projection. So how does it look into looks like this? Okay, so here you can see, I justSo here you can see a all the storeys that the left side are the epics. It is showing the epics. And these are the things the storeys that you will be able to complete stating the months you residency, the months in which month border the things that we can complete, right?so maybe this epic will be able to complete in the month of December. The second epic will be able to again complete in December the cross team effort epic they will be completing by November. So this other projections that have been made right and the the strike type of things will also be explaining this is kind of dependence is that's right slinking here.so far, the key concepts of ethics. Okay, so for I'm in for creating a road map, things that you need to know at the Buddhism and epic is a large body of us that can be broken down into individual tasks required to ship of feature. The world probe becomes a child issue of the epic. Sometimes owner spending epics are displayed as collard bus onthe road map. As I showed you, it was so of epics Are you know again? As I said, like a feature, you there is a feature. Okay, So if that feature is a small feature, if it is a big feature than again, features will be broken down. But if it is a small features that you can't convert into an epic,so just you will create an epic, and underneath it you will again create storeys of that in order to achieve that feature, what other things you need to what other steps you need to do border the storeys that need to be turning out to create that feature in order to complete that feature. So that is epics. So as again, as I said to you, So these are the epics, this whatever icon you are saying in the left, those are epic aiglons.and these are, though, things depicted in coloured bars. what is a child issue again? As I said, under need the epic the create storeys. So the storeys are nothing but child issues. Child issues can be created directly from the road map and administered within the epic the belonged So the storeys that will create under the epic an honest child issues the most common childish you a storeys, tasks and bugs. Okay, but you can create new issue types to represent different type of work for your team's quickly move issues to other tipping and reorder issues or epics by dragging and dropping them", 'keywords': ['Roadmap', 'Epics', 'Features', 'Sprints', 'Child Issues', 'Tasks', 'Stories'], 'summary': 'The transcript discusses the process of using a roadmap to organize and visualize project features and their timelines. It explains how epics, which are large bodies of work, can be broken down into smaller tasks or stories required to complete a feature. The speaker emphasizes the importance of projecting timelines for completing features within specific sprints and how to manage these tasks effectively through the roadmap interface. The discussion also touches on the creation of child issues from epics, the representation of these tasks as colored bars on the roadmap, and the ability to reorder and manage these issues through a drag-and-drop mechanism.'}, {'topic': 'Roadmap Planning and Management', 'start_time': '00:36:38', 'end_time': '00:39:43', 'transcript': "directly from your road map. So this is kind of saying how you are able to do that. Okay, so you can see the screenshot here. So this is a bug. So under name this epic, which is group booking experience. So they are trying to create a bag or a storey or a tusk. Okay,next to start and dude is the length of the bar on the road map for alleged at the start and due date set for Europe. Pick setting dates for your epic helps to communicate plans with the team and provide visual visibility to external stakeholders. Informed dependence in mapping and helped the resource management. So yeah, so start and doodles are very important. In order to project when you will be able to complete the feature or the epic,you're starting a due date of each of the storeys or child into issues matter, you know, so that you are able to understand. OK, completely a get this epic we will be able to complete in the stand this epic. This temps of this feature will be done by this time Fring.So this is depicting being depicted here. As you can see, the the the the thing that the Yeah. So So far epic when you are putting her start date and the due date So that is kind of you know, high level but in a storey is you know, when you are taking up storeys we normally understand that this storey will be completing in this print trade even if it's a storey you were expectingto take two days. Okay, But out of everything it mill maximum taker, Another buffer two days you will complete by four days. Right? So definitely by the end of the sprint you will complete that storey, right? So when you were giving the start date and ended to the storeys, that is a definite dates night. Almost definite it there is a major.Bata How If you are talking about projection of the epic skirt things then you can say a air kind of predicting When's once all the bodies the end it here is when all the storeys within the epic will end Right That date we will give us the end. Eh?We are assigning like okay in desperate will do this in district will do this And once all the storeys of this under Newt this epic whatever storeys are there will complete that sprint ended will put us the duty for the fix it while doing the activity from THING is also the part ofThey are completely a part of this because of they are the ones who will you know, who will be actually doing the work. Right? So they at the ones who will say Okay, Veil late leaders will need four days to definitely they their input matters a lot.", 'keywords': ['Roadmap Planning', 'Epic', 'Story', 'Resource Management', 'Sprint', 'Dependencies'], 'summary': 'The transcript discusses the importance of roadmap planning and management in project execution, emphasizing the significance of setting start and due dates for epics and stories. It explains how these dates help communicate plans with the team and provide visibility to external stakeholders. The speaker illustrates the process of mapping dependencies and managing resources effectively, indicating that understanding the timelines for completing features is crucial. The discussion also highlights the iterative nature of estimating completion times for stories within a sprint and how inputs from team members are vital for accurate projections.'}, {'topic': 'Roadmap Dependencies and Visualization', 'start_time': '00:39:45', 'end_time': '00:41:34', 'transcript': "Okay, so then there is philtres and view settings with again. These are some of the features of roadmap Yadira software roadmap has built in philtres that make waving and managing work simple. Find and refine your road member searching for key words and filled of a Sinus status labelled issue at just view settings or your road map to cheque.What is displaced. Add or remove dependency in progress. Views and filtered expressed doubled to specific time. Frame on the fly is a leave you a road map. Bye weeks months of it Sasuke Zara features that we can use for the road maps, abilities and view setting feature is that then there is the dependency So what is dependency is like you know one storey you will be able to startThere are some times this situation's right In other storey the you will be able to start when you have completed the storey again there will be like a storey See you can be able to start menu of computers the storey So these kind of dependence is of these things These are dependencies and the dependencies were also one kind of You can sit blockers right, Unless and until you complete Storey eh? You cannot start storey pright. So this can be, you know, Mom, this can be shown in the road map dependency Management is critical for teams. When dependence is our visualised and well mapped, a team can adapt and plan for alternative parts. Indira Software You can easily show the relationship between epics by mapping dependence is directly from the road.So this is the way. As I told you, these things show that dependencies. Okay, So for example, once this is done, you can be able to do this. Okay? Say it's mentioned, Bill. Cheque out Experience blocks this. So you have to do this epic bill cheque out experience first, and then only you can be able to do the improve U M U S lite score.", 'keywords': ['Roadmap Management', 'Dependencies', 'Filters', 'View Settings', 'Yadira Software'], 'summary': "The transcript discusses the features of roadmap management, specifically focusing on filters and view settings in the Yadira software. It highlights how these features facilitate the management of work by allowing users to search for keywords and filter issues based on their status. The speaker explains the concept of dependencies within roadmaps, illustrating how certain tasks can only commence once preceding tasks are completed. Visualizing these dependencies is presented as critical for team planning and adaptation, helping teams to navigate their work more effectively. The speaker also provides an example of a specific dependency related to the 'bill checkout experience' that must be completed before another task can start."}, {'topic': 'Roadmap Reporting and Adjustments', 'start_time': '00:41:35', 'end_time': '00:44:07', 'transcript': "this on owners at the dependency. Right? This one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back? This is a plan. And the kind of things can I say that this is a plan the way ofyeah, you You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.I understand. But bear, can I Is there a way of being the actual that being in claim are going with the plan or not? If we look at the very first effect which is going to be completed by first week of April, the lower? Yes. So let's get extent in actual it gets extended by that same one month's end of April. How can I see that we are? Then you have to. Then you have to change the due date, right?Then it will show you have to change the due. Did that Okay. We are not able to achieve by this time frame we have extended it. Then it will again show you the actual do. Did that time thing can? Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reportsat Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what we actually you ST road map you can see Like, for example, you are saying that it is epically an audible to complete by the time we haveestimated the an audible to complete rate. So then again you have to bow and I manually changing, told the due date that we have right. Then you will be able to see the actual it. It's something you have to do it then only will be able to project. It is like not like it'll automatically change and show it, er themselves. It will not tell me if I've changed to April then it will extend the time and the label. But it will not like show me that.earlier date was April for speak of April, but now it is invalid. Nikola recorded. No, no, no. It's not like the No, no, no, no. It won't be like that. It will show you whatever due date you have given It is like that that that sort of complexity is not there in road map. Right? So growth map is kind of you know, you can discuss this with", 'keywords': ['Roadmap Reporting', 'Dependencies', 'Project Planning', 'Due Dates', 'Adjustments'], 'summary': 'The transcript discusses the complexities involved in roadmap reporting and adjustments, particularly focusing on how to track actual progress against planned timelines. The speaker addresses questions about viewing dependencies and how to compare the actual work being done with the original roadmap. They explain that changes in due dates must be manually updated to reflect extensions, and while the roadmap can display current estimates, it does not automatically track historical changes or prior due dates. The conversation highlights the importance of clear communication and documentation in project planning.'}, {'topic': 'Roadmap Creation Steps', 'start_time': '00:44:32', 'end_time': '00:48:52', 'transcript': "so again and other feature is sure and exports of whatever road matter of created, you will be able to share and export the road map. So sandy, a roadmap directly from Gina to from here a software by typing in news animal innocently copy to grab the roadmap, your export year old map and just the timeline views Star date and in dates before expecting it as an image. So this is like some of the features of road map.create a roadmap injera software. So one of the steps to create a roadmap, Najera software creator, knew Gina Software Project or go to an existing project and then navigate to the side bag and click roadmap. Okay, not if they're not showing saying your roadmap have enabled the road map in the board setting. So again there's a Y.And here, if you are not able to see the roadmap tap than definitely in the board sitting, you need to go and enable it. So people who are comfortable Najera will be understanding what I'm talking about. But if people who are not having hand from Nigeria, they may find it difficult in reading this and understanding that.Then click plus create a pick on the road map to create a picks directly on your road map. If he roadmap is empty, simply start typing to create right name, year epic and hit Enter. You can double click into epics at any time from your road map to add information such a start and ended assigning attachment and more at child issues to European from the road map by clickingnext to the epic name. Okay, select the type of childish uses in the drop down on the named Asia and of the covered it right in a single single points. Few tips for or Mac creation visualise dependence is between epics by creating or removing dependence ceilings directly on Iroda. So this thing for this thing, you actually need to work with the team, right?The team will be able to help you, guy do and understand and of took Lego, the product owner as well as the team. Both will be able to guide do help you in understanding what other dependencies and how to create the road map and how to mention the dependencies. Right? So that's whythe product owner as well as the team members both are very important for creating year proper road map in with all the details. Keep your old man up today by adjusting the length of the epic or slide the epic to change the start and due dates. Okay,So again, as I said on that, you can change the started do days. You know, if you something happened and you are not able to complete on the mention time or whatever time the timeframe has registered or shifted. So then you can definitely change the start in. And when work is assigned to team members in Gina, they can easily see how theywork ladders up to epics. Okay, so, yes. So they there is, so this, actually, I have we haven't used much, so we normally have road maps which will project. But here, this is a feature. They're saying that the other team members can also see, like how their work is getting completed. Party. I am not with NGOs. This on very common confirm. I'm not really sure about thisroadmaps. Help Help your team track progress towards big picture bulls in a single do. So this is the main importantly, the lamp later, the feature releases it happening on proper time. The the epics How many pixie horrible to complete, which picks terrible to complete. All districts make your roadmap shine by changing the colour of your epics. There are clear on the road map. Simply rightly, they're picking pick yokel, This is aexternal feature. So now there is a some of those slide, sir there, which I just created so that you guys can go through and no, but these are some sort of repetitive things, but since these are What can you say? Like some of the points I thought should be included in thein the I mean, the thing that I'm presenting, I just put it on, but yeah, these are kind of same of what I have explained to you guys. Right? Sources. This is like creation of road map, as you can seek border, the positive water, the features, one of the comments. So you guys can go drew this.", 'keywords': ['Roadmap Creation', 'Jira Software', 'Epics', 'Dependencies', 'Team Collaboration'], 'summary': 'The transcript discusses the steps and features involved in creating a roadmap using the Jira software. It outlines the ability to share and export roadmaps, the process of navigating to the roadmap section within an existing project, and the importance of enabling the roadmap feature in board settings. The speaker provides guidance on creating epics, adding information such as start and end dates, and managing dependencies between epics. Emphasis is placed on collaboration with team members and product owners to ensure a comprehensive roadmap. Additionally, tips for visualizing dependencies and keeping the roadmap updated are provided, along with suggestions for color-coding epics for clarity.'}, {'topic': 'Conclusion and Q&A', 'start_time': '00:48:53', 'end_time': '00:50:23', 'transcript': "So that's all from my side. Any other questions here? for any in any questions still. anyone. any questions on this, so I will be sharing, I think. I think for 100 shared this. topic with you If you don't have this p pity than definitely this slide show for a financial she's shared with you both the capacity as well as this. Soa roadmap ting So far handed, we share with the people who have joined here. not are not can go ahead and share this but Ariel so that people can go through it and the in future, if they have anything, they can get back to me. Hand indefinitely, discussso intense, guys. Any other questions? Thank you. Thanks times a lot. of frustration. And I including the feedback An assessment form with the recording on, please. Thank you.Thank you.", 'keywords': ['Q&A', 'Feedback', 'Slideshow', 'Assessment'], 'summary': 'The conclusion of the session includes a recap from the speaker, who invites any remaining questions from the audience. They mention sharing a slideshow related to the topic, which will help attendees review the material. The speaker encourages participants to reach out in the future with any inquiries and emphasizes the importance of feedback and assessments. The session wraps up with expressions of gratitude towards the attendees for their participation.'}], 'yellow_line': [{'Topic': 'Capacity Planning Overview', 'transcript': 'Okay, So hello, everyone on this Iman Alyssa. So today will be conducting session on two topics. One is capacity planning, and the second is the road map in Jiro. So try to cover capacity planning within the first half an hour span and then will continue with the road map injera,', 'start_time': '00:00:03', 'end_time': '00:00:21'}, {'Topic': 'Capacity Planning Process', 'transcript': "so the festival bodies capacity planning. So, according to the definition that is given here, is capacity planning is the process of identifying how many hours a project or task will require too demanding whether or not your team has the available bans it to complete it and then coordinating that work for maximum efficiency. So what it exactly means is instead offer. You know, I'm just guessing that how much offer can be done.Capacity planning is a complete process in which we are actually identifying the number of work hours that a person on already member in the scrum team can put in and the maximum work that can be achieved with within the spring time frame. For example, if it is a two week spent, then what is the maximum number of effective work hours that each of the resource can give? So that determines the capacityand er It also includes things like, you know, complexity of the storey, and also it's like if it is a very complex storey, then definitely the storey point is more and so that's the reason the efficiency or the, you know work hours will be more and if it is a a medium or lesser complex than definitely the number of our covers required will be lives. So everything of this we take into consideration along witha, for example, a team member out of 15 days. Or to explain that the stand a strength, he will be only for the next two days or last two days. Whatever. Okay, so his effective days will be around eight days, right? So they'll also consider that that okay, he is actually available for eight days, and according to its, his work hours will be calculated.So what is the benefit of this? So the benefit of this is that you know, we are not keeping anything for, you know, like Cobb, depending on the chance of completion. It's like a sure shot. What they are projecting, what they are planning, what we are focusing, we are able to achieve it. So that is the main benefit of compactD planning. When we do capacity planning in a proper weight and there is very less chance that the gold will be missed or, you know, the maximum among the work we are able to achieve, rather than if we are not doing any capacity planning and randomly taking into work the new know Most of the time it's like we miss on the target and there are storeys which will spill over and you know there will be a chaos with industry.So this is the basic things are going forward with some more points on capacity planning. It's like on tapestry. Planning helps the team understand the amount of productive engineering time available in a sprint. For example, To perform capacity planning for energy team, you must gather each teammembers availability and time of, as I said regarding their holidays or leaves, you know, I said about the leaves. If there is holidays during those springtime, then definitely we also considered that. And that time of will be for everybody. That is part of the strength.So So this is telling that and then add up the individual capacity to calculate the team's overall capacity. So the complete work covers for each of the team members in adding of all each team members complete work hours. We can make the full capacity of the T right that aghast on your team's overall capacity, which is maximum amount of work that you can pile on their plate before you have over extended them, which we don't want.", 'start_time': '00:00:22', 'end_time': '00:03:58'}, {'Topic': 'Capacity Estimation Techniques', 'transcript': "So once you have that information, you move into the planning stage. That's very will prioritise task and scheduled those hours so that work is completed by the intended deadline. So capacity means you will root the project plan expectations in reality. So we are not keeping anything for, you know, guess work rather than you're optimistic guesses about what team can churn. Oh, this is the basic thing about capacity. The next comes the ways to estimate so.if a some of you guys are working currently on sprint based projects or even if you are not, I think you must be familiar with things like estimation of the storeys. So how do we do the estimates? So the most common thing that we currently laid to is Storey pointing right?So this is just a just in which I am trying to explain to Otis Storey pointing. So there are a couple of methods that we tried to estimate there's old school, May 3rd storey point, May 3rd storey count and hybrid matters. The most common method is the storey appointments or which we normally deal in storey pointing. Also, there are two ways of Storey pointing that this T shirt sizing and the Fibonacci series oneso again a T shirt sizing, which is like small, medium large Axl, this is not that much used and the Fib Unity series, which is the most commonly used currently on storey pointing.So how is this done? For example? It's a very simple storey and we do not have anything to explore or lots of understanding. Then it will be a storey 0.1 or two, so here. The series is given of it wrong. And sorry I didn't cheque that out. It will be one told 357 notches. Cities. Okay, so if it is a simple one will give a one or two pointers.that a storey pointing is done along with the whole team. As you know, there are grooming sessions during which the whole team sits together, understands the storey and then, as per everybody is voting that is decided whether that storeys and easy one then will give an auto. If it is a medium complex storey will give it a three if it is more complex than it is a five and if it is extremely complicated and very, very difficult will give it eight.So most of the times we tried to break down eight point of storeys into lesser points. Like, you know, two models of three and five. Okay, one storey of three points, another of five points. So body A. This is the way of just, you know, deciding which storey is of how much difficulty level", 'start_time': '00:03:58', 'end_time': '00:06:37'}, {'Topic': 'Capacity Planning Tools', 'transcript': "So this is just a rough or in a very simple what can is it? A table which is showing how we are doing the capacity planning, though in other real instance are in show you how it issues showing. So the normally we have two ways of doing this capacity planning.Either we do we have a template of Axl shit temperate in which we put in the work hours or else we can donate directly through. So how we are putting a tear in the simple largest explained to him So these are the name of the resources that are part of those Graham.So although people are names are written one other work days for which, for example, this is showing that it is a to experience that why that's why it is 10 days. Okay, In the two weeks we have 10 days, then we have categorised each type of work. Okay, so here you can see the availablenumber of days. Okay, So for example, this person don't have any vacation or anything else. So that's why he is completely available for all the 10 days and his complete work hours is 7010 into seven sewing plans. Seven hours. I am sorrysomething is here in miss Okay, He So we are considering here seven work hours per day. That's the reason we're have given a den into 7. 3070 of us. Okay, then the second person, as you can see here, he has a vacation of one day. Right? So that's the reason his effective days is only nine.And hence the calculation that is coming. It's nine into seven. That is an an hours per day of her, which comes to 63. So in this way, all the team's effort or work hours is calculated, and the total comes to around 3 15 hours.So this is a basic capacity plan, so I'll just give you a glimpse of the actual ones, which we normally use, so it's a bit more complicated than what you have seen, so", 'start_time': '00:06:40', 'end_time': '00:08:49'}, {'Topic': 'Capacity Planning Benefits', 'transcript': "not able to. I was able to see this. it's the said this light show. right. the thinking, okay? so went above this one. Is it so now unable to? You guys were able to say this.it's better than before. Yeah, literally. Can you zoom? And I don't think it's a numbing with resume.Maybe you have to come out on the slide show and land new China. There's an option to. consume you never screams as well.There is a plus sign the next two years. Aargh! Point on ya, hon. Just under Insert Manu Under in 30 days a zoo Michael.just take on the drop down arrow and them. Zuman. Okay. Okay. Lydia. Thank you, Yah! so Yeah. So this is actually some sort of a real life capacity planning sheet that we are actually using. So it's a bit more complex than what I show new as a unit sister format, you can seeSo here you can say everything is mentioned. Who are the team members? What are the total number of this string shot is not full. So because I couldn't take it in a single stream. So there are some more few more members the chairman sing here. So this is train shot with, I mean part of the scrum team, not the full. As you can see from here, all the members are being seenso here that the members are there. So total spring daisy A mentioning water, the holidays. If there is any any leads for any of the resources, what on the actual days. So what are the actual days means what at the days that they are actually working per day hours. So here we have taken six tapesix hours per day and we keep two hours for buffer. Usually that is assigned because, you know, we do have several meetings when we are part of the sprint or a scam. We have several meetings. So that's why be assigned belief to ask per day for this kind of activities, meeting activities and other, you know.Connexion, connecting with the your team members and also effective work hours. This six. So accordingly of what is the number of hours per person gets is 36 hours for the full sprint, which is two week Sprint Reich.So hearing you can see for 68 here we have another small thing where we are calculating the total death effort, complete depth effort of work hours and the queue way work hours. Okay, so 20 for is the Dever covers and 140 for Solly. It's percent estimate. Whatever 135 you ever coveredalong with, we have another. okay? becoming Dombeck 50 person, 100%. Okay, so yeah, along that we have a few more things, like, you know, what is the available capacity? What is the time estimate and capacity utilisation. Capacity remaining. So, for example, a person has 36 capacity. But as per the storey points, we are able to assign only 30 work hours, so he will have a remaining capacity of 5% or fivein which he can accommodate any ad host stance or anything that comes in between. So those kind of things are also there. So here we can monitor which team member has got the, you know, his capacities move than his actual available capacity or it is lesser. And if if he has any banned with left, where we can take on", 'start_time': '00:08:57', 'end_time': '00:13:50'}, {'Topic': 'Challenges in Capacity Planning', 'transcript': "one Moting here is like here is the like, for example, here having all the team members and then So we are calculating here. The total devours the total Q hours. So he are out of these members. The people that are mentioned in yellow are testing team people, so the addition of all these peoplewe will be able to calculate the the way of us. And similarly, the addition of all these people that are in grade are the other deaf people. So the damper cars were able to calculate separately, and then we have the total bar covers. But yeah, this thing, whatever is the total, is it? It's coming here and we're getting the total were covers for Q and the for deaf and also for the team, So this is the way so.some of them things like. so long. Also, you know, though, didn't use this one much, but sometimes also from this. whatever data we are giving, we can also culprit velocity here. Or we can project the velocity that we will be able to achieve, okay?sahib. department in this manually, or is it through the era? So I am telling youth of this Excel sheet is actually mental manually. But we do have a G option of it doesn't happen like this. I will show you the gene option as after we have discussed. So I told him in to his red wine, raise the Excel sheet, which is a manual thing, which we do right. This is the one and also may have a Gina option which have issued.Sorry, Mon Amis. However question So withdrawing the screen on the right hand side where you have listed down the storey numbers and the name of the other way of doing the capacity Planning, however, know like this is the same capacity. So here now we are register jotting down the storeys that will be covering in the spread ride for every sprint before starting the spring. We aredoing a capacity planning, right? So the upcoming streamed We are listing down all the storeys that we will do in this train. And who will work on this print. Right? So for example, if this storey is being done by the developer Dipak So the package will have here his workouts. How many work of us even allocated? For example, out of his total capacity of 36 he will just give three hours for this. And then again there will besome Barca was for the tested as well they will give. Maybe they will give two hours. Okay, so that is the reason the invention ing it. Storey buys how much a storey points or how much Barca will not store ippon. Sorry hours breakdown actually right at the breakdown and the the task, right? Completely a ride. So every storeys we are breaking down. We're taking the hours considering the hours that will beof more like the developer. How much hours they spend? The tester, How much I was Davis pen And how much is the total hours? So accordingly you know, open the Pakis parking on this storey as well as this storey as well as this Storey said the complete fire cover should come to near about 36 so we can keep a track. Okay Addition of all these storeys will come to around 36 right? So you can get the totally here.So next comes is the advantages of capacity planning. So I want to just zoom out. You can get a you. so so for the advantages. So first of all, it is avoid burnout. So what is about team won out is like, you know, the Arges piling work on somebody. And we exactly do not have any idea that whether that person will be able to do or not, or whether he is stretching more just to, you know, fulfil the work and to awe do not want want to stumped him to function like that. We want the work to be done. But also it's not like a person is, you know, working late nights and weekends just to compete. We do not one that can be a planning properly,and we are able to estimate that. Okay, we have a delivery in the state. And so if they are planning in this way, our definitely will meet our posts will meet her deliberated. So this will help to do the work effectively without any stress on the team bus. It is the main thing, like so taking steps to get for understanding of your teams at Children positive in she won't overwhelm them with too many tasks and responsibilities and also support them in managing their time by prioritising the most impactful.then sent more realistic deadlines again the same thing. So it's like something which they can achieve. It's not like a career piling them on, and then at the end of the strength of, even if they are trying their level best, they are not able to achieve so Yah, we do not want that. So get details about availability straight from your team. You will get a much needed reality. Cheques on the Dugan manage deadline expectations according to what your team can actually produce,then the third point is identify skin sock shortages. So by evaluating your team's capacity and planning work in advance, it's easier to spot if projects require skills that your team doesn't have. Accounting for that early allows you to take proactive action, such as training someone on your team. Outsourcing attacks are changing the scope of the project, so I think this is very self explanatory. So when we are planning ahead, so we in.So what is the You know what is lacking and what will blockers in achieving our booths? All this identification will not come once we have jumped into the sprint, so it will come before you have actually taken the work, so you can project it and you can, you know, avoid that. And whatever you are committing, you will be able to deliver. That's the most important thing, right?so the challenges of capacity planning said stuff to understand band with. So, yeah, it is tough to understand band with because, you know, view we are projecting that. Okay, this person can do this much hours. It may be that Okay, that person, even if for he is mentioning that I will need three hours of world,Sometimes something happens and he is getting stuck and he needs another more two hours. It's actually not three hours. It's actually five hours. So in that way, when we are calculating everything we are considering, Okay, this work will only take three hours, but actually it is taking more. So this type of difficulty comes.And so that's why it is written. It's tough to understand band with, and though we have a solution to this, which is like the always came buffer hours, as I told you so, that that will take care of this and the gritty or whatever. So your team's bandits is always evolving as projects change and team members leave or join the ranks. So this is another challenge, right? Because, you know, team members are leaving and joining in the middle of this print and also that definitely impacts it.So plus, you need to rely on people's honesty about the current again. The same thing as I told a work may take more a work may take less. So that is also restriction all of that making a challenging to get a firm grasp on just how much capacity your team has available to tackle new work and request, particularly if you have a team full of high achievers always believed that they can takemore. Okay, the more often you have, you talked your team about their most three teams to it weekly, the easier it will get for you to be realist. So as an venue work with a certain team. You know, maybe in the first print your capacity may not be a perfect, but as and when you work on a multiple sprints, you know, like erafter first a Ken than third and consecutive sprint. Then you get the more better grasp on how much each person's capacities is. And if you were, you know, if you are committing more than that, also can district or if you are committing less than also that also you can increase it, so we will get a more realistic idea. Changes will throw you off track. They're gonna risk associated with them.The project and enforcement circumstances, from sense in seasonality to industry changes, will throw wrenches senior plans when you need to try to account for all these potentials. At best, capacity planning isn't always so straight forward. Planning in a cushion, even if it's just an extra day or two, will help you roll with the punches without things running of Paris. So again, this is something it it is likeeven if you are planning, there may be some hindrances, but you know it's much better to go with capacity than without capacity. Then it is like completely chaos, andthere is no planning and all if you're doing any, you know, starting or sprint without the capacity, so you will have to engage in some hard conversations again. This is a part of capacity and a tapestry. Planning is only useful if you though something with the information you identify that can involve turning down projects due to lack of bandwidth, adjusting a reducing expectations, pushing out deadlines. It's always better to say no than too serious and not to deliver. So this is the most inPorton part, you know. So capacity planning is for this reason only that you know what you are committing. You should be able to deliver. And if you you are saying like you are able to predict that, Okay, if this much of a commitment I'm giving, I will not be able to deliver than it's better to mention that beforehand rather than taking that one and then not delivering. So that's the main", 'start_time': '00:13:51', 'end_time': '00:23:50'}, {'Topic': 'Best Practices in Capacity Planning', 'transcript': "purpose of the president planning the next is capital planning. Best Praxis is so some of the tapestry planning West practises are sorry. So learn from past projects. Okay, so this is the main our thing, you know, and a capacity in the first sprint that Udo will never be perfect. It will be a kind of Okay,we are just trying to see. But as and when the A growth, the capacity planning for the future strengths on the next prince will definitely be better and will have a better idea about the amount of work which we should take and will be able to complete. Have honest conversations with Team OK song in here. The you know, transparency is very important, though Scram, Master and theA team member should be completely true with each other so that the another's come. Master understands the limitations of the developer of the tester and also the developer, and the tester truly identifies water. The actual bar covers that he or she is putting, which will again, you know, help us in doing a good capacity.so get the necessary details up front. So when a project request some across comes across your desk as thoughtful questions to make sure you grass the INS and out awards being requested, you can also create a brief. So it is again. It's like you are predictingthings as per year, you know? you're taking all the details from the team. So as a schoolmaster we tried to take in okay voting. Stand with. Done what? Things cannot be done. And if things cannot be done, what part of it can be done? What part of it cannot be done and accordingly will chalk out the plant like so this is states thatso. This is kind of a flow A charge Stating of what? We are putting it all together so they can go through. It is just", 'start_time': '00:23:50', 'end_time': '00:25:42'}, {'Topic': 'Roadmapping Introduction', 'transcript': "so I think we are five minutes more. So can we moved to the road map. okay? So now moving ahead with the road maps of what is roadmap? Okay, so road mapping, Jill A software. Our team level roadmaps useful for planning large basis of work several months in advance. A terrific level within a single project. Simple planning and dependency management features help your team's visualise and manage work better. So what is exactly a roadmap is nothing but a planning feature in bet. You know, you can", 'start_time': '00:32:45', 'end_time': '00:33:19'}, {'Topic': 'Roadmap Features and Usage', 'transcript': "put in all the epics and under native storeys, and you can see the complete picture of like, for example, in which sprint you will be able to complete what feature Sova. Normally, you know the identify features okay, will do this by this April end will do this feature by maybe June will do this feature so fnothing will be clearly visible. If we are using a Roadmaster of Witch spring, we will be able to complete feature one will sprint will be able to complete feature too. So this was kind of a projection. So how does it look into looks like this? Okay, so here you can see, I justSo here you can see a all the storeys that the left side are the epics. It is showing the epics. And these are the things the storeys that you will be able to complete stating the months you residency, the months in which month border the things that we can complete, right?so maybe this epic will be able to complete in the month of December. The second epic will be able to again complete in December the cross team effort epic they will be completing by November. So this other projections that have been made right and the the strike type of things will also be explaining this is kind of dependence is that's right slinking here.so far, the key concepts of ethics. Okay, so for I'm in for creating a road map, things that you need to know at the Buddhism and epic is a large body of us that can be broken down into individual tasks required to ship of feature. The world probe becomes a child issue of the epic. Sometimes owner spending epics are displayed as collard bus onthe road map. As I showed you, it was so of epics Are you know again? As I said, like a feature, you there is a feature. Okay, So if that feature is a small feature, if it is a big feature than again, features will be broken down. But if it is a small features that you can't convert into an epic,so just you will create an epic, and underneath it you will again create storeys of that in order to achieve that feature, what other things you need to what other steps you need to do border the storeys that need to be turning out to create that feature in order to complete that feature. So that is epics. So as again, as I said to you, So these are the epics, this whatever icon you are saying in the left, those are epic aiglons.and these are, though, things depicted in coloured bars. what is a child issue again? As I said, under need the epic the create storeys. So the storeys are nothing but child issues. Child issues can be created directly from the road map and administered within the epic the belonged So the storeys that will create under the epic an honest child issues the most common childish you a storeys, tasks and bugs. Okay, but you can create new issue types to represent different type of work for your team's quickly move issues to other tipping and reorder issues or epics by dragging and dropping them", 'start_time': '00:33:19', 'end_time': '00:36:37'}, {'Topic': 'Roadmap Planning and Management', 'transcript': "directly from your road map. So this is kind of saying how you are able to do that. Okay, so you can see the screenshot here. So this is a bug. So under name this epic, which is group booking experience. So they are trying to create a bag or a storey or a tusk. Okay,next to start and dude is the length of the bar on the road map for alleged at the start and due date set for Europe. Pick setting dates for your epic helps to communicate plans with the team and provide visual visibility to external stakeholders. Informed dependence in mapping and helped the resource management. So yeah, so start and doodles are very important. In order to project when you will be able to complete the feature or the epic,you're starting a due date of each of the storeys or child into issues matter, you know, so that you are able to understand. OK, completely a get this epic we will be able to complete in the stand this epic. This temps of this feature will be done by this time Fring.So this is depicting being depicted here. As you can see, the the the the thing that the Yeah. So So far epic when you are putting her start date and the due date So that is kind of you know, high level but in a storey is you know, when you are taking up storeys we normally understand that this storey will be completing in this print trade even if it's a storey you were expectingto take two days. Okay, But out of everything it mill maximum taker, Another buffer two days you will complete by four days. Right? So definitely by the end of the sprint you will complete that storey, right? So when you were giving the start date and ended to the storeys, that is a definite dates night. Almost definite it there is a major.Bata How If you are talking about projection of the epic skirt things then you can say a air kind of predicting When's once all the bodies the end it here is when all the storeys within the epic will end Right That date we will give us the end. Eh?We are assigning like okay in desperate will do this in district will do this And once all the storeys of this under Newt this epic whatever storeys are there will complete that sprint ended will put us the duty for the fix it while doing the activity from THING is also the part ofThey are completely a part of this because of they are the ones who will you know, who will be actually doing the work. Right? So they at the ones who will say Okay, Veil late leaders will need four days to definitely they their input matters a lot.", 'start_time': '00:36:38', 'end_time': '00:39:43'}, {'Topic': 'Roadmap Dependencies and Visualization', 'transcript': "Okay, so then there is philtres and view settings with again. These are some of the features of roadmap Yadira software roadmap has built in philtres that make waving and managing work simple. Find and refine your road member searching for key words and filled of a Sinus status labelled issue at just view settings or your road map to cheque.What is displaced. Add or remove dependency in progress. Views and filtered expressed doubled to specific time. Frame on the fly is a leave you a road map. Bye weeks months of it Sasuke Zara features that we can use for the road maps, abilities and view setting feature is that then there is the dependency So what is dependency is like you know one storey you will be able to startThere are some times this situation's right In other storey the you will be able to start when you have completed the storey again there will be like a storey See you can be able to start menu of computers the storey So these kind of dependence is of these things These are dependencies and the dependencies were also one kind of You can sit blockers right, Unless and until you complete Storey eh? You cannot start storey pright. So this can be, you know, Mom, this can be shown in the road map dependency Management is critical for teams. When dependence is our visualised and well mapped, a team can adapt and plan for alternative parts. Indira Software You can easily show the relationship between epics by mapping dependence is directly from the road.So this is the way. As I told you, these things show that dependencies. Okay, So for example, once this is done, you can be able to do this. Okay? Say it's mentioned, Bill. Cheque out Experience blocks this. So you have to do this epic bill cheque out experience first, and then only you can be able to do the improve U M U S lite score.", 'start_time': '00:39:45', 'end_time': '00:41:34'}, {'Topic': 'Roadmap Reporting and Adjustments', 'transcript': "this on owners at the dependency. Right? This one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back? This is a plan. And the kind of things can I say that this is a plan the way ofyeah, you You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.I understand. But bear, can I Is there a way of being the actual that being in claim are going with the plan or not? If we look at the very first effect which is going to be completed by first week of April, the lower? Yes. So let's get extent in actual it gets extended by that same one month's end of April. How can I see that we are? Then you have to. Then you have to change the due date, right?Then it will show you have to change the due. Did that Okay. We are not able to achieve by this time frame we have extended it. Then it will again show you the actual do. Did that time thing can? Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reportsat Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what we actually you ST road map you can see Like, for example, you are saying that it is epically an audible to complete by the time we haveestimated the an audible to complete rate. So then again you have to bow and I manually changing, told the due date that we have right. Then you will be able to see the actual it. It's something you have to do it then only will be able to project. It is like not like it'll automatically change and show it, er themselves. It will not tell me if I've changed to April then it will extend the time and the label. But it will not like show me that.earlier date was April for speak of April, but now it is invalid. Nikola recorded. No, no, no. It's not like the No, no, no, no. It won't be like that. It will show you whatever due date you have given It is like that that that sort of complexity is not there in road map. Right? So growth map is kind of you know, you can discuss this with", 'start_time': '00:41:35', 'end_time': '00:44:07'}, {'Topic': 'Roadmap Creation Steps', 'transcript': "so again and other feature is sure and exports of whatever road matter of created, you will be able to share and export the road map. So sandy, a roadmap directly from Gina to from here a software by typing in news animal innocently copy to grab the roadmap, your export year old map and just the timeline views Star date and in dates before expecting it as an image. So this is like some of the features of road map.create a roadmap injera software. So one of the steps to create a roadmap, Najera software creator, knew Gina Software Project or go to an existing project and then navigate to the side bag and click roadmap. Okay, not if they're not showing saying your roadmap have enabled the road map in the board setting. So again there's a Y.And here, if you are not able to see the roadmap tap than definitely in the board sitting, you need to go and enable it. So people who are comfortable Najera will be understanding what I'm talking about. But if people who are not having hand from Nigeria, they may find it difficult in reading this and understanding that.Then click plus create a pick on the road map to create a picks directly on your road map. If he roadmap is empty, simply start typing to create right name, year epic and hit Enter. You can double click into epics at any time from your road map to add information such a start and ended assigning attachment and more at child issues to European from the road map by clickingnext to the epic name. Okay, select the type of childish uses in the drop down on the named Asia and of the covered it right in a single single points. Few tips for or Mac creation visualise dependence is between epics by creating or removing dependence ceilings directly on Iroda. So this thing for this thing, you actually need to work with the team, right?The team will be able to help you, guy do and understand and of took Lego, the product owner as well as the team. Both will be able to guide do help you in understanding what other dependencies and how to create the road map and how to mention the dependencies. Right? So that's whythe product owner as well as the team members both are very important for creating year proper road map in with all the details. Keep your old man up today by adjusting the length of the epic or slide the epic to change the start and due dates. Okay,So again, as I said on that, you can change the started do days. You know, if you something happened and you are not able to complete on the mention time or whatever time the timeframe has registered or shifted. So then you can definitely change the start in. And when work is assigned to team members in Gina, they can easily see how theywork ladders up to epics. Okay, so, yes. So they there is, so this, actually, I have we haven't used much, so we normally have road maps which will project. But here, this is a feature. They're saying that the other team members can also see, like how their work is getting completed. Party. I am not with NGOs. This on very common confirm. I'm not really sure about thisroadmaps. Help Help your team track progress towards big picture bulls in a single do. So this is the main importantly, the lamp later, the feature releases it happening on proper time. The the epics How many pixie horrible to complete, which picks terrible to complete. All districts make your roadmap shine by changing the colour of your epics. There are clear on the road map. Simply rightly, they're picking pick yokel, This is aexternal feature. So now there is a some of those slide, sir there, which I just created so that you guys can go through and no, but these are some sort of repetitive things, but since these are What can you say? Like some of the points I thought should be included in thein the I mean, the thing that I'm presenting, I just put it on, but yeah, these are kind of same of what I have explained to you guys. Right? Sources. This is like creation of road map, as you can seek border, the positive water, the features, one of the comments. So you guys can go drew this.", 'start_time': '00:44:32', 'end_time': '00:48:52'}, {'Topic': 'Conclusion and Q&A', 'transcript': "So that's all from my side. Any other questions here? for any in any questions still. anyone. any questions on this, so I will be sharing, I think. I think for 100 shared this. topic with you If you don't have this p pity than definitely this slide show for a financial she's shared with you both the capacity as well as this. Soa roadmap ting So far handed, we share with the people who have joined here. not are not can go ahead and share this but Ariel so that people can go through it and the in future, if they have anything, they can get back to me. Hand indefinitely, discussso intense, guys. Any other questions? Thank you. Thanks times a lot. of frustration. And I including the feedback An assessment form with the recording on, please. Thank you.Thank you.", 'start_time': '00:48:53', 'end_time': '00:50:23'}], 'session_id': [ObjectId('640062c3f521b8e83e39f961')], 'assessment': ObjectId('66f440c0c248cb8c521538f9'), 'interaction': [{'status': 'not answered', 'answer': 'No answer.', 'completeness': "Incomplete, the question 'you zoom?' was not addressed.", 'relevancy': '0', 'question': 'you zoom?', 'timestamp': '[0:09:44]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How did you come to this cream? The app that', 'timestamp': '[0:28:08]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Can you go back to the queen like the Yeah. So what does this mean, Ours? Out of expected 38 hours.', 'timestamp': '[0:31:46]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting?', 'timestamp': '[0:41:40]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question is complex and not directly addressed.', 'relevancy': '0', 'question': "that time thing can? Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reports at Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what we", 'timestamp': '[0:42:49]'}], 'job_name': 'my-transcription-job8a33e779-c9a4-480d-9be1-3e6e0cdb23cc', 'keywords': ['Feasibility Assessment', 'Epic', 'Visibility Issues', 'Slide Show', 'Voting Process', 'Effective Days', 'Capacity Evaluation', 'Team Bandwidth', 'Due Dates', 'Project Coordination', 'Epics', 'Buffer Hours', 'Work Days', 'Availability', 'Time Estimates', 'Progress Tracking', 'Sprint Management', 'Engineering Time', 'Honesty', 'Team Dynamics', 'Basic Plan', 'Team Contributions', 'Efficiency', 'Task Prioritization', 'Effective Workdays', 'Workload', 'Team Communication', 'Fibonacci Series', 'Roadmaps', 'Team Capacity', 'Real-Life Examples', 'Collaboration', 'Feedback', 'Calculation', 'Estimation Methods', 'Best Practices', 'Project Scope', 'Child Issues', 'Available Capacity', 'Capacity Monitoring', 'Template', 'Roadmap', 'Excel', 'Dependency Management', 'Leaves', 'Leave Considerations', 'Progress Reporting', 'Closing Remarks', 'Team Members', 'Effort Calculation', 'Complexity', 'Request', 'Roadmap Development', 'Resource Allocation', 'Work Hours', 'Scheduling', 'Team Effort', 'Outsourcing', 'T-Shirt Sizing', 'Planning', 'Organizational Goals', 'Team Member Availability', 'Stakeholders', 'Conclusion', 'Meetings', 'Indira Software', 'Work Intake', 'Seasonality', 'Resource Management', 'Tester Efforts', 'Bandwidth', 'Time Allocation', 'Project Management', 'Jira', 'Methods', 'Screen Sharing', 'Transparent Communication', 'Scrum', 'Roadmap Planning', 'Goal Achievement', 'Jiro', 'Team Workload', 'Developer Efforts', 'Storyline Complexity', 'Dependencies', 'Product Owner', 'Sprints', 'Vacation', 'Zoom', 'Team Availability', 'Blockers', 'Gratitude', 'Holidays', 'Presentation', 'Time Frames', 'Audience Interaction', 'Project Details', 'Estimation', 'Categorization', 'Industry Changes', 'Grooming Sessions', 'Total Capacity', 'Light Show', 'Sprint', 'Capacity Planning', 'Story Pointing', 'Capacity', 'Exporting', 'Agile', 'Assessment Form', 'Team Collaboration', 'Instructions', 'Projecting', 'Technical Issues', 'Timeline', 'Story Points', 'Agile Practices', 'Capacity Utilization', 'Skill Shortages', 'Scrum Team', 'Transparency', 'Brief', 'Visual Presentation'], 'topic': 'Project Management and Capacity Planning', 'summary': 'The session covers two main topics: capacity planning and roadmap management in JIRA. Capacity planning is defined as determining the necessary hours for projects while assessing team bandwidth. It involves accurately identifying work hours for scrum team members within a sprint, considering factors like task complexity and individual availability. Techniques for capacity estimation, including story pointing methods like T-shirt sizing and the Fibonacci series, are discussed to collaboratively estimate user story complexity. The use of capacity planning tools is highlighted, with a focus on tracking work hours, member availability, and total team capacity, emphasizing the need for efficient resource allocation.\n\nChallenges in capacity planning, such as understanding team bandwidth and the evolving nature of team composition, are addressed. Best practices include ongoing communication and adapting to changes. The session also discusses roadmapping as an essential tool for planning large projects, breaking down epics into smaller tasks, and managing timelines and dependencies. The importance of roadmap management in project execution is emphasized, alongside features in JIRA for creating and managing roadmaps, including setting start and due dates, tracking progress, and visualizing dependencies.\n\nFinally, the session concludes with a recap and an invitation for questions, underlining the importance of feedback and continuous improvement in capacity planning and roadmap management.'}
{'_id': ObjectId('66b26b7bb80f3f3035517f6b'), 'file_id': ObjectId('642ac42ebfc7d530942897ff'), 'file_name': 'Transcription1__1680524330-5f4347ab7d11d148d0575f2b.mp4', 'file_type': 'Video', 'file_path': 'add-resources/Transcription1__1680524330-5f4347ab7d11d148d0575f2b.mp4', 'runtime': '00:50:31', 'transcription_path': 'video-results/out_66b26b7bb80f3f3035517f6b.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 15, 77000), 'file_process_date': datetime.datetime(2024, 9, 25, 18, 45, 39, 377000), 'execution_time': 541.732055, 'status': 'COMPLETED', 'green_line': [{'topic': 'Capacity Planning Overview', 'start_time': '00:00:03', 'end_time': '00:00:21', 'transcript': 'Okay, So hello, everyone on this Iman Alyssa. So today will be conducting session on two topics. One is capacity planning, and the second is the road map in Jiro. So try to cover capacity planning within the first half an hour span and then will continue with the road map injera,', 'keywords': ['Capacity Planning', 'Roadmap', 'Jira'], 'summary': 'The session begins with a greeting from the speaker, Alyssa, who outlines the agenda for the day. The focus will be on two main topics: capacity planning and the roadmap in Jira. The speaker plans to cover the capacity planning aspect in the first half-hour before moving on to discuss the Jira roadmap.'}, {'topic': 'Capacity Planning Definition', 'start_time': '00:00:22', 'end_time': '00:03:58', 'transcript': "so the festival bodies capacity planning. So, according to the definition that is given here, is capacity planning is the process of identifying how many hours a project or task will require too demanding whether or not your team has the available bans it to complete it and then coordinating that work for maximum efficiency. So what it exactly means is instead offer. You know, I'm just guessing that how much offer can be done.Capacity planning is a complete process in which we are actually identifying the number of work hours that a person on already member in the scrum team can put in and the maximum work that can be achieved with within the spring time frame. For example, if it is a two week spent, then what is the maximum number of effective work hours that each of the resource can give? So that determines the capacityand er It also includes things like, you know, complexity of the storey, and also it's like if it is a very complex storey, then definitely the storey point is more and so that's the reason the efficiency or the, you know work hours will be more and if it is a a medium or lesser complex than definitely the number of our covers required will be lives. So everything of this we take into consideration along witha, for example, a team member out of 15 days. Or to explain that the stand a strength, he will be only for the next two days or last two days. Whatever. Okay, so his effective days will be around eight days, right? So they'll also consider that that okay, he is actually available for eight days, and according to its, his work hours will be calculated.So what is the benefit of this? So the benefit of this is that you know, we are not keeping anything for, you know, like Cobb, depending on the chance of completion. It's like a sure shot. What they are projecting, what they are planning, what we are focusing, we are able to achieve it. So that is the main benefit of compactD planning. When we do capacity planning in a proper weight and there is very less chance that the gold will be missed or, you know, the maximum among the work we are able to achieve, rather than if we are not doing any capacity planning and randomly taking into work the new know Most of the time it's like we miss on the target and there are storeys which will spill over and you know there will be a chaos with industry.So this is the basic things are going forward with some more points on capacity planning. It's like on tapestry. Planning helps the team understand the amount of productive engineering time available in a sprint. For example, To perform capacity planning for energy team, you must gather each teammembers availability and time of, as I said regarding their holidays or leaves, you know, I said about the leaves. If there is holidays during those springtime, then definitely we also considered that. And that time of will be for everybody. That is part of the strength.So So this is telling that and then add up the individual capacity to calculate the team's overall capacity. So the complete work covers for each of the team members in adding of all each team members complete work hours. We can make the full capacity of the T right that aghast on your team's overall capacity, which is maximum amount of work that you can pile on their plate before you have over extended them, which we don't want.", 'keywords': ['Capacity Planning', 'Team Availability', 'Work Efficiency'], 'summary': 'The transcript provides an in-depth explanation of capacity planning, defining it as the process of determining the necessary work hours for projects or tasks to assess whether a team can meet its demands. It emphasizes the importance of coordinating tasks for maximum efficiency and avoiding guesswork. The speaker elaborates on how capacity planning involves evaluating the available hours of team members, considering factors like the complexity of tasks and individual availability. By calculating the effective work hours within a set timeframe, such as a two-week sprint, teams can better understand their capacity. This careful planning minimizes the risk of missing targets and helps achieve project goals by ensuring that work is allocated realistically based on team capabilities. The discussion also highlights the benefits of capacity planning, including improved predictability and reduced chaos in project execution.'}, {'topic': 'Capacity Planning Benefits', 'start_time': '00:03:58', 'end_time': '00:07:00', 'transcript': "So once you have that information, you move into the planning stage. That's very will prioritise task and scheduled those hours so that work is completed by the intended deadline. So capacity means you will root the project plan expectations in reality. So we are not keeping anything for, you know, guess work rather than you're optimistic guesses about what team can churn. Oh, this is the basic thing about capacity. The next comes the ways to estimate so.if a some of you guys are working currently on sprint based projects or even if you are not, I think you must be familiar with things like estimation of the storeys. So how do we do the estimates? So the most common thing that we currently laid to is Storey pointing right?So this is just a just in which I am trying to explain to Otis Storey pointing. So there are a couple of methods that we tried to estimate there's old school, May 3rd storey point, May 3rd storey count and hybrid matters. The most common method is the storey appointments or which we normally deal in storey pointing. Also, there are two ways of Storey pointing that this T shirt sizing and the Fibonacci series oneso again a T shirt sizing, which is like small, medium large Axl, this is not that much used and the Fib Unity series, which is the most commonly used currently on storey pointing.So how is this done? For example? It's a very simple storey and we do not have anything to explore or lots of understanding. Then it will be a storey 0.1 or two, so here. The series is given of it wrong. And sorry I didn't cheque that out. It will be one told 357 notches. Cities. Okay, so if it is a simple one will give a one or two pointers.that a storey pointing is done along with the whole team. As you know, there are grooming sessions during which the whole team sits together, understands the storey and then, as per everybody is voting that is decided whether that storeys and easy one then will give an auto. If it is a medium complex storey will give it a three if it is more complex than it is a five and if it is extremely complicated and very, very difficult will give it eight.So most of the times we tried to break down eight point of storeys into lesser points. Like, you know, two models of three and five. Okay, one storey of three points, another of five points. So body A. This is the way of just, you know, deciding which storey is of how much difficulty levelSo this is just a rough or in a very simple what can is it? A table which is showing how we are doing the capacity planning, though in other real instance are in show you how it issues showing. So the normally we have two ways of doing this capacity planning.", 'keywords': ['Capacity Planning', 'Story Pointing', 'Estimation Methods'], 'summary': 'The transcript discusses the planning stage of capacity planning, highlighting its importance in prioritizing tasks and scheduling work to meet deadlines effectively. It emphasizes that capacity planning should align project expectations with reality, avoiding optimistic guesses about team productivity. The speaker introduces estimation methods commonly used in sprint-based projects, particularly story pointing. Various techniques for story pointing, including the Fibonacci series and T-shirt sizing, are explained, detailing how teams collaboratively assess the complexity of tasks during grooming sessions. The speaker notes that simpler stories may receive lower point values, while more complex ones are assigned higher values, with a focus on breaking down challenging tasks into manageable components.'}, {'topic': 'Capacity Planning Templates', 'start_time': '00:07:00', 'end_time': '00:08:49', 'transcript': "Either we do we have a template of Axl shit temperate in which we put in the work hours or else we can donate directly through. So how we are putting a tear in the simple largest explained to him So these are the name of the resources that are part of those Graham.So although people are names are written one other work days for which, for example, this is showing that it is a to experience that why that's why it is 10 days. Okay, In the two weeks we have 10 days, then we have categorised each type of work. Okay, so here you can see the availablenumber of days. Okay, So for example, this person don't have any vacation or anything else. So that's why he is completely available for all the 10 days and his complete work hours is 7010 into seven sewing plans. Seven hours. I am sorrysomething is here in miss Okay, He So we are considering here seven work hours per day. That's the reason we're have given a den into 7. 3070 of us. Okay, then the second person, as you can see here, he has a vacation of one day. Right? So that's the reason his effective days is only nine.And hence the calculation that is coming. It's nine into seven. That is an an hours per day of her, which comes to 63. So in this way, all the team's effort or work hours is calculated, and the total comes to around 3 15 hours.So this is a basic capacity plan, so I'll just give you a glimpse of the actual ones, which we normally use, so it's a bit more complicated than what you have seen, so", 'keywords': ['Capacity Planning', 'Work Hours', 'Resource Allocation'], 'summary': 'The transcript discusses the process of capacity planning using templates. The speaker outlines a method for tracking work hours, emphasizing the importance of recording the availability of team members and categorizing their work types. An example is provided where a resource is shown with 10 available days of work, with calculations made based on their availability, including vacation days. The speaker explains the calculations for effective work hours, demonstrating how to derive total work hours for the team. The discussion concludes with a hint that actual capacity planning templates are more complex than the basic example shared.'}, {'topic': 'Technical Issues', 'start_time': '00:08:57', 'end_time': '00:09:59', 'transcript': "not able to. I was able to see this. it's the said this light show. right. the thinking, okay? so went above this one. Is it so now unable to? You guys were able to say this.it's better than before. Yeah, literally. Can you zoom? And I don't think it's a numbing with resume.Maybe you have to come out on the slide show and land new China. There's an option to. consume you never screams as well.", 'keywords': ['Technical Issues', 'Slideshow', 'Visibility'], 'summary': 'The speaker discusses various technical issues encountered during a presentation, particularly related to visibility and functionality of a slideshow. They express frustration about not being able to see certain elements and suggest potential solutions like zooming in or coming out of the slideshow. The conversation indicates a collaborative effort to resolve these issues.'}, {'topic': 'Real Life Capacity Planning', 'start_time': '00:10:17', 'end_time': '00:12:32', 'transcript': "just take on the drop down arrow and them. Zuman. Okay. Okay. Lydia. Thank you, Yah! so Yeah. So this is actually some sort of a real life capacity planning sheet that we are actually using. So it's a bit more complex than what I show new as a unit sister format, you can seeSo here you can say everything is mentioned. Who are the team members? What are the total number of this string shot is not full. So because I couldn't take it in a single stream. So there are some more few more members the chairman sing here. So this is train shot with, I mean part of the scrum team, not the full. As you can see from here, all the members are being seenso here that the members are there. So total spring daisy A mentioning water, the holidays. If there is any any leads for any of the resources, what on the actual days. So what are the actual days means what at the days that they are actually working per day hours. So here we have taken six tapesix hours per day and we keep two hours for buffer. Usually that is assigned because, you know, we do have several meetings when we are part of the sprint or a scam. We have several meetings. So that's why be assigned belief to ask per day for this kind of activities, meeting activities and other, you know.Connexion, connecting with the your team members and also effective work hours. This six. So accordingly of what is the number of hours per person gets is 36 hours for the full sprint, which is two week Sprint Reich.So hearing you can see for 68 here we have another small thing where we are calculating the total death effort, complete depth effort of work hours and the queue way work hours. Okay, so 20 for is the Dever covers and 140 for Solly. It's percent estimate. Whatever 135 you ever covered", 'keywords': ['Capacity Planning', 'Scrum Team', 'Work Hours'], 'summary': 'The transcript discusses a real-life capacity planning sheet used by a scrum team, highlighting its complexity compared to simpler formats. It details the inclusion of team members, total sprint days, and working hours. The speaker explains the allocation of hours per day, accounting for meetings and buffer time, resulting in a total of 36 hours per person for a two-week sprint. Additionally, there is a brief mention of calculating total development effort and work hours, indicating a structured approach to manage resources effectively.'}, {'topic': 'Capacity Utilization', 'start_time': '00:12:32', 'end_time': '00:14:44', 'transcript': "along with, we have another. okay? becoming Dombeck 50 person, 100%. Okay, so yeah, along that we have a few more things, like, you know, what is the available capacity? What is the time estimate and capacity utilisation. Capacity remaining. So, for example, a person has 36 capacity. But as per the storey points, we are able to assign only 30 work hours, so he will have a remaining capacity of 5% or fivein which he can accommodate any ad host stance or anything that comes in between. So those kind of things are also there. So here we can monitor which team member has got the, you know, his capacities move than his actual available capacity or it is lesser. And if if he has any banned with left, where we can take onone Moting here is like here is the like, for example, here having all the team members and then So we are calculating here. The total devours the total Q hours. So he are out of these members. The people that are mentioned in yellow are testing team people, so the addition of all these peoplewe will be able to calculate the the way of us. And similarly, the addition of all these people that are in grade are the other deaf people. So the damper cars were able to calculate separately, and then we have the total bar covers. But yeah, this thing, whatever is the total, is it? It's coming here and we're getting the total were covers for Q and the for deaf and also for the team, So this is the way so.", 'keywords': ['Capacity Utilization', 'Workload Assignment', 'Remaining Capacity'], 'summary': "The transcript discusses capacity utilization, focusing on the assessment of available capacity and time estimates for workload assignment. It highlights how to calculate remaining capacity for team members, illustrating with an example where an individual has a capacity of 36 but can only manage 30 work hours, resulting in a 5% remaining capacity. The speaker emphasizes the importance of monitoring each team member's capacity to ensure workloads are balanced and identifies team members involved in different tasks, calculating total work hours for various groups, including testing and development teams."}, {'topic': 'Capacity Planning Challenges', 'start_time': '00:14:45', 'end_time': '00:23:50', 'transcript': "some of them things like. so long. Also, you know, though, didn't use this one much, but sometimes also from this. whatever data we are giving, we can also culprit velocity here. Or we can project the velocity that we will be able to achieve, okay?sahib. department in this manually, or is it through the era? So I am telling youth of this Excel sheet is actually mental manually. But we do have a G option of it doesn't happen like this. I will show you the gene option as after we have discussed. So I told him in to his red wine, raise the Excel sheet, which is a manual thing, which we do right. This is the one and also may have a Gina option which have issued.Sorry, Mon Amis. However question So withdrawing the screen on the right hand side where you have listed down the storey numbers and the name of the other way of doing the capacity Planning, however,know like this is the same capacity. So here now we are register jotting down the storeys that will be covering in the spread ride for every sprint before starting the spring. We aredoing a capacity planning, right? So the upcoming streamed We are listing down all the storeys that we will do in this train. And who will work on this print. Right? So for example, if this storey is being done by the developer Dipak So the package will have here his workouts. How many work of us even allocated? For example, out of his total capacity of 36 he will just give three hours for this. And then again there will besome Barca was for the tested as well they will give. Maybe they will give two hours. Okay, so that is the reason the invention ing it. Storey buys how much a storey points or how much Barca will not store ippon. Sorry hours breakdown actually right at the breakdown and the the task, right? Completely a ride. So every storeys we are breaking down. We're taking the hours considering the hours that will beof more like the developer. How much hours they spend? The tester, How much I was Davis pen And how much is the total hours? So accordingly you know, open the Pakis parking on this storey as well as this storey as well as this Storey said the complete fire cover should come to near about 36 so we can keep a track. Okay Addition of all these storeys will come to around 36 right? So you can get the totally here.So next comes is the advantages of capacity planning. So I want to just zoom out. You can get a you. so so for the advantages. So first of all, it is avoid burnout. So what is about team won out is like, you know, the Arges piling work on somebody. And we exactly do not have any idea that whether that person will be able to do or not, or whether he is stretching more just to, you know, fulfil the work and to awe do not want want to stumped him to function like that. We want the work to be done. But also it's not like a person is, you know, working late nights and weekends just to compete. We do not one that can be a planning properly,and we are able to estimate that. Okay, we have a delivery in the state. And so if they are planning in this way, our definitely will meet our posts will meet her deliberated. So this will help to do the work effectively without any stress on the team bus. It is the main thing, like so taking steps to get for understanding of your teams at Children positive in she won't overwhelm them with too many tasks and responsibilities and also support them in managing their time by prioritising the most impactful.then sent more realistic deadlines again the same thing. So it's like something which they can achieve. It's not like a career piling them on, and then at the end of the strength of, even if they are trying their level best, they are not able to achieve so Yah, we do not want that. So get details about availability straight from your team. You will get a much needed reality. Cheques on the Dugan manage deadline expectations according to what your team can actually produce,then the third point is identify skin sock shortages. So by evaluating your team's capacity and planning work in advance, it's easier to spot if projects require skills that your team doesn't have. Accounting for that early allows you to take proactive action, such as training someone on your team. Outsourcing attacks are changing the scope of the project, so I think this is very self explanatory. So when we are planning ahead, so we in.So what is the You know what is lacking and what will blockers in achieving our booths? All this identification will not come once we have jumped into the sprint, so it will come before you have actually taken the work, so you can project it and you can, you know, avoid that. And whatever you are committing, you will be able to deliver. That's the most important thing, right?so the challenges of capacity planning said stuff to understand band with. So, yeah, it is tough to understand band with because, you know, view we are projecting that. Okay, this person can do this much hours. It may be that Okay, that person, even if for he is mentioning that I will need three hours of world,Sometimes something happens and he is getting stuck and he needs another more two hours. It's actually not three hours. It's actually five hours. So in that way, when we are calculating everything we are considering, Okay, this work will only take three hours, but actually it is taking more. So this type of difficulty comes.And so that's why it is written. It's tough to understand band with, and though we have a solution to this, which is like the always came buffer hours, as I told you so, that that will take care of this and the gritty or whatever. So your team's bandits is always evolving as projects change and team members leave or join the ranks. So this is another challenge, right? Because, you know, team members are leaving and joining in the middle of this print and also that definitely impacts it.So plus, you need to rely on people's honesty about the current again. The same thing as I told a work may take more a work may take less. So that is also restriction all of that making a challenging to get a firm grasp on just how much capacity your team has available to tackle new work and request, particularly if you have a team full of high achievers always believed that they can takemore. Okay, the more often you have, you talked your team about their most three teams to it weekly, the easier it will get for you to be realist. So as an venue work with a certain team. You know, maybe in the first print your capacity may not be a perfect, but as and when you work on a multiple sprints, you know, like erafter first a Ken than third and consecutive sprint. Then you get the more better grasp on how much each person's capacities is. And if you were, you know, if you are committing more than that, also can district or if you are committing less than also that also you can increase it, so we will get a more realistic idea. Changes will throw you off track. They're gonna risk associated with them.The project and enforcement circumstances, from sense in seasonality to industry changes, will throw wrenches senior plans when you need to try to account for all these potentials. At best, capacity planning isn't always so straight forward. Planning in a cushion, even if it's just an extra day or two, will help you roll with the punches without things running of Paris. So again, this is something it it is likeeven if you are planning, there may be some hindrances, but you know it's much better to go with capacity than without capacity. Then it is like completely chaos, andthere is no planning and all if you're doing any, you know, starting or sprint without the capacity, so you will have to engage in some hard conversations again. This is a part of capacity and a tapestry. Planning is only useful if you though something with the information you identify that can involve turning down projects due to lack of bandwidth, adjusting a reducing expectations, pushing out deadlines. It's always better to say no than too serious and not to deliver. So this is the most inPorton part, you know. So capacity planning is for this reason only that you know what you are committing. You should be able to deliver. And if you you are saying like you are able to predict that, Okay, if this much of a commitment I'm giving, I will not be able to deliver than it's better to mention that beforehand rather than taking that one and then not delivering. So that's the main", 'keywords': ['Capacity Planning', 'Bandwidth', 'Team Management'], 'summary': 'The transcript discusses the challenges and importance of capacity planning within project management. It starts by highlighting the need for accurate data and the use of tools like Excel to track and project team workload and velocity. The speaker explains how to conduct capacity planning by breaking down tasks and assigning hours to each team member based on their total available capacity. The advantages of capacity planning, such as avoiding burnout and managing realistic deadlines, are emphasized, along with the identification of skill shortages and the importance of proactive management. Challenges include understanding team bandwidth, reliance on team honesty, and the impact of changes in team composition. The speaker stresses the need to engage in honest conversations about capacity and the importance of setting realistic expectations to ensure commitments can be met.'}, {'topic': 'Capacity Planning Best Practices', 'start_time': '00:23:50', 'end_time': '00:24:56', 'transcript': "purpose of the president planning the next is capital planning. Best Praxis is so some of the tapestry planning West practises are sorry. So learn from past projects. Okay, so this is the main our thing, you know, and a capacity in the first sprint that Udo will never be perfect. It will be a kind of Okay,we are just trying to see. But as and when the A growth, the capacity planning for the future strengths on the next prince will definitely be better and will have a better idea about the amount of work which we should take and will be able to complete. Have honest conversations with Team OK song in here. The you know, transparency is very important, though Scram, Master and theA team member should be completely true with each other so that the another's come. Master understands the limitations of the developer of the tester and also the developer, and the tester truly identifies water. The actual bar covers that he or she is putting, which will again, you know, help us in doing a good capacity.", 'keywords': ['Capacity Planning', 'Scrum', 'Team Communication'], 'summary': "The transcript discusses capacity planning best practices, highlighting the importance of learning from past projects to improve future planning efforts. It notes that initial capacity estimates may be imperfect, but with experience, teams can better gauge the workload for future sprints. Emphasis is placed on the necessity of honest communication among team members and transparency between Scrum Masters and developers. This open dialogue is crucial for understanding each individual's limitations and ensuring effective capacity planning."}, {'topic': 'Roadmapping Overview', 'start_time': '00:32:45', 'end_time': '00:33:59', 'transcript': "so I think we are five minutes more. So can we moved to the road map. okay? So now moving ahead with the road maps of what is roadmap? Okay, so road mapping, Jill A software. Our team level roadmaps useful for planning large basis of work several months in advance. A terrific level within a single project. Simple planning and dependency management features help your team's visualise and manage work better. So what is exactly a roadmap is nothing but a planning feature in bet. You know, you canput in all the epics and under native storeys, and you can see the complete picture of like, for example, in which sprint you will be able to complete what feature Sova. Normally, you know the identify features okay, will do this by this April end will do this feature by maybe June will do this feature so fnothing will be clearly visible. If we are using a Roadmaster of Witch spring, we will be able to complete feature one will sprint will be able to complete feature too. So this was kind of a projection. So how does it look into looks like this? Okay, so here you can see, I just", 'keywords': ['Roadmap', 'Epics', 'Dependency Management'], 'summary': 'The transcript discusses the concept of road mapping in software development, highlighting its importance for planning extensive work over several months. It describes how team-level roadmaps aid in visualizing and managing projects by allowing teams to lay out epics and user stories, thereby providing a clear overview of when features are expected to be completed. The speaker emphasizes the utility of roadmaps in identifying project timelines and dependencies, illustrating how roadmaps can project the completion of features within specific sprints.'}, {'topic': 'Roadmap Creation', 'start_time': '00:34:01', 'end_time': '00:39:21', 'transcript': "So here you can see a all the storeys that the left side are the epics. It is showing the epics. And these are the things the storeys that you will be able to complete stating the months you residency, the months in which month border the things that we can complete, right?so maybe this epic will be able to complete in the month of December. The second epic will be able to again complete in December the cross team effort epic they will be completing by November. So this other projections that have been made right and the the strike type of things will also be explaining this is kind of dependence is that's right slinking here.so far, the key concepts of ethics. Okay, so for I'm in for creating a road map, things that you need to know at the Buddhism and epic is a large body of us that can be broken down into individual tasks required to ship of feature. The world probe becomes a child issue of the epic. Sometimes owner spending epics are displayed as collard bus onthe road map. As I showed you, it was so of epics Are you know again? As I said, like a feature, you there is a feature. Okay, So if that feature is a small feature, if it is a big feature than again, features will be broken down. But if it is a small features that you can't convert into an epic,so just you will create an epic, and underneath it you will again create storeys of that in order to achieve that feature, what other things you need to what other steps you need to do border the storeys that need to be turning out to create that feature in order to complete that feature. So that is epics. So as again, as I said to you, So these are the epics, this whatever icon you are saying in the left, those are epic aiglons.and these are, though, things depicted in coloured bars. what is a child issue again? As I said, under need the epic the create storeys. So the storeys are nothing but child issues. Child issues can be created directly from the road map and administered within the epic the belonged So the storeys that will create under the epic an honest child issues the most common childish you a storeys, tasks and bugs. Okay, but you can create new issue types to represent different type of work for your team's quickly move issues to other tipping and reorder issues or epics by dragging and dropping themdirectly from your road map. So this is kind of saying how you are able to do that. Okay, so you can see the screenshot here. So this is a bug. So under name this epic, which is group booking experience. So they are trying to create a bag or a storey or a tusk. Okay,next to start and dude is the length of the bar on the road map for alleged at the start and due date set for Europe. Pick setting dates for your epic helps to communicate plans with the team and provide visual visibility to external stakeholders. Informed dependence in mapping and helped the resource management. So yeah, so start and doodles are very important. In order to project when you will be able to complete the feature or the epic,you're starting a due date of each of the storeys or child into issues matter, you know, so that you are able to understand. OK, completely a get this epic we will be able to complete in the stand this epic. This temps of this feature will be done by this time Fring.So this is depicting being depicted here. As you can see, the the the the thing that the Yeah. So So far epic when you are putting her start date and the due date So that is kind of you know, high level but in a storey is you know, when you are taking up storeys we normally understand that this storey will be completing in this print trade even if it's a storey you were expectingto take two days. Okay, But out of everything it mill maximum taker, Another buffer two days you will complete by four days. Right? So definitely by the end of the sprint you will complete that storey, right? So when you were giving the start date and ended to the storeys, that is a definite dates night. Almost definite it there is a major.Bata How If you are talking about projection of the epic skirt things then you can say a air kind of predicting When's once all the bodies the end it here is when all the storeys within the epic will end Right That date we will give us the end. Eh?We are assigning like okay in desperate will do this in district will do this And once all the storeys of this under Newt this epic whatever storeys are there will complete that sprint ended will put us the duty for the fix", 'keywords': ['Roadmap Creation', 'Epics', 'Child Issues'], 'summary': 'The transcript discusses the process of roadmap creation, focusing on the concepts of epics and child issues within a project management framework. It explains that epics are large bodies of work that can be divided into smaller tasks, referred to as stories, which are essential for shipping a feature. The speaker details how to manage these epics and their respective stories, emphasizing the importance of setting start and due dates for visibility and effective resource management. Additionally, the transcript describes how to visualize progress on a roadmap and highlights the significance of understanding dependencies among tasks to ensure timely completion of features.'}, {'topic': 'Roadmap Features', 'start_time': '00:39:21', 'end_time': '00:41:34', 'transcript': "it while doing the activity from THING is also the part of They are completely a part of this because of they are the ones who will you know, who will be actually doing the work. Right? So they at the ones who will say Okay, Veil late leaders will need four days to definitely they their input matters a lot.Okay, so then there is philtres and view settings with again. These are some of the features of roadmap Yadira software roadmap has built in philtres that make waving and managing work simple. Find and refine your road member searching for key words and filled of a Sinus status labelled issue at just view settings or your road map to cheque.What is displaced. Add or remove dependency in progress. Views and filtered expressed doubled to specific time. Frame on the fly is a leave you a road map. Bye weeks months of it Sasuke Zara features that we can use for the road maps, abilities and view setting feature is that then there is the dependency So what is dependency is like you know one storey you will be able to startThere are some times this situation's right In other storey the you will be able to start when you have completed the storey again there will be like a storey See you can be able to start menu of computers the storey So these kind of dependence is of these things These are dependencies and the dependencies were also one kind of You can sit blockers right, Unless and until you complete Storey eh? You cannot start storey pright. So this can be, you know, Mom, this can be shown in the road map dependency Management is critical for teams. When dependence is our visualised and well mapped, a team can adapt and plan for alternative parts. Indira Software You can easily show the relationship between epics by mapping dependence is directly from the road.So this is the way. As I told you, these things show that dependencies. Okay, So for example, once this is done, you can be able to do this. Okay? Say it's mentioned, Bill. Cheque out Experience blocks this. So you have to do this epic bill cheque out experience first, and then only you can be able to do the improve U M U S lite score.", 'keywords': ['Roadmap Software', 'Dependency Management', 'Task Visualization'], 'summary': 'The transcript discusses the features of a roadmap software, emphasizing the importance of user input in project management. It highlights built-in filters and view settings that facilitate the organization and management of tasks. The speaker explains the concept of dependencies, illustrating how certain tasks must be completed before others can begin. This dependency management is crucial for teams to visualize relationships between tasks and plan effectively. The speaker also mentions specific examples of dependencies that affect project scheduling.'}, {'topic': 'Dependency Management', 'start_time': '00:41:35', 'end_time': '00:44:07', 'transcript': "this on owners at the dependency. Right? This one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back? This is a plan. And the kind of things can I say that this is a plan the way ofyeah, you You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.I understand. But bear, can I Is there a way of being the actual that being in claim are going with the plan or not? If we look at the very first effect which is going to be completed by first week of April, the lower? Yes. So let's get extent in actual it gets extended by that same one month's end of April. How can I see thatwe are? Then you have to. Then you have to change the due date, right? Then it will show you have to change the due. Did that Okay. We are not able to achieve by this time frame we have extended it. Then it will again show you the actual do. Didthat time thing can? Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reportsat Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what weactually you ST road map you can see Like, for example, you are saying that it is epically an audible to complete by the time we haveestimated the an audible to complete rate. So then again you have to bow and I manually changing, told the due date that we have right. Then you will be able to see the actual it. It's something you have to do it then only will be able to project. It is like not like it'll automatically change and show it, er themselves. It willnot tell me if I've changed to April then it will extend the time and the label. But it will not like show me that.earlier date was April for speak of April, but now it is invalid. Nikola recorded. No, no, no. It's not like the No, no, no, no. It won't be like that. It will show you whatever due date you have given It is like that that that sort of complexity is not there in road map. Right? So growth map is kind of you know, you can discuss this with", 'keywords': ['Dependency Management', 'Project Planning', 'Roadmap'], 'summary': "The transcript focuses on dependency management within project planning. The discussion revolves around tracking progress against a roadmap, particularly how to compare planned timelines with actual completion dates. The speaker addresses concerns about monitoring if the current work aligns with the initial roadmap and how to adjust due dates accordingly. They emphasize that while it's necessary to manually change due dates when projects are extended, the system will not automatically indicate discrepancies between estimated and actual timelines. The conversation also touches on the limitations of the roadmap tool in reflecting changes in project timelines and the need for manual updates to maintain accurate tracking."}, {'topic': 'Roadmap Sharing and Exporting', 'start_time': '00:44:07', 'end_time': '00:46:40', 'transcript': "product on a bit. Your stakeholders, you not to show them, project them these things. So But if you're telling a could be initially projected this then I don't think that is not for example, this have didn't happen to me. But as far as I know that you will not be able to show it will show whatever you have given current do death.so again and other feature is sure and exports of whatever road matter of created, you will be able to share and export the road map. So sandy, a roadmap directly from Gina to from here a software by typing in news animal innocently copy to grab the roadmap, your export year old map and just the timeline views Star date and in dates before expecting it as an image. So this is like some of the features of road map.create a roadmap injera software. So one of the steps to create a roadmap, Najera software creator, knew Gina Software Project or go to an existing project and then navigate to the side bag and click roadmap. Okay, not if they're not showing saying your roadmap have enabled the road map in the board setting. So again there's a Y.And here, if you are not able to see the roadmap tap than definitely in the board sitting, you need to go and enable it. So people who are comfortable Najera will be understanding what I'm talking about. But if people who are not having hand from Nigeria, they may find it difficult in reading this and understanding that.Then click plus create a pick on the road map to create a picks directly on your road map. If he roadmap is empty, simply start typing to create right name, year epic and hit Enter. You can double click into epics at any time from your road map to add information such a start and ended assigning attachment and more at child issues to European from the road map by clickingnext to the epic name. Okay, select the type of childish uses in the drop down on the named Asia and of the covered it right in a single single points. Few tips for or Mac creation visualise dependence is between epics by creating or removing dependence ceilings directly on Iroda. So this thing for this thing, you actually need to work with the team, right?The team will be able to help you, guy do and understand and of took Lego, the product owner as well as the team. Both will be able to guide do help you in understanding what other dependencies and how to create the road map and how to mention the dependencies. Right? So that's why", 'keywords': ['Roadmap', 'Najera Software', 'Epics'], 'summary': "The transcript discusses the features of creating and exporting roadmaps using a specific software named 'Najera'. It emphasizes the importance of sharing project details with stakeholders and explains how to create a roadmap by navigating through the software. The speaker outlines the steps to enable roadmap visibility in board settings, create epics, and manage child issues. Additionally, it highlights the need for collaboration with the team and product owner to understand dependencies and effectively utilize the roadmap functionalities."}, {'topic': 'Final Thoughts and Q&A', 'start_time': '00:48:53', 'end_time': '00:50:23', 'transcript': "So that's all from my side. Any other questions here? for any in any questions still. anyone. any questions on this, so I will be sharing, I think. I think for 100 shared this. topic with you If you don't have this p pity than definitely this slide show for a financial she's shared with you both the capacity as well as this. Soa roadmap ting So far handed, we share with the people who have joined here. not are not can go ahead and share this but Ariel so that people can go through it and the in future, if they have anything, they can get back to me. Hand indefinitely, discussso intense, guys. Any other questions? Thank you. Thanks times a lot. of frustration. And I including the feedback An assessment form with the recording on, please. Thank you.Thank you.", 'keywords': ['Q&A', 'Feedback', 'Resources'], 'summary': 'The speaker concludes the session by inviting final questions from the audience, indicating an openness to further discussion. They mention sharing additional resources, including a slide show and a roadmap, to help participants with the topic discussed. The speaker encourages feedback and expresses gratitude for the engagement during the session, suggesting that attendees can reach out for further clarification or discussion in the future.'}], 'yellow_line': [{'Topic': 'Capacity Planning Overview', 'transcript': 'Okay, So hello, everyone on this Iman Alyssa. So today will be conducting session on two topics. One is capacity planning, and the second is the road map in Jiro. So try to cover capacity planning within the first half an hour span and then will continue with the road map injera,', 'start_time': '00:00:03', 'end_time': '00:00:21'}, {'Topic': 'Capacity Planning Definition', 'transcript': "so the festival bodies capacity planning. So, according to the definition that is given here, is capacity planning is the process of identifying how many hours a project or task will require too demanding whether or not your team has the available bans it to complete it and then coordinating that work for maximum efficiency. So what it exactly means is instead offer. You know, I'm just guessing that how much offer can be done.Capacity planning is a complete process in which we are actually identifying the number of work hours that a person on already member in the scrum team can put in and the maximum work that can be achieved with within the spring time frame. For example, if it is a two week spent, then what is the maximum number of effective work hours that each of the resource can give? So that determines the capacityand er It also includes things like, you know, complexity of the storey, and also it's like if it is a very complex storey, then definitely the storey point is more and so that's the reason the efficiency or the, you know work hours will be more and if it is a a medium or lesser complex than definitely the number of our covers required will be lives. So everything of this we take into consideration along witha, for example, a team member out of 15 days. Or to explain that the stand a strength, he will be only for the next two days or last two days. Whatever. Okay, so his effective days will be around eight days, right? So they'll also consider that that okay, he is actually available for eight days, and according to its, his work hours will be calculated.So what is the benefit of this? So the benefit of this is that you know, we are not keeping anything for, you know, like Cobb, depending on the chance of completion. It's like a sure shot. What they are projecting, what they are planning, what we are focusing, we are able to achieve it. So that is the main benefit of compactD planning. When we do capacity planning in a proper weight and there is very less chance that the gold will be missed or, you know, the maximum among the work we are able to achieve, rather than if we are not doing any capacity planning and randomly taking into work the new know Most of the time it's like we miss on the target and there are storeys which will spill over and you know there will be a chaos with industry.So this is the basic things are going forward with some more points on capacity planning. It's like on tapestry. Planning helps the team understand the amount of productive engineering time available in a sprint. For example, To perform capacity planning for energy team, you must gather each teammembers availability and time of, as I said regarding their holidays or leaves, you know, I said about the leaves. If there is holidays during those springtime, then definitely we also considered that. And that time of will be for everybody. That is part of the strength.So So this is telling that and then add up the individual capacity to calculate the team's overall capacity. So the complete work covers for each of the team members in adding of all each team members complete work hours. We can make the full capacity of the T right that aghast on your team's overall capacity, which is maximum amount of work that you can pile on their plate before you have over extended them, which we don't want.", 'start_time': '00:00:22', 'end_time': '00:03:58'}, {'Topic': 'Capacity Planning Benefits', 'transcript': "So once you have that information, you move into the planning stage. That's very will prioritise task and scheduled those hours so that work is completed by the intended deadline. So capacity means you will root the project plan expectations in reality. So we are not keeping anything for, you know, guess work rather than you're optimistic guesses about what team can churn. Oh, this is the basic thing about capacity. The next comes the ways to estimate so.if a some of you guys are working currently on sprint based projects or even if you are not, I think you must be familiar with things like estimation of the storeys. So how do we do the estimates? So the most common thing that we currently laid to is Storey pointing right?So this is just a just in which I am trying to explain to Otis Storey pointing. So there are a couple of methods that we tried to estimate there's old school, May 3rd storey point, May 3rd storey count and hybrid matters. The most common method is the storey appointments or which we normally deal in storey pointing. Also, there are two ways of Storey pointing that this T shirt sizing and the Fibonacci series oneso again a T shirt sizing, which is like small, medium large Axl, this is not that much used and the Fib Unity series, which is the most commonly used currently on storey pointing.So how is this done? For example? It's a very simple storey and we do not have anything to explore or lots of understanding. Then it will be a storey 0.1 or two, so here. The series is given of it wrong. And sorry I didn't cheque that out. It will be one told 357 notches. Cities. Okay, so if it is a simple one will give a one or two pointers.that a storey pointing is done along with the whole team. As you know, there are grooming sessions during which the whole team sits together, understands the storey and then, as per everybody is voting that is decided whether that storeys and easy one then will give an auto. If it is a medium complex storey will give it a three if it is more complex than it is a five and if it is extremely complicated and very, very difficult will give it eight.So most of the times we tried to break down eight point of storeys into lesser points. Like, you know, two models of three and five. Okay, one storey of three points, another of five points. So body A. This is the way of just, you know, deciding which storey is of how much difficulty levelSo this is just a rough or in a very simple what can is it? A table which is showing how we are doing the capacity planning, though in other real instance are in show you how it issues showing. So the normally we have two ways of doing this capacity planning.", 'start_time': '00:03:58', 'end_time': '00:07:00'}, {'Topic': 'Capacity Planning Templates', 'transcript': "Either we do we have a template of Axl shit temperate in which we put in the work hours or else we can donate directly through. So how we are putting a tear in the simple largest explained to him So these are the name of the resources that are part of those Graham.So although people are names are written one other work days for which, for example, this is showing that it is a to experience that why that's why it is 10 days. Okay, In the two weeks we have 10 days, then we have categorised each type of work. Okay, so here you can see the availablenumber of days. Okay, So for example, this person don't have any vacation or anything else. So that's why he is completely available for all the 10 days and his complete work hours is 7010 into seven sewing plans. Seven hours. I am sorrysomething is here in miss Okay, He So we are considering here seven work hours per day. That's the reason we're have given a den into 7. 3070 of us. Okay, then the second person, as you can see here, he has a vacation of one day. Right? So that's the reason his effective days is only nine.And hence the calculation that is coming. It's nine into seven. That is an an hours per day of her, which comes to 63. So in this way, all the team's effort or work hours is calculated, and the total comes to around 3 15 hours.So this is a basic capacity plan, so I'll just give you a glimpse of the actual ones, which we normally use, so it's a bit more complicated than what you have seen, so", 'start_time': '00:07:00', 'end_time': '00:08:49'}, {'Topic': 'Technical Issues', 'transcript': "not able to. I was able to see this. it's the said this light show. right. the thinking, okay? so went above this one. Is it so now unable to? You guys were able to say this.it's better than before. Yeah, literally. Can you zoom? And I don't think it's a numbing with resume.Maybe you have to come out on the slide show and land new China. There's an option to. consume you never screams as well.", 'start_time': '00:08:57', 'end_time': '00:09:59'}, {'Topic': 'Real Life Capacity Planning', 'transcript': "just take on the drop down arrow and them. Zuman. Okay. Okay. Lydia. Thank you, Yah! so Yeah. So this is actually some sort of a real life capacity planning sheet that we are actually using. So it's a bit more complex than what I show new as a unit sister format, you can seeSo here you can say everything is mentioned. Who are the team members? What are the total number of this string shot is not full. So because I couldn't take it in a single stream. So there are some more few more members the chairman sing here. So this is train shot with, I mean part of the scrum team, not the full. As you can see from here, all the members are being seenso here that the members are there. So total spring daisy A mentioning water, the holidays. If there is any any leads for any of the resources, what on the actual days. So what are the actual days means what at the days that they are actually working per day hours. So here we have taken six tapesix hours per day and we keep two hours for buffer. Usually that is assigned because, you know, we do have several meetings when we are part of the sprint or a scam. We have several meetings. So that's why be assigned belief to ask per day for this kind of activities, meeting activities and other, you know.Connexion, connecting with the your team members and also effective work hours. This six. So accordingly of what is the number of hours per person gets is 36 hours for the full sprint, which is two week Sprint Reich.So hearing you can see for 68 here we have another small thing where we are calculating the total death effort, complete depth effort of work hours and the queue way work hours. Okay, so 20 for is the Dever covers and 140 for Solly. It's percent estimate. Whatever 135 you ever covered", 'start_time': '00:10:17', 'end_time': '00:12:32'}, {'Topic': 'Capacity Utilization', 'transcript': "along with, we have another. okay? becoming Dombeck 50 person, 100%. Okay, so yeah, along that we have a few more things, like, you know, what is the available capacity? What is the time estimate and capacity utilisation. Capacity remaining. So, for example, a person has 36 capacity. But as per the storey points, we are able to assign only 30 work hours, so he will have a remaining capacity of 5% or fivein which he can accommodate any ad host stance or anything that comes in between. So those kind of things are also there. So here we can monitor which team member has got the, you know, his capacities move than his actual available capacity or it is lesser. And if if he has any banned with left, where we can take onone Moting here is like here is the like, for example, here having all the team members and then So we are calculating here. The total devours the total Q hours. So he are out of these members. The people that are mentioned in yellow are testing team people, so the addition of all these peoplewe will be able to calculate the the way of us. And similarly, the addition of all these people that are in grade are the other deaf people. So the damper cars were able to calculate separately, and then we have the total bar covers. But yeah, this thing, whatever is the total, is it? It's coming here and we're getting the total were covers for Q and the for deaf and also for the team, So this is the way so.", 'start_time': '00:12:32', 'end_time': '00:14:44'}, {'Topic': 'Capacity Planning Challenges', 'transcript': "some of them things like. so long. Also, you know, though, didn't use this one much, but sometimes also from this. whatever data we are giving, we can also culprit velocity here. Or we can project the velocity that we will be able to achieve, okay?sahib. department in this manually, or is it through the era? So I am telling youth of this Excel sheet is actually mental manually. But we do have a G option of it doesn't happen like this. I will show you the gene option as after we have discussed. So I told him in to his red wine, raise the Excel sheet, which is a manual thing, which we do right. This is the one and also may have a Gina option which have issued.Sorry, Mon Amis. However question So withdrawing the screen on the right hand side where you have listed down the storey numbers and the name of the other way of doing the capacity Planning, however,know like this is the same capacity. So here now we are register jotting down the storeys that will be covering in the spread ride for every sprint before starting the spring. We aredoing a capacity planning, right? So the upcoming streamed We are listing down all the storeys that we will do in this train. And who will work on this print. Right? So for example, if this storey is being done by the developer Dipak So the package will have here his workouts. How many work of us even allocated? For example, out of his total capacity of 36 he will just give three hours for this. And then again there will besome Barca was for the tested as well they will give. Maybe they will give two hours. Okay, so that is the reason the invention ing it. Storey buys how much a storey points or how much Barca will not store ippon. Sorry hours breakdown actually right at the breakdown and the the task, right? Completely a ride. So every storeys we are breaking down. We're taking the hours considering the hours that will beof more like the developer. How much hours they spend? The tester, How much I was Davis pen And how much is the total hours? So accordingly you know, open the Pakis parking on this storey as well as this storey as well as this Storey said the complete fire cover should come to near about 36 so we can keep a track. Okay Addition of all these storeys will come to around 36 right? So you can get the totally here.So next comes is the advantages of capacity planning. So I want to just zoom out. You can get a you. so so for the advantages. So first of all, it is avoid burnout. So what is about team won out is like, you know, the Arges piling work on somebody. And we exactly do not have any idea that whether that person will be able to do or not, or whether he is stretching more just to, you know, fulfil the work and to awe do not want want to stumped him to function like that. We want the work to be done. But also it's not like a person is, you know, working late nights and weekends just to compete. We do not one that can be a planning properly,and we are able to estimate that. Okay, we have a delivery in the state. And so if they are planning in this way, our definitely will meet our posts will meet her deliberated. So this will help to do the work effectively without any stress on the team bus. It is the main thing, like so taking steps to get for understanding of your teams at Children positive in she won't overwhelm them with too many tasks and responsibilities and also support them in managing their time by prioritising the most impactful.then sent more realistic deadlines again the same thing. So it's like something which they can achieve. It's not like a career piling them on, and then at the end of the strength of, even if they are trying their level best, they are not able to achieve so Yah, we do not want that. So get details about availability straight from your team. You will get a much needed reality. Cheques on the Dugan manage deadline expectations according to what your team can actually produce,then the third point is identify skin sock shortages. So by evaluating your team's capacity and planning work in advance, it's easier to spot if projects require skills that your team doesn't have. Accounting for that early allows you to take proactive action, such as training someone on your team. Outsourcing attacks are changing the scope of the project, so I think this is very self explanatory. So when we are planning ahead, so we in.So what is the You know what is lacking and what will blockers in achieving our booths? All this identification will not come once we have jumped into the sprint, so it will come before you have actually taken the work, so you can project it and you can, you know, avoid that. And whatever you are committing, you will be able to deliver. That's the most important thing, right?so the challenges of capacity planning said stuff to understand band with. So, yeah, it is tough to understand band with because, you know, view we are projecting that. Okay, this person can do this much hours. It may be that Okay, that person, even if for he is mentioning that I will need three hours of world,Sometimes something happens and he is getting stuck and he needs another more two hours. It's actually not three hours. It's actually five hours. So in that way, when we are calculating everything we are considering, Okay, this work will only take three hours, but actually it is taking more. So this type of difficulty comes.And so that's why it is written. It's tough to understand band with, and though we have a solution to this, which is like the always came buffer hours, as I told you so, that that will take care of this and the gritty or whatever. So your team's bandits is always evolving as projects change and team members leave or join the ranks. So this is another challenge, right? Because, you know, team members are leaving and joining in the middle of this print and also that definitely impacts it.So plus, you need to rely on people's honesty about the current again. The same thing as I told a work may take more a work may take less. So that is also restriction all of that making a challenging to get a firm grasp on just how much capacity your team has available to tackle new work and request, particularly if you have a team full of high achievers always believed that they can takemore. Okay, the more often you have, you talked your team about their most three teams to it weekly, the easier it will get for you to be realist. So as an venue work with a certain team. You know, maybe in the first print your capacity may not be a perfect, but as and when you work on a multiple sprints, you know, like erafter first a Ken than third and consecutive sprint. Then you get the more better grasp on how much each person's capacities is. And if you were, you know, if you are committing more than that, also can district or if you are committing less than also that also you can increase it, so we will get a more realistic idea. Changes will throw you off track. They're gonna risk associated with them.The project and enforcement circumstances, from sense in seasonality to industry changes, will throw wrenches senior plans when you need to try to account for all these potentials. At best, capacity planning isn't always so straight forward. Planning in a cushion, even if it's just an extra day or two, will help you roll with the punches without things running of Paris. So again, this is something it it is likeeven if you are planning, there may be some hindrances, but you know it's much better to go with capacity than without capacity. Then it is like completely chaos, andthere is no planning and all if you're doing any, you know, starting or sprint without the capacity, so you will have to engage in some hard conversations again. This is a part of capacity and a tapestry. Planning is only useful if you though something with the information you identify that can involve turning down projects due to lack of bandwidth, adjusting a reducing expectations, pushing out deadlines. It's always better to say no than too serious and not to deliver. So this is the most inPorton part, you know. So capacity planning is for this reason only that you know what you are committing. You should be able to deliver. And if you you are saying like you are able to predict that, Okay, if this much of a commitment I'm giving, I will not be able to deliver than it's better to mention that beforehand rather than taking that one and then not delivering. So that's the main", 'start_time': '00:14:45', 'end_time': '00:23:50'}, {'Topic': 'Capacity Planning Best Practices', 'transcript': "purpose of the president planning the next is capital planning. Best Praxis is so some of the tapestry planning West practises are sorry. So learn from past projects. Okay, so this is the main our thing, you know, and a capacity in the first sprint that Udo will never be perfect. It will be a kind of Okay,we are just trying to see. But as and when the A growth, the capacity planning for the future strengths on the next prince will definitely be better and will have a better idea about the amount of work which we should take and will be able to complete. Have honest conversations with Team OK song in here. The you know, transparency is very important, though Scram, Master and theA team member should be completely true with each other so that the another's come. Master understands the limitations of the developer of the tester and also the developer, and the tester truly identifies water. The actual bar covers that he or she is putting, which will again, you know, help us in doing a good capacity.", 'start_time': '00:23:50', 'end_time': '00:24:56'}, {'Topic': 'Roadmapping Overview', 'transcript': "so I think we are five minutes more. So can we moved to the road map. okay? So now moving ahead with the road maps of what is roadmap? Okay, so road mapping, Jill A software. Our team level roadmaps useful for planning large basis of work several months in advance. A terrific level within a single project. Simple planning and dependency management features help your team's visualise and manage work better. So what is exactly a roadmap is nothing but a planning feature in bet. You know, you canput in all the epics and under native storeys, and you can see the complete picture of like, for example, in which sprint you will be able to complete what feature Sova. Normally, you know the identify features okay, will do this by this April end will do this feature by maybe June will do this feature so fnothing will be clearly visible. If we are using a Roadmaster of Witch spring, we will be able to complete feature one will sprint will be able to complete feature too. So this was kind of a projection. So how does it look into looks like this? Okay, so here you can see, I just", 'start_time': '00:32:45', 'end_time': '00:33:59'}, {'Topic': 'Roadmap Creation', 'transcript': "So here you can see a all the storeys that the left side are the epics. It is showing the epics. And these are the things the storeys that you will be able to complete stating the months you residency, the months in which month border the things that we can complete, right?so maybe this epic will be able to complete in the month of December. The second epic will be able to again complete in December the cross team effort epic they will be completing by November. So this other projections that have been made right and the the strike type of things will also be explaining this is kind of dependence is that's right slinking here.so far, the key concepts of ethics. Okay, so for I'm in for creating a road map, things that you need to know at the Buddhism and epic is a large body of us that can be broken down into individual tasks required to ship of feature. The world probe becomes a child issue of the epic. Sometimes owner spending epics are displayed as collard bus onthe road map. As I showed you, it was so of epics Are you know again? As I said, like a feature, you there is a feature. Okay, So if that feature is a small feature, if it is a big feature than again, features will be broken down. But if it is a small features that you can't convert into an epic,so just you will create an epic, and underneath it you will again create storeys of that in order to achieve that feature, what other things you need to what other steps you need to do border the storeys that need to be turning out to create that feature in order to complete that feature. So that is epics. So as again, as I said to you, So these are the epics, this whatever icon you are saying in the left, those are epic aiglons.and these are, though, things depicted in coloured bars. what is a child issue again? As I said, under need the epic the create storeys. So the storeys are nothing but child issues. Child issues can be created directly from the road map and administered within the epic the belonged So the storeys that will create under the epic an honest child issues the most common childish you a storeys, tasks and bugs. Okay, but you can create new issue types to represent different type of work for your team's quickly move issues to other tipping and reorder issues or epics by dragging and dropping themdirectly from your road map. So this is kind of saying how you are able to do that. Okay, so you can see the screenshot here. So this is a bug. So under name this epic, which is group booking experience. So they are trying to create a bag or a storey or a tusk. Okay,next to start and dude is the length of the bar on the road map for alleged at the start and due date set for Europe. Pick setting dates for your epic helps to communicate plans with the team and provide visual visibility to external stakeholders. Informed dependence in mapping and helped the resource management. So yeah, so start and doodles are very important. In order to project when you will be able to complete the feature or the epic,you're starting a due date of each of the storeys or child into issues matter, you know, so that you are able to understand. OK, completely a get this epic we will be able to complete in the stand this epic. This temps of this feature will be done by this time Fring.So this is depicting being depicted here. As you can see, the the the the thing that the Yeah. So So far epic when you are putting her start date and the due date So that is kind of you know, high level but in a storey is you know, when you are taking up storeys we normally understand that this storey will be completing in this print trade even if it's a storey you were expectingto take two days. Okay, But out of everything it mill maximum taker, Another buffer two days you will complete by four days. Right? So definitely by the end of the sprint you will complete that storey, right? So when you were giving the start date and ended to the storeys, that is a definite dates night. Almost definite it there is a major.Bata How If you are talking about projection of the epic skirt things then you can say a air kind of predicting When's once all the bodies the end it here is when all the storeys within the epic will end Right That date we will give us the end. Eh?We are assigning like okay in desperate will do this in district will do this And once all the storeys of this under Newt this epic whatever storeys are there will complete that sprint ended will put us the duty for the fix", 'start_time': '00:34:01', 'end_time': '00:39:21'}, {'Topic': 'Roadmap Features', 'transcript': "it while doing the activity from THING is also the part of They are completely a part of this because of they are the ones who will you know, who will be actually doing the work. Right? So they at the ones who will say Okay, Veil late leaders will need four days to definitely they their input matters a lot.Okay, so then there is philtres and view settings with again. These are some of the features of roadmap Yadira software roadmap has built in philtres that make waving and managing work simple. Find and refine your road member searching for key words and filled of a Sinus status labelled issue at just view settings or your road map to cheque.What is displaced. Add or remove dependency in progress. Views and filtered expressed doubled to specific time. Frame on the fly is a leave you a road map. Bye weeks months of it Sasuke Zara features that we can use for the road maps, abilities and view setting feature is that then there is the dependency So what is dependency is like you know one storey you will be able to startThere are some times this situation's right In other storey the you will be able to start when you have completed the storey again there will be like a storey See you can be able to start menu of computers the storey So these kind of dependence is of these things These are dependencies and the dependencies were also one kind of You can sit blockers right, Unless and until you complete Storey eh? You cannot start storey pright. So this can be, you know, Mom, this can be shown in the road map dependency Management is critical for teams. When dependence is our visualised and well mapped, a team can adapt and plan for alternative parts. Indira Software You can easily show the relationship between epics by mapping dependence is directly from the road.So this is the way. As I told you, these things show that dependencies. Okay, So for example, once this is done, you can be able to do this. Okay? Say it's mentioned, Bill. Cheque out Experience blocks this. So you have to do this epic bill cheque out experience first, and then only you can be able to do the improve U M U S lite score.", 'start_time': '00:39:21', 'end_time': '00:41:34'}, {'Topic': 'Dependency Management', 'transcript': "this on owners at the dependency. Right? This one more question, monolith A Is there a way of I can see side by side house. My actual work is going on. Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back? This is a plan. And the kind of things can I say that this is a plan the way ofyeah, you You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.I understand. But bear, can I Is there a way of being the actual that being in claim are going with the plan or not? If we look at the very first effect which is going to be completed by first week of April, the lower? Yes. So let's get extent in actual it gets extended by that same one month's end of April. How can I see thatwe are? Then you have to. Then you have to change the due date, right? Then it will show you have to change the due. Did that Okay. We are not able to achieve by this time frame we have extended it. Then it will again show you the actual do. Didthat time thing can? Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reportsat Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is is there a way of I can see what we estimated and what weactually you ST road map you can see Like, for example, you are saying that it is epically an audible to complete by the time we haveestimated the an audible to complete rate. So then again you have to bow and I manually changing, told the due date that we have right. Then you will be able to see the actual it. It's something you have to do it then only will be able to project. It is like not like it'll automatically change and show it, er themselves. It willnot tell me if I've changed to April then it will extend the time and the label. But it will not like show me that.earlier date was April for speak of April, but now it is invalid. Nikola recorded. No, no, no. It's not like the No, no, no, no. It won't be like that. It will show you whatever due date you have given It is like that that that sort of complexity is not there in road map. Right? So growth map is kind of you know, you can discuss this with", 'start_time': '00:41:35', 'end_time': '00:44:07'}, {'Topic': 'Roadmap Sharing and Exporting', 'transcript': "product on a bit. Your stakeholders, you not to show them, project them these things. So But if you're telling a could be initially projected this then I don't think that is not for example, this have didn't happen to me. But as far as I know that you will not be able to show it will show whatever you have given current do death.so again and other feature is sure and exports of whatever road matter of created, you will be able to share and export the road map. So sandy, a roadmap directly from Gina to from here a software by typing in news animal innocently copy to grab the roadmap, your export year old map and just the timeline views Star date and in dates before expecting it as an image. So this is like some of the features of road map.create a roadmap injera software. So one of the steps to create a roadmap, Najera software creator, knew Gina Software Project or go to an existing project and then navigate to the side bag and click roadmap. Okay, not if they're not showing saying your roadmap have enabled the road map in the board setting. So again there's a Y.And here, if you are not able to see the roadmap tap than definitely in the board sitting, you need to go and enable it. So people who are comfortable Najera will be understanding what I'm talking about. But if people who are not having hand from Nigeria, they may find it difficult in reading this and understanding that.Then click plus create a pick on the road map to create a picks directly on your road map. If he roadmap is empty, simply start typing to create right name, year epic and hit Enter. You can double click into epics at any time from your road map to add information such a start and ended assigning attachment and more at child issues to European from the road map by clickingnext to the epic name. Okay, select the type of childish uses in the drop down on the named Asia and of the covered it right in a single single points. Few tips for or Mac creation visualise dependence is between epics by creating or removing dependence ceilings directly on Iroda. So this thing for this thing, you actually need to work with the team, right?The team will be able to help you, guy do and understand and of took Lego, the product owner as well as the team. Both will be able to guide do help you in understanding what other dependencies and how to create the road map and how to mention the dependencies. Right? So that's why", 'start_time': '00:44:07', 'end_time': '00:46:40'}, {'Topic': 'Final Thoughts and Q&A', 'transcript': "So that's all from my side. Any other questions here? for any in any questions still. anyone. any questions on this, so I will be sharing, I think. I think for 100 shared this. topic with you If you don't have this p pity than definitely this slide show for a financial she's shared with you both the capacity as well as this. Soa roadmap ting So far handed, we share with the people who have joined here. not are not can go ahead and share this but Ariel so that people can go through it and the in future, if they have anything, they can get back to me. Hand indefinitely, discussso intense, guys. Any other questions? Thank you. Thanks times a lot. of frustration. And I including the feedback An assessment form with the recording on, please. Thank you.Thank you.", 'start_time': '00:48:53', 'end_time': '00:50:23'}], 'session_id': [ObjectId('642ac4d6bfc7d53094289803')], 'assessment': ObjectId('66f45b19c248cb8c52154139'), 'job_name': 'my-transcription-job8165db88-4ccb-432f-b35d-68cdc84960f4', 'keywords': ['Resource Allocation', 'Work Hours', 'Slideshow', 'Team Communication', 'Najera Software', 'Team Management', 'Roadmap Software', 'Story Pointing', 'Capacity Planning', 'Roadmap Creation', 'Epics', 'Feedback', 'Estimation Methods', 'Child Issues', 'Bandwidth', 'Jira', 'Workload Assignment', 'Q&A', 'Roadmap', 'Dependency Management', 'Technical Issues', 'Scrum', 'Remaining Capacity', 'Capacity Utilization', 'Visibility', 'Resources', 'Scrum Team', 'Task Visualization', 'Work Efficiency', 'Project Planning', 'Team Availability'], 'topic': 'Project Management and Resource Allocation', 'interaction': [{'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How did you come to this cream? The app that', 'timestamp': '[0:28:08]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Can you go back to the queen like the Yeah. So what does this mean, Ours? Out of expected 38 hours.', 'timestamp': '[0:31:46]'}, {'status': 'answered', 'answer': 'You are creating a road map and then you are creating all this dependence. You are giving everything that you know so that you can see the overall planning. You know it will help you in planning red.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'Is there a way of I can see side by side how my actual work is going on? Is it mapping the road map that I have planned, or is it getting? Thing is being extended? Where can I see back?', 'timestamp': '[0:41:40]'}, {'status': 'answered', 'answer': "You can see the actual due date by manually changing it in the roadmap. It won't automatically show the earlier projected date, but it will display whatever due date you have given currently.", 'completeness': 'Complete answer, all aspects of the question addressed.', 'relevancy': '2', 'question': "Is there a way of what I've planned earlier and halted actual right now, Is there a way of England? Reports at Silly Gandhi estimated it was supposed to be completed by April. But United is going to be extended till end of April. Is there a way of I can see what we estimated and what we", 'timestamp': '[0:42:49]'}], 'summary': "The session focuses on two main topics: capacity planning and the Jira roadmap. Capacity planning is defined as the process of determining necessary work hours for projects to assess team demands, emphasizing task coordination and realistic work allocation to minimize risks and achieve project goals. It involves evaluating team members' available hours, considering task complexity, and using estimation methods like story pointing with techniques such as the Fibonacci series and T-shirt sizing for task assessment. The speaker discusses using templates to track work hours, noting the importance of recording team availability and calculating effective work hours. Capacity utilization is addressed, focusing on assessing available capacity and workload assignment, with examples illustrating the calculation of remaining capacity for team members.\n\nThe discussion also covers challenges in capacity planning, including the need for accurate data and tools like Excel, as well as the importance of honest communication about team capacity. Best practices emphasize learning from past projects and maintaining transparency between Scrum Masters and developers. The concept of road mapping in software development is introduced, highlighting its role in planning extensive work, visualizing project timelines, and managing dependencies among tasks. The process of creating a roadmap involves managing epics and child issues, setting start and due dates, and visualizing progress. The speaker discusses the significance of dependency management and tracking progress against the roadmap, including the need for manual updates to reflect changes in project timelines. The session concludes with an overview of creating and exporting roadmaps using the software 'Najera' and an invitation for further questions and engagement."}
{'_id': ObjectId('66b26b81b80f3f3035517fa3'), 'file_id': ObjectId('648ae8992d791f6f8779c9bd'), 'file_name': 'Long video__1686825110-5efad25b42832eeca41d0e78.mp4', 'file_type': 'Video', 'file_path': 'course-resources/Long video__1686825110-5efad25b42832eeca41d0e78.mp4', 'runtime': '01:28:17', 'transcription_path': 'video-results/out_66b26b81b80f3f3035517fa3.json', 'file_add_date': datetime.datetime(2024, 8, 6, 23, 59, 21, 434000), 'file_process_date': datetime.datetime(2024, 10, 3, 15, 38, 56, 741000), 'execution_time': 1043.21271, 'status': 'COMPLETED', 'green_line': [{'topic': 'Technical Setup', 'start_time': '00:00:23', 'end_time': '00:00:56', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'keywords': ['Technical Setup', 'Screen Sharing', 'Preparation'], 'summary': 'The conversation revolves around a technical setup, where one participant asks another to share their screen. There is a brief exchange of confirmations and clarity regarding the setup process, indicating that they are preparing to proceed with the session.'}, {'topic': 'Introduction to Convolutional Neural Networks', 'start_time': '00:01:23', 'end_time': '00:03:42', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,", 'keywords': ['Convolutional Neural Networks', 'Image Analysis', 'Deep Learning'], 'summary': "The session begins with an introduction to convolutional neural networks (CNNs), highlighting their relevance in image analysis through deep learning. The speaker introduces a colleague who has significant experience in this area, particularly mentioning a project involving an app that analyzes images of a user's fridge to identify ingredients and suggest recipes. This project exemplifies the application of CNNs in real-world scenarios."}, {'topic': 'Applications of CNNs', 'start_time': '00:03:42', 'end_time': '00:05:23', 'transcript': "you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's and", 'keywords': ['CNN', 'Natural Language Processing', 'Speech Data'], 'summary': 'The transcript discusses the diverse applications of convolutional neural networks (CNNs) beyond image analysis, highlighting their effectiveness in areas such as insect detection, disease detection in plants, and natural language processing (NLP). The speaker emphasizes that while CNNs are commonly associated with image data, they can also significantly contribute to speech data analysis and NLP tasks. The session aims to clarify the motivations for using CNNs over simpler networks and to provide historical context on the advancements made in this field.'}, {'topic': 'CNN Architecture Overview', 'start_time': '00:05:24', 'end_time': '00:06:49', 'transcript': 'Then we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,', 'keywords': ['CNN Architecture', 'Backpropagation', 'Multi-layer Perceptron'], 'summary': 'The transcript outlines an overview of CNN architecture, highlighting the fundamental building blocks and various layers encountered in convolutional neural networks. The speaker discusses backpropagation in CNNs and mentions previous familiarity with shallow neural networks. Additionally, there is a focus on common CNN architectures and methods to regularize and enhance their performance. The example provided involves processing black and white images of digits (0-9) sized 28x28 pixels, illustrating how a simple multi-layer perceptron (MLP) can be applied to flatten the images into a 784-dimensional vector for classification, achieving high accuracy rates.'}, {'topic': 'Model Performance and Generalization', 'start_time': '00:06:49', 'end_time': '00:09:52', 'transcript': "So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?", 'keywords': ['Model Performance', 'Generalization', 'Spatial Invariance'], 'summary': "The transcript discusses model performance and generalization in the context of neural networks, particularly focusing on the challenges posed by slight alterations in input images. The speaker describes a scenario where the model is trained on images of digits, and after making minor adjustments to the images' size and position, the model's predictions become significantly inaccurate. This highlights the lack of robustness in the model's performance when faced with variations such as translation and rotation. The speaker emphasizes the need for models to possess some degree of spatial invariance to maintain performance across these variations, prompting the audience to consider potential architectural solutions to address this issue."}, {'topic': 'Image Processing Challenges', 'start_time': '00:09:52', 'end_time': '00:12:27', 'transcript': "Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.", 'keywords': ['Image Processing', 'Spatial Information', 'Convolutional Neural Networks'], 'summary': "The transcript discusses the challenges in image processing, particularly the loss of spatial information when images are flattened. It references historical research conducted by Hubel and Wiesel in the 1950s, where they studied a cat's brain responses to visual stimuli while measuring electrical impulses. The findings revealed that certain neurons in the cat's brain are activated by edges of varying orientations and movements. The discussion highlights the importance of maintaining spatial invariance in image processing and suggests the need for a hierarchical model to preserve this information without flattening the images."}, {'topic': 'Historical Context of CNNs', 'start_time': '00:12:29', 'end_time': '00:13:36', 'transcript': "Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'keywords': ['CNN', 'LeNet-5', 'Character Recognition'], 'summary': 'The transcript discusses the historical context of convolutional neural networks (CNNs), beginning with experiments that laid the groundwork for future research over the next two decades. It highlights the work of scientist Fukushima in 1986, who developed the neo-cabinet architecture for digit recognition, which was considered state-of-the-art at the time but limited by computational constraints. The narrative continues into the 1990s, noting the creation of the first successful CNN, known as LeNet-5, which demonstrated effective character recognition without significant errors. The speaker indicates that further discussion will focus on this architecture.'}, {'topic': 'Practical Applications of CNNs', 'start_time': '00:13:37', 'end_time': '00:16:06', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.", 'keywords': ['CNN', 'Spatial Invariance', 'Multi-Layer Perceptron'], 'summary': "The speaker discusses practical applications of convolutional neural networks (CNNs), focusing on how to enhance the robustness of neural networks to spatial invariance. They present a scenario where a modified neural network, referred to as a zero detector, is utilized to identify the presence of the digit zero in images. The process involves taking small segments of the image, flattening them, and inputting them into a multi-layer perceptron (MLP) that outputs a probability distribution indicating whether a zero is detected. The speaker emphasizes the importance of scanning the entire image for high outputs from the model, signaling the detection of the digit, thereby showcasing the method's effectiveness in achieving spatial robustness."}, {'topic': 'Hyperparameters in CNNs', 'start_time': '00:16:06', 'end_time': '00:18:57', 'transcript': "In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. Soone question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uh", 'keywords': ['Hyperparameters', 'CNN', 'Digit Detection'], 'summary': 'The transcript discusses the concept of hyperparameters in convolutional neural networks (CNNs), particularly focusing on the identification of digits through scanning techniques. It explains how probabilities are utilized to determine the presence of specific digits, using a maximum value approach to confirm detection. The speaker emphasizes the need for additional features to refine the detection process, suggesting that rather than analyzing entire digits, smaller parts or features can be examined. This hierarchical approach aims to enhance accuracy by considering overlapping features and adjusting the scanning box size. The discussion also prompts further questioning regarding the scanning method and the implications of shifting the scanning window.'}, {'topic': 'Feature Extraction and Hierarchical Learning', 'start_time': '00:18:58', 'end_time': '00:22:18', 'transcript': "uh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the questionwho asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.", 'keywords': ['Feature Extraction', 'Hierarchical Learning', 'Multi-layer Perceptron'], 'summary': 'The transcript discusses the concept of feature extraction and hierarchical learning within the context of multi-layer perceptrons (MLPs). It explains how MLPs process small sets of pixels in an image, building upon features from previous layers to eventually lead to classification. A key aspect highlighted is weight sharing, where the same weights are used across different layers to reduce the total number of parameters. The speaker emphasizes that each layer computes a weighted sum of inputs followed by a non-linearity, which is fundamental in the scanning approach. The discussion also illustrates the construction of a hierarchy of features, with simpler features being combined to form more complex representations.'}, {'topic': 'Weight Sharing and Parameter Reduction', 'start_time': '00:22:19', 'end_time': '00:24:35', 'transcript': "Okay, so you just, uh, scan. So these are the hair are different. New MLPs here. So this this MLP has, uh, one set of age. This is a new MLP. Here we are, scanning through it, okay. And then we have the final classification will happen. And so now we have sequentially added layers in one direction. We could also add, uh, complexity in the depth of it.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.right. And so, finally, you just can't get it. All of the features and you have a final classification.So this is how the idea of hair are key is taken into account from that horrible and visual experiment that we just build upon small features of the offer input and use those to classify, uh, actual image.Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regression", 'keywords': ['Weight Sharing', 'Parameter Reduction', 'Hyperparameters'], 'summary': 'The transcript discusses the concept of weight sharing and parameter reduction in the context of multilayer perceptrons (MLPs). It explains how different MLPs can be utilized to detect various features in an image, elaborating on the sequential addition of layers and the potential for increasing complexity through depth. The speaker illustrates the process of building upon features from the input to achieve final classification, likening it to a cube structure. Additionally, there is a discussion on hyperparameters, distinguishing them from model parameters, and defining their role in the architecture of MLPs.'}, {'topic': 'Advanced Concepts in CNNs', 'start_time': '00:24:36', 'end_time': '00:29:00', 'transcript': "where we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.", 'keywords': ['Hyperparameters', 'Filters', 'Feature Extraction'], 'summary': 'The discussion delves into advanced concepts of convolutional neural networks (CNNs), focusing on hyperparameters such as step size, the number of hidden nodes, and layers within multilayer perceptrons (MLPs). The speaker highlights the significance of filters in CNNs, explaining their role in feature extraction from input images. Various types of filters are mentioned, including those designed to detect horizontal, vertical, and curved lines. The transformation process is described, emphasizing how filters compress input images into compact representations. The speaker contrasts CNNs with MLPs, noting that while MLPs flatten entire images, CNNs operate on smaller segments defined by filter sizes, enabling efficient feature extraction without the need for weight adjustments. The session underscores the shared weights in CNNs as a means of identifying features consistently across different segments of the image.'}, {'topic': 'Convolution vs Cross-Correlation', 'start_time': '00:29:01', 'end_time': '00:31:01', 'transcript': "okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimensionis three. So it's a M by n by three or the image that is a colour image which has got the red, green and blue.channels. right. So one way of visualising this you've got an image of some size. You are reducing the size of the image by doing the scanningright. And with every feature that you're creating is like another channel. Right? So we went from RGB Channel to another description of the same data which has a smaller X and Y axis as such of the image. But it has a depth to it, which is the number of features that have been extracted. Right. And this is a very common feature that you will see when you book shows you the more complicated structures of a CNN.You'll find that you start off with a large image with three channels and you end up with very small images, but with lots of features, lots of channels with it.Right. So this is a very, very important thing to remember when you're doing CNN's, because later on, you will see some very interesting uses of the same philtre to reduce dimensionality.", 'keywords': ['Convolution', 'Feature Extraction', 'Dimensionality Reduction'], 'summary': 'The transcript discusses the concepts of convolution and cross-correlation, focusing on feature extraction from images. It explains how a set of features can be derived from a grayscale image and extends this understanding to color images, where the data is represented in three dimensions corresponding to the RGB channels. The speaker emphasizes the process of reducing image size during feature extraction and how this leads to images with fewer pixels but a greater number of extracted features, highlighting the complexity involved in convolutional neural networks (CNNs). This reduction in dimensionality and the transformation of image data into a higher number of channels is crucial for understanding CNN architectures.'}, {'topic': 'Pooling Techniques', 'start_time': '00:31:02', 'end_time': '00:34:46', 'transcript': "Okay, so do you understand all of these concepts? the shift size. you can see that the boxes are overlapping over each other, right? And so you can have a shiftof one pixel or two pixels or whatever. So that becomes a hyper parameter. Like you said, the philtre size definitely the size of the box, the number of philtres at each layer that you're definingright, and the number of such hidden layers that are transforming the input into a smaller, more compact representation.Right is another type of parameters. So very good. And what is the shift called? What is the technical term for shift?stride. Okay, great. Excellent. Okay. Good luck. Any questions on this before it goes on? Because things will only get more complex as we go on.Okay, Wonderful. Okay, So this is the example of, uh, typical Syrian architecture. This is called the Leonard five, which was developed by young liquid.Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresThen you will have six feature maps for each philtre because one feature because one philtre will scan the entire image.So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,", 'keywords': ['Pooling Techniques', 'Max Pooling', 'Feature Maps'], 'summary': 'The transcript discusses various pooling techniques in convolutional neural networks (CNNs), focusing on concepts such as stride, filter size, and hyperparameters. The speaker explains the significance of overlapping boxes in feature extraction and introduces the architecture of a CNN, specifically mentioning the LeNet-5 model. Key terms such as feature maps and subsampling are defined, with an emphasis on max pooling as a common subsampling technique. The speaker illustrates how max pooling reduces the dimensions of feature maps while retaining important features. The session concludes with a reminder that these foundational concepts will be built upon in subsequent discussions.'}, {'topic': 'Output Classification and Architecture', 'start_time': '00:34:47', 'end_time': '00:37:43', 'transcript': "okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.okay? Okay, So there was one thing I want to visualise here. Yeah, so? So this is a typical grayscale image. So this is the original image you can see here. And this is just a zoom in version, so you can see that every pixel has a value from 0 to 2. 56 to 55. Sorry.So you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,uh, let's take something near the so you can see here. Uh, the left, the left, and the first element in this, uh,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.", 'keywords': ['Feature Maps', 'Grayscale Image', 'Sharpening Filter'], 'summary': 'The transcript discusses the concept of feature maps in convolutional neural networks, specifically highlighting the third dimension associated with the six channels created during processing. It describes a volume with six depths, 28 in time, and 20 in height. The speaker visualizes a typical grayscale image, explaining how pixel values range from 0 to 255, with examples illustrating the values for white and black pixels. The focus then shifts to a three-by-three sharpening filter, detailing the process of element-wise multiplication between the filter and a corresponding matrix, resulting in a single output value from the operation. This example emphasizes the mechanics of image processing within CNN architectures.'}, {'topic': 'Normalization and Its Importance', 'start_time': '00:37:45', 'end_time': '00:39:45', 'transcript': "uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.So, uh, we've got an answer. Which is minus 157. Yes. Uh, be clipped to zero. It will be close to zero.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.", 'keywords': ['Normalization', 'Filters', 'Feature Maps'], 'summary': 'The transcript discusses the process of normalization in image processing, focusing on the application of filters to pixel values. It highlights the importance of padding images with a black border to handle edge cases and prevent loss of data. The speaker explains various types of filters, such as sharp and blur filters, and how they create different feature maps. Specific filters like the Sobel filter for edge detection are mentioned, with variations for different orientations, illustrating the significance of filters in image analysis.'}, {'topic': 'Learning Filters in CNNs', 'start_time': '00:39:45', 'end_time': '00:44:43', 'transcript': "Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.Okay, so there is another example of this image. So this is the original image. Okay, Now, if I apply, sharpen, uh around it, you can see it's got a bit sharp.And if you you stop symbol on it, it detects, uh, like horizontal edges. If I apply right Sobel, it detects vertical edges so on and so forth.is this clear? Yes, sir. Okay. so these weights are okay, So, uh, which no one is asking a question here. Uh, how? Well, normalising the pixel values affect the neural network.Um, so we should make sure you don't send it privately because those questions come to me, Uh, is not able to see it, but I've explained this, right? So when you talk about normalising the pixel values, what are you referring to? What you're talking about theapplication of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.", 'keywords': ['Filters', 'Normalization', 'Feature Extraction'], 'summary': "The transcript discusses the concept of learning filters in convolutional neural networks (CNNs) and how these filters affect image processing. The speaker first explains the visual representation of different filters, such as sharpen and Sobel filters, which detect edges in images. They then address the importance of normalizing pixel values, explaining how it impacts the neural network's performance and the minimization of the cost function. Normalization helps create a more uniform input scale, facilitating the learning process. The conversation further explores the distinction between handcrafted filters and those learned by the neural network, emphasizing that the network can automatically learn useful features from the data that may not be easily interpretable by humans. This ability to learn an infinite number of filters allows CNNs to effectively extract relevant information from images."}, {'topic': 'Backpropagation in CNNs', 'start_time': '00:44:44', 'end_time': '00:47:57', 'transcript': "that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.Uh, so let's say for, uh, I'll take an example of this portion of this image. I'm just, uh, mathematically describing what we have just discussed. Okay,so here we are going from minus Kate. Okay, for let's say, let's say this philtre will have zero in the centre zeroth index.instead of beginning from any side, we begin from the centre. So this has, uh, zero comma zero. Uh, Index, this has, uh,minus one comma one. I could have minus one for my one. This is my new school, Uh this is minus one common minus one just to be clear.And this is, uh, one comma one. And this is one common minus one. So basically, we are saying that the loop power fromminus 1 to 1 in case of a three dimensional feature or philtre so for, Let's say. four g three or three. So Okay,the left corner will be minus 11. the corner with bottom, Yeah. mhm. uh, one here because we are going from, uh, which is, uh,so So, uh, this is the X one. And this is why? right. So, uh, but the other way around. Right. So why is pointing downwards?", 'keywords': ['Backpropagation', 'Convolution', 'Feature Extraction'], 'summary': 'The transcript discusses backpropagation in convolutional neural networks (CNNs), focusing on the identification of features within images, specifically distinguishing between digits such as zero, one, and two. The speaker elaborates on concepts like convolution and its mathematical representation, detailing the configuration of a filter used in image processing. They describe the positioning of indices within the filter and illustrate the process of feature extraction in a three-dimensional context, providing clarity on the relationship between the filter and the image being processed.'}, {'topic': 'CNN Architecture Details', 'start_time': '00:47:57', 'end_time': '00:50:48', 'transcript': "Yeah. So the coordinator, there will be a minus 11, left bottom. X is minus right the X coordinate ofminus one. uh this should be minus 11. okay, so Okay, So, uh, idea here is So let's say we have this original image, and we want to, uh, slide this fritter across this entire image. And I want to have an output G, which is my feature map. You could sayokay. So what I'm gonna do here is, um So starting with U N. Vehicle to minus one here in this submission,you equal to minus one and equal to minus one. So I will take the minus one minus 11 element of this, uh, this edge metrics, which is the A.Okay. And, uh, I plus Youth Index. So I am calculating for G three of three. So this is +0123 and again. 0123. So this is my G three comma three.Okay. So if I take, uh, take this philtre and, uh, make the cost cross correlation, I will have a single value, which will be substituted in the place of E here.Right. So what I'm looking here is that, uh, eyes here three and us minus one. And Jay is also three.This is the icon DJ and J minus one. So I'm looking at second element here. So for her 01 to zero. we want. So to buy second by second element is this so I'm multiplying, uh, small a from the philtre with this matrix A herewith a element of these, uh, metrics. and similarly, I'm just looping over. So being small capital B plus small capital C includes. So this way, this time calculating the, uh, waited waited some hereand this will be a single output, which will be replaced here in my future map. Uh, so let's see if I have this. This is my G output. So in place of E here, I will have one single value, which will be the output of this entire operation.", 'keywords': ['Feature Map', 'Cross-Correlation', 'Convolution'], 'summary': 'The transcript details the process of calculating a feature map in a convolutional neural network (CNN) by sliding a filter across an original image. The speaker explains the steps involved in this operation, including the use of specific coordinates and elements from the input matrix to compute the output values. They describe the cross-correlation process, illustrating how values from the filter interact with the image matrix to produce a single output value for the feature map. The explanation emphasizes the iterative nature of this calculation, where multiple values are computed and replaced in the resulting feature map.'}, {'topic': 'Feature Maps and Their Interpretations', 'start_time': '00:50:50', 'end_time': '00:53:53', 'transcript': "Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.", 'keywords': ['Feature Maps', 'Convolution', 'Cross-Correlation'], 'summary': 'The discussion focuses on the mathematical representation of feature maps in convolutional neural networks, particularly through the concepts of cross-correlation and convolution. The speaker explains how different filters, such as sharpen, blur, and edge detectors, are applied to an original image to generate feature maps. A detailed example illustrates how to calculate feature representations by taking a portion of the input image and performing dot products with filters, emphasizing the importance of flipping the filter during convolution calculations. Visual aids are used to clarify how the filters interact with image elements.'}, {'topic': 'Convolutional Operation Explained', 'start_time': '00:53:54', 'end_time': '00:55:17', 'transcript': "Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottomto the top. Okay. So because the future has rotated and just changing the sign here, uh, will assist in that happening, so", 'keywords': ['Convolution', 'Cross-Correlation', 'Backpropagation'], 'summary': 'The transcript discusses the concept of convolution in relation to cross-correlation, emphasizing that during the forward pass of a neural network, the operation performed is actually cross-correlation, not convolution. The speaker clarifies that this distinction is often misunderstood. They explain the mathematical process involved in both operations, detailing how the filter is applied in different directions for convolution and cross-correlation. The importance of recognizing this difference in operations is highlighted, particularly in the context of backpropagation.'}, {'topic': 'Implementation Insights for CNNs', 'start_time': '00:55:18', 'end_time': '00:58:20', 'transcript': "Okay, Uh, you can just explore this on your own later on. If you just try to write these expressions down and you will be able to figure out that we're just recreating the philtreand doing the cross correlation, okay? Okay, so So till now we discuss these handcrafted philtres like the blur sharpen, agitation, etcetera. But these are the things which the model learns as just described. So what we're gonna do is we're gonna visualise these features for the religion. It Okay, Uh, so let me first explain that how these, uhhow these architectures look like. Okay, so, uh, the input here is, uh, before we go into the architecture, can we just, uh, do a little bit of discussion around how the philtre size impact, the output image size, But is that coming after this?Yes. I was just trying to bring Troy. I don't have, uh Okay. Okay. So let's say religion yet We use colour images, so let's say it will be a three dimensional image.And let's say it is 2. 56 by 2. 56 with three channels of input. Okay, so now we want to, uh, involved used 32 philtres here.Okay of dimensions, Uh, three by three. Okay, So this is how you generally defining your chaos or you're open source, uh, libraries, but under the hood. Uh, what is happening is that each philtre will have dimensionsthree by three. And this three, the depth is coming from the input. because the input image has three channels as death. So you're each philtre will also have a depth of three. Okay, so what we do here is that we take small, uh,crop of size three by three hair from this bigger image. three by three by three And we just, uh, do an element wise multiplication of all these elements in this cubewith this philtre. Okay, So if there are, let's say, uh, three numbers here and three numbers in the first, uh, slice. Then you just, uh, do the cross correlation, and there would be one output.Okay. And you do same for all the layers. So for second slice here also, okay, and output of this result would be single number.", 'keywords': ['Convolution', 'Filters', 'Cross-Correlation'], 'summary': 'The transcript delves into the implementation insights for convolutional neural networks (CNNs), highlighting the process of recreating filters and performing cross-correlation. The speaker discusses handcrafted filters such as blur and sharpen, explaining that these filters are learned by the model. They also touch on the architecture of CNNs, describing the input as a three-dimensional color image of size 256x256 with three channels. The conversation includes the use of 32 filters of size 3x3, emphasizing the importance of filter size in relation to the output image size. The process involves taking a small 3x3 crop from the larger image and performing element-wise multiplication with the filter, ultimately producing an output for each layer.'}, {'topic': 'Stride and Padding in CNNs', 'start_time': '00:58:21', 'end_time': '01:01:30', 'transcript': "this is very important to note. Okay, so after conclusion where there will be one value here. So you do this for across entire this image. So you have access right of one.so let's let's leave it to them to come up with the answer. Okay, So with the stride of one pixel means that you're shifting by one pixel to the right all the way till you get to the end of the image, right? So recognise that you get to the end of the image when the right side of your philtre reaches the edge. Okay, so there's no paddingfor those of you know what padding is. There's no padding. For those of you who don't know about padding, just don't worry about it. Just tell us what is going to be the size of the image that comes out on the other side when we do the scanning. Now the stride works left to rightand talk to bottom. right. So as you scan across, you're going one pixel at a time and going to the next position where the philtre is applied. And then when you get to the end, you shift the philtre down by one,uh, pixel and apply it again. Correct? Yes, sir. Okay. So what is going to be the size of the image that is coming out on the other end? Or the the two dimensional array that's coming out at the end? Because remember what is sayingthat the three by three by three is producing only one number, so the multilayered Perceptron is taking27 inputs and is out putting one value. Okay, So what you're getting as a result of applying this philtre is a two dimensionalmatrix of numbers, and I want to know the dimensionality of that. 54. other ways, okay? there were two people speaking. So one person said to 54.And what was the other person saying? I think, uh, zero comma zero is concerned at the centre, and, uh, the other things are taken at that size in the same way you look at work,right? So, like I said, the we are resuming zero padding go padding right now. Right? So your philtre starts from the edge and takes the first three into account.right, and then it moves by one and moves by one. Right? So the size is going to be there. One answer that's been given us 254.Is that the number of rows or the number of columns, or what is to 54? I think both. Okay, Anybody else have a different answer?", 'keywords': ['Stride', 'Padding', 'Convolutional Neural Networks'], 'summary': 'The transcript discusses the concepts of stride and padding in convolutional neural networks (CNNs). It emphasizes the importance of stride, explaining that a stride of one pixel means shifting the filter one pixel to the right until the end of the image is reached. The speaker clarifies that there is no padding involved in this example and invites the audience to determine the size of the resulting image after scanning. The process of applying the filter is described, highlighting that it generates a two-dimensional matrix of numbers. The conversation includes audience participation, with questions about the output dimensions and the specifics of the filter application.'}, {'topic': 'Parameter Counts in CNNs', 'start_time': '01:01:31', 'end_time': '01:03:57', 'transcript': "no sort of 54 and 54 in total Tito. in 2. 32. Okay, 32 because we've got 32 philtres. Good. Okay. I have been looking for one philtre with Excellent. Okay, so 254 by 2. 50 for 5. 32 will be the third dimension.Uh, just for this philtre Yes, output will be just a matrix. Uh, considering for just one philtre, this is just one,Uh, that's correct that we will have 32 such philtres. So for each of that philtre, we will have one,to the output. Yes. Yes. And then that will build up to 30 to do that. Yeah. Perfect. Perfect. Okay, So what happens now if we make the stride?Ooh! Okay, so now let's make the strive to what becomes the output size now? Does the output size change?instead. How much does it change? Uh, third dimension in the same 1. 27 1 27 127. So how did you come up with 1. 27?sir. And if you take in putting measures in and the philtres. I just Yes. And we We are taking a straight to that isminus Yes. And we are adding one to the and mine the eff s blossom. Okay. Do you want to write the formula they're given? You've got access toYes, Uh, like the formula, which, uh Okay, can you please repeat and I say important measure that is 256 in 2016 and a filtered site.and at that stage. the farm law of the output. The message will be and minus f s plus one. listen. so that would be a 56 minus.", 'keywords': ['Filters', 'Stride', 'Output Size'], 'summary': 'The transcript focuses on the discussion surrounding parameter counts in convolutional neural networks (CNNs). It begins with a conversation about the number of filters, specifically mentioning 32 filters and their dimensions. The speaker explains how the output from a single filter results in a matrix and how multiple filters combine to form the overall output. They then delve into the impact of changing the stride on the output size, discussing calculations related to the output dimensions and the relevant formulas. The dialogue highlights the importance of understanding these parameters in CNNs.'}, {'topic': 'Advantages of CNNs', 'start_time': '01:03:59', 'end_time': '01:05:22', 'transcript': "three dots. Bye. HM. That doesn't seems correct. It's two less 127. So now you've got 253 divided by two, right?So what happens? We've got a decimal number there. So I have that too. From the looks. you will take in digital partnership.If we have fraction, then we protect right? so Yeah. So that is the same formula. Uh, only were riding fighting out here. Right? Fighting is zero w minus scale over this. That's whywhich is fine. And then what you're saying is we are taking the interior part. So are we rounding up or are we rounding down?so if there is greater than five, then we are all being up. but now it's point. What do we do? I think running, don't you?", 'keywords': ['Digital Processing', 'Rounding', 'Computational Aspects'], 'summary': 'The transcript appears to be a discussion that touches on mathematical principles related to digital processing and possibly the workings of convolutional neural networks (CNNs). The speaker navigates through calculations, mentioning fractions, rounding methods, and how to handle decimal numbers, indicating a focus on the computational aspects of CNNs and their advantages in handling data effectively. However, the conversation is somewhat fragmented and lacks a clear structure.'}, {'topic': 'Multi-layered Perceptron vs CNN', 'start_time': '01:05:23', 'end_time': '01:08:15', 'transcript': "Okay, so let's just take a small example of, uh, seven by seven image, right? and what is happening here when we are not doing a padding, So the first one is three by three.the philtre application. And then we're taking a stride of two, which means now we're starting from pixel, too.23. And, uh, so we're starting the numbering from zero. Right, So 0 to 6 is the pixel numbering. Okay,Right. And now we're doing a three by three. right. So the three by three the first philtre, then we're taking a stride of two.so we start from now 23 and four. And now we take another stride of two, which gives us now. four, five and six.right. So in this case, if we look at the formula, what's happening is N is seven minus three. great.stride is too so seven minus 3/2. which is three, right? So that's 4/2. That's 13, so we can see we have created three. Now the problem comes when we have an eight by eight image, right? And now we have an issue in that if we had another pixels in rows and columns.we basically not be able to do any further, right? So if we had an eight by eight image, if you can just draw that additional problem and go.Now, when we go for the stride of two, we are going over the edge, so we can't do anymore, right? So we are always looking at the number below, as the output were basically ignoring the that last follow. And that last room. Right? So we will always take the lower number out here.", 'keywords': ['Convolutional Filters', 'Stride', 'Image Processing'], 'summary': 'The speaker discusses the application of convolutional filters on a seven by seven image, explaining the process of applying a three by three filter with a stride of two. They illustrate how pixel numbering starts from zero and how this affects the output dimensions. The discussion highlights the calculations involved to determine the output size based on the image size, filter size, and stride. The speaker also addresses the complications that arise when processing an eight by eight image, noting that the stride can lead to going over the edge of the image and thus limits further processing. The emphasis is on understanding how padding and stride influence the output of convolution operations.'}, {'topic': 'Computational Complexity in CNNs', 'start_time': '01:08:17', 'end_time': '01:11:13', 'transcript': "right. okay? So now my question is, how many parameters does the neural network have just in this layer?So who's gonna tell me that now? How many parameters? Now we've got 32 philtres. We've got a three by three philtres,right? And an RGB image. How many parameters do we need to learn in this? one pair of lives. who's gonna tell us?930 two. Sorry. nine by 30 to 1930 to 19 to 19 to 32. Okay. Any other answers? 20 7 to 32. Okay. Any other answers?thanks. Nobody else wants to suggest the answer. 20 730 to 30 two. Correct. So the reason why it's 27 by 32 and not nine by 32 it would be nine by 32 if we had a.grayscale image, right? We didn't have the channel. So you must always remember that we have got a three dimensional Fridawhere the third dimensions depth is defined by the number of input channels to that live. Okay, good. Now, what would be the number of parameters that needs to be learned? If we were not using CNN,we were actually using a multilayered percent promise. that depends on the number of notes hidden next to them. Iwant the same number of notes as I have in the hidden layer in the CNN. So how many notes do I have in the hidden layer in the CNN?trick questions. mhm. 56. Close to 56. Crusty. That is my input layer. Right? So that's 2. 56 times 2, 56 times three.", 'keywords': ['Parameters', 'CNN', 'Image Channels'], 'summary': 'The transcript discusses the computation of parameters in a convolutional neural network (CNN) layer, particularly focusing on how to calculate the number of parameters needed for a specific layer with 32 filters and a 3x3 filter size applied to an RGB image. The speaker engages the audience in answering how many parameters are required, leading to a range of responses. The correct calculation is 27,730 parameters, which the speaker explains is based on the three-dimensional nature of the data, highlighting the importance of considering the number of input channels. Additionally, there is a comparison made with multilayer perceptrons (MLPs) in terms of the number of nodes in the hidden layer, with the speaker prompting the audience to think critically about the relationship between CNNs and MLPs.'}, {'topic': 'Feature Map Visualizations', 'start_time': '01:11:15', 'end_time': '01:13:50', 'transcript': "that's the input Lear sites. what it was before. Before 254 by 254. right. by 32 right, and how many parameters would we have to learn?uh, we have to do, like the four 130 two cross, uh, test is too extreme. right. So we're basically multiplying all of these, right? Because every note in the input layer must be connected to every note and the output.right, So it's 256 squared, multiplied by three. multiplied by 254 squared, multiplied by 32. right. which one is big?There's no argument, right? I mean, we are comparing a very large number of parameters here with just 27 multiplied by 32.right, and this is a huge advantage of CNN. It's the weird. sharing with sharing. That's happening. That is a hugely important aspect.Oh, CNN. Okay, so you appreciate that. And what have we talked about that as the number of parameters increases, what do we need to do? We need a lot more data to learn them.right. And so we are actually talking about unnecessarily learning a lot of weights. Whereas we know that really what we're looking for is a scan through theright. So hopefully this is clear to you that actually the CNN can be represented as a multi layer perceptron also. So the multi layer Perceptron can do the work of the CNN as we see it right now, but the number of parameters is going to be much larger.okay, and so it's much more difficult to learn the same representation comparative. Okay, so here's another question.Now we have a 54 by 2. 54 by 32. right, and we are again using. Now we are using a five by five philtres.", 'keywords': ['Feature Map', 'CNN', 'Parameters'], 'summary': 'The transcript discusses the complexities of feature map visualizations in convolutional neural networks (CNNs). It begins by highlighting the dimensions of input data and the considerable number of parameters required for learning, indicating the extensive connections between input and output nodes. The speaker compares the large number of parameters in CNNs to a much smaller number in traditional methods, emphasizing the advantages of parameter sharing in CNNs. They also note that as the number of parameters increases, more data is necessary for effective learning. The discussion further explains that CNNs can be represented as multilayer perceptrons, although with a significantly larger number of parameters, making them more challenging to learn. The importance of using filters in the CNN architecture is also briefly mentioned.'}, {'topic': 'Feature Activation and Classification Outputs', 'start_time': '01:13:52', 'end_time': '01:16:54', 'transcript': "So what is going to be the dimensions of the next left? 54 by 254. by 32. right. So now we're using a five by five philtre.how many such features, let's say 64. such tried stride of, mm. 124 into 1, 24 and 60 for the lesson.Mm. for 254. find us. five, divided by two plus one. so that's 249 divided by two. 1 24 +11 25 1 25 by 125 by 64.how many parameters. and what will be the shape of the philtre? you tell me. Uh, sorry. Was that good book?Uh, that's part of the number 64. 55 or 60. Uh, And so we got an answer here for the number of parameters, I think.Okay, 25 by 64. So he said it could be what we do here. pretty good. so one person's answer is 25 by 64.Don't you find it that you don't look beautiful? 25 and 32. That's right. Okay. And so they will be. Bias is also right. Yes.good point. Thank you for keeping us right there. So in the last one, also, we forgot about the biases thatso remember the bias stone is important, right? What does the bias give us gives us? It gives us a fine transformation.Right? So we must have that constant added and also so, plus 64 there and we've got the total number of parameters yet.", 'keywords': ['Feature Activation', 'Classification Outputs', 'CNN Parameters'], 'summary': 'The transcript discusses the dimensions and parameters involved in feature activation and classification outputs in a convolutional neural network (CNN). It begins by determining the dimensions of a certain layer, specifying a 5x5 filter applied to a feature map. The conversation includes calculations for the number of features, strides, and the resulting dimensions, leading to discussions about the total number of parameters and the importance of biases in the model. The speaker emphasizes the role of biases in achieving fine transformations in the network.'}, {'topic': 'Classifying Images and Final Thoughts', 'start_time': '01:16:56', 'end_time': '01:28:14', 'transcript': "Okay, Good. Excellent. Okay. Uh, let's, uh, move on. I think hopefully everybody's got anybody. Got a question here? I know there are a few of you who have dealt with CNN's and done some deep learning. That does not mean that people who are not understanding this can't ask questions.Okay, So for those of you who are new to this, this is very, very important that you understand this. Okay, here's another. Okay, Let's go. There is another question I want to ask you, okay?which is the number of computations you're doing. so floating point operations, floating point operations do you need to do here? But I believe that as an exercise for you, let's carry on.okay? Okay, So next, uh, was trying to visualise these features. So? So what we have here is so he worked with it was that we took an RGB image.and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'keywords': ['CNN', 'Feature Maps', 'Image Classification'], 'summary': 'The session covers the classification of images using convolutional neural networks (CNNs), emphasizing the importance of understanding the computations involved, specifically floating point operations. The speaker discusses visualizing features extracted from RGB images through CNN architectures, detailing the process of applying filters to create feature maps. They explain how various layers of the CNN progressively extract more abstract features, highlighting specific examples from the architecture, such as VGG, and illustrating how different filters respond to various aspects of the input images. The lecture concludes with a summary of the activation of features for classification, distinguishing between different image categories, such as houses and human faces, and invites any final questions before ending the session.'}], 'yellow_line': [{'Topic': 'Technical Setup', 'transcript': 'Can you try and share your screen? Yes, sir. is it? okay? So we just give a couple of months joint? Sure, so?', 'start_time': '00:00:23', 'end_time': '00:00:56'}, {'Topic': 'Introduction to Convolutional Neural Networks', 'transcript': "mhm. folks. We're going to start with convolutional neural networks today as promised and as a special treat, we've got a colleague of mine here with meand, uh, has done a lot of work. in, uh, image analysis, using deep learning algorithms and, uh, primarily be teaching you, uh, the CNN part. I'll be here, too.To assist were required. Um, barbeque has built. Like I said, a number of projects using vision, um, and deep learning. Specifically, he worked on the project for a client based out of California.where he built, uh, the components of an app where you can open up the fridge and take a photograph of your fridge. And the image analysis that had developed would identify all the ingredients in your fridge And, uh, you know, other, uh, cupboards in your kitchen, Um, and then start recommending recipes that you could of food that you could focus. Okay, so, um,", 'start_time': '00:01:23', 'end_time': '00:03:42'}, {'Topic': 'Applications of CNNs', 'transcript': "you know, these are the kinds of things that you would, uh, of course, other than that there are all sorts of other applications looking at insects detection, disease detection and in, uh, in plants. He's also done a few projects in natural language processing. And while, uh, convolutional neural networks, people always think of them as being useful in image analysis.Um, what I hope during this course, you will realise, is that it's not just images, but it's also, um, uh, you know, speech data and natural language processing, where CNN's can add value. So typically people think of CNN's for image and then ordinance foror recurrent neural networks for, um, you know, speech and and, uh, LP problems. But actually, CNN's are just as effective or, you know, have applications and architecture that have been based around CNN's for applications in speech as well as in, uh, NLP. So I'll, uh, pass it on to you, and you can start the lecture.sure. So thank you. Okay, so so the agenda for today's, uh so that we will be talking about the motivations for CNN like by just simple. Little networks won't do it on images or several other kinds of data. So why do we need CNN? First, we'll discuss that and then some history regarding what work has been done regarding CNN's and", 'start_time': '00:03:42', 'end_time': '00:05:23'}, {'Topic': 'CNN Architecture Overview', 'transcript': 'Then we will see the basic building blocks and different layers which people have came across. Uh, and we will then discuss the back propagation CNN as, uh, you must have done in a mist, uh, using the, uh, shallow neural. Introducing the mystery does it.And then we will finally discuss, uh, some common architecture. Is CNN architectures and some way to regularise them or improve their performance.Okay, so, uh, I believe that you are very familiar with Mr Asset, so it basically consists, uh, black and white images, which are 28 by 2018 size. So And they have one digit from 0 to 9 representing in that image.So basically, a simple MLP for, uh would require you to flatten this image. So you flatten it out into a 287, 84 dimensional victor one by 74uh, Dimension vector. And you just fit a simple multi layer perceptron into it and classify each input into one of the 10 classes.So this is the typical, uh, workflow for amnesty, and we are easily able to achieve 95 maybe 98% accuracy on the state of using very simple Uh, okay,', 'start_time': '00:05:24', 'end_time': '00:06:49'}, {'Topic': 'Model Performance and Generalization', 'transcript': "So a typical output for for the last level look something like this. So this is a 10 dimensions input output. So this is the zero index, and this is the ninth index. So, uh, each the index. Basically, it tells you what is the budget on this image. So for this in 49 you can see the ninth, uh, value in this output. Uh, this is basically a probability distribution.So the ninth area has the ninth value. Sorry. The 10th value, The last value has the value of 0.99. So the model is very confident that this image contains the ninth.Similarly, for three, you can see the third index has, uh, like a perfect one probability for being three. And similarly, for two, you have this. So what I did was simply I just, uh,changed the input to the, uh, neural network, which was trained on this administrator. So I just shrink the images slightly and, uh, changed the position where the budgets were so earlier. It was just sent in central incentive, but now I am putting these digits on the sideways, and they are slightly smaller than earlier So what happened immediately was that the predictions were very messed up.So the model thinks that this budget is 012345. So the model think it's five, but it's actually zero. So you see that, uh, only with a slide shift of the image, the model's performance has reduced drastically. Similarly, for six, the model thinks it is 0123456.uh sure. Uh Yeah. So the model thinks 87. Okay, but, uh, So the key idea here is that the predictions got messed up similarly with one hair. So we would expect this to be the outfit of your model, but model was predicting this. So there is some error. So we need to make which is robust to these, uh, these kinds of variations,okay. So the key idea. So the key findings from about exercise for where that model does not generalise. Well, okay, so we need a model which have some degree of spatial invariance so we could have translation invariance.Okay, if we shift the digits slightly, the model's performance should not be, uh, affected drastically. So some amount of rotation should also be taken into account,right? And some amount of side invariants elimination invariants all these kinds of things should be taken into account. Okay, So I would just like you to just keep this in your mind. That what problem? Uh, what, uh, how would you solve this problem? What kind of architecture could you use?", 'start_time': '00:06:49', 'end_time': '00:09:52'}, {'Topic': 'Image Processing Challenges', 'transcript': "Okay. And the key idea is that by flattening the image, we lose the spatial information, which is very important. So we need to think some, uh, some other activity does not flatten the imageOkay. So again, here is an example of dog from different, uh, angles. They're different sizes, different angles of the storey.so coming to some history of CNN's. So this problem has been quite well known. And since 1950 there's a lot of research going on. So one of the study done by Hubble and Weasel was, uh, they took a catand, uh, gave the card anaesthesia, so they forcefully kept the eyes opened up the card in the separatist, as you can see here.and they flashed a stimulus in front of cat's eyes. And in turn, they measure the electrical impulse generated in the brain in the brain of the cat. So they put electrodes in the brain. And whenever they would show some stimulus, there would be some neurons that would get excited, and they recorded that electric impulse.So what they did was, uh, showed some edges, uh, to the cat, some edges of various orientation, somewhere moving so you could see this board. This man is flashing this boat in front of the cat's eyes and in turn, they are recording the impulse in the cat's brain.Okay, so this was the experiment done by them, uh, human and basil. And the key findings were that, uh, there are some cells which get activated, uh, by some small edges or moving edges.Okay. And some cells are often direction specific. They only get excited when some edges being shown to them, Huh? Which is sliding from a particular direction onlyand, uh, there are higher higher level of cells, uh, more complex cells, which are selected with the length of the moving edge. So these kinds of these features simply build up over each other. So this was the key findings from the experiment.Okay, So that, uh, without losing the spatial invariance, how could we without flattening them? And how could we use that? So they figured out that somehow you need to build some hierarchy into the model to preserve the spatial information.", 'start_time': '00:09:52', 'end_time': '00:12:27'}, {'Topic': 'Historical Context of CNNs', 'transcript': "Okay, So these experiments basically set the stage for, uh, some outstanding research for the next 20 years and building on these ideas in 1986. Uh, there was, uh, scientists called Fukushima, so he built something called neo cabinet trump.So it's basically an architecture. It was an unsurprised, uh, machine learning based architecture, which used to which was used to, uh, recognise digits.And it was the state of the art at its time. But some people said that due to, uh, computational limitations, they were not able to take it to the next close. Okay. And in the 19 nineties, building on these ideas, uh, so he was able to create first successful, uh, conclusion neural network. And it was called Lane at five. So it was the first successful demonstration for character recognition,uh, without, like, frightening damage. So we will discuss about this. Architecture it in the spotlight.", 'start_time': '00:12:29', 'end_time': '00:13:36'}, {'Topic': 'Practical Applications of CNNs', 'transcript': "Okay, So now I would like to pause for a moment. And I want you all to think that how would you use this information To modify the existing neural network, which you have trained and administrators, uh, so that it is more robust to spatial invariance. Like how we approach this problem? Just think for a moment.Okay, So the solution would be to just stand for digits. Okay, so let's say, uh, this isn't modified image image, so I have just shrink the zero and, uh, introduced some translation variance. So what I'm doing here is that I took a simple MLP.You can call it, uh, zero director for now. It only detects if, uh, zero is present in some part of image or not. Okay, so, uh, what I'm doing here is I'm taking small part of the image and then flattening it. Okay,so, uh, let's say it has, uh, 2020 some 400 pixels here. Okay, Le, let's assume that this is a small part of this entire image and then flattening it and then putting it into one MLP. Okay, then I'm scanning across all this, uh, this entire image and looking for occurrence of zero.So what is the output of this? MLP would be, uh, probability distribution between 0 to, uh 1 which says that if it has detected zero or not. So if it thinks that the image which was cast into this MLP contains a zero, it will have a very high probability, otherwise very low probability.Okay, so I'm just scanning this entire image, using my MLP who look for the zero. Okay. So once I have scanned the entire image. And if I see if at any place there was a high output from a model, then I would say, Okay, I have found a zero. So in this way. So this is the idea that by scanning, we can, uh, actually, uh, use some kind of, uh, introduce some kind of special robustness. So, uh, relevant of this, uh, space where? Irrelevant of location.", 'start_time': '00:13:37', 'end_time': '00:16:06'}, {'Topic': 'Hyperparameters in CNNs', 'transcript': "In this image where the zero occurs by scanning, we are able to identify if it's present or not. Okay, so this was a key idea that so we will just take, uh, this idea forward and modified, and, uh, let's see how growth. Soone question there, uh, you were showing this. Oh, is that a kind of an or gate or kind of order of the outputs from here? What is, uh,yes? So basically, uh, I'm saying the highest of the highest for all these. Let's say this is, uh, the probability of finding a 00.10 0.01 and sometimes they'd say, Okay, I have very high probability of occurrence of zero. So I take the maximum of all these and then say Okay,I have found So zero Harris means means that I have found that the zero. Okay, so that's confusing. That, uhthat's good. So it was probably in the mind of the students, so I just thought I'd cheque. So it's a maximum that you're taking That takes the maximum. Yes.So this is where we have? Yeah, Yeah, for me. It's like 740. It's okay, but for seven, if we scan some part of seven and we could get one, right?Yeah, that's a valid problem. Uh, for that, uh, what we can do is we could we could add additional features. So that, uh, one so we can search for specific features, often digit digit. So let's say,uh, we could Instead of searching for the entire digit, we could search for some parts of it. So let's say if I have a feature like this, then maybe it's, uh indicates the presence of zero. Okay. And if I say that, Okay, there are four features which looks like this. They are coming in an image, so I can say, Okay, these are very close to zero, so you can just break that down into small features instead of taking into account the entire dignity.So what we're doing is we're hierarchically building this storey. So even another question that you should be asking at this point is that, uh, has chosen a box size that stores all of zero in it. Right? So also, he's shifting the scan that's taking place. He's shifting that, uh, square box in this exampleby a certain amount. Right. So if you are shifting by a certain amount, you might get part of the digit. Uh, and in fact, the square maybe too small to include the full digits. Right. So these are all questions that should be in your mind right now. Uh, now, the whole idea here is that we don't have to have one layer of, uh", 'start_time': '00:16:06', 'end_time': '00:18:57'}, {'Topic': 'Feature Extraction and Hierarchical Learning', 'transcript': "uh, somebody who needs to mute here. Uh, okay, So the idea here is that what has shown as a set of multi layer perceptron that are working on a small set of pixels in the neighbourhood,those are then being built upon by a second layer right, which is incorporating what are the features that have been seen in the previous player? So you're stacking up these features one on top of the other that are all essentially learning partial features to start with, and then more complete features, which then finally can lead to your classification. Does that make sense? The person who asked the questionwho asked the question. Yes. Okay, so this is just building on on what you know right now, which is a multi level perception, right?Yeah, go on. Sorry. Thank you. So, uh, mhm. So the idea here is that while scanning this entire image, the MLP is saying we are using the same MLB. We're not changing its weight, so this is very important. So this is called wait sharing him here. So we are sharing the weights. We're not introducing new weights at every, uh, box here,so which helps in reducing the A total number of parameters. We will study this, uh, detailing for the slides.So the key idea is that any any layer in MLP there's only one thing which is taking the weighted sum of inputs and applying a non linearity. So you must have you must be very familiar with this, uh, expression that output off any layer is basically a weighted sum of, uhuh, inputs to the input stood from previous layer and the weight. Right. So you're just basically Sundays and put some activation function. Might be sick model any any kind of non linearity. So in this scanning approach, we are also doing the same thing. We're just taking a small part of the bigger image using, uh, those inputs, flattening them out, multiplying them with some weights and just putting some activation over it.Okay, so So this is an example where I am building the hierarchy. So as Selves are just explained that we are building hierarchy. So here you can see that output of this, uh, from this box. So the first box in this cream colour. So this output would go here in the next,uh, and output from this second box, which is shifted slightly. It would be just a decent road here. So by doing this, you're just building a compact representation of this image here.Okay, So this is one level of hierarchy. You could add another level. So you're just building over these hierarchies. So you're just learning some small features. And then, uh, on those small features, you're learning some more complex features using their combination.", 'start_time': '00:18:58', 'end_time': '00:22:18'}, {'Topic': 'Weight Sharing and Parameter Reduction', 'transcript': "Okay, so you just, uh, scan. So these are the hair are different. New MLPs here. So this this MLP has, uh, one set of age. This is a new MLP. Here we are, scanning through it, okay. And then we have the final classification will happen. And so now we have sequentially added layers in one direction. We could also add, uh, complexity in the depth of it.So let's say you could have, uh, multiple different MLPs to scan on the first image itself. Earlier, I took an example of where MLP was detecting the zero.zero so you could have another MLP detects budget one another MLP for 32 for that kind of thing. And then you just basically build upon their features as well. So there is one head on. So you think. Think of this as a cube.right. And so, finally, you just can't get it. All of the features and you have a final classification.So this is how the idea of hair are key is taken into account from that horrible and visual experiment that we just build upon small features of the offer input and use those to classify, uh, actual image.Okay, so that's that's great. Let's just make sure that everybody is following this. Right. So, uh, guys, what? What do you think? Here are some of the hyper parameters.in what has been discussed up until now. What do you think are the hyper parameters? Remember, the hyper parametersare defined when we, uh, you know, kind of, uh, they're not the model parameters. The weights that are connecting one layer input layer into the next hidden layer we're talking about hyper parameters is the definition ofthe architecture and other parameters that define that architecture. Right? So, for example, in linear regression", 'start_time': '00:22:19', 'end_time': '00:24:35'}, {'Topic': 'Advanced Concepts in CNNs', 'transcript': "where we are using, uh, you know, say some regularisation. The regularisation constant is a hyper parameter, and the step size is a hyper parameter, right? We're still going to use gradient descent to learn the weights,but we, uh are defining. Uh, you know, uh, some other aspects of the network, right? So clearly step sizes. One hyper parameter here in a multilayered perceptron. What are the hyper parameters? It's the number of hidden nodes.and the number of hidden layers, right? Those are important hyper parameters. So what do you think are the hyper parameters here?maybe the ship. The shift. Science. Okay, so one of them is the shift size. That's good. what else? sorry.Philtre sides. So by philtre you're referring to the size of the square that we are shifting. Right, So good. Okay.What else? Number of philtres. Number of Philtres, Okay. a number of hidden layers. So what are we showing here? What is this,uh, diagram showing you each of these layers that you're seeing here? Uh, you know, so that we've got this image, the input image,right? And from each of the input images where we are creating one of these blue, uh, kind of compact representations, each of those blue compact representations aredifferent Philtres, right? So, as as government said in in one set of Philtres, you may be looking for horizontal lines in others, you may be looking at vertical lines, others you might be looking at, you know, uh,lines that are, in some way curved. Right? So you're looking for all of these different types of features. So when we talk about philtres, another way of thinking of these philtres these philtres comes from image processing,right where humans used to handcraft these philtres to extract features like edges and so on. Think of them as features that are being extracted, right? And so what you're now saying is you're getting this smaller sized image, which is the compaction. And then, as government has drawn these lines across these, uh, compact representations you're saying There are different features that are extracted from the same set of small number of.all located pixels, right? So philtre is nothing other than an M by N box right that defines which philtres are which pixels are connected to each other.in that MLP. So earlier, the multi layer Perceptron be flattened out the whole image. Now we only flattening out a small piece, which is this m by N box, which we're calling peopleright? And that's getting flattened and it can have a multilayered perceptron that finally gives an output. Now we're actually using a very simple multi layer perceptron here.which is essentially just got an input and an output layer. The output layers out, putting, like you said,a non linear transformation of the weighted sum of the parts. But remember that we are looking for the same feature with this, uh, N box, right? And so as we scan across, we are not needing to change the way. It's because the weights define which feature we're extracting, whether it's a vertical line or a horizontal line at the simplest right, so we don't need to change the weights, and that's why we're doing we're sharing.", 'start_time': '00:24:36', 'end_time': '00:29:00'}, {'Topic': 'Convolution vs Cross-Correlation', 'transcript': "okay. And then, similarly from the same set of pixels, we may want to have another feature extracted. So we are now got a new set of features and we're extracting that. The other thing to remember is right now is only talking about black and white image grayscale image.If we had a colour image, then we would actually the spirit er would not be an M by N. box. It would actually be a three dimensional box right where the third dimensionis three. So it's a M by n by three or the image that is a colour image which has got the red, green and blue.channels. right. So one way of visualising this you've got an image of some size. You are reducing the size of the image by doing the scanningright. And with every feature that you're creating is like another channel. Right? So we went from RGB Channel to another description of the same data which has a smaller X and Y axis as such of the image. But it has a depth to it, which is the number of features that have been extracted. Right. And this is a very common feature that you will see when you book shows you the more complicated structures of a CNN.You'll find that you start off with a large image with three channels and you end up with very small images, but with lots of features, lots of channels with it.Right. So this is a very, very important thing to remember when you're doing CNN's, because later on, you will see some very interesting uses of the same philtre to reduce dimensionality.", 'start_time': '00:29:01', 'end_time': '00:31:01'}, {'Topic': 'Pooling Techniques', 'transcript': "Okay, so do you understand all of these concepts? the shift size. you can see that the boxes are overlapping over each other, right? And so you can have a shiftof one pixel or two pixels or whatever. So that becomes a hyper parameter. Like you said, the philtre size definitely the size of the box, the number of philtres at each layer that you're definingright, and the number of such hidden layers that are transforming the input into a smaller, more compact representation.Right is another type of parameters. So very good. And what is the shift called? What is the technical term for shift?stride. Okay, great. Excellent. Okay. Good luck. Any questions on this before it goes on? Because things will only get more complex as we go on.Okay, Wonderful. Okay, So this is the example of, uh, typical Syrian architecture. This is called the Leonard five, which was developed by young liquid.Okay, so here we can see that, uh, this is, uh, example of the box. We were talking earlier. And by scanning this, uh, moving this box across this image. So we end up with several feature maps, you can see.So let's, uh let's start moving towards, uh, terminology. So these are called the future maps here. Okay. And so let's say we have six philtres of such types. This is one philtre, so if you have six philtresThen you will have six feature maps for each philtre because one feature because one philtre will scan the entire image.So we'll have one future map similarly for six philtre six philtres. You have six feature maps. Okay. And then there is a layer called sub sampling. So where you just, uh, take the max? Uh, just sample down. So, uh, one of the most common, uh, sub sampling technique is called Max pooling. So what they do here is they take two by two, sample out of this feature map and say this has value one. This is 263, and this is forso they take the maximum out of it and say so. This, uh, two by two matrix has four as the maximum value. So for the next, uh, through the next feature map, the four will be representing one pixel here instead of four pixels.Okay, So this is basically how we sub samples. So we are just if it has 2828 dimensions, then the output will have 14 by 14 dimensions by using this, uh, two by two Max schooling.Okay, so this is called sub sampling, and then we have another conclusion. Blog, another sub sampling layer, and then we have a fully connected layer. So this is the layer which actually does the classification into 10 outputs for administrator. They will pretend for any other data. There would be different number of classes Where, uh, where we want to classify our input image to be.uh, is this clear? So we will understand all these terms, uh, in the next slaves. So this is the typical architecture. So every architecture of the CNN has some, uh, modification of it,", 'start_time': '00:31:02', 'end_time': '00:34:46'}, {'Topic': 'Output Classification and Architecture', 'transcript': "okay. When you are saying that there are six feature maps, you're basically talking about the third dimension, which is the under six channelsthat are being created. Yes. So here. You could say this is a volume which have six dimensions. Six depth. 28 is the time. 20 at theheight. And are you going to walk through how they get from 32 by 32 28 20 years? Yes. Okay. Thank you.okay? Okay, So there was one thing I want to visualise here. Yeah, so? So this is a typical grayscale image. So this is the original image you can see here. And this is just a zoom in version, so you can see that every pixel has a value from 0 to 2. 56 to 55. Sorry.So you can see, uh, the white pixel here it has value of 2. 55. Is the number eligible on the left hand side?okay. And for a black pixel, let's say, down here, the value is, uh, close to zero. Okay, so, uh, this is the representation of grayscale image, soSo now I just wanted to visualise that how this future would work. So here we have. uh, let's on the left hand side. You have this, uh, three by three matrix. Right? So what we're doing here is just, uh here in the centre, you have a philtre by three by three philtre So the it's called sharpen philtre. And it has, uh, these values. So what we are doing here is that just taking the value for each box in this red metricsand just doing an element wise multiplication with this, uh, sharp and philtre. And the output is represented here in the right hand side. So, for example,uh, let's take something near the so you can see here. Uh, the left, the left, and the first element in this, uh,read matrix is 103. You can see it here. right. So you're multiplying it with zero and then 128 with minus one and so on and so forth. And the output of this entire operation is just a single value, which is minus 157. You can see it in the middle, and this is represented here.", 'start_time': '00:34:47', 'end_time': '00:37:43'}, {'Topic': 'Normalization and Its Importance', 'transcript': "uh, one pixel value in the right image. Okay, so this is basically the process of applying any philtre here.So, uh, we've got an answer. Which is minus 157. Yes. Uh, be clipped to zero. It will be close to zero.okay. And so you can see here that while working with the edges here so there won't be three values available.Right? So that's why the right image is padded with black border. That's all zeros it contains okay? So, uh, the key idea here is that these features these these philtres basically give rise to different feature maps. So this, this is called sharp and philtre.There is another thing called blur Philtre. So what does this basically takes the, uh, centre value of, uh, this red metricsand just adds, uh, surrounding pixel values basically smooth out the entire image so you can see that, uh, the multiplication happening and the images looks a bit blurry or, you could say, smoothed out image.Okay. So the idea to understand here is that we can have different types of these features. Sorry. Philtres there is called right, Sobel.So you can say it's kind. It's, uh, edges. It will. This is the right Sobel philtre. You can see the values are changing. So there is a left Sobel which detects different orientation of hedges. There is, uh,top Sobel, which identifies different orientations of the edges. So basically, everything is dependent on this philtre. So these are basically featured maps.", 'start_time': '00:37:45', 'end_time': '00:39:45'}, {'Topic': 'Learning Filters in CNNs', 'transcript': "Okay, so now that we have some visual understanding of how philtre looks and what and this is this is how the future maps would look.Okay, so there is another example of this image. So this is the original image. Okay, Now, if I apply, sharpen, uh around it, you can see it's got a bit sharp.And if you you stop symbol on it, it detects, uh, like horizontal edges. If I apply right Sobel, it detects vertical edges so on and so forth.is this clear? Yes, sir. Okay. so these weights are okay, So, uh, which no one is asking a question here. Uh, how? Well, normalising the pixel values affect the neural network.Um, so we should make sure you don't send it privately because those questions come to me, Uh, is not able to see it, but I've explained this, right? So when you talk about normalising the pixel values, what are you referring to? What you're talking about theapplication of these philtres. a new a new mutants piece. so, like dividing each pixel value by 2. 55.Okay, so that is really bringing the scale down to become from 0 to 1, right? Is that what you're? Okay, So what you're saying is, how does the normalisation of pixel values affect the neural network?a good book. Do you want to take this socialite? Uh, so please go ahead. Okay. So essentially, visual, what happens with the neural network when your input layer, uh, is essentially got very differing skills, right for each of the teachers. Then what is happening to the cost function that you're trying to minimise this that is stretched in certain directions and squeezed in other directions.Right. So whenever you actually calculate the gradient, you start kind of bouncing between points and don't move necessarily in the direction that gives you the, uh, which leads you directly to the ideal, uh, solution. Right? So what happens when you scale or normalise the numbers, All of the skills of all of the inputs? What ends up happening is that you get a much more rounder shift,uh, cost function, and so you will actually start to now the first known more directly towards the minimum,so it speeds up the minimisation of the past. That's the advantage of doing this normalisation okay? right. Anybody else have any questions around the application of the philtres themselves?are you making the Connexion between the fact that these philtres that are being played with up here, the colonel's as they're being referred to here, are essentially handcrafted Wales. Right? So you only have seven or eight philtres here.that are shown where the minus 101 minus 20 to minus 101 is one set of weights that have been handcrafted.Now, if you think about what a multilayered Perceptron is doing, it's actually learning these. It's learning these weights,right? So rather than us having to humanly created this, um, these philtres that we then know what kind of feature is going to be extracted by them by each application of the philtre throughout the image. What we are saying is we can actually now with neural networks, learn the weights, which will extract features that humans may not be able to interpret.but the neural network finds them useful. because they have been able to minimise the cost function as it is.does that make sense? so we are automatically extracting features that humans may not understand. right through each of these applications. Where the waves that you're seeing here, the minus 101 minus zero minus 101 are waves that are being set by the neural network automatically.right. And so we are learning these philtres. We have an infinite number of philtres we can learn here.", 'start_time': '00:39:45', 'end_time': '00:44:43'}, {'Topic': 'Backpropagation in CNNs', 'transcript': "that are each tuned to the final result of what we are trying to achieve. In this case, the example that government was talking about it was to identify whether the image contains a zero or a one or two and each of the digitalright, So we don't know what those features are out here is showing you examples of well understood teachers that have been drafted by image processing research.any questions on this comment of mine. No. Okay, carry on. listen. So, uh, this thing which we just discussed is called coalition or a sliding dot org in mathematical terms, uh, to represent it. Uh, we can,uh okay. So this is your H metrics. You can call it the photo. and this capital F is your image. Okay.Uh, so let's say for, uh, I'll take an example of this portion of this image. I'm just, uh, mathematically describing what we have just discussed. Okay,so here we are going from minus Kate. Okay, for let's say, let's say this philtre will have zero in the centre zeroth index.instead of beginning from any side, we begin from the centre. So this has, uh, zero comma zero. Uh, Index, this has, uh,minus one comma one. I could have minus one for my one. This is my new school, Uh this is minus one common minus one just to be clear.And this is, uh, one comma one. And this is one common minus one. So basically, we are saying that the loop power fromminus 1 to 1 in case of a three dimensional feature or philtre so for, Let's say. four g three or three. So Okay,the left corner will be minus 11. the corner with bottom, Yeah. mhm. uh, one here because we are going from, uh, which is, uh,so So, uh, this is the X one. And this is why? right. So, uh, but the other way around. Right. So why is pointing downwards?", 'start_time': '00:44:44', 'end_time': '00:47:57'}, {'Topic': 'CNN Architecture Details', 'transcript': "Yeah. So the coordinator, there will be a minus 11, left bottom. X is minus right the X coordinate ofminus one. uh this should be minus 11. okay, so Okay, So, uh, idea here is So let's say we have this original image, and we want to, uh, slide this fritter across this entire image. And I want to have an output G, which is my feature map. You could sayokay. So what I'm gonna do here is, um So starting with U N. Vehicle to minus one here in this submission,you equal to minus one and equal to minus one. So I will take the minus one minus 11 element of this, uh, this edge metrics, which is the A.Okay. And, uh, I plus Youth Index. So I am calculating for G three of three. So this is +0123 and again. 0123. So this is my G three comma three.Okay. So if I take, uh, take this philtre and, uh, make the cost cross correlation, I will have a single value, which will be substituted in the place of E here.Right. So what I'm looking here is that, uh, eyes here three and us minus one. And Jay is also three.This is the icon DJ and J minus one. So I'm looking at second element here. So for her 01 to zero. we want. So to buy second by second element is this so I'm multiplying, uh, small a from the philtre with this matrix A herewith a element of these, uh, metrics. and similarly, I'm just looping over. So being small capital B plus small capital C includes. So this way, this time calculating the, uh, waited waited some hereand this will be a single output, which will be replaced here in my future map. Uh, so let's see if I have this. This is my G output. So in place of E here, I will have one single value, which will be the output of this entire operation.", 'start_time': '00:47:57', 'end_time': '00:50:48'}, {'Topic': 'Feature Maps and Their Interpretations', 'transcript': "Uh, okay. So basically, uh, we are just representing what we have done till now in mathematical terms, because we are going to use this cross correlation and the idea behind it, Uh, mathematicallyfind expression for back propagation. Uh, is this clear? Yes, sir. okay? uh, So there are a few examples. Uh, this is the original image, and this is the philtre. So after, uh, sliding this philtre on the original image we get this is everything in This is the output of the free to map. This is the sharpen philtre. This is the blur philtre. And this is an edge detector.Okay, so now, uh, there's another term which is called convolution, so it is very similar to, uh cross cross correlation. But the key idea here is that while doing these calculations, your future map will be rotated by one or two degrees.Okay. Uh, so there is a visual example here, so So let's say this is your fault. The A B C D e f g h i and this is your input image.and you want to calculate, uh, the feature at some representation for on the output. So let's say you take, uh, this portion of your input image.three by three matrix. And you, uh, take the dot product with the element byproduct with these metrics. So you see here they will be, uh, multiplied with zero B also with zero except the ICT. Uh, I will get multiplied with one, so the output would be, uh and it will go in this place in the place of centre of these metrics, so in here.so in here, the central element will be I right. So if you do this for this entire image, you will see that your failure just got flipped by 180 degrees.okay. And to see a visual representation. So consider this. This has an image where all are all elements are zero. Only one has very one. And this is how your philtre looks like. So there is the black edge black pixel on this, uh, left top and white on this bottom. Right. And after performing this cross correlation, your philtre just got flipped. The white is now here on the above.", 'start_time': '00:50:50', 'end_time': '00:53:53'}, {'Topic': 'Convolutional Operation Explained', 'transcript': "Okay, so the idea behind conclusion is that if you just, uh, flip your philtre by 12 degrees and then blue cross correlation. Uh, then this term is called Coalition. So the basic idea is that we are going to use this cross correlation and conclusion to find the mathematical expressions for back propagation, so it will come hand in later.okay. It's important to recognise that what is actually happening in the forward fast is actually cross correlation. It's not convolution. Most people cannot get confused and think that that's the convolution operation. Mathematically, you're actually doing a cross correlation.Yes. Okay. Okay. Yeah. So, uh, mathematically. So we saw that in cross correlation. We are going to, uh, multiply in this direction. So if we have a free to called a B c e f g h i j So we will multiply it with There is no image in this direction.Okay, we'll begin from the top left and move towards the bottom. Right. But in the case of convolution, uh, we move from bottomto the top. Okay. So because the future has rotated and just changing the sign here, uh, will assist in that happening, so", 'start_time': '00:53:54', 'end_time': '00:55:17'}, {'Topic': 'Implementation Insights for CNNs', 'transcript': "Okay, Uh, you can just explore this on your own later on. If you just try to write these expressions down and you will be able to figure out that we're just recreating the philtreand doing the cross correlation, okay? Okay, so So till now we discuss these handcrafted philtres like the blur sharpen, agitation, etcetera. But these are the things which the model learns as just described. So what we're gonna do is we're gonna visualise these features for the religion. It Okay, Uh, so let me first explain that how these, uhhow these architectures look like. Okay, so, uh, the input here is, uh, before we go into the architecture, can we just, uh, do a little bit of discussion around how the philtre size impact, the output image size, But is that coming after this?Yes. I was just trying to bring Troy. I don't have, uh Okay. Okay. So let's say religion yet We use colour images, so let's say it will be a three dimensional image.And let's say it is 2. 56 by 2. 56 with three channels of input. Okay, so now we want to, uh, involved used 32 philtres here.Okay of dimensions, Uh, three by three. Okay, So this is how you generally defining your chaos or you're open source, uh, libraries, but under the hood. Uh, what is happening is that each philtre will have dimensionsthree by three. And this three, the depth is coming from the input. because the input image has three channels as death. So you're each philtre will also have a depth of three. Okay, so what we do here is that we take small, uh,crop of size three by three hair from this bigger image. three by three by three And we just, uh, do an element wise multiplication of all these elements in this cubewith this philtre. Okay, So if there are, let's say, uh, three numbers here and three numbers in the first, uh, slice. Then you just, uh, do the cross correlation, and there would be one output.Okay. And you do same for all the layers. So for second slice here also, okay, and output of this result would be single number.", 'start_time': '00:55:18', 'end_time': '00:58:20'}, {'Topic': 'Stride and Padding in CNNs', 'transcript': "this is very important to note. Okay, so after conclusion where there will be one value here. So you do this for across entire this image. So you have access right of one.so let's let's leave it to them to come up with the answer. Okay, So with the stride of one pixel means that you're shifting by one pixel to the right all the way till you get to the end of the image, right? So recognise that you get to the end of the image when the right side of your philtre reaches the edge. Okay, so there's no paddingfor those of you know what padding is. There's no padding. For those of you who don't know about padding, just don't worry about it. Just tell us what is going to be the size of the image that comes out on the other side when we do the scanning. Now the stride works left to rightand talk to bottom. right. So as you scan across, you're going one pixel at a time and going to the next position where the philtre is applied. And then when you get to the end, you shift the philtre down by one,uh, pixel and apply it again. Correct? Yes, sir. Okay. So what is going to be the size of the image that is coming out on the other end? Or the the two dimensional array that's coming out at the end? Because remember what is sayingthat the three by three by three is producing only one number, so the multilayered Perceptron is taking27 inputs and is out putting one value. Okay, So what you're getting as a result of applying this philtre is a two dimensionalmatrix of numbers, and I want to know the dimensionality of that. 54. other ways, okay? there were two people speaking. So one person said to 54.And what was the other person saying? I think, uh, zero comma zero is concerned at the centre, and, uh, the other things are taken at that size in the same way you look at work,right? So, like I said, the we are resuming zero padding go padding right now. Right? So your philtre starts from the edge and takes the first three into account.right, and then it moves by one and moves by one. Right? So the size is going to be there. One answer that's been given us 254.Is that the number of rows or the number of columns, or what is to 54? I think both. Okay, Anybody else have a different answer?", 'start_time': '00:58:21', 'end_time': '01:01:30'}, {'Topic': 'Parameter Counts in CNNs', 'transcript': "no sort of 54 and 54 in total Tito. in 2. 32. Okay, 32 because we've got 32 philtres. Good. Okay. I have been looking for one philtre with Excellent. Okay, so 254 by 2. 50 for 5. 32 will be the third dimension.Uh, just for this philtre Yes, output will be just a matrix. Uh, considering for just one philtre, this is just one,Uh, that's correct that we will have 32 such philtres. So for each of that philtre, we will have one,to the output. Yes. Yes. And then that will build up to 30 to do that. Yeah. Perfect. Perfect. Okay, So what happens now if we make the stride?Ooh! Okay, so now let's make the strive to what becomes the output size now? Does the output size change?instead. How much does it change? Uh, third dimension in the same 1. 27 1 27 127. So how did you come up with 1. 27?sir. And if you take in putting measures in and the philtres. I just Yes. And we We are taking a straight to that isminus Yes. And we are adding one to the and mine the eff s blossom. Okay. Do you want to write the formula they're given? You've got access toYes, Uh, like the formula, which, uh Okay, can you please repeat and I say important measure that is 256 in 2016 and a filtered site.and at that stage. the farm law of the output. The message will be and minus f s plus one. listen. so that would be a 56 minus.", 'start_time': '01:01:31', 'end_time': '01:03:57'}, {'Topic': 'Advantages of CNNs', 'transcript': "three dots. Bye. HM. That doesn't seems correct. It's two less 127. So now you've got 253 divided by two, right?So what happens? We've got a decimal number there. So I have that too. From the looks. you will take in digital partnership.If we have fraction, then we protect right? so Yeah. So that is the same formula. Uh, only were riding fighting out here. Right? Fighting is zero w minus scale over this. That's whywhich is fine. And then what you're saying is we are taking the interior part. So are we rounding up or are we rounding down?so if there is greater than five, then we are all being up. but now it's point. What do we do? I think running, don't you?", 'start_time': '01:03:59', 'end_time': '01:05:22'}, {'Topic': 'Multi-layered Perceptron vs CNN', 'transcript': "Okay, so let's just take a small example of, uh, seven by seven image, right? and what is happening here when we are not doing a padding, So the first one is three by three.the philtre application. And then we're taking a stride of two, which means now we're starting from pixel, too.23. And, uh, so we're starting the numbering from zero. Right, So 0 to 6 is the pixel numbering. Okay,Right. And now we're doing a three by three. right. So the three by three the first philtre, then we're taking a stride of two.so we start from now 23 and four. And now we take another stride of two, which gives us now. four, five and six.right. So in this case, if we look at the formula, what's happening is N is seven minus three. great.stride is too so seven minus 3/2. which is three, right? So that's 4/2. That's 13, so we can see we have created three. Now the problem comes when we have an eight by eight image, right? And now we have an issue in that if we had another pixels in rows and columns.we basically not be able to do any further, right? So if we had an eight by eight image, if you can just draw that additional problem and go.Now, when we go for the stride of two, we are going over the edge, so we can't do anymore, right? So we are always looking at the number below, as the output were basically ignoring the that last follow. And that last room. Right? So we will always take the lower number out here.", 'start_time': '01:05:23', 'end_time': '01:08:15'}, {'Topic': 'Computational Complexity in CNNs', 'transcript': "right. okay? So now my question is, how many parameters does the neural network have just in this layer?So who's gonna tell me that now? How many parameters? Now we've got 32 philtres. We've got a three by three philtres,right? And an RGB image. How many parameters do we need to learn in this? one pair of lives. who's gonna tell us?930 two. Sorry. nine by 30 to 1930 to 19 to 19 to 32. Okay. Any other answers? 20 7 to 32. Okay. Any other answers?thanks. Nobody else wants to suggest the answer. 20 730 to 30 two. Correct. So the reason why it's 27 by 32 and not nine by 32 it would be nine by 32 if we had a.grayscale image, right? We didn't have the channel. So you must always remember that we have got a three dimensional Fridawhere the third dimensions depth is defined by the number of input channels to that live. Okay, good. Now, what would be the number of parameters that needs to be learned? If we were not using CNN,we were actually using a multilayered percent promise. that depends on the number of notes hidden next to them. Iwant the same number of notes as I have in the hidden layer in the CNN. So how many notes do I have in the hidden layer in the CNN?trick questions. mhm. 56. Close to 56. Crusty. That is my input layer. Right? So that's 2. 56 times 2, 56 times three.", 'start_time': '01:08:17', 'end_time': '01:11:13'}, {'Topic': 'Feature Map Visualizations', 'transcript': "that's the input Lear sites. what it was before. Before 254 by 254. right. by 32 right, and how many parameters would we have to learn?uh, we have to do, like the four 130 two cross, uh, test is too extreme. right. So we're basically multiplying all of these, right? Because every note in the input layer must be connected to every note and the output.right, So it's 256 squared, multiplied by three. multiplied by 254 squared, multiplied by 32. right. which one is big?There's no argument, right? I mean, we are comparing a very large number of parameters here with just 27 multiplied by 32.right, and this is a huge advantage of CNN. It's the weird. sharing with sharing. That's happening. That is a hugely important aspect.Oh, CNN. Okay, so you appreciate that. And what have we talked about that as the number of parameters increases, what do we need to do? We need a lot more data to learn them.right. And so we are actually talking about unnecessarily learning a lot of weights. Whereas we know that really what we're looking for is a scan through theright. So hopefully this is clear to you that actually the CNN can be represented as a multi layer perceptron also. So the multi layer Perceptron can do the work of the CNN as we see it right now, but the number of parameters is going to be much larger.okay, and so it's much more difficult to learn the same representation comparative. Okay, so here's another question.Now we have a 54 by 2. 54 by 32. right, and we are again using. Now we are using a five by five philtres.", 'start_time': '01:11:15', 'end_time': '01:13:50'}, {'Topic': 'Feature Activation and Classification Outputs', 'transcript': "So what is going to be the dimensions of the next left? 54 by 254. by 32. right. So now we're using a five by five philtre.how many such features, let's say 64. such tried stride of, mm. 124 into 1, 24 and 60 for the lesson.Mm. for 254. find us. five, divided by two plus one. so that's 249 divided by two. 1 24 +11 25 1 25 by 125 by 64.how many parameters. and what will be the shape of the philtre? you tell me. Uh, sorry. Was that good book?Uh, that's part of the number 64. 55 or 60. Uh, And so we got an answer here for the number of parameters, I think.Okay, 25 by 64. So he said it could be what we do here. pretty good. so one person's answer is 25 by 64.Don't you find it that you don't look beautiful? 25 and 32. That's right. Okay. And so they will be. Bias is also right. Yes.good point. Thank you for keeping us right there. So in the last one, also, we forgot about the biases thatso remember the bias stone is important, right? What does the bias give us gives us? It gives us a fine transformation.Right? So we must have that constant added and also so, plus 64 there and we've got the total number of parameters yet.", 'start_time': '01:13:52', 'end_time': '01:16:54'}, {'Topic': 'Classifying Images and Final Thoughts', 'transcript': "Okay, Good. Excellent. Okay. Uh, let's, uh, move on. I think hopefully everybody's got anybody. Got a question here? I know there are a few of you who have dealt with CNN's and done some deep learning. That does not mean that people who are not understanding this can't ask questions.Okay, So for those of you who are new to this, this is very, very important that you understand this. Okay, here's another. Okay, Let's go. There is another question I want to ask you, okay?which is the number of computations you're doing. so floating point operations, floating point operations do you need to do here? But I believe that as an exercise for you, let's carry on.okay? Okay, So next, uh, was trying to visualise these features. So? So what we have here is so he worked with it was that we took an RGB image.and used 32 philtres to create 32 future maps. Okay, so what we're basically doing is we are just, uh, cross finding the cross correlation of each of this philtre with entire image. So as we, uh, looked earlier, uh, visual representation of cross correlation. So I just wanted to visualise that what these 32 philtres look like. Okay, SoI'm going to show you that how they look like, So I'm using really 16 for that. That's an architecture. It's a CNN architecture, very common.So it has taken, uh, RGB images of size 24 by 24. And so these are, uh this is the basic basic architecture. So it has to conclusion blockseach using 64 philtres. It then has a max full, then to conclusion blocks of 128. uh, philtres each again for school and then three conclusions by, uh, containing 2. 56 philtres and so on. You can see here and then we have a fully connected layer. Uh, the final layer, which classifies each imagine 2000 categories.This is the basic architecture of this video. 16. So, what we're trying to do here that in each conclusion lock so you can see there are 60 for future maps. We will just see how the 16th of future maps look like.So there are 1 28 ft high maps. We will look at each of them. Okay. So for the sake of convenience, I am only displaying features for these four or five players. The first, the very first conclusion there. The fourth player. 7, 1114. Okay, so let's just have a look at them.So this is, uh, first, uh, output of the conclusion block. Okay, so in what is this image of a house? Okay. And, uh, there are three, philtres of this dimension three by three by three.right. So after, uh, cross correlation of one philtre with the entire image, we get one feature map like this.Okay. For 60 for Philtres, 50 for such 60. For such philtres, we have 64 future maps, so you can see that each of the philtre is, uh,trying to highlight some specific features. So if you see here, this philtre is highlighting grass here.uh, this philtre here is highlighting the pillars. Or you could say the vertical edges. Okay. And, uhthis philtre here is highlighting the door so you can see each philtre is, uh, targeting some features.All right, so next I'm moving on to the fourth layer. So this was the layer of confusion blocks having 128 philtres.Okay, so I'm not showing all of the 128 philtres just because it gets very messy. So these are just 60 for philtres out of this 1. 28 here. So you can see, uh, compared from this is compared from the first congressional put, this one has become a little bit more detailed or abstract. You could say there is a lot more detail. There is a lot more textual information here.Some, uh, very dark. Some are highlighting several features. Okay, this is the fourth layer next, moving on to the seventh layer so you can see, uh, things are getting more abstract here. It's difficult to describe what features. Uh, CNN is learning,but we can see that something different is happening with each feature map. So there is a definition of house here, but in here, we have totally lost it. Maybe this this philtre would was looking for something else. which is not present in this feature in this image,maybe something like that. Okay, so now we have reached 11th layer. It has, I think, 2. 56 philtres and I'm displaying only 64 corresponding feature maps out of these two physics. Okay, No, things have become more abstract. And then, you know, 15th layer,uh, things become even more abstract. You could see that that some freedom maps are, uh, not saying anything at all. For example, there's there's only slight activation here, but for some philtres, there are a lot of evacuations happening.and in 17 player. So this has, uh, 512 feature maps and displaying only 64. You could see that only some some part of theafter the conclusion. Output has some information in it. Rest everything is just shut down. Okay, so let me just go through that again. So this is the first congressional put second. So ifeverybody realising that each of these small images is one layer now in that output right in this, so I shouldn't say one layer one feature, right? So one channel within the fourth layer. So everybody using, uh, you know, onepretty good right to generate each of these small images here, Right? And we're seeing What is it that it is learning from this image? And of course, this is the house. And, like, uh, was saying the V G architecture has been developed to learn 1000 different classes, right? So for different classes of images, you'll have different features, uh, getting highlighted right. And as we go throughright now, we are identifying edges and some relationships between those edges. But we're basically as we go, deeper and deeper,it actually becomes much more abstract, but is useful finally to make a classification that this is a house as opposed to an elephantright. Okay. Carry on group. Yeah. So this was the output of first conclusion block. 2nd, 3rd, 4th, 5th, 6th. And finally, we could use this output for classification. So basically, what we have done here is that we took an image and we extracted features out of that,and to some to that extent, that we are able to build a classified over it. That when we have an image of in house, we could say some features get activated if we have, uh, image of human that several different features get activated, and then we can use these activations to basically just classify or input dimension.Right. So here have how blood cells are. Okay, So the first output you could see here is that, uh, several feature maps are looking at the skin. Some are looking at beard. Some are looking at this the turbo and some are looking at the edges. So this is this little These feature maps would work for any human rights.On the second conclusion output, you could see things become more abstract. Then in third National Boardfort, you can see that this, uh, these features around here, they somehow represent I guess that human face that eyes and mouth Maybe that's my guess. I'm not sure.And again, in the just the final conclusion block things become very extracted. Only few future master activity dressed are just shut down.So here we have, uh, to human faces in the image so you could see in the final layer. So I'm showing, uh, all the 512 accusations here in the final conclusion block. So you could see, uh, things which are highlighted here in yellow.So similar features have been activated here. If you take a look at these two, these two here, and these two here, they look pretty similar.So we expect that any human, uh, face would excite these, uh, future maps of this, uh, Jeanette. And then later we can use this information, uh, to just classify that which category an image belongs to.Remember that the objective here is not to discriminate and identify between Luke and myself. Here. This is actually just to classify it into, uh, face versus house.Yes. So here we have a face versus house, so you can see that, uh, these are the features activated and different set of features activated in the final constitution outputso you can see they are not in this In this area, these we can have some not activity. any questions on this.Okay, Uh, we are at the end of the lecture, so I think Is this a good place to stop? Yes. Great. Excellent. Okay. So thank you so much for this. I think that's been wonderful. Uh, folks, uh, carry on with CNN's in on Saturday, so if there are no questions now, we'll end this session.Okay. No questions. So I'm ending the session. Thank you. Thanks, everyone. Thank you, sir.", 'start_time': '01:16:56', 'end_time': '01:28:14'}], 'session_id': [ObjectId('648ae89ed657fdfe901c7732')], 'assessment': ObjectId('66f465b4c248cb8c52154207'), 'job_name': 'my-transcription-job792d87f3-dba6-4901-b325-877ad018f654', 'keywords': ['Computational Aspects', 'Normalization', 'Model Performance', 'Image Classification', 'Image Analysis', 'Classification Outputs', 'Sharpening Filter', 'Weight Sharing', 'Digital Processing', 'Max Pooling', 'Feature Map', 'Grayscale Image', 'Backpropagation', 'Natural Language Processing', 'Parameter Reduction', 'Digit Detection', 'Filters', 'Padding', 'Pooling Techniques', 'Cross-Correlation', 'Speech Data', 'Spatial Invariance', 'Rounding', 'Preparation', 'Convolutional Neural Networks', 'Parameters', 'Character Recognition', 'Screen Sharing', 'Spatial Information', 'Feature Maps', 'Feature Extraction', 'Convolution', 'Dimensionality Reduction', 'CNN', 'LeNet-5', 'Convolutional Filters', 'Technical Setup', 'Output Size', 'CNN Parameters', 'Hierarchical Learning', 'Feature Activation', 'Image Channels', 'Image Processing', 'Multi-Layer Perceptron', 'Generalization', 'CNN Architecture', 'Deep Learning', 'Stride', 'Hyperparameters', 'Multi-layer Perceptron'], 'topic': 'Convolutional Neural Networks', 'interaction': [{'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about what kind of architecture could be used is not addressed.', 'relevancy': '0', 'question': 'What kind of architecture could you use?', 'timestamp': '[0:16:50]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': 'Incomplete, the question about modifying the existing neural network was not addressed.', 'relevancy': '0', 'question': 'How would you use this information to modify the existing neural network?', 'timestamp': '[0:16:50]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about hyper parameters was not addressed.', 'relevancy': '0', 'question': 'What are the hyper parameters?', 'timestamp': '[0:25:25]'}, {'status': 'answered', 'answer': 'The technical term for shift is stride.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What is the technical term for shift?', 'timestamp': '[0:25:51]'}, {'status': 'answered', 'answer': 'Normalising the pixel values affects the neural network by ensuring that the input layer has similar scales for each input, which helps in minimizing the cost function more effectively. It leads to a more rounded cost function, allowing the gradient to move more directly towards the minimum, thus speeding up the minimization process.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How does the normalisation of pixel values affect the neural network?', 'timestamp': '[0:40:30]'}, {'status': 'answered', 'answer': 'The size of the image that comes out on the other side when we do the scanning is 254 by 254.', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'What is the size of the image that comes out on the other side when we do the scanning?', 'timestamp': '[0:58:38]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the question about what happens if we make the stride is not addressed.', 'relevancy': '0', 'question': 'What happens now if we make the stride?', 'timestamp': '[1:02:11]'}, {'status': 'answered', 'answer': '930', 'completeness': 'Complete answer', 'relevancy': '2', 'question': 'How many parameters does the neural network have just in this layer?', 'timestamp': '[1:09:14]'}, {'status': 'not answered', 'answer': 'No answer.', 'completeness': 'Incomplete, the dimensions of the next layer are not addressed.', 'relevancy': '0', 'question': 'What is going to be the dimensions of the next layer?', 'timestamp': '[1:14:20]'}, {'status': 'not answered', 'answer': 'not answered', 'completeness': "Incomplete, the question 'How many such features?' is not addressed.", 'relevancy': '0', 'question': 'How many such features?', 'timestamp': '[1:14:22]'}], 'summary': 'The discussion centers on convolutional neural networks (CNNs) and their technical aspects, beginning with an overview of their architecture and relevance in image analysis. CNNs utilize convolutional layers to detect features, pooling layers to reduce dimensionality, and activation functions to introduce non-linearity. The conversation highlights various applications of CNNs, including insect and disease detection, natural language processing (NLP), and their role in enhancing robustness against spatial variations in images. Historical context is provided, mentioning key developments such as the neo-cabinet architecture and LeNet-5. The importance of feature extraction, weight sharing, and the impact of hyperparameters on CNN performance is discussed. The session covers mathematical concepts related to convolution, cross-correlation, and the effects of stride and padding. The calculation of parameters in CNN layers is emphasized, illustrating how to determine the number of parameters based on filter size and input channels. The significance of biases in models and the dimensionality of feature maps is also addressed. The lecture concludes with an explanation of feature activation for classification tasks, using examples from CNN architectures like VGG, and emphasizes the progressive extraction of abstract features from images.', 'pinecone': True}
